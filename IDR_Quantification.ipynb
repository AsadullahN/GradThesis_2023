{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "163aadf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a33596a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from pandas import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure, subplots, imshow, xticks, yticks, title\n",
    "import pickle\n",
    "from scipy import stats\n",
    "import copy\n",
    "from scipy.stats import entropy\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics.cluster import mutual_info_score\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# For statistics. Requires statsmodels 5.0 or more\n",
    "#from statsmodels.formula.api import ols,gls,wls\n",
    "# Analysis of Variance (ANOVA) on linear models\n",
    "#from statsmodels.stats.anova import anova_lm\n",
    "#tutorial link: https://www.kaggle.com/kanncaa1/recurrent-neural-network-with-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2695695e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 5, 4) (8, 6) (3, 8, 2) (40, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x1000 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#make dataset\n",
    "startCondition=[\n",
    "    [ 0.0, 0.0, 0.0, 0.0,-1.0, 0.0],\n",
    "    [ 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
    "    [ 0.0, 0.0, 0.0, 0.0,-1.0,-1.0],\n",
    "    [ 0.0, 0.0, 0.0, 0.0, 1.0, 1.0],\n",
    "    [ 0.0,-1.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [ 0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [-1.0,-1.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [ 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
    "]\n",
    "X=[]\n",
    "Y=[]\n",
    "worldS=[[],[],[]]\n",
    "worldConcept=[]\n",
    "figure(figsize=[2,8])\n",
    "plt.gcf().set_size_inches(6, 10) \n",
    "for d in range(2):\n",
    "    for s in range(2):\n",
    "        for b in range(2):\n",
    "            sequence=[]\n",
    "            condInt=d*4+s*2+b\n",
    "            currentCondition=startCondition[condInt]\n",
    "            for steps in range(5):\n",
    "                row=[0.0,0.0,0.0,0.0]\n",
    "                for r in range(4):\n",
    "                    row[r]=currentCondition[r+1]\n",
    "                if d==0:\n",
    "                    currentCondition.pop(0)\n",
    "                    currentCondition.append(0.0)\n",
    "                else:\n",
    "                    currentCondition.pop()\n",
    "                    currentCondition.insert(0,0.0)\n",
    "                #print(d,s,b,steps,row)\n",
    "                sequence.append(row)\n",
    "                worldConcept.append([d,s,b])\n",
    "            subplot(4,2,condInt+1)\n",
    "            X.append(copy.deepcopy(sequence))\n",
    "            answer=[0.0,0.0,0.0,0.0,0.0,0.0]\n",
    "            answer[d]=1.0\n",
    "            answer[s+2]=1.0\n",
    "            answer[b+4]=1.0\n",
    "            Y.append(answer)\n",
    "            imshow(sequence,cmap=\"gray\",vmin=-1.0,vmax=1.0)\n",
    "            #ylim(-0.5,7.5)\n",
    "            xticks([],[])\n",
    "            yticks(range(5),[\"\"]*5)\n",
    "            subplots_adjust(top=0.8)\n",
    "            title(answer)\n",
    "            subAd=[0.0,0.0]\n",
    "            subAd[d]=1.0\n",
    "            subAs=[0.0,0.0]\n",
    "            subAs[s]=1.0\n",
    "            subAb=[0.0,0.0]\n",
    "            subAb[b]=1.0\n",
    "            worldS[0].append(subAd)\n",
    "            worldS[1].append(subAs)\n",
    "            worldS[2].append(subAb)\n",
    "    #tight_layout()\n",
    "X=numpy.array(X)\n",
    "Y=numpy.array(Y)\n",
    "worldS=numpy.array(worldS)\n",
    "worldConcept=numpy.array(worldConcept)\n",
    "print(X.shape,Y.shape,worldS.shape,worldConcept.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97099f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64,) (64, 6) (3, 64, 2) (512, 3)\n"
     ]
    }
   ],
   "source": [
    "def makeNoisyDataset(X,Y,replicatesPerItem,noise,randomize=True,delayRange=[3]):\n",
    "    nX=[]\n",
    "    nY=[]\n",
    "    nW=[]\n",
    "    wc=[[0,0,0],[0,0,1],[0,1,0],[0,1,1],[1,0,0],[1,0,1],[1,1,0],[1,1,1]]\n",
    "    for n in range(8):\n",
    "        for i in range(replicatesPerItem):\n",
    "            dr=numpy.random.choice(delayRange)\n",
    "            M=numpy.concatenate((X[n],numpy.zeros((int(dr),4))))\n",
    "            nX.append(M+numpy.random.normal(0.0,noise,(M.shape)))\n",
    "            nY.append(Y[n])\n",
    "            nW.append(wc[n])\n",
    "    #nX=numpy.array(nX)\n",
    "    nX=numpy.array(nX, dtype=object)\n",
    "    nY=numpy.array(nY)\n",
    "    nW=numpy.array(nW)\n",
    "    if randomize:\n",
    "        m=8*replicatesPerItem\n",
    "        order=numpy.random.choice(list(range(m)),(m),replace=False)\n",
    "        nX=nX[order]\n",
    "        nY=nY[order]\n",
    "        nW=nW[numpy.repeat(order,8)]\n",
    "    nS=[]\n",
    "    nS.append(nY.transpose()[0:2].transpose())\n",
    "    nS.append(nY.transpose()[2:4].transpose())\n",
    "    nS.append(nY.transpose()[4:6].transpose())\n",
    "    nS=numpy.array(nS)\n",
    "    return nX,nY,nS,nW \n",
    "nX,nY,nS,nW=makeNoisyDataset(X,Y,8,0.2,delayRange=[1,5])\n",
    "#h=hist(nX.flatten(),linspace(-1.5,1.5,101))\n",
    "print(nX.shape,nY.shape,nS.shape,nW.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bf675db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64,) (64, 6) (3, 64, 2) (512, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enajasa\\AppData\\Local\\Temp\\ipykernel_10840\\1205567648.py:13: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  nX=numpy.array(nX)\n"
     ]
    }
   ],
   "source": [
    "def makeNoisyDataset(X,Y,replicatesPerItem,noise,randomize=True,delayRange=[3]):\n",
    "    nX=[]\n",
    "    nY=[]\n",
    "    nW=[]\n",
    "    wc=[[0,0,0],[0,0,1],[0,1,0],[0,1,1],[1,0,0],[1,0,1],[1,1,0],[1,1,1]]\n",
    "    for n in range(8):\n",
    "        for i in range(replicatesPerItem):\n",
    "            dr=numpy.random.choice(delayRange)\n",
    "            M=numpy.concatenate((X[n],numpy.zeros((int(dr),4))))\n",
    "            nX.append(M+numpy.random.normal(0.0,noise,(M.shape)).astype(numpy.float32)) #explicit cast to numpy.float32\n",
    "            nY.append(Y[n].astype(numpy.float32))\n",
    "            nW.append(wc[n])\n",
    "    nX=numpy.array(nX)\n",
    "    nY=numpy.array(nY)\n",
    "    nW=numpy.array(nW)\n",
    "    if randomize:\n",
    "        m=8*replicatesPerItem\n",
    "        order=numpy.random.choice(list(range(m)),(m),replace=False)\n",
    "        nX=nX[order]\n",
    "        nY=nY[order]\n",
    "        nW=nW[numpy.repeat(order,8)]\n",
    "    nS=[]\n",
    "    nS.append(nY.transpose()[0:2].transpose())\n",
    "    nS.append(nY.transpose()[2:4].transpose())\n",
    "    nS.append(nY.transpose()[4:6].transpose())\n",
    "    nS=numpy.array(nS)\n",
    "    return nX,nY,nS,nW \n",
    "nX,nY,nS,nW=makeNoisyDataset(X,Y,8,0.2,delayRange=[1,5])\n",
    "print(nX.shape,nY.shape,nS.shape,nW.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7b107d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,hidden_dim=12,output_dim=6):\n",
    "        super(Net, self).__init__()\n",
    "        self.rnnLayer=nn.RNN(4,hidden_dim,batch_first=True)\n",
    "        self.outputLayer=nn.Linear(hidden_dim,output_dim)\n",
    "        self.hidden_dim=hidden_dim\n",
    "        self.resetHidden()\n",
    "        \n",
    "    def resetHidden(self):\n",
    "        self.hidden=list()\n",
    "        \n",
    "    def forward(self, x,return_activations=False):\n",
    "        self.h0=torch.Tensor(numpy.zeros((1,x.shape[0],self.hidden_dim)))\n",
    "        out,self.h0=self.rnnLayer(x,self.h0)\n",
    "        out=torch.tanh(out)\n",
    "        self.hidden.append(copy.deepcopy(self.h0.detach().numpy()))\n",
    "        out=torch.sigmoid(self.outputLayer(out[:, -1, :]))\n",
    "        if return_activations:\n",
    "            activations = out.detach().numpy()\n",
    "            return out, activations\n",
    "        return out\n",
    "    \n",
    "\n",
    "    \n",
    "    def step(self,x):\n",
    "        O=[]\n",
    "        H=[]\n",
    "        for l in range(x.shape[0]):\n",
    "            h0=torch.Tensor(numpy.zeros((1,1,self.hidden_dim)))\n",
    "            for i in range(x.shape[1]):\n",
    "                out,h0=self.rnnLayer(x[l][i].reshape((1,1,4)),h0)\n",
    "                H.append(out.detach().numpy().flatten())\n",
    "            out=torch.tanh(out)\n",
    "            out=torch.sigmoid(self.outputLayer(out[:, -1, :]))\n",
    "            for i in range(x.shape[1]):\n",
    "                O.append(out.detach().numpy().flatten())\n",
    "        return numpy.array(O),numpy.array(H)\n",
    "    \n",
    "model=Net()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b81dc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full model: (0.5, [0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n"
     ]
    }
   ],
   "source": [
    "def test(model,X=X,Y=Y,S=worldS):\n",
    "    model.resetHidden()\n",
    "    output=model(torch.Tensor(X))\n",
    "    O=1.0*(output.detach().numpy()>0.5)\n",
    "    subA=[]\n",
    "    antiA=[]\n",
    "    for i in range(3):\n",
    "        sY=O.transpose()[(i*2):(i*2)+2].transpose()\n",
    "        subA.append((1.0*(sY==S[i])).mean())\n",
    "        antiA.append((1.0*(sY==(1.0-S[i]))).mean())\n",
    "    totalAcc=(1.0*(O==Y)).mean()\n",
    "    return totalAcc,subA,antiA\n",
    "\n",
    "model=Net(hidden_dim=12,output_dim=6)\n",
    "#model.load_state_dict(torch.load(\"fullModel.model\"))\n",
    "print(\"full model:\",test(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5eaa2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for delay range [1]...\n",
      "Iteration: 64, Loss: 0.2329576015472412, Accuracy: 0.5000205594114959\n",
      "Iteration: 128, Loss: 0.24711187183856964, Accuracy: 0.5058715352788568\n",
      "Iteration: 192, Loss: 0.20822246372699738, Accuracy: 0.528904743026942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enajasa\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([6])) that is different to the input size (torch.Size([1, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 256, Loss: 0.16070376336574554, Accuracy: 0.5695213032886386\n",
      "Iteration: 320, Loss: 0.1605972945690155, Accuracy: 0.5986245041713119\n",
      "Iteration: 384, Loss: 0.18172180652618408, Accuracy: 0.6146705034188926\n",
      "Iteration: 448, Loss: 0.1814524531364441, Accuracy: 0.6246015280485153\n",
      "Iteration: 512, Loss: 0.16735027730464935, Accuracy: 0.6317236805334687\n",
      "Iteration: 576, Loss: 0.1740981489419937, Accuracy: 0.6358052925206721\n",
      "Iteration: 640, Loss: 0.17236952483654022, Accuracy: 0.6390325743705034\n",
      "Iteration: 704, Loss: 0.17119288444519043, Accuracy: 0.642227596603334\n",
      "Iteration: 768, Loss: 0.1696958690881729, Accuracy: 0.6442772522568703\n",
      "Iteration: 832, Loss: 0.1755843162536621, Accuracy: 0.6459627151489258\n",
      "Iteration: 896, Loss: 0.1728333979845047, Accuracy: 0.6481377412565053\n",
      "Iteration: 960, Loss: 0.17190460860729218, Accuracy: 0.6495170276612043\n",
      "Iteration: 1024, Loss: 0.17484454810619354, Accuracy: 0.6511294385418296\n",
      "Iteration: 1088, Loss: 0.17278309166431427, Accuracy: 0.6537362136878073\n",
      "Iteration: 1152, Loss: 0.16872192919254303, Accuracy: 0.6566811907105148\n",
      "Iteration: 1216, Loss: 0.1822035312652588, Accuracy: 0.6568781211972237\n",
      "Iteration: 1280, Loss: 0.16158050298690796, Accuracy: 0.6588957109488547\n",
      "Iteration: 1344, Loss: 0.1253909468650818, Accuracy: 0.6659190636128187\n",
      "Iteration: 1408, Loss: 0.14176100492477417, Accuracy: 0.6723411567509174\n",
      "Iteration: 1472, Loss: 0.17463648319244385, Accuracy: 0.6754428171552718\n",
      "Iteration: 1536, Loss: 0.12894906103610992, Accuracy: 0.6781882750801742\n",
      "Iteration: 1600, Loss: 0.1701860874891281, Accuracy: 0.6856402489356697\n",
      "Iteration: 1664, Loss: 0.11750463396310806, Accuracy: 0.6892697471193969\n",
      "Iteration: 1728, Loss: 0.12002848833799362, Accuracy: 0.6927513629198074\n",
      "Iteration: 1792, Loss: 0.15290741622447968, Accuracy: 0.6978672021068633\n",
      "Iteration: 1856, Loss: 0.11300762742757797, Accuracy: 0.7007934772409499\n",
      "Iteration: 1920, Loss: 0.1461629867553711, Accuracy: 0.7126296230126172\n",
      "Iteration: 1984, Loss: 0.14027497172355652, Accuracy: 0.7191447424702346\n",
      "Iteration: 2048, Loss: 0.10879921168088913, Accuracy: 0.7253136746585369\n",
      "Iteration: 2112, Loss: 0.10239651054143906, Accuracy: 0.7320241162087768\n",
      "Iteration: 2176, Loss: 0.12330053001642227, Accuracy: 0.7357092453166842\n",
      "Iteration: 2240, Loss: 0.09289666265249252, Accuracy: 0.7435761822853237\n",
      "Iteration: 2304, Loss: 0.08783682435750961, Accuracy: 0.7476612674072385\n",
      "Iteration: 2368, Loss: 0.10186901688575745, Accuracy: 0.754060288425535\n",
      "Iteration: 2432, Loss: 0.09707719087600708, Accuracy: 0.7499041601549834\n",
      "Iteration: 2496, Loss: 0.08920999616384506, Accuracy: 0.7619047535117716\n",
      "Iteration: 2560, Loss: 0.08715007454156876, Accuracy: 0.7658266648650169\n",
      "Iteration: 2624, Loss: 0.08138776570558548, Accuracy: 0.7671916363760829\n",
      "Iteration: 2688, Loss: 0.11637548357248306, Accuracy: 0.7724889854434878\n",
      "Iteration: 2752, Loss: 0.07793540507555008, Accuracy: 0.7734408637043089\n",
      "Iteration: 2816, Loss: 0.11509072780609131, Accuracy: 0.7757758277002722\n",
      "Iteration: 2880, Loss: 0.08031661063432693, Accuracy: 0.778513936791569\n",
      "Iteration: 2944, Loss: 0.07754364609718323, Accuracy: 0.7818065744359046\n",
      "Iteration: 3008, Loss: 0.06926070153713226, Accuracy: 0.7816664651036263\n",
      "Iteration: 3072, Loss: 0.07115097343921661, Accuracy: 0.7835876613389701\n",
      "Iteration: 3136, Loss: 0.08401474356651306, Accuracy: 0.7836588681675494\n",
      "Iteration: 3200, Loss: 0.08316978067159653, Accuracy: 0.7889434371609241\n",
      "Iteration: 3264, Loss: 0.06896474212408066, Accuracy: 0.7922852479387075\n",
      "Iteration: 3328, Loss: 0.0885109081864357, Accuracy: 0.7933108846191317\n",
      "Iteration: 3392, Loss: 0.08531825989484787, Accuracy: 0.7953635030426085\n",
      "Iteration: 3456, Loss: 0.07238294929265976, Accuracy: 0.7899587457068264\n",
      "Iteration: 3520, Loss: 0.07013087719678879, Accuracy: 0.7975848454516381\n",
      "Iteration: 3584, Loss: 0.11961785703897476, Accuracy: 0.8003662116825581\n",
      "Iteration: 3648, Loss: 0.07664529979228973, Accuracy: 0.7993210616987199\n",
      "Iteration: 3712, Loss: 0.06077789142727852, Accuracy: 0.8025151730980724\n",
      "Iteration: 3776, Loss: 0.0670059323310852, Accuracy: 0.8044198707211763\n",
      "Iteration: 3840, Loss: 0.0851101204752922, Accuracy: 0.806257666554302\n",
      "Iteration: 3904, Loss: 0.11643026024103165, Accuracy: 0.8080796068534255\n",
      "Iteration: 3968, Loss: 0.05991433188319206, Accuracy: 0.8136143351439387\n",
      "Iteration: 4032, Loss: 0.0603114552795887, Accuracy: 0.8126735775731504\n",
      "Iteration: 4096, Loss: 0.05940902605652809, Accuracy: 0.8156242971308529\n",
      "Iteration: 4160, Loss: 0.12537026405334473, Accuracy: 0.8191812040749937\n",
      "Iteration: 4224, Loss: 0.03989585116505623, Accuracy: 0.8208910736721009\n",
      "Iteration: 4288, Loss: 0.05325411632657051, Accuracy: 0.8187933990266174\n",
      "Iteration: 4352, Loss: 0.046540308743715286, Accuracy: 0.8118235977599397\n",
      "Iteration: 4416, Loss: 0.04389965161681175, Accuracy: 0.826320938533172\n",
      "Iteration: 4480, Loss: 0.0670032873749733, Accuracy: 0.8251717154635116\n",
      "Iteration: 4544, Loss: 0.05072852969169617, Accuracy: 0.8285720428684726\n",
      "Iteration: 4608, Loss: 0.051973193883895874, Accuracy: 0.8345984285697341\n",
      "Iteration: 4672, Loss: 0.033968403935432434, Accuracy: 0.8324456863338128\n",
      "Iteration: 4736, Loss: 0.052959371358156204, Accuracy: 0.8368090708972886\n",
      "Iteration: 4800, Loss: 0.021264879032969475, Accuracy: 0.835440422873944\n",
      "Iteration: 4864, Loss: 0.03265859931707382, Accuracy: 0.8337194273481146\n",
      "Iteration: 4928, Loss: 0.0502607636153698, Accuracy: 0.8387002785457298\n",
      "Iteration: 4992, Loss: 0.04001595079898834, Accuracy: 0.835115609341301\n",
      "Iteration: 5056, Loss: 0.024641335010528564, Accuracy: 0.8426562916720286\n",
      "Iteration: 5120, Loss: 0.03921182453632355, Accuracy: 0.8462881039595231\n",
      "Iteration: 5184, Loss: 0.04217281565070152, Accuracy: 0.840848291059956\n",
      "Iteration: 5248, Loss: 0.04769338294863701, Accuracy: 0.8443121180171147\n",
      "Iteration: 5312, Loss: 0.1371021419763565, Accuracy: 0.8477238833438605\n",
      "Iteration: 5376, Loss: 0.04842038080096245, Accuracy: 0.85227198258508\n",
      "Iteration: 5440, Loss: 0.047200072556734085, Accuracy: 0.851825755671598\n",
      "Iteration: 5504, Loss: 0.13570135831832886, Accuracy: 0.8495199664030224\n",
      "Iteration: 5568, Loss: 0.011556235142052174, Accuracy: 0.8479757320601493\n",
      "Iteration: 5632, Loss: 0.04201870039105415, Accuracy: 0.8532645561499521\n",
      "Iteration: 5696, Loss: 0.02858058549463749, Accuracy: 0.8490559858037159\n",
      "Iteration: 5760, Loss: 0.02574256621301174, Accuracy: 0.8542983595980331\n",
      "Iteration: 5824, Loss: 0.05347936972975731, Accuracy: 0.8544248171383515\n",
      "Iteration: 5888, Loss: 0.028168095275759697, Accuracy: 0.8618249811697751\n",
      "Iteration: 5952, Loss: 0.026182835921645164, Accuracy: 0.8615831390488893\n",
      "Iteration: 6016, Loss: 0.01971244625747204, Accuracy: 0.8669744587969035\n",
      "Iteration: 6080, Loss: 0.044819802045822144, Accuracy: 0.8631003557238728\n",
      "Iteration: 6144, Loss: 0.014620275236666203, Accuracy: 0.8707057671272196\n",
      "Iteration: 6208, Loss: 0.020149311050772667, Accuracy: 0.8643421415472403\n",
      "Iteration: 6272, Loss: 0.029323456808924675, Accuracy: 0.8679287494160235\n",
      "Iteration: 6336, Loss: 0.05767916142940521, Accuracy: 0.868201253877487\n",
      "Iteration: 6400, Loss: 0.037095580250024796, Accuracy: 0.8712730078259483\n",
      "Iteration: 6464, Loss: 0.034526996314525604, Accuracy: 0.8715354687301442\n",
      "Iteration: 6528, Loss: 0.11842381954193115, Accuracy: 0.8757774658151902\n",
      "Iteration: 6592, Loss: 0.061142634600400925, Accuracy: 0.8749401402892545\n",
      "Iteration: 6656, Loss: 0.012622345238924026, Accuracy: 0.8799455417902209\n",
      "Iteration: 6720, Loss: 0.029820458963513374, Accuracy: 0.8824462504126132\n",
      "Iteration: 6784, Loss: 0.01427098736166954, Accuracy: 0.8849936812766828\n",
      "Iteration: 6848, Loss: 0.015089464373886585, Accuracy: 0.8812853101408109\n",
      "Iteration: 6912, Loss: 0.01908900775015354, Accuracy: 0.8839958240860142\n",
      "Iteration: 6976, Loss: 0.021712325513362885, Accuracy: 0.8849662496941164\n",
      "Iteration: 7040, Loss: 0.025919219478964806, Accuracy: 0.882329024199862\n",
      "Iteration: 7104, Loss: 0.011605154722929, Accuracy: 0.8856285297661088\n",
      "Iteration: 7168, Loss: 0.012135130353271961, Accuracy: 0.8913289335323498\n",
      "Iteration: 7232, Loss: 0.007456085179001093, Accuracy: 0.887011615850497\n",
      "Iteration: 7296, Loss: 0.023219017311930656, Accuracy: 0.8927859552786686\n",
      "Iteration: 7360, Loss: 0.004655645228922367, Accuracy: 0.8939572598319501\n",
      "Iteration: 7424, Loss: 0.0027890149503946304, Accuracy: 0.8929527686559595\n",
      "Iteration: 7488, Loss: 0.03702607750892639, Accuracy: 0.8917073676129803\n",
      "Iteration: 7552, Loss: 0.02751421369612217, Accuracy: 0.8971741648274474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 7616, Loss: 0.03109603188931942, Accuracy: 0.9017489622347057\n",
      "Iteration: 7680, Loss: 0.00401992816478014, Accuracy: 0.8965119005297311\n",
      "Iteration: 7744, Loss: 0.023385822772979736, Accuracy: 0.8998621221981011\n",
      "Iteration: 7808, Loss: 0.002667047781869769, Accuracy: 0.9003471003379673\n",
      "Iteration: 7872, Loss: 0.026475833728909492, Accuracy: 0.89930704026483\n",
      "Iteration: 7936, Loss: 0.06743329763412476, Accuracy: 0.9019552386598662\n",
      "Iteration: 8000, Loss: 0.009348924271762371, Accuracy: 0.9096319723757915\n",
      "Iteration: 8064, Loss: 0.06001637503504753, Accuracy: 0.9076273019891232\n",
      "Iteration: 8128, Loss: 0.024687601253390312, Accuracy: 0.909511142061092\n",
      "Iteration: 8192, Loss: 0.004238925874233246, Accuracy: 0.9083854542113841\n",
      "Iteration: 8256, Loss: 0.011214536614716053, Accuracy: 0.9059166187071241\n",
      "Iteration: 8320, Loss: 0.011831424199044704, Accuracy: 0.9112340293941088\n",
      "Iteration: 8384, Loss: 0.034876950085163116, Accuracy: 0.9162799925543368\n",
      "Iteration: 8448, Loss: 0.005709609482437372, Accuracy: 0.9102558927261271\n",
      "Iteration: 8512, Loss: 0.006692234892398119, Accuracy: 0.916238462930778\n",
      "Iteration: 8576, Loss: 0.00509062921628356, Accuracy: 0.9159227992640808\n",
      "Iteration: 8640, Loss: 0.016751596704125404, Accuracy: 0.9194806060695555\n",
      "Iteration: 8704, Loss: 0.009347434155642986, Accuracy: 0.9201158135547303\n",
      "Iteration: 8768, Loss: 0.007261680904775858, Accuracy: 0.9179701589455362\n",
      "Iteration: 8832, Loss: 0.060951102524995804, Accuracy: 0.9184165146725718\n",
      "Iteration: 8896, Loss: 0.005442705471068621, Accuracy: 0.9176637285563629\n",
      "Iteration: 8960, Loss: 0.004618966486304998, Accuracy: 0.9240748446027283\n",
      "Iteration: 9024, Loss: 0.02433418668806553, Accuracy: 0.9189600030658767\n",
      "Iteration: 9088, Loss: 0.007585593964904547, Accuracy: 0.9222667442809325\n",
      "Iteration: 9152, Loss: 0.014541027136147022, Accuracy: 0.9274108267272823\n",
      "Iteration: 9216, Loss: 0.0162243340164423, Accuracy: 0.9222749383188784\n",
      "Iteration: 9280, Loss: 0.0038351721595972776, Accuracy: 0.9248429478611797\n",
      "Iteration: 9344, Loss: 0.002165188081562519, Accuracy: 0.918087417492643\n",
      "Iteration: 9408, Loss: 0.006059490609914064, Accuracy: 0.9229443533113226\n",
      "Iteration: 9472, Loss: 0.004031071905046701, Accuracy: 0.931308857165277\n",
      "Iteration: 9536, Loss: 0.017675966024398804, Accuracy: 0.9315644377202261\n",
      "Iteration: 9600, Loss: 0.005877485033124685, Accuracy: 0.9255782125110272\n",
      "Iteration: 9664, Loss: 0.005995518993586302, Accuracy: 0.9331590790534392\n",
      "Iteration: 9728, Loss: 0.023418555036187172, Accuracy: 0.9354680883989204\n",
      "Iteration: 9792, Loss: 0.0030990333762019873, Accuracy: 0.9316287589026615\n",
      "Iteration: 9856, Loss: 0.03513228893280029, Accuracy: 0.9399059136048891\n",
      "Iteration: 9920, Loss: 0.001261717057786882, Accuracy: 0.9384860322461464\n",
      "Iteration: 9984, Loss: 0.00613397778943181, Accuracy: 0.9332476129347924\n",
      "Iteration: 10048, Loss: 0.007945802994072437, Accuracy: 0.9286330002942123\n",
      "Iteration: 10112, Loss: 0.007470868993550539, Accuracy: 0.9366915772552602\n",
      "Iteration: 10176, Loss: 0.0026061739772558212, Accuracy: 0.9336110517615452\n",
      "Iteration: 10240, Loss: 0.004841724876314402, Accuracy: 0.9322947662731167\n",
      "Iteration: 10304, Loss: 0.057619597762823105, Accuracy: 0.9411265360831749\n",
      "Iteration: 10368, Loss: 0.003973659593611956, Accuracy: 0.9440141669474542\n",
      "Iteration: 10432, Loss: 0.005975756794214249, Accuracy: 0.9405592021212215\n",
      "Iteration: 10496, Loss: 0.008302032016217709, Accuracy: 0.9439102241012733\n",
      "Iteration: 10560, Loss: 0.01136274728924036, Accuracy: 0.9425680557033047\n",
      "Iteration: 10624, Loss: 0.0037633711472153664, Accuracy: 0.942523924226407\n",
      "Iteration: 10688, Loss: 0.005324288737028837, Accuracy: 0.9475103447912261\n",
      "Iteration: 10752, Loss: 0.0030074387323111296, Accuracy: 0.9439429308258696\n",
      "Iteration: 10816, Loss: 0.0055190399289131165, Accuracy: 0.9487643237662269\n",
      "Iteration: 10880, Loss: 0.004212141502648592, Accuracy: 0.947393356836983\n",
      "Iteration: 10944, Loss: 0.0012229260755702853, Accuracy: 0.9467738887906307\n",
      "Iteration: 11008, Loss: 0.004729926586151123, Accuracy: 0.9499046871351311\n",
      "Iteration: 11072, Loss: 0.004006558563560247, Accuracy: 0.9506395063363016\n",
      "Iteration: 11136, Loss: 0.00030351130408234894, Accuracy: 0.9412768954207422\n",
      "Iteration: 11200, Loss: 0.004206305369734764, Accuracy: 0.949481693431153\n",
      "Iteration: 11264, Loss: 0.028403298929333687, Accuracy: 0.9408569335646462\n",
      "Iteration: 11328, Loss: 0.0037485479842871428, Accuracy: 0.9468616793892579\n",
      "Iteration: 11392, Loss: 0.0034951213747262955, Accuracy: 0.9548691213567508\n",
      "Iteration: 11456, Loss: 0.0002285429509356618, Accuracy: 0.9531528262450593\n",
      "Iteration: 11520, Loss: 0.003931187093257904, Accuracy: 0.955021355766803\n",
      "Iteration: 11584, Loss: 0.004674070980399847, Accuracy: 0.955774611356901\n",
      "Iteration: 11648, Loss: 0.008247398771345615, Accuracy: 0.9485502928873757\n",
      "Iteration: 11712, Loss: 0.003187498776242137, Accuracy: 0.9505682783928933\n",
      "Iteration: 11776, Loss: 0.009915958158671856, Accuracy: 0.9546246483223513\n",
      "Iteration: 11840, Loss: 0.0008175495895557106, Accuracy: 0.9511978350201389\n",
      "Iteration: 11904, Loss: 0.002851623808965087, Accuracy: 0.957093832505052\n",
      "Iteration: 11968, Loss: 0.062047746032476425, Accuracy: 0.9578790035448037\n",
      "Iteration: 12032, Loss: 0.00476892339065671, Accuracy: 0.957339359112666\n",
      "Iteration: 12096, Loss: 0.0032236166298389435, Accuracy: 0.9554296864225762\n",
      "Iteration: 12160, Loss: 0.0026102454867213964, Accuracy: 0.9591994313814212\n",
      "Iteration: 12224, Loss: 0.0032222261652350426, Accuracy: 0.9531434328091564\n",
      "Iteration: 12288, Loss: 0.002118899254128337, Accuracy: 0.9607713696022984\n",
      "Iteration: 12352, Loss: 0.005925025790929794, Accuracy: 0.9617749979806831\n",
      "Iteration: 12416, Loss: 0.0023323039058595896, Accuracy: 0.9611665479314979\n",
      "Iteration: 12480, Loss: 0.0008576675900258124, Accuracy: 0.9513005562039325\n",
      "Iteration: 12544, Loss: 0.0028290629852563143, Accuracy: 0.9627968783315737\n",
      "Iteration: 12608, Loss: 0.002031611045822501, Accuracy: 0.9605871963285608\n",
      "Iteration: 12672, Loss: 0.0011229848023504019, Accuracy: 0.9596175610058708\n",
      "Iteration: 12736, Loss: 0.000943332735914737, Accuracy: 0.9646456543996464\n",
      "Iteration: 12800, Loss: 0.00013237954408396035, Accuracy: 0.963282589596929\n",
      "Iteration: 12864, Loss: 0.0012010904029011726, Accuracy: 0.9670832696283469\n",
      "Iteration: 12928, Loss: 0.0007828795351088047, Accuracy: 0.9584492719586706\n",
      "Iteration: 12992, Loss: 0.0017205275362357497, Accuracy: 0.958685509453062\n",
      "Iteration: 13056, Loss: 0.001726327114738524, Accuracy: 0.9662451784242876\n",
      "Iteration: 13120, Loss: 0.004573112819343805, Accuracy: 0.9643535404466093\n",
      "Iteration: 13184, Loss: 6.47673150524497e-05, Accuracy: 0.9665502695643227\n",
      "Iteration: 13248, Loss: 0.00035961694084107876, Accuracy: 0.9660422222077614\n",
      "Iteration: 13312, Loss: 0.0015702019445598125, Accuracy: 0.9615414948930265\n",
      "Iteration: 13376, Loss: 0.0015110564418137074, Accuracy: 0.9657518699023058\n",
      "Iteration: 13440, Loss: 0.0005344566307030618, Accuracy: 0.9573492754279869\n",
      "Iteration: 13504, Loss: 0.00023216746922116727, Accuracy: 0.9584166608110536\n",
      "Iteration: 13568, Loss: 0.0001953327446244657, Accuracy: 0.9694001904426841\n",
      "Iteration: 13632, Loss: 0.04048678278923035, Accuracy: 0.9677671349490993\n",
      "Iteration: 13696, Loss: 0.094077467918396, Accuracy: 0.9586515117844101\n",
      "Iteration: 13760, Loss: 7.818468293407932e-05, Accuracy: 0.967110343852255\n",
      "Iteration: 13824, Loss: 0.0043195500038564205, Accuracy: 0.9666704443079652\n",
      "Iteration: 13888, Loss: 0.00022260344121605158, Accuracy: 0.9650508252598229\n",
      "Iteration: 13952, Loss: 0.0013080030912533402, Accuracy: 0.9708957360489876\n",
      "Saved fullModel_dr[1]_replicate0.model\n",
      "Saved W_dr[1]_replicate0.p\n",
      "1 1.0 [1.0, 1.0, 1.0]\n",
      "Saved w_dr[1]_replicate0.p\n",
      "Replicate 0 completed\n",
      "Time elapsed: 20.890625 seconds\n",
      "Iteration: 64, Loss: 0.2197888046503067, Accuracy: 0.5017389049753547\n",
      "Iteration: 128, Loss: 0.21089398860931396, Accuracy: 0.5322141395881772\n",
      "Iteration: 192, Loss: 0.14855211973190308, Accuracy: 0.5852155881002545\n",
      "Iteration: 256, Loss: 0.17998702824115753, Accuracy: 0.6134498626925051\n",
      "Iteration: 320, Loss: 0.17734144628047943, Accuracy: 0.6250311471521854\n",
      "Iteration: 384, Loss: 0.18477784097194672, Accuracy: 0.6322418502531946\n",
      "Iteration: 448, Loss: 0.1665433943271637, Accuracy: 0.63748296815902\n",
      "Iteration: 512, Loss: 0.17967642843723297, Accuracy: 0.6405001957900822\n",
      "Iteration: 576, Loss: 0.18191464245319366, Accuracy: 0.6434652148745954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 640, Loss: 0.15892751514911652, Accuracy: 0.645891067571938\n",
      "Iteration: 704, Loss: 0.16580362617969513, Accuracy: 0.6464267144910991\n",
      "Iteration: 768, Loss: 0.1806427389383316, Accuracy: 0.6480990936979651\n",
      "Iteration: 832, Loss: 0.1621657758951187, Accuracy: 0.6502175726927817\n",
      "Iteration: 896, Loss: 0.15626958012580872, Accuracy: 0.6510979747399688\n",
      "Iteration: 960, Loss: 0.17567472159862518, Accuracy: 0.65168726304546\n",
      "Iteration: 1024, Loss: 0.17764264345169067, Accuracy: 0.6524383081123233\n",
      "Iteration: 1088, Loss: 0.15702684223651886, Accuracy: 0.651905641425401\n",
      "Iteration: 1152, Loss: 0.18004494905471802, Accuracy: 0.6545542129315436\n",
      "Iteration: 1216, Loss: 0.16619937121868134, Accuracy: 0.6544940648600459\n",
      "Iteration: 1280, Loss: 0.1622616946697235, Accuracy: 0.6549255885183811\n",
      "Iteration: 1344, Loss: 0.1564081907272339, Accuracy: 0.6544824801385403\n",
      "Iteration: 1408, Loss: 0.16179214417934418, Accuracy: 0.6544504044577479\n",
      "Iteration: 1472, Loss: 0.1564452201128006, Accuracy: 0.6571216722950339\n",
      "Iteration: 1536, Loss: 0.16140390932559967, Accuracy: 0.6565266195684671\n",
      "Iteration: 1600, Loss: 0.1675562858581543, Accuracy: 0.6577809918671846\n",
      "Iteration: 1664, Loss: 0.17907960712909698, Accuracy: 0.6575272679328918\n",
      "Iteration: 1728, Loss: 0.149835467338562, Accuracy: 0.6570279337465763\n",
      "Iteration: 1792, Loss: 0.16381590068340302, Accuracy: 0.657661602832377\n",
      "Iteration: 1856, Loss: 0.15741927921772003, Accuracy: 0.6589062646962702\n",
      "Iteration: 1920, Loss: 0.16228392720222473, Accuracy: 0.6607022141106427\n",
      "Iteration: 1984, Loss: 0.1631259173154831, Accuracy: 0.660681776702404\n",
      "Iteration: 2048, Loss: 0.14094580709934235, Accuracy: 0.6612941240891814\n",
      "Iteration: 2112, Loss: 0.16417135298252106, Accuracy: 0.6601791437715292\n",
      "Iteration: 2176, Loss: 0.14676380157470703, Accuracy: 0.6636556088924408\n",
      "Iteration: 2240, Loss: 0.16990120708942413, Accuracy: 0.6659777527675033\n",
      "Iteration: 2304, Loss: 0.1266431361436844, Accuracy: 0.6681625577621162\n",
      "Iteration: 2368, Loss: 0.17477743327617645, Accuracy: 0.668840398080647\n",
      "Iteration: 2432, Loss: 0.1430215835571289, Accuracy: 0.6744207390584052\n",
      "Iteration: 2496, Loss: 0.12418434768915176, Accuracy: 0.6749145691283047\n",
      "Iteration: 2560, Loss: 0.10893851518630981, Accuracy: 0.680239659268409\n",
      "Iteration: 2624, Loss: 0.09639948606491089, Accuracy: 0.6823875065892935\n",
      "Iteration: 2688, Loss: 0.14928273856639862, Accuracy: 0.6876030806452036\n",
      "Iteration: 2752, Loss: 0.15164905786514282, Accuracy: 0.6889430098235607\n",
      "Iteration: 2816, Loss: 0.10788947343826294, Accuracy: 0.6942064180038869\n",
      "Iteration: 2880, Loss: 0.06759840250015259, Accuracy: 0.6992314241360873\n",
      "Iteration: 2944, Loss: 0.19644765555858612, Accuracy: 0.7050719233229756\n",
      "Iteration: 3008, Loss: 0.12224867939949036, Accuracy: 0.7046327847056091\n",
      "Iteration: 3072, Loss: 0.14296860992908478, Accuracy: 0.713733698008582\n",
      "Iteration: 3136, Loss: 0.1400025486946106, Accuracy: 0.7161725144833326\n",
      "Iteration: 3200, Loss: 0.20764535665512085, Accuracy: 0.7174417686183006\n",
      "Iteration: 3264, Loss: 0.13361768424510956, Accuracy: 0.7216650142800063\n",
      "Iteration: 3328, Loss: 0.195394828915596, Accuracy: 0.7234306593891233\n",
      "Iteration: 3392, Loss: 0.05407652258872986, Accuracy: 0.7300679464824498\n",
      "Iteration: 3456, Loss: 0.18547241389751434, Accuracy: 0.731907581910491\n",
      "Iteration: 3520, Loss: 0.1101570650935173, Accuracy: 0.7338672208134085\n",
      "Iteration: 3584, Loss: 0.047861676663160324, Accuracy: 0.7413038117811084\n",
      "Iteration: 3648, Loss: 0.17497248947620392, Accuracy: 0.7481964202597737\n",
      "Iteration: 3712, Loss: 0.12296908348798752, Accuracy: 0.7479344222228974\n",
      "Iteration: 3776, Loss: 0.030494287610054016, Accuracy: 0.7573257945477962\n",
      "Iteration: 3840, Loss: 0.0958918035030365, Accuracy: 0.7614167248830199\n",
      "Iteration: 3904, Loss: 0.10282959789037704, Accuracy: 0.7662146766670048\n",
      "Iteration: 3968, Loss: 0.0393577478826046, Accuracy: 0.7702331505715847\n",
      "Iteration: 4032, Loss: 0.09113502502441406, Accuracy: 0.7763622615020722\n",
      "Iteration: 4096, Loss: 0.09586337953805923, Accuracy: 0.7793230407405645\n",
      "Iteration: 4160, Loss: 0.09417640417814255, Accuracy: 0.7833838779479265\n",
      "Iteration: 4224, Loss: 0.13956452906131744, Accuracy: 0.7873297713231295\n",
      "Iteration: 4288, Loss: 0.14474675059318542, Accuracy: 0.7947390052722767\n",
      "Iteration: 4352, Loss: 0.06647881120443344, Accuracy: 0.799981418880634\n",
      "Iteration: 4416, Loss: 0.020412247627973557, Accuracy: 0.8025042794179171\n",
      "Iteration: 4480, Loss: 0.06217190623283386, Accuracy: 0.8078724719816819\n",
      "Iteration: 4544, Loss: 0.08096503466367722, Accuracy: 0.8091144644422457\n",
      "Iteration: 4608, Loss: 0.053176041692495346, Accuracy: 0.8153020784957334\n",
      "Iteration: 4672, Loss: 0.0667756050825119, Accuracy: 0.8175305559998378\n",
      "Iteration: 4736, Loss: 0.02660442888736725, Accuracy: 0.819862701697275\n",
      "Iteration: 4800, Loss: 0.02463795244693756, Accuracy: 0.8234196866396815\n",
      "Iteration: 4864, Loss: 0.02618955262005329, Accuracy: 0.8261323978658766\n",
      "Iteration: 4928, Loss: 0.04373781755566597, Accuracy: 0.834589600097388\n",
      "Iteration: 4992, Loss: 0.08224911987781525, Accuracy: 0.8307147982995957\n",
      "Iteration: 5056, Loss: 0.047388602048158646, Accuracy: 0.8366870649624616\n",
      "Iteration: 5120, Loss: 0.02024795673787594, Accuracy: 0.837057642871514\n",
      "Iteration: 5184, Loss: 0.021522505208849907, Accuracy: 0.8435544539242983\n",
      "Iteration: 5248, Loss: 0.012251615524291992, Accuracy: 0.8468152554705739\n",
      "Iteration: 5312, Loss: 0.011831417679786682, Accuracy: 0.8524103260133415\n",
      "Iteration: 5376, Loss: 0.05365665629506111, Accuracy: 0.853759081219323\n",
      "Iteration: 5440, Loss: 0.02344895713031292, Accuracy: 0.858488978818059\n",
      "Iteration: 5504, Loss: 0.04664630815386772, Accuracy: 0.8576002062764019\n",
      "Iteration: 5568, Loss: 0.0072705927304923534, Accuracy: 0.8616410027025267\n",
      "Iteration: 5632, Loss: 0.04317120090126991, Accuracy: 0.8626766783418134\n",
      "Iteration: 5696, Loss: 0.02840392477810383, Accuracy: 0.8675219982396811\n",
      "Iteration: 5760, Loss: 0.009768239222466946, Accuracy: 0.8720132486196235\n",
      "Iteration: 5824, Loss: 0.01980268582701683, Accuracy: 0.877584955887869\n",
      "Iteration: 5888, Loss: 0.032987892627716064, Accuracy: 0.8735501819173805\n",
      "Iteration: 5952, Loss: 0.011350083164870739, Accuracy: 0.8754796432331204\n",
      "Iteration: 6016, Loss: 0.02191031537950039, Accuracy: 0.8820439190603793\n",
      "Iteration: 6080, Loss: 0.020944291725754738, Accuracy: 0.8846355868154205\n",
      "Iteration: 6144, Loss: 0.02744622342288494, Accuracy: 0.8815908284741454\n",
      "Iteration: 6208, Loss: 0.011065124534070492, Accuracy: 0.8927536723786034\n",
      "Iteration: 6272, Loss: 0.008559652604162693, Accuracy: 0.8933572442620061\n",
      "Iteration: 6336, Loss: 0.02212904952466488, Accuracy: 0.89107489597518\n",
      "Iteration: 6400, Loss: 0.006801061797887087, Accuracy: 0.8931264018174261\n",
      "Iteration: 6464, Loss: 0.0070693050511181355, Accuracy: 0.8943402630393393\n",
      "Iteration: 6528, Loss: 0.005173027981072664, Accuracy: 0.9035280534881167\n",
      "Iteration: 6592, Loss: 0.00483392970636487, Accuracy: 0.9003998060361482\n",
      "Iteration: 6656, Loss: 0.010327287949621677, Accuracy: 0.8911596951656975\n",
      "Iteration: 6720, Loss: 0.0037292332854121923, Accuracy: 0.8947129491716623\n",
      "Iteration: 6784, Loss: 0.017843814566731453, Accuracy: 0.9024035076145083\n",
      "Iteration: 6848, Loss: 0.029116928577423096, Accuracy: 0.9075702409609221\n",
      "Iteration: 6912, Loss: 0.023837929591536522, Accuracy: 0.9079886022373103\n",
      "Iteration: 6976, Loss: 0.005729947704821825, Accuracy: 0.910622663795948\n",
      "Iteration: 7040, Loss: 0.01950404793024063, Accuracy: 0.9122627211618237\n",
      "Iteration: 7104, Loss: 0.00640466995537281, Accuracy: 0.916994011728093\n",
      "Iteration: 7168, Loss: 0.01905793696641922, Accuracy: 0.9148562405607663\n",
      "Iteration: 7232, Loss: 0.014194401912391186, Accuracy: 0.9142313210177235\n",
      "Iteration: 7296, Loss: 0.031300414353609085, Accuracy: 0.9200951554521453\n",
      "Iteration: 7360, Loss: 0.043014928698539734, Accuracy: 0.9113261469756253\n",
      "Iteration: 7424, Loss: 0.01425343006849289, Accuracy: 0.9178227626834996\n",
      "Iteration: 7488, Loss: 0.010505725629627705, Accuracy: 0.9235927982954308\n",
      "Iteration: 7552, Loss: 0.005540108308196068, Accuracy: 0.9238228368049022\n",
      "Iteration: 7616, Loss: 0.01619374193251133, Accuracy: 0.9253060505434405\n",
      "Iteration: 7680, Loss: 0.0075163450092077255, Accuracy: 0.9282805529946927\n",
      "Iteration: 7744, Loss: 0.007745315786451101, Accuracy: 0.9294594157254323\n",
      "Iteration: 7808, Loss: 0.008863926865160465, Accuracy: 0.9280909251538105\n",
      "Iteration: 7872, Loss: 0.003810642519965768, Accuracy: 0.925012280989904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 7936, Loss: 0.02965199388563633, Accuracy: 0.9291010729211848\n",
      "Iteration: 8000, Loss: 0.006359373684972525, Accuracy: 0.9305115730385296\n",
      "Iteration: 8064, Loss: 0.005140676628798246, Accuracy: 0.9363579786149785\n",
      "Iteration: 8128, Loss: 0.010525867342948914, Accuracy: 0.9366144078085199\n",
      "Iteration: 8192, Loss: 0.0022668945603072643, Accuracy: 0.9432191490777768\n",
      "Iteration: 8256, Loss: 0.0021382097620517015, Accuracy: 0.9411909665795974\n",
      "Iteration: 8320, Loss: 0.006837157066911459, Accuracy: 0.9400869050004985\n",
      "Iteration: 8384, Loss: 0.005101060029119253, Accuracy: 0.9447248033538926\n",
      "Iteration: 8448, Loss: 0.007359800394624472, Accuracy: 0.9440435784345027\n",
      "Iteration: 8512, Loss: 0.001555409631691873, Accuracy: 0.9450283041514922\n",
      "Iteration: 8576, Loss: 0.005106107797473669, Accuracy: 0.9441444921831135\n",
      "Iteration: 8640, Loss: 0.005031183827668428, Accuracy: 0.9491087319620419\n",
      "Iteration: 8704, Loss: 0.11483118683099747, Accuracy: 0.9346296677540522\n",
      "Iteration: 8768, Loss: 0.004929515067487955, Accuracy: 0.9435736619052477\n",
      "Iteration: 8832, Loss: 0.005515252705663443, Accuracy: 0.9385938651103061\n",
      "Iteration: 8896, Loss: 0.008126669563353062, Accuracy: 0.9439534678240307\n",
      "Iteration: 8960, Loss: 0.011572529561817646, Accuracy: 0.9438740181358298\n",
      "Iteration: 9024, Loss: 0.004686793778091669, Accuracy: 0.9451958925637882\n",
      "Iteration: 9088, Loss: 0.0012693213066086173, Accuracy: 0.9495410706149414\n",
      "Iteration: 9152, Loss: 0.0028872464317828417, Accuracy: 0.9384528640221106\n",
      "Iteration: 9216, Loss: 0.011644136160612106, Accuracy: 0.9517810033430578\n",
      "Iteration: 9280, Loss: 0.0031545714009553194, Accuracy: 0.9425352916878182\n",
      "Iteration: 9344, Loss: 0.001579298172146082, Accuracy: 0.9526735584222479\n",
      "Iteration: 9408, Loss: 0.0031831618398427963, Accuracy: 0.9547694147186121\n",
      "Iteration: 9472, Loss: 0.00046692215255461633, Accuracy: 0.9552788568107644\n",
      "Iteration: 9536, Loss: 0.001933555118739605, Accuracy: 0.957332668825984\n",
      "Iteration: 9600, Loss: 0.0010910994606092572, Accuracy: 0.9573770443967078\n",
      "Iteration: 9664, Loss: 0.0009071200620383024, Accuracy: 0.9566645043523749\n",
      "Iteration: 9728, Loss: 0.000491712533403188, Accuracy: 0.9612469255516771\n",
      "Iteration: 9792, Loss: 0.02455092966556549, Accuracy: 0.9496672557288548\n",
      "Iteration: 9856, Loss: 0.0928419828414917, Accuracy: 0.955319617074565\n",
      "Iteration: 9920, Loss: 0.003611477790400386, Accuracy: 0.9537178243190283\n",
      "Iteration: 9984, Loss: 0.0032789602410048246, Accuracy: 0.9590654334315332\n",
      "Iteration: 10048, Loss: 0.00488104484975338, Accuracy: 0.9550716936500976\n",
      "Iteration: 10112, Loss: 0.00014885120617691427, Accuracy: 0.9604173159459606\n",
      "Iteration: 10176, Loss: 0.0009119159658439457, Accuracy: 0.9633212921326049\n",
      "Iteration: 10240, Loss: 0.00041550761670805514, Accuracy: 0.9661264873866457\n",
      "Iteration: 10304, Loss: 0.0006087877554818988, Accuracy: 0.9667126255080802\n",
      "Iteration: 10368, Loss: 0.0067844875156879425, Accuracy: 0.9597089831659105\n",
      "Iteration: 10432, Loss: 0.001123040565289557, Accuracy: 0.9667348752700491\n",
      "Iteration: 10496, Loss: 0.0019404292106628418, Accuracy: 0.9652750637906138\n",
      "Iteration: 10560, Loss: 0.0003056989808101207, Accuracy: 0.96604234741244\n",
      "Iteration: 10624, Loss: 0.0013928995467722416, Accuracy: 0.958602261292981\n",
      "Iteration: 10688, Loss: 0.003847521962597966, Accuracy: 0.960521524262731\n",
      "Iteration: 10752, Loss: 0.011904281564056873, Accuracy: 0.9688026995572727\n",
      "Iteration: 10816, Loss: 0.03742878511548042, Accuracy: 0.9688333541707834\n",
      "Iteration: 10880, Loss: 0.14943864941596985, Accuracy: 0.9565384274610551\n",
      "Iteration: 10944, Loss: 0.002038265811279416, Accuracy: 0.9589998533047037\n",
      "Iteration: 11008, Loss: 0.0018065962940454483, Accuracy: 0.9658424354274757\n",
      "Iteration: 11072, Loss: 0.0009448698256164789, Accuracy: 0.9649647850746987\n",
      "Iteration: 11136, Loss: 0.0003844391612801701, Accuracy: 0.9651625543629052\n",
      "Iteration: 11200, Loss: 0.0019334140233695507, Accuracy: 0.9695930351153947\n",
      "Iteration: 11264, Loss: 0.0004026413371320814, Accuracy: 0.9652478712960146\n",
      "Iteration: 11328, Loss: 0.0012969784438610077, Accuracy: 0.967240619531367\n",
      "Iteration: 11392, Loss: 0.0009116186411119998, Accuracy: 0.966474153494346\n",
      "Iteration: 11456, Loss: 0.0002569112984929234, Accuracy: 0.9690716532495571\n",
      "Iteration: 11520, Loss: 0.001546471961773932, Accuracy: 0.9700772162323119\n",
      "Saved fullModel_dr[1]_replicate1.model\n",
      "Saved W_dr[1]_replicate1.p\n",
      "1 1.0 [1.0, 1.0, 1.0]\n",
      "Saved w_dr[1]_replicate1.p\n",
      "Replicate 1 completed\n",
      "Time elapsed: 33.625 seconds\n",
      "Iteration: 64, Loss: 0.2416529506444931, Accuracy: 0.5007999241352081\n",
      "Iteration: 128, Loss: 0.2339158058166504, Accuracy: 0.5086156334728003\n",
      "Iteration: 192, Loss: 0.20780165493488312, Accuracy: 0.544498230330646\n",
      "Iteration: 256, Loss: 0.18163245916366577, Accuracy: 0.5859267949126661\n",
      "Iteration: 320, Loss: 0.18197131156921387, Accuracy: 0.6106282598339021\n",
      "Iteration: 384, Loss: 0.17845787107944489, Accuracy: 0.6238151448778808\n",
      "Iteration: 448, Loss: 0.20084960758686066, Accuracy: 0.6305639361962676\n",
      "Iteration: 512, Loss: 0.16362567245960236, Accuracy: 0.63645282946527\n",
      "Iteration: 576, Loss: 0.1878662258386612, Accuracy: 0.6404666639864445\n",
      "Iteration: 640, Loss: 0.1640312671661377, Accuracy: 0.643298908136785\n",
      "Iteration: 704, Loss: 0.19277410209178925, Accuracy: 0.6451772572472692\n",
      "Iteration: 768, Loss: 0.17534993588924408, Accuracy: 0.6471277098171413\n",
      "Iteration: 832, Loss: 0.1512971967458725, Accuracy: 0.6467068060301244\n",
      "Iteration: 896, Loss: 0.17523278295993805, Accuracy: 0.6496414239518344\n",
      "Iteration: 960, Loss: 0.1504957675933838, Accuracy: 0.6504870965145528\n",
      "Iteration: 1024, Loss: 0.17539529502391815, Accuracy: 0.6515093063935637\n",
      "Iteration: 1088, Loss: 0.18109755218029022, Accuracy: 0.652689830865711\n",
      "Iteration: 1152, Loss: 0.17203406989574432, Accuracy: 0.6529204240068793\n",
      "Iteration: 1216, Loss: 0.16229656338691711, Accuracy: 0.6540432604961097\n",
      "Iteration: 1280, Loss: 0.18255607783794403, Accuracy: 0.6542265536263585\n",
      "Iteration: 1344, Loss: 0.16626335680484772, Accuracy: 0.6547116823494434\n",
      "Iteration: 1408, Loss: 0.17381243407726288, Accuracy: 0.6553114848211408\n",
      "Iteration: 1472, Loss: 0.16233186423778534, Accuracy: 0.6558595108799636\n",
      "Iteration: 1536, Loss: 0.16537266969680786, Accuracy: 0.6565400403924286\n",
      "Iteration: 1600, Loss: 0.17116332054138184, Accuracy: 0.6561424997635186\n",
      "Iteration: 1664, Loss: 0.172183558344841, Accuracy: 0.6573207126930356\n",
      "Iteration: 1728, Loss: 0.1556878536939621, Accuracy: 0.6572138597257435\n",
      "Iteration: 1792, Loss: 0.17952822148799896, Accuracy: 0.6573715447448194\n",
      "Iteration: 1856, Loss: 0.15913152694702148, Accuracy: 0.6579142101109028\n",
      "Iteration: 1920, Loss: 0.1691216379404068, Accuracy: 0.6583022149279714\n",
      "Iteration: 1984, Loss: 0.15772271156311035, Accuracy: 0.6582678845152259\n",
      "Iteration: 2048, Loss: 0.17162056267261505, Accuracy: 0.6585989594459534\n",
      "Iteration: 2112, Loss: 0.16253791749477386, Accuracy: 0.6587478467263281\n",
      "Iteration: 2176, Loss: 0.1665249466896057, Accuracy: 0.6590999076142907\n",
      "Iteration: 2240, Loss: 0.1664738804101944, Accuracy: 0.6593436384573579\n",
      "Iteration: 2304, Loss: 0.1610858142375946, Accuracy: 0.6593571151606739\n",
      "Iteration: 2368, Loss: 0.16978853940963745, Accuracy: 0.6596772214397788\n",
      "Iteration: 2432, Loss: 0.16858810186386108, Accuracy: 0.6597106819972396\n",
      "Iteration: 2496, Loss: 0.17133617401123047, Accuracy: 0.6593120088800788\n",
      "Iteration: 2560, Loss: 0.16968823969364166, Accuracy: 0.6603062059730291\n",
      "Iteration: 2624, Loss: 0.17176412045955658, Accuracy: 0.6603938844054937\n",
      "Iteration: 2688, Loss: 0.16298530995845795, Accuracy: 0.6604376183822751\n",
      "Iteration: 2752, Loss: 0.17470665276050568, Accuracy: 0.6599964848719537\n",
      "Iteration: 2816, Loss: 0.17126069962978363, Accuracy: 0.6604884942062199\n",
      "Iteration: 2880, Loss: 0.1710953265428543, Accuracy: 0.6606845711357892\n",
      "Iteration: 2944, Loss: 0.16541264951229095, Accuracy: 0.660333399195224\n",
      "Iteration: 3008, Loss: 0.1667274385690689, Accuracy: 0.6607535015791655\n",
      "Iteration: 3072, Loss: 0.16098140180110931, Accuracy: 0.6608215947635472\n",
      "Iteration: 3136, Loss: 0.163895383477211, Accuracy: 0.6562560508027673\n",
      "Iteration: 3200, Loss: 0.17348651587963104, Accuracy: 0.6609485354274511\n",
      "Iteration: 3264, Loss: 0.1647689789533615, Accuracy: 0.6619383818469942\n",
      "Iteration: 3328, Loss: 0.1667584627866745, Accuracy: 0.6626705345697701\n",
      "Iteration: 3392, Loss: 0.163768470287323, Accuracy: 0.6623344952240586\n",
      "Iteration: 3456, Loss: 0.15790759027004242, Accuracy: 0.6618647263385355\n",
      "Iteration: 3520, Loss: 0.1730324774980545, Accuracy: 0.662855064496398\n",
      "Iteration: 3584, Loss: 0.1574498862028122, Accuracy: 0.6632303651422262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3648, Loss: 0.15790842473506927, Accuracy: 0.6625572936609387\n",
      "Iteration: 3712, Loss: 0.1553986370563507, Accuracy: 0.6655598552897573\n",
      "Iteration: 3776, Loss: 0.17780788242816925, Accuracy: 0.6661974531598389\n",
      "Iteration: 3840, Loss: 0.15945129096508026, Accuracy: 0.6673559974879026\n",
      "Iteration: 3904, Loss: 0.15735723078250885, Accuracy: 0.6668783985078335\n",
      "Iteration: 3968, Loss: 0.15853624045848846, Accuracy: 0.669552213512361\n",
      "Iteration: 4032, Loss: 0.17481154203414917, Accuracy: 0.6700857589021325\n",
      "Iteration: 4096, Loss: 0.14702358841896057, Accuracy: 0.6714569684118032\n",
      "Iteration: 4160, Loss: 0.14973367750644684, Accuracy: 0.6747555234469473\n",
      "Iteration: 4224, Loss: 0.15534399449825287, Accuracy: 0.676021627150476\n",
      "Iteration: 4288, Loss: 0.15940441191196442, Accuracy: 0.6769037232734263\n",
      "Iteration: 4352, Loss: 0.12021518498659134, Accuracy: 0.6817984986118972\n",
      "Iteration: 4416, Loss: 0.13937515020370483, Accuracy: 0.6835198067128658\n",
      "Iteration: 4480, Loss: 0.14114414155483246, Accuracy: 0.6912791859358549\n",
      "Iteration: 4544, Loss: 0.1297692060470581, Accuracy: 0.6954584694467485\n",
      "Iteration: 4608, Loss: 0.10986421257257462, Accuracy: 0.6991975237615407\n",
      "Iteration: 4672, Loss: 0.10463399440050125, Accuracy: 0.7033435029443353\n",
      "Iteration: 4736, Loss: 0.09508016705513, Accuracy: 0.7107459474354982\n",
      "Iteration: 4800, Loss: 0.09256448596715927, Accuracy: 0.7161552398465574\n",
      "Iteration: 4864, Loss: 0.15901851654052734, Accuracy: 0.7233957136049867\n",
      "Iteration: 4928, Loss: 0.14136244356632233, Accuracy: 0.7302813399583101\n",
      "Iteration: 4992, Loss: 0.10286542773246765, Accuracy: 0.7382020284421742\n",
      "Iteration: 5056, Loss: 0.08913472294807434, Accuracy: 0.7428874003235251\n",
      "Iteration: 5120, Loss: 0.09466912597417831, Accuracy: 0.7504414739087224\n",
      "Iteration: 5184, Loss: 0.07991278171539307, Accuracy: 0.7607801188714802\n",
      "Iteration: 5248, Loss: 0.11788491159677505, Accuracy: 0.7644946346990764\n",
      "Iteration: 5312, Loss: 0.06527295708656311, Accuracy: 0.7677266076207161\n",
      "Iteration: 5376, Loss: 0.051349688321352005, Accuracy: 0.7796218923758715\n",
      "Iteration: 5440, Loss: 0.029573211446404457, Accuracy: 0.7830997800920159\n",
      "Iteration: 5504, Loss: 0.06976955384016037, Accuracy: 0.7881614258512855\n",
      "Iteration: 5568, Loss: 0.07815568894147873, Accuracy: 0.7962962011806667\n",
      "Iteration: 5632, Loss: 0.09751685708761215, Accuracy: 0.8027422798331827\n",
      "Iteration: 5696, Loss: 0.042899250984191895, Accuracy: 0.8077713462989777\n",
      "Iteration: 5760, Loss: 0.10759761184453964, Accuracy: 0.8035448605660349\n",
      "Iteration: 5824, Loss: 0.023918883875012398, Accuracy: 0.8198534161783755\n",
      "Iteration: 5888, Loss: 0.054879069328308105, Accuracy: 0.8225424069678411\n",
      "Iteration: 5952, Loss: 0.0857972502708435, Accuracy: 0.8258321626344696\n",
      "Iteration: 6016, Loss: 0.03160430118441582, Accuracy: 0.8307281524175778\n",
      "Iteration: 6080, Loss: 0.05185317620635033, Accuracy: 0.8312412324594334\n",
      "Iteration: 6144, Loss: 0.029795773327350616, Accuracy: 0.8327690951991826\n",
      "Iteration: 6208, Loss: 0.030612466856837273, Accuracy: 0.843172871042043\n",
      "Iteration: 6272, Loss: 0.07978203147649765, Accuracy: 0.8473644779296592\n",
      "Iteration: 6336, Loss: 0.045214924961328506, Accuracy: 0.8482725374633446\n",
      "Iteration: 6400, Loss: 0.02663472294807434, Accuracy: 0.8477173149585724\n",
      "Iteration: 6464, Loss: 0.012148582376539707, Accuracy: 0.8448246344923973\n",
      "Iteration: 6528, Loss: 0.05134395882487297, Accuracy: 0.8544743114616722\n",
      "Iteration: 6592, Loss: 0.02504378743469715, Accuracy: 0.8607051512226462\n",
      "Iteration: 6656, Loss: 0.0746358335018158, Accuracy: 0.8677560600917786\n",
      "Iteration: 6720, Loss: 0.033300500363111496, Accuracy: 0.8675149149494246\n",
      "Iteration: 6784, Loss: 0.016584930941462517, Accuracy: 0.8696117773652077\n",
      "Iteration: 6848, Loss: 0.029175596311688423, Accuracy: 0.869022113038227\n",
      "Iteration: 6912, Loss: 0.012817864306271076, Accuracy: 0.875243341550231\n",
      "Iteration: 6976, Loss: 0.02853533811867237, Accuracy: 0.8754635313525796\n",
      "Iteration: 7040, Loss: 0.026168474927544594, Accuracy: 0.8759616205934435\n",
      "Iteration: 7104, Loss: 0.016991449519991875, Accuracy: 0.8851299094967544\n",
      "Iteration: 7168, Loss: 0.021775303408503532, Accuracy: 0.8840771862887777\n",
      "Iteration: 7232, Loss: 0.08484859019517899, Accuracy: 0.8820235105813481\n",
      "Iteration: 7296, Loss: 0.01642613112926483, Accuracy: 0.8883667640620843\n",
      "Iteration: 7360, Loss: 0.02151961624622345, Accuracy: 0.8917463446850888\n",
      "Iteration: 7424, Loss: 0.015497520565986633, Accuracy: 0.8919628838193603\n",
      "Iteration: 7488, Loss: 0.008081451989710331, Accuracy: 0.8925515757291578\n",
      "Iteration: 7552, Loss: 0.01658637821674347, Accuracy: 0.8953482962679118\n",
      "Iteration: 7616, Loss: 0.05454229190945625, Accuracy: 0.8845422603772022\n",
      "Iteration: 7680, Loss: 0.019189640879631042, Accuracy: 0.8956896008457989\n",
      "Iteration: 7744, Loss: 0.03574790805578232, Accuracy: 0.9016599780879915\n",
      "Iteration: 7808, Loss: 0.004899617750197649, Accuracy: 0.9059511287487112\n",
      "Iteration: 7872, Loss: 0.007134598214179277, Accuracy: 0.9089263154310174\n",
      "Iteration: 7936, Loss: 0.004614129662513733, Accuracy: 0.9074047121684998\n",
      "Iteration: 8000, Loss: 0.014265458099544048, Accuracy: 0.9062536045676097\n",
      "Iteration: 8064, Loss: 0.022999120876193047, Accuracy: 0.910334471729584\n",
      "Iteration: 8128, Loss: 0.00315819401293993, Accuracy: 0.9082022422226146\n",
      "Iteration: 8192, Loss: 0.013261775486171246, Accuracy: 0.9102350164321251\n",
      "Iteration: 8256, Loss: 0.0053294445388019085, Accuracy: 0.9166105370386504\n",
      "Iteration: 8320, Loss: 0.002990530803799629, Accuracy: 0.9190605602925643\n",
      "Iteration: 8384, Loss: 0.004666986409574747, Accuracy: 0.913185506069567\n",
      "Iteration: 8448, Loss: 0.012677635066211224, Accuracy: 0.9169677795143798\n",
      "Iteration: 8512, Loss: 0.014453474432229996, Accuracy: 0.9181376283522695\n",
      "Iteration: 8576, Loss: 0.008753598667681217, Accuracy: 0.9253213653573766\n",
      "Iteration: 8640, Loss: 0.011159420013427734, Accuracy: 0.9267923796433024\n",
      "Iteration: 8704, Loss: 0.002321649342775345, Accuracy: 0.9262335655512288\n",
      "Iteration: 8768, Loss: 0.0040982672944664955, Accuracy: 0.9250442679622211\n",
      "Iteration: 8832, Loss: 0.013709156773984432, Accuracy: 0.927302963740658\n",
      "Iteration: 8896, Loss: 0.021199896931648254, Accuracy: 0.9247414547717199\n",
      "Iteration: 8960, Loss: 0.028319576755166054, Accuracy: 0.9298315966734663\n",
      "Iteration: 9024, Loss: 0.010694555006921291, Accuracy: 0.9326234211912379\n",
      "Iteration: 9088, Loss: 0.014629223383963108, Accuracy: 0.933087654877454\n",
      "Iteration: 9152, Loss: 0.01045402605086565, Accuracy: 0.9304158801096492\n",
      "Iteration: 9216, Loss: 0.008838922716677189, Accuracy: 0.9342386888456531\n",
      "Iteration: 9280, Loss: 0.009690918028354645, Accuracy: 0.9262238080264069\n",
      "Iteration: 9344, Loss: 0.013878143392503262, Accuracy: 0.9354826526832767\n",
      "Iteration: 9408, Loss: 0.003880677744746208, Accuracy: 0.9282703718636185\n",
      "Iteration: 9472, Loss: 0.002168788807466626, Accuracy: 0.9342515172902495\n",
      "Iteration: 9536, Loss: 0.003838342847302556, Accuracy: 0.9375414422829635\n",
      "Iteration: 9600, Loss: 0.007402925286442041, Accuracy: 0.9286957594449632\n",
      "Iteration: 9664, Loss: 0.001009190222248435, Accuracy: 0.9375057684374042\n",
      "Iteration: 9728, Loss: 0.022579966112971306, Accuracy: 0.9434502849471755\n",
      "Iteration: 9792, Loss: 0.0018400023691356182, Accuracy: 0.9431024528166745\n",
      "Iteration: 9856, Loss: 0.015524429269134998, Accuracy: 0.9323213179595768\n",
      "Iteration: 9920, Loss: 0.00466676102951169, Accuracy: 0.9407408818951808\n",
      "Iteration: 9984, Loss: 0.005160412285476923, Accuracy: 0.9481282557535451\n",
      "Iteration: 10048, Loss: 0.0012621687492355704, Accuracy: 0.9474936288897879\n",
      "Iteration: 10112, Loss: 0.004696669522672892, Accuracy: 0.9493296136206482\n",
      "Iteration: 10176, Loss: 0.10334300994873047, Accuracy: 0.9422945285914466\n",
      "Iteration: 10240, Loss: 0.0016830259701237082, Accuracy: 0.9511618540273048\n",
      "Iteration: 10304, Loss: 0.011680717580020428, Accuracy: 0.9312497246428393\n",
      "Iteration: 10368, Loss: 0.004208046942949295, Accuracy: 0.9488441576831974\n",
      "Iteration: 10432, Loss: 0.004847823176532984, Accuracy: 0.9463085755705833\n",
      "Iteration: 10496, Loss: 0.0030390825122594833, Accuracy: 0.9543981046008412\n",
      "Iteration: 10560, Loss: 0.003941353410482407, Accuracy: 0.9542504656419624\n",
      "Iteration: 10624, Loss: 0.00284037203527987, Accuracy: 0.9480106371047441\n",
      "Iteration: 10688, Loss: 0.006329746451228857, Accuracy: 0.9491740728844889\n",
      "Iteration: 10752, Loss: 0.016443602740764618, Accuracy: 0.9379201360861771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10816, Loss: 0.006933063734322786, Accuracy: 0.9445606287335977\n",
      "Iteration: 10880, Loss: 0.0022930775303393602, Accuracy: 0.9543298958160449\n",
      "Iteration: 10944, Loss: 0.0011532852659001946, Accuracy: 0.9498894819698762\n",
      "Iteration: 11008, Loss: 0.0205692108720541, Accuracy: 0.9524100504058879\n",
      "Iteration: 11072, Loss: 0.0010418700985610485, Accuracy: 0.9498884893255308\n",
      "Iteration: 11136, Loss: 0.00305210635997355, Accuracy: 0.9489266396558378\n",
      "Iteration: 11200, Loss: 0.0014144674642011523, Accuracy: 0.9454386466240976\n",
      "Iteration: 11264, Loss: 0.0036902192514389753, Accuracy: 0.950005546445027\n",
      "Iteration: 11328, Loss: 0.003454013727605343, Accuracy: 0.959126809873851\n",
      "Iteration: 11392, Loss: 0.004689928609877825, Accuracy: 0.9385093878954649\n",
      "Iteration: 11456, Loss: 0.0008463312988169491, Accuracy: 0.9521359457576182\n",
      "Iteration: 11520, Loss: 0.005906419828534126, Accuracy: 0.9552927390614059\n",
      "Iteration: 11584, Loss: 0.0027828195597976446, Accuracy: 0.9580380569968838\n",
      "Iteration: 11648, Loss: 0.003248750464990735, Accuracy: 0.961170731956372\n",
      "Iteration: 11712, Loss: 0.001001168042421341, Accuracy: 0.9627233494684333\n",
      "Iteration: 11776, Loss: 0.0009601758210919797, Accuracy: 0.9488379287504358\n",
      "Iteration: 11840, Loss: 0.00040761762647889555, Accuracy: 0.9597710153611843\n",
      "Iteration: 11904, Loss: 0.0010514560854062438, Accuracy: 0.956019820747315\n",
      "Iteration: 11968, Loss: 0.0030264363158494234, Accuracy: 0.9615852821734734\n",
      "Iteration: 12032, Loss: 0.0039007931482046843, Accuracy: 0.9597793449647725\n",
      "Iteration: 12096, Loss: 0.0008543357835151255, Accuracy: 0.9617801450367551\n",
      "Iteration: 12160, Loss: 0.005496487021446228, Accuracy: 0.9577540056052385\n",
      "Iteration: 12224, Loss: 0.0031748877372592688, Accuracy: 0.9646340714825783\n",
      "Iteration: 12288, Loss: 0.0005525170709006488, Accuracy: 0.96301329441485\n",
      "Iteration: 12352, Loss: 0.0005003742408007383, Accuracy: 0.9660380213899771\n",
      "Iteration: 12416, Loss: 0.002206269884482026, Accuracy: 0.9679859255993506\n",
      "Iteration: 12480, Loss: 0.0025357643608003855, Accuracy: 0.966997167095542\n",
      "Iteration: 12544, Loss: 0.000597868871409446, Accuracy: 0.9668171678931685\n",
      "Iteration: 12608, Loss: 0.0006184407975524664, Accuracy: 0.9615300549485255\n",
      "Iteration: 12672, Loss: 0.00133332924451679, Accuracy: 0.9668775995087344\n",
      "Iteration: 12736, Loss: 0.001160955522209406, Accuracy: 0.963767071662005\n",
      "Iteration: 12800, Loss: 0.002403940074145794, Accuracy: 0.9686081605323125\n",
      "Iteration: 12864, Loss: 0.006956595461815596, Accuracy: 0.9644121993915178\n",
      "Iteration: 12928, Loss: 0.0038528491277247667, Accuracy: 0.9694060471520061\n",
      "Iteration: 12992, Loss: 0.0015901457518339157, Accuracy: 0.9698374787840294\n",
      "Iteration: 13056, Loss: 0.0003565918013919145, Accuracy: 0.9716035211313283\n",
      "Saved fullModel_dr[1]_replicate2.model\n",
      "Saved W_dr[1]_replicate2.p\n",
      "1 1.0 [1.0, 1.0, 1.0]\n",
      "Saved w_dr[1]_replicate2.p\n",
      "Replicate 2 completed\n",
      "Time elapsed: 47.53125 seconds\n",
      "Iteration: 64, Loss: 0.24386148154735565, Accuracy: 0.5018003825098276\n",
      "Iteration: 128, Loss: 0.24250291287899017, Accuracy: 0.512976722791791\n",
      "Iteration: 192, Loss: 0.2221660166978836, Accuracy: 0.5376582220196724\n",
      "Iteration: 256, Loss: 0.21538321673870087, Accuracy: 0.5748388958163559\n",
      "Iteration: 320, Loss: 0.17197316884994507, Accuracy: 0.6018839539028704\n",
      "Iteration: 384, Loss: 0.16647018492221832, Accuracy: 0.6158744511194527\n",
      "Iteration: 448, Loss: 0.1908552199602127, Accuracy: 0.6246854057535529\n",
      "Iteration: 512, Loss: 0.18739862740039825, Accuracy: 0.6305135507136583\n",
      "Iteration: 576, Loss: 0.16661150753498077, Accuracy: 0.6358955190517008\n",
      "Iteration: 640, Loss: 0.18205155432224274, Accuracy: 0.6379327117465436\n",
      "Iteration: 704, Loss: 0.16356365382671356, Accuracy: 0.6419293400831521\n",
      "Iteration: 768, Loss: 0.1617114096879959, Accuracy: 0.6438345247879624\n",
      "Iteration: 832, Loss: 0.17241732776165009, Accuracy: 0.6426633321680129\n",
      "Iteration: 896, Loss: 0.1667906492948532, Accuracy: 0.6471962328068912\n",
      "Iteration: 960, Loss: 0.1615583747625351, Accuracy: 0.6481207790784538\n",
      "Iteration: 1024, Loss: 0.16549773514270782, Accuracy: 0.6495216335169971\n",
      "Iteration: 1088, Loss: 0.1634647250175476, Accuracy: 0.6497479360550642\n",
      "Iteration: 1152, Loss: 0.16233158111572266, Accuracy: 0.6503529413603246\n",
      "Iteration: 1216, Loss: 0.16386879980564117, Accuracy: 0.6516191423870623\n",
      "Iteration: 1280, Loss: 0.16779525578022003, Accuracy: 0.6513816751539707\n",
      "Iteration: 1344, Loss: 0.17301911115646362, Accuracy: 0.6523321005515754\n",
      "Iteration: 1408, Loss: 0.1631874293088913, Accuracy: 0.6530698495917022\n",
      "Iteration: 1472, Loss: 0.1596306711435318, Accuracy: 0.6536988490261137\n",
      "Iteration: 1536, Loss: 0.15520916879177094, Accuracy: 0.6542900232598186\n",
      "Iteration: 1600, Loss: 0.15694813430309296, Accuracy: 0.6562293916940689\n",
      "Iteration: 1664, Loss: 0.17875367403030396, Accuracy: 0.6579008735716343\n",
      "Iteration: 1728, Loss: 0.15337751805782318, Accuracy: 0.6623694356530905\n",
      "Iteration: 1792, Loss: 0.19356121122837067, Accuracy: 0.6618894804269075\n",
      "Iteration: 1856, Loss: 0.14466355741024017, Accuracy: 0.6666159932501614\n",
      "Iteration: 1920, Loss: 0.1521625816822052, Accuracy: 0.6693624602630734\n",
      "Iteration: 1984, Loss: 0.14770269393920898, Accuracy: 0.6745843132957816\n",
      "Iteration: 2048, Loss: 0.1291239708662033, Accuracy: 0.6777168335393071\n",
      "Iteration: 2112, Loss: 0.18745911121368408, Accuracy: 0.6775272935628891\n",
      "Iteration: 2176, Loss: 0.18918029963970184, Accuracy: 0.6806626338511705\n",
      "Iteration: 2240, Loss: 0.13270865380764008, Accuracy: 0.6858526095747948\n",
      "Iteration: 2304, Loss: 0.18570204079151154, Accuracy: 0.686944711022079\n",
      "Iteration: 2368, Loss: 0.10888678580522537, Accuracy: 0.6900509176775813\n",
      "Iteration: 2432, Loss: 0.19205217063426971, Accuracy: 0.6942946808412671\n",
      "Iteration: 2496, Loss: 0.15470831096172333, Accuracy: 0.6950629048515111\n",
      "Iteration: 2560, Loss: 0.10548773407936096, Accuracy: 0.6963298523332924\n",
      "Iteration: 2624, Loss: 0.17874939739704132, Accuracy: 0.6982930162921548\n",
      "Iteration: 2688, Loss: 0.11290910094976425, Accuracy: 0.7019393453374505\n",
      "Iteration: 2752, Loss: 0.09886476397514343, Accuracy: 0.7020132981706411\n",
      "Iteration: 2816, Loss: 0.09968624264001846, Accuracy: 0.7073572208173573\n",
      "Iteration: 2880, Loss: 0.16397573053836823, Accuracy: 0.7102550019044429\n",
      "Iteration: 2944, Loss: 0.09470853954553604, Accuracy: 0.7109483384992927\n",
      "Iteration: 3008, Loss: 0.1600581407546997, Accuracy: 0.7123430781066418\n",
      "Iteration: 3072, Loss: 0.08102061599493027, Accuracy: 0.7147506338078529\n",
      "Iteration: 3136, Loss: 0.09033829718828201, Accuracy: 0.71160902781412\n",
      "Iteration: 3200, Loss: 0.13763149082660675, Accuracy: 0.7160210984293371\n",
      "Iteration: 3264, Loss: 0.08984062820672989, Accuracy: 0.7160908954683691\n",
      "Iteration: 3328, Loss: 0.0987417995929718, Accuracy: 0.7228434265125543\n",
      "Iteration: 3392, Loss: 0.16156868636608124, Accuracy: 0.7220762802753597\n",
      "Iteration: 3456, Loss: 0.08244544267654419, Accuracy: 0.721088275546208\n",
      "Iteration: 3520, Loss: 0.1542639285326004, Accuracy: 0.7169073207769543\n",
      "Iteration: 3584, Loss: 0.08959604054689407, Accuracy: 0.7214692137204111\n",
      "Iteration: 3648, Loss: 0.09413991123437881, Accuracy: 0.7316993367858231\n",
      "Iteration: 3712, Loss: 0.14280277490615845, Accuracy: 0.7268805596977472\n",
      "Iteration: 3776, Loss: 0.09870927780866623, Accuracy: 0.7302746765781194\n",
      "Iteration: 3840, Loss: 0.15517370402812958, Accuracy: 0.724008641205728\n",
      "Iteration: 3904, Loss: 0.14573216438293457, Accuracy: 0.7363254597876221\n",
      "Iteration: 3968, Loss: 0.12115132063627243, Accuracy: 0.7351652316283435\n",
      "Iteration: 4032, Loss: 0.13632172346115112, Accuracy: 0.7401871078182012\n",
      "Iteration: 4096, Loss: 0.1500822752714157, Accuracy: 0.7348035671748221\n",
      "Iteration: 4160, Loss: 0.0835358276963234, Accuracy: 0.7365106216166168\n",
      "Iteration: 4224, Loss: 0.11620816588401794, Accuracy: 0.7352137733250856\n",
      "Iteration: 4288, Loss: 0.11601541191339493, Accuracy: 0.7458029477857053\n",
      "Iteration: 4352, Loss: 0.19796015322208405, Accuracy: 0.7414334935601801\n",
      "Iteration: 4416, Loss: 0.12692402303218842, Accuracy: 0.7468554058577865\n",
      "Iteration: 4480, Loss: 0.10263258218765259, Accuracy: 0.7433783782180399\n",
      "Iteration: 4544, Loss: 0.06600180268287659, Accuracy: 0.7498111370950937\n",
      "Iteration: 4608, Loss: 0.20680372416973114, Accuracy: 0.7500650191213936\n",
      "Iteration: 4672, Loss: 0.06560744345188141, Accuracy: 0.7518232071306556\n",
      "Iteration: 4736, Loss: 0.10513629764318466, Accuracy: 0.752557325642556\n",
      "Iteration: 4800, Loss: 0.07957548648118973, Accuracy: 0.7499962232541293\n",
      "Iteration: 4864, Loss: 0.08057332038879395, Accuracy: 0.7569478256627917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4928, Loss: 0.10365218669176102, Accuracy: 0.7545927793253213\n",
      "Iteration: 4992, Loss: 0.11436798423528671, Accuracy: 0.7563153924420476\n",
      "Iteration: 5056, Loss: 0.10012602061033249, Accuracy: 0.7566137367393821\n",
      "Iteration: 5120, Loss: 0.06942237913608551, Accuracy: 0.7567596787121147\n",
      "Iteration: 5184, Loss: 0.07086598873138428, Accuracy: 0.7691727371420711\n",
      "Iteration: 5248, Loss: 0.12734389305114746, Accuracy: 0.7653907295316458\n",
      "Iteration: 5312, Loss: 0.12206030637025833, Accuracy: 0.7687530270777643\n",
      "Iteration: 5376, Loss: 0.11677303165197372, Accuracy: 0.7724628506693989\n",
      "Iteration: 5440, Loss: 0.055017706006765366, Accuracy: 0.7711248963605613\n",
      "Iteration: 5504, Loss: 0.09061533212661743, Accuracy: 0.7712450944818556\n",
      "Iteration: 5568, Loss: 0.11742138862609863, Accuracy: 0.7725051348097622\n",
      "Iteration: 5632, Loss: 0.058955952525138855, Accuracy: 0.76970727997832\n",
      "Iteration: 5696, Loss: 0.1096753478050232, Accuracy: 0.7780155863147229\n",
      "Iteration: 5760, Loss: 0.10816207528114319, Accuracy: 0.7790249541867524\n",
      "Iteration: 5824, Loss: 0.09397762268781662, Accuracy: 0.782823664136231\n",
      "Iteration: 5888, Loss: 0.07968078553676605, Accuracy: 0.7772484377492219\n",
      "Iteration: 5952, Loss: 0.11183544993400574, Accuracy: 0.7839252091944218\n",
      "Iteration: 6016, Loss: 0.03178342059254646, Accuracy: 0.7824206560617313\n",
      "Iteration: 6080, Loss: 0.0957493782043457, Accuracy: 0.782605660147965\n",
      "Iteration: 6144, Loss: 0.04249793291091919, Accuracy: 0.782796120387502\n",
      "Iteration: 6208, Loss: 0.10976164788007736, Accuracy: 0.7809484606841579\n",
      "Iteration: 6272, Loss: 0.07949548214673996, Accuracy: 0.7978431491646916\n",
      "Iteration: 6336, Loss: 0.09197690337896347, Accuracy: 0.7895708525320515\n",
      "Iteration: 6400, Loss: 0.09676406532526016, Accuracy: 0.790220063412562\n",
      "Iteration: 6464, Loss: 0.09191726893186569, Accuracy: 0.7937976580578834\n",
      "Iteration: 6528, Loss: 0.04260735213756561, Accuracy: 0.8016374352155253\n",
      "Iteration: 6592, Loss: 0.022338783368468285, Accuracy: 0.7986954513471574\n",
      "Iteration: 6656, Loss: 0.1026759147644043, Accuracy: 0.8077206377638504\n",
      "Iteration: 6720, Loss: 0.09061325341463089, Accuracy: 0.8127728039398789\n",
      "Iteration: 6784, Loss: 0.03833462670445442, Accuracy: 0.8104465560754761\n",
      "Iteration: 6848, Loss: 0.09056676179170609, Accuracy: 0.8113288116874173\n",
      "Iteration: 6912, Loss: 0.015819936990737915, Accuracy: 0.8092605069978163\n",
      "Iteration: 6976, Loss: 0.08780727535486221, Accuracy: 0.8191804370144382\n",
      "Iteration: 7040, Loss: 0.03217281773686409, Accuracy: 0.8219289830885828\n",
      "Iteration: 7104, Loss: 0.021085010841488838, Accuracy: 0.8230266738682985\n",
      "Iteration: 7168, Loss: 0.035218581557273865, Accuracy: 0.8257704391144216\n",
      "Iteration: 7232, Loss: 0.09230121225118637, Accuracy: 0.8162429685471579\n",
      "Iteration: 7296, Loss: 0.0910789743065834, Accuracy: 0.8253219412872568\n",
      "Iteration: 7360, Loss: 0.09046144038438797, Accuracy: 0.8306613948661834\n",
      "Iteration: 7424, Loss: 0.10141948610544205, Accuracy: 0.8275181849021465\n",
      "Iteration: 7488, Loss: 0.010359452106058598, Accuracy: 0.8263021105667576\n",
      "Iteration: 7552, Loss: 0.09467118233442307, Accuracy: 0.8273321510059759\n",
      "Iteration: 7616, Loss: 0.02231179177761078, Accuracy: 0.8310340768657625\n",
      "Iteration: 7680, Loss: 0.02146240323781967, Accuracy: 0.8386568420100957\n",
      "Iteration: 7744, Loss: 0.019324587658047676, Accuracy: 0.8321273750625551\n",
      "Iteration: 7808, Loss: 0.09016566723585129, Accuracy: 0.8250988211948425\n",
      "Iteration: 7872, Loss: 0.08531451225280762, Accuracy: 0.8410840310389176\n",
      "Iteration: 7936, Loss: 0.08825460076332092, Accuracy: 0.843038315884769\n",
      "Iteration: 8000, Loss: 0.10793554782867432, Accuracy: 0.8435506282839924\n",
      "Iteration: 8064, Loss: 0.007002241909503937, Accuracy: 0.8377301711589098\n",
      "Iteration: 8128, Loss: 0.0925164446234703, Accuracy: 0.8438082014326937\n",
      "Iteration: 8192, Loss: 0.013238572515547276, Accuracy: 0.8455296952161007\n",
      "Iteration: 8256, Loss: 0.0063751693814992905, Accuracy: 0.8442435022443533\n",
      "Iteration: 8320, Loss: 0.0903705358505249, Accuracy: 0.8345416446099989\n",
      "Iteration: 8384, Loss: 0.08835172653198242, Accuracy: 0.8537306247162633\n",
      "Iteration: 8448, Loss: 0.005549760069698095, Accuracy: 0.8512425689259544\n",
      "Iteration: 8512, Loss: 0.08988871425390244, Accuracy: 0.849100339517463\n",
      "Iteration: 8576, Loss: 0.22854731976985931, Accuracy: 0.8444512747228146\n",
      "Iteration: 8640, Loss: 0.021504022181034088, Accuracy: 0.8531212863745168\n",
      "Iteration: 8704, Loss: 0.008359191007912159, Accuracy: 0.8510231544496492\n",
      "Iteration: 8768, Loss: 0.005151111166924238, Accuracy: 0.8518808668595739\n",
      "Iteration: 8832, Loss: 0.005134942475706339, Accuracy: 0.8592406366951764\n",
      "Iteration: 8896, Loss: 0.008113760501146317, Accuracy: 0.855576868809294\n",
      "Iteration: 8960, Loss: 0.01566428504884243, Accuracy: 0.8446211263653822\n",
      "Iteration: 9024, Loss: 0.09052330255508423, Accuracy: 0.8487582025118172\n",
      "Iteration: 9088, Loss: 0.08393383026123047, Accuracy: 0.853841339063365\n",
      "Iteration: 9152, Loss: 0.007118463981896639, Accuracy: 0.8542185062542558\n",
      "Iteration: 9216, Loss: 0.079341359436512, Accuracy: 0.8619258678518236\n",
      "Iteration: 9280, Loss: 0.08561775833368301, Accuracy: 0.8525457474170253\n",
      "Iteration: 9344, Loss: 0.09394166618585587, Accuracy: 0.8627794533385895\n",
      "Iteration: 9408, Loss: 0.08436170220375061, Accuracy: 0.8616683263098821\n",
      "Iteration: 9472, Loss: 0.08242934197187424, Accuracy: 0.8516377944033593\n",
      "Iteration: 9536, Loss: 0.07987017184495926, Accuracy: 0.8668454328435473\n",
      "Iteration: 9600, Loss: 0.0032462086528539658, Accuracy: 0.8674525565002114\n",
      "Iteration: 9664, Loss: 0.07941964268684387, Accuracy: 0.8624336080974899\n",
      "Iteration: 9728, Loss: 0.02066178061068058, Accuracy: 0.8644707475905307\n",
      "Iteration: 9792, Loss: 0.00568353570997715, Accuracy: 0.8688065709429793\n",
      "Iteration: 9856, Loss: 0.0033023811411112547, Accuracy: 0.8621951859095134\n",
      "Iteration: 9920, Loss: 0.006000249180942774, Accuracy: 0.8621193702565506\n",
      "Iteration: 9984, Loss: 0.007978945039212704, Accuracy: 0.8690034040482715\n",
      "Iteration: 10048, Loss: 0.09385029226541519, Accuracy: 0.8659389488748275\n",
      "Iteration: 10112, Loss: 0.00568191846832633, Accuracy: 0.8673805179423653\n",
      "Iteration: 10176, Loss: 0.006685700733214617, Accuracy: 0.8732591650332324\n",
      "Iteration: 10240, Loss: 0.08976120501756668, Accuracy: 0.8719035750254989\n",
      "Iteration: 10304, Loss: 0.0964910015463829, Accuracy: 0.8725411941413768\n",
      "Iteration: 10368, Loss: 0.002656330121681094, Accuracy: 0.865893893642351\n",
      "Iteration: 10432, Loss: 0.007468201220035553, Accuracy: 0.8672760199406184\n",
      "Iteration: 10496, Loss: 0.07816208153963089, Accuracy: 0.8686020716559142\n",
      "Iteration: 10560, Loss: 0.07865020632743835, Accuracy: 0.8751489084679633\n",
      "Iteration: 10624, Loss: 0.07188352942466736, Accuracy: 0.8712313325959258\n",
      "Iteration: 10688, Loss: 0.007786915171891451, Accuracy: 0.8734040802228265\n",
      "Iteration: 10752, Loss: 0.006105710286647081, Accuracy: 0.872974572237581\n",
      "Iteration: 10816, Loss: 0.0074394517578184605, Accuracy: 0.8745179158868268\n",
      "Iteration: 10880, Loss: 0.005647813901305199, Accuracy: 0.8703564488678239\n",
      "Iteration: 10944, Loss: 0.07996473461389542, Accuracy: 0.8737163861515\n",
      "Iteration: 11008, Loss: 0.0036847467999905348, Accuracy: 0.869026257598307\n",
      "Iteration: 11072, Loss: 0.07858856767416, Accuracy: 0.8734672134742141\n",
      "Iteration: 11136, Loss: 0.07006923854351044, Accuracy: 0.8743610574747436\n",
      "Iteration: 11200, Loss: 0.002029895083978772, Accuracy: 0.8729133200831711\n",
      "Iteration: 11264, Loss: 0.1627943366765976, Accuracy: 0.8727896508644335\n",
      "Iteration: 11328, Loss: 0.07454977184534073, Accuracy: 0.8712651653913781\n",
      "Iteration: 11392, Loss: 0.0033407174050807953, Accuracy: 0.8764478745288216\n",
      "Iteration: 11456, Loss: 0.07258323580026627, Accuracy: 0.8774805387365632\n",
      "Iteration: 11520, Loss: 0.09021999686956406, Accuracy: 0.8767665258783381\n",
      "Iteration: 11584, Loss: 0.06756037473678589, Accuracy: 0.8769013395358343\n",
      "Iteration: 11648, Loss: 0.004281741101294756, Accuracy: 0.8748036558681633\n",
      "Iteration: 11712, Loss: 0.07237043231725693, Accuracy: 0.8785677898558788\n",
      "Iteration: 11776, Loss: 0.09856734424829483, Accuracy: 0.8740857554948889\n",
      "Iteration: 11840, Loss: 0.08949755877256393, Accuracy: 0.8793660825467668\n",
      "Iteration: 11904, Loss: 0.006647031754255295, Accuracy: 0.8802961758337915\n",
      "Iteration: 11968, Loss: 0.09588876366615295, Accuracy: 0.8771394561917987\n",
      "Iteration: 12032, Loss: 0.07313301414251328, Accuracy: 0.8799725016579032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 12096, Loss: 0.0019212925108149648, Accuracy: 0.8796734974021092\n",
      "Iteration: 12160, Loss: 0.0736701488494873, Accuracy: 0.8824833665566985\n",
      "Iteration: 12224, Loss: 0.0029368968680500984, Accuracy: 0.8839767136669252\n",
      "Iteration: 12288, Loss: 0.09842904657125473, Accuracy: 0.8820323775580619\n",
      "Iteration: 12352, Loss: 0.006741931661963463, Accuracy: 0.8866506880149245\n",
      "Iteration: 12416, Loss: 0.06390071660280228, Accuracy: 0.8821459606115241\n",
      "Iteration: 12480, Loss: 0.0761837363243103, Accuracy: 0.8753650404687505\n",
      "Iteration: 12544, Loss: 0.09146595001220703, Accuracy: 0.8832437231030781\n",
      "Iteration: 12608, Loss: 0.09904059767723083, Accuracy: 0.8806077265180647\n",
      "Iteration: 12672, Loss: 0.05712135136127472, Accuracy: 0.8807133218506351\n",
      "Iteration: 12736, Loss: 0.07376234978437424, Accuracy: 0.8769620112725534\n",
      "Iteration: 12800, Loss: 0.06647535413503647, Accuracy: 0.883775215188507\n",
      "Iteration: 12864, Loss: 0.05547553673386574, Accuracy: 0.8851196379109751\n",
      "Iteration: 12928, Loss: 0.1023683249950409, Accuracy: 0.8857599392940756\n",
      "Iteration: 12992, Loss: 0.07076957076787949, Accuracy: 0.8886652855726425\n",
      "Iteration: 13056, Loss: 0.06488179415464401, Accuracy: 0.8801459240203258\n",
      "Iteration: 13120, Loss: 0.07574895769357681, Accuracy: 0.8879926850786433\n",
      "Iteration: 13184, Loss: 0.06696833670139313, Accuracy: 0.8874565864098258\n",
      "Iteration: 13248, Loss: 0.0011063673300668597, Accuracy: 0.8828413698938675\n",
      "Iteration: 13312, Loss: 0.013406540267169476, Accuracy: 0.8840140463144053\n",
      "Iteration: 13376, Loss: 0.0011749465484172106, Accuracy: 0.878617462440161\n",
      "Iteration: 13440, Loss: 0.16316793859004974, Accuracy: 0.8783441122213844\n",
      "Iteration: 13504, Loss: 0.0022748077753931284, Accuracy: 0.8838764189858921\n",
      "Iteration: 13568, Loss: 0.0775703713297844, Accuracy: 0.8867470152035821\n",
      "Iteration: 13632, Loss: 0.001489911344833672, Accuracy: 0.8860771657491568\n",
      "Iteration: 13696, Loss: 0.05430877208709717, Accuracy: 0.8812852849951014\n",
      "Iteration: 13760, Loss: 0.05667733773589134, Accuracy: 0.8842782273713965\n",
      "Iteration: 13824, Loss: 0.0032283670734614134, Accuracy: 0.8923311996913981\n",
      "Iteration: 13888, Loss: 0.0031914093997329473, Accuracy: 0.8920985729491804\n",
      "Iteration: 13952, Loss: 0.11259493976831436, Accuracy: 0.8887027694727294\n",
      "Iteration: 14016, Loss: 0.0027037460822612047, Accuracy: 0.8946847089391667\n",
      "Iteration: 14080, Loss: 0.005971146281808615, Accuracy: 0.8901290569920093\n",
      "Iteration: 14144, Loss: 0.0831460952758789, Accuracy: 0.8938067317358218\n",
      "Iteration: 14208, Loss: 0.005432437639683485, Accuracy: 0.89148871274665\n",
      "Iteration: 14272, Loss: 0.002143110381439328, Accuracy: 0.8955682486703154\n",
      "Iteration: 14336, Loss: 0.01115322019904852, Accuracy: 0.8925412469252478\n",
      "Iteration: 14400, Loss: 0.047704096883535385, Accuracy: 0.8943972028500866\n",
      "Iteration: 14464, Loss: 0.0017949497560039163, Accuracy: 0.9006745736405719\n",
      "Iteration: 14528, Loss: 0.01208201702684164, Accuracy: 0.9019419982796535\n",
      "Iteration: 14592, Loss: 0.0016667459858581424, Accuracy: 0.9045580392994452\n",
      "Iteration: 14656, Loss: 0.0035636883694678545, Accuracy: 0.9101560626877472\n",
      "Iteration: 14720, Loss: 0.003286331659182906, Accuracy: 0.9041917673603166\n",
      "Iteration: 14784, Loss: 0.0565020777285099, Accuracy: 0.9113378382753581\n",
      "Iteration: 14848, Loss: 0.043333228677511215, Accuracy: 0.9108991045795847\n",
      "Iteration: 14912, Loss: 0.0017641541780903935, Accuracy: 0.9102361427503638\n",
      "Iteration: 14976, Loss: 0.04181881248950958, Accuracy: 0.9123993687389884\n",
      "Iteration: 15040, Loss: 0.0016487817047163844, Accuracy: 0.9189062585064676\n",
      "Iteration: 15104, Loss: 0.0015586167573928833, Accuracy: 0.9130352149077225\n",
      "Iteration: 15168, Loss: 0.03691483661532402, Accuracy: 0.918305534083629\n",
      "Iteration: 15232, Loss: 0.004181106109172106, Accuracy: 0.9153823053347878\n",
      "Iteration: 15296, Loss: 0.0018204051302745938, Accuracy: 0.9189166373398621\n",
      "Iteration: 15360, Loss: 0.03359905257821083, Accuracy: 0.9224160949233919\n",
      "Iteration: 15424, Loss: 0.012801069766283035, Accuracy: 0.9211899375659414\n",
      "Iteration: 15488, Loss: 0.012423788197338581, Accuracy: 0.9294549572950928\n",
      "Iteration: 15552, Loss: 0.002249292330816388, Accuracy: 0.9253228733432479\n",
      "Iteration: 15616, Loss: 0.004402715712785721, Accuracy: 0.926809705037158\n",
      "Iteration: 15680, Loss: 0.021274784579873085, Accuracy: 0.9285206159984227\n",
      "Iteration: 15744, Loss: 0.0005647064535878599, Accuracy: 0.9292005392198917\n",
      "Iteration: 15808, Loss: 0.010813925415277481, Accuracy: 0.9294556854583789\n",
      "Iteration: 15872, Loss: 0.009305021725594997, Accuracy: 0.934426113468362\n",
      "Iteration: 15936, Loss: 0.001959111075848341, Accuracy: 0.9333027479733573\n",
      "Iteration: 16000, Loss: 0.016537172719836235, Accuracy: 0.930757193127647\n",
      "Iteration: 16064, Loss: 0.000554120633751154, Accuracy: 0.9385511477448745\n",
      "Iteration: 16128, Loss: 0.0020707433577626944, Accuracy: 0.9259622553217923\n",
      "Iteration: 16192, Loss: 0.003236527321860194, Accuracy: 0.9333432819694281\n",
      "Iteration: 16256, Loss: 0.01528969407081604, Accuracy: 0.9391960146313068\n",
      "Iteration: 16320, Loss: 0.014614317566156387, Accuracy: 0.9274866060295608\n",
      "Iteration: 16384, Loss: 0.0005252690752968192, Accuracy: 0.9368918700056383\n",
      "Iteration: 16448, Loss: 0.0008055375074036419, Accuracy: 0.9377371037116973\n",
      "Iteration: 16512, Loss: 0.0023911490570753813, Accuracy: 0.9415146456740331\n",
      "Iteration: 16576, Loss: 0.010984105058014393, Accuracy: 0.9436606622766703\n",
      "Iteration: 16640, Loss: 0.004983470309525728, Accuracy: 0.939500747655984\n",
      "Iteration: 16704, Loss: 0.011487786658108234, Accuracy: 0.9452458911400754\n",
      "Iteration: 16768, Loss: 0.0033903352450579405, Accuracy: 0.9446106635441538\n",
      "Iteration: 16832, Loss: 0.0034486122895032167, Accuracy: 0.9491618556930916\n",
      "Iteration: 16896, Loss: 0.005229082424193621, Accuracy: 0.9470042621396715\n",
      "Iteration: 16960, Loss: 0.002128078369423747, Accuracy: 0.947281260319869\n",
      "Iteration: 17024, Loss: 0.00505035137757659, Accuracy: 0.9498388078936841\n",
      "Iteration: 17088, Loss: 0.009230151772499084, Accuracy: 0.9498066618252778\n",
      "Iteration: 17152, Loss: 0.0036124566104263067, Accuracy: 0.9533072815538617\n",
      "Iteration: 17216, Loss: 0.0008216938585974276, Accuracy: 0.9523389212845359\n",
      "Iteration: 17280, Loss: 0.1954798698425293, Accuracy: 0.9500022055144655\n",
      "Iteration: 17344, Loss: 0.009930728934705257, Accuracy: 0.9515963159064995\n",
      "Iteration: 17408, Loss: 0.007396945264190435, Accuracy: 0.9553320869454183\n",
      "Iteration: 17472, Loss: 0.001649233396165073, Accuracy: 0.9530285766959423\n",
      "Iteration: 17536, Loss: 0.004553676582872868, Accuracy: 0.9483185074350331\n",
      "Iteration: 17600, Loss: 0.008415286429226398, Accuracy: 0.9534183218056569\n",
      "Iteration: 17664, Loss: 0.005420466419309378, Accuracy: 0.9566935617913259\n",
      "Iteration: 17728, Loss: 0.00041806712397374213, Accuracy: 0.95230683866248\n",
      "Iteration: 17792, Loss: 0.002874563215300441, Accuracy: 0.9561127503984608\n",
      "Iteration: 17856, Loss: 0.0018739016959443688, Accuracy: 0.9587240140681388\n",
      "Iteration: 17920, Loss: 0.0013024407671764493, Accuracy: 0.9610386800341075\n",
      "Iteration: 17984, Loss: 0.0023350536357611418, Accuracy: 0.9601294188032625\n",
      "Iteration: 18048, Loss: 0.004925608169287443, Accuracy: 0.9532315938849933\n",
      "Iteration: 18112, Loss: 0.007051354739814997, Accuracy: 0.9526244120061165\n",
      "Iteration: 18176, Loss: 0.005784479435533285, Accuracy: 0.9519554069120204\n",
      "Iteration: 18240, Loss: 0.00022918851755093783, Accuracy: 0.9609328423248371\n",
      "Iteration: 18304, Loss: 0.0014588717604056, Accuracy: 0.9602985135425115\n",
      "Iteration: 18368, Loss: 0.00022380474547389895, Accuracy: 0.9614565186493564\n",
      "Iteration: 18432, Loss: 0.0001259781129192561, Accuracy: 0.9612310486991191\n",
      "Iteration: 18496, Loss: 0.0006803732831031084, Accuracy: 0.9603143103013281\n",
      "Iteration: 18560, Loss: 0.005369772668927908, Accuracy: 0.9527209378429689\n",
      "Iteration: 18624, Loss: 0.001546921324916184, Accuracy: 0.9620378199033439\n",
      "Iteration: 18688, Loss: 0.0012585384538397193, Accuracy: 0.966510750062298\n",
      "Iteration: 18752, Loss: 0.0022523493971675634, Accuracy: 0.9658876699977554\n",
      "Iteration: 18816, Loss: 0.0013846815563738346, Accuracy: 0.9668025908467826\n",
      "Iteration: 18880, Loss: 0.0018481112783774734, Accuracy: 0.96822633134434\n",
      "Iteration: 18944, Loss: 0.0014732995769008994, Accuracy: 0.9674200343724806\n",
      "Iteration: 19008, Loss: 0.0034881478641182184, Accuracy: 0.9663592939468799\n",
      "Iteration: 19072, Loss: 0.002070765709504485, Accuracy: 0.968246206335607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 19136, Loss: 0.0010394483106210828, Accuracy: 0.9678016195539385\n",
      "Iteration: 19200, Loss: 0.0009945371421054006, Accuracy: 0.9617300682511996\n",
      "Iteration: 19264, Loss: 0.001205435604788363, Accuracy: 0.9682659970640088\n",
      "Iteration: 19328, Loss: 0.0013089976273477077, Accuracy: 0.9676123769240803\n",
      "Iteration: 19392, Loss: 0.00021468743216246367, Accuracy: 0.9684902580047492\n",
      "Iteration: 19456, Loss: 0.0013017256278544664, Accuracy: 0.9699033846554812\n",
      "Iteration: 19520, Loss: 0.0031685810536146164, Accuracy: 0.970772706605203\n",
      "Saved fullModel_dr[1]_replicate3.model\n",
      "Saved W_dr[1]_replicate3.p\n",
      "1 0.9947916666666666 [1.0, 0.984375, 1.0]\n",
      "Saved w_dr[1]_replicate3.p\n",
      "Replicate 3 completed\n",
      "Time elapsed: 67.921875 seconds\n",
      "Iteration: 64, Loss: 0.24437664449214935, Accuracy: 0.5023696767166257\n",
      "Iteration: 128, Loss: 0.23747186362743378, Accuracy: 0.5149901122786105\n",
      "Iteration: 192, Loss: 0.18117676675319672, Accuracy: 0.5464405938982964\n",
      "Iteration: 256, Loss: 0.19262562692165375, Accuracy: 0.584282049909234\n",
      "Iteration: 320, Loss: 0.18006764352321625, Accuracy: 0.6068984041921794\n",
      "Iteration: 384, Loss: 0.17544303834438324, Accuracy: 0.6193932848982513\n",
      "Iteration: 448, Loss: 0.18616783618927002, Accuracy: 0.62630156846717\n",
      "Iteration: 512, Loss: 0.16261260211467743, Accuracy: 0.6329701202921569\n",
      "Iteration: 576, Loss: 0.16266751289367676, Accuracy: 0.6365506486035883\n",
      "Iteration: 640, Loss: 0.16401737928390503, Accuracy: 0.6399610727094114\n",
      "Iteration: 704, Loss: 0.16543935239315033, Accuracy: 0.6444136220961809\n",
      "Iteration: 768, Loss: 0.1403491050004959, Accuracy: 0.6456196377985179\n",
      "Iteration: 832, Loss: 0.17268650233745575, Accuracy: 0.6508153756149113\n",
      "Iteration: 896, Loss: 0.14623858034610748, Accuracy: 0.6516953017562628\n",
      "Iteration: 960, Loss: 0.1704188734292984, Accuracy: 0.6540983188897371\n",
      "Iteration: 1024, Loss: 0.138229101896286, Accuracy: 0.6585761103779078\n",
      "Iteration: 1088, Loss: 0.19490301609039307, Accuracy: 0.6619557957164943\n",
      "Iteration: 1152, Loss: 0.15955500304698944, Accuracy: 0.6629213602282107\n",
      "Iteration: 1216, Loss: 0.1950223445892334, Accuracy: 0.6694146208465099\n",
      "Iteration: 1280, Loss: 0.1913629174232483, Accuracy: 0.676352615468204\n",
      "Iteration: 1344, Loss: 0.1307423710823059, Accuracy: 0.6790068531408906\n",
      "Iteration: 1408, Loss: 0.12401944398880005, Accuracy: 0.6846739533357322\n",
      "Iteration: 1472, Loss: 0.12129590660333633, Accuracy: 0.6917772404849529\n",
      "Iteration: 1536, Loss: 0.10959628969430923, Accuracy: 0.6916382305789739\n",
      "Iteration: 1600, Loss: 0.1435709446668625, Accuracy: 0.7006590021774173\n",
      "Iteration: 1664, Loss: 0.13702751696109772, Accuracy: 0.7108124569058418\n",
      "Iteration: 1728, Loss: 0.10741069167852402, Accuracy: 0.7241355881560594\n",
      "Iteration: 1792, Loss: 0.088238924741745, Accuracy: 0.7333667632192373\n",
      "Iteration: 1856, Loss: 0.08685770630836487, Accuracy: 0.7403624833095819\n",
      "Iteration: 1920, Loss: 0.08438000082969666, Accuracy: 0.7477613899391145\n",
      "Iteration: 1984, Loss: 0.0829242467880249, Accuracy: 0.7530713411979377\n",
      "Iteration: 2048, Loss: 0.09751860052347183, Accuracy: 0.762313456274569\n",
      "Iteration: 2112, Loss: 0.0826776921749115, Accuracy: 0.7672953619621694\n",
      "Iteration: 2176, Loss: 0.06269221752882004, Accuracy: 0.7735717678442597\n",
      "Iteration: 2240, Loss: 0.081092968583107, Accuracy: 0.7733582553919405\n",
      "Iteration: 2304, Loss: 0.11083793640136719, Accuracy: 0.7794092916883528\n",
      "Iteration: 2368, Loss: 0.06637642532587051, Accuracy: 0.7870529303327203\n",
      "Iteration: 2432, Loss: 0.07303056120872498, Accuracy: 0.7913377790246159\n",
      "Iteration: 2496, Loss: 0.08240742236375809, Accuracy: 0.793440958019346\n",
      "Iteration: 2560, Loss: 0.06928067654371262, Accuracy: 0.7938689936418086\n",
      "Iteration: 2624, Loss: 0.08755302429199219, Accuracy: 0.7943618709687144\n",
      "Iteration: 2688, Loss: 0.0881100594997406, Accuracy: 0.7995232415851206\n",
      "Iteration: 2752, Loss: 0.10933849215507507, Accuracy: 0.8022906980477273\n",
      "Iteration: 2816, Loss: 0.0861375704407692, Accuracy: 0.8035153546370566\n",
      "Iteration: 2880, Loss: 0.05721540376543999, Accuracy: 0.8063675144221634\n",
      "Iteration: 2944, Loss: 0.05583475902676582, Accuracy: 0.808856229763478\n",
      "Iteration: 3008, Loss: 0.11191005259752274, Accuracy: 0.8132976675406098\n",
      "Iteration: 3072, Loss: 0.05420459806919098, Accuracy: 0.8100512032397091\n",
      "Iteration: 3136, Loss: 0.09171468019485474, Accuracy: 0.814326140563935\n",
      "Iteration: 3200, Loss: 0.07244419306516647, Accuracy: 0.8103925501927733\n",
      "Iteration: 3264, Loss: 0.03516775742173195, Accuracy: 0.8215257227420807\n",
      "Iteration: 3328, Loss: 0.03216530382633209, Accuracy: 0.8211086059454829\n",
      "Iteration: 3392, Loss: 0.04463362693786621, Accuracy: 0.8233342990279198\n",
      "Iteration: 3456, Loss: 0.09546667337417603, Accuracy: 0.8249963163398206\n",
      "Iteration: 3520, Loss: 0.06855268031358719, Accuracy: 0.8280007264111191\n",
      "Iteration: 3584, Loss: 0.07719557732343674, Accuracy: 0.827492157346569\n",
      "Iteration: 3648, Loss: 0.08567184209823608, Accuracy: 0.8280236470745876\n",
      "Iteration: 3712, Loss: 0.07251375913619995, Accuracy: 0.8334691489581019\n",
      "Iteration: 3776, Loss: 0.03935543820261955, Accuracy: 0.8306182688102126\n",
      "Iteration: 3840, Loss: 0.08651422709226608, Accuracy: 0.8340481561608613\n",
      "Iteration: 3904, Loss: 0.05759849026799202, Accuracy: 0.836297994479537\n",
      "Iteration: 3968, Loss: 0.06880452483892441, Accuracy: 0.8368167952867225\n",
      "Iteration: 4032, Loss: 0.0636196956038475, Accuracy: 0.8372150924988091\n",
      "Iteration: 4096, Loss: 0.02903541922569275, Accuracy: 0.8318788767792284\n",
      "Iteration: 4160, Loss: 0.03812720999121666, Accuracy: 0.8389793464448303\n",
      "Iteration: 4224, Loss: 0.029430413618683815, Accuracy: 0.8430226282216609\n",
      "Iteration: 4288, Loss: 0.029338687658309937, Accuracy: 0.846002007368952\n",
      "Iteration: 4352, Loss: 0.02307579480111599, Accuracy: 0.8494140662951395\n",
      "Iteration: 4416, Loss: 0.02040824107825756, Accuracy: 0.8482909882441163\n",
      "Iteration: 4480, Loss: 0.10674125701189041, Accuracy: 0.8470811619190499\n",
      "Iteration: 4544, Loss: 0.0841187834739685, Accuracy: 0.8469354283297434\n",
      "Iteration: 4608, Loss: 0.041010525077581406, Accuracy: 0.8539347342448309\n",
      "Iteration: 4672, Loss: 0.024493591859936714, Accuracy: 0.8508398439735174\n",
      "Iteration: 4736, Loss: 0.08062081784009933, Accuracy: 0.8586469973670319\n",
      "Iteration: 4800, Loss: 0.07073009014129639, Accuracy: 0.8581829607719555\n",
      "Iteration: 4864, Loss: 0.09232041239738464, Accuracy: 0.8553145042387769\n",
      "Iteration: 4928, Loss: 0.05007588490843773, Accuracy: 0.8592428385745734\n",
      "Iteration: 4992, Loss: 0.07311729341745377, Accuracy: 0.8590610962128267\n",
      "Iteration: 5056, Loss: 0.06341861188411713, Accuracy: 0.8595318313455209\n",
      "Iteration: 5120, Loss: 0.013497627340257168, Accuracy: 0.866838276386261\n",
      "Iteration: 5184, Loss: 0.02229088358581066, Accuracy: 0.8685720610665157\n",
      "Iteration: 5248, Loss: 0.018278293311595917, Accuracy: 0.864049399504438\n",
      "Iteration: 5312, Loss: 0.1432723104953766, Accuracy: 0.8669136430835351\n",
      "Iteration: 5376, Loss: 0.09709420055150986, Accuracy: 0.8582776943221688\n",
      "Iteration: 5440, Loss: 0.017111895605921745, Accuracy: 0.8680814376566559\n",
      "Iteration: 5504, Loss: 0.010522154159843922, Accuracy: 0.8716766977449879\n",
      "Iteration: 5568, Loss: 0.010344299487769604, Accuracy: 0.8766365339979529\n",
      "Iteration: 5632, Loss: 0.058073967695236206, Accuracy: 0.8780875543598086\n",
      "Iteration: 5696, Loss: 0.03892604634165764, Accuracy: 0.8742504605324939\n",
      "Iteration: 5760, Loss: 0.015116834081709385, Accuracy: 0.8802654442260973\n",
      "Iteration: 5824, Loss: 0.04871358349919319, Accuracy: 0.8871592641808093\n",
      "Iteration: 5888, Loss: 0.026920698583126068, Accuracy: 0.8859709055395797\n",
      "Iteration: 5952, Loss: 0.032983168959617615, Accuracy: 0.888532847398892\n",
      "Iteration: 6016, Loss: 0.006362162996083498, Accuracy: 0.8898956665070727\n",
      "Iteration: 6080, Loss: 0.02504720352590084, Accuracy: 0.893894532637205\n",
      "Iteration: 6144, Loss: 0.006295028608292341, Accuracy: 0.8931629018043168\n",
      "Iteration: 6208, Loss: 0.028862887993454933, Accuracy: 0.8961146830115467\n",
      "Iteration: 6272, Loss: 0.013730029575526714, Accuracy: 0.890439891605638\n",
      "Iteration: 6336, Loss: 0.013816135935485363, Accuracy: 0.9035344188450836\n",
      "Iteration: 6400, Loss: 0.008087852038443089, Accuracy: 0.9024154780199751\n",
      "Iteration: 6464, Loss: 0.029169699177145958, Accuracy: 0.907029380730819\n",
      "Iteration: 6528, Loss: 0.047173917293548584, Accuracy: 0.9080402305116877\n",
      "Iteration: 6592, Loss: 0.00594531511887908, Accuracy: 0.9052232194226235\n",
      "Iteration: 6656, Loss: 0.006163842976093292, Accuracy: 0.9123071956564672\n",
      "Iteration: 6720, Loss: 0.026916256174445152, Accuracy: 0.9141852491302416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 6784, Loss: 0.038006726652383804, Accuracy: 0.9044732343754731\n",
      "Iteration: 6848, Loss: 0.005673116073012352, Accuracy: 0.9171442699735053\n",
      "Iteration: 6912, Loss: 0.01309566106647253, Accuracy: 0.9170924034551717\n",
      "Iteration: 6976, Loss: 0.022787773981690407, Accuracy: 0.912111985089723\n",
      "Iteration: 7040, Loss: 0.014170792885124683, Accuracy: 0.9170407425262965\n",
      "Iteration: 7104, Loss: 0.002964074956253171, Accuracy: 0.9165243383031338\n",
      "Iteration: 7168, Loss: 0.012380372732877731, Accuracy: 0.9245174860116094\n",
      "Iteration: 7232, Loss: 0.0036993350367993116, Accuracy: 0.928177519061137\n",
      "Iteration: 7296, Loss: 0.004857620224356651, Accuracy: 0.9246241609216668\n",
      "Iteration: 7360, Loss: 0.019297247752547264, Accuracy: 0.9265496653388254\n",
      "Iteration: 7424, Loss: 0.005668934900313616, Accuracy: 0.926465725468006\n",
      "Iteration: 7488, Loss: 0.0031768325716257095, Accuracy: 0.9287125208065845\n",
      "Iteration: 7552, Loss: 0.00418136827647686, Accuracy: 0.9365574892726727\n",
      "Iteration: 7616, Loss: 0.01414093654602766, Accuracy: 0.9309231858351268\n",
      "Iteration: 7680, Loss: 0.022837435826659203, Accuracy: 0.9279236953007057\n",
      "Iteration: 7744, Loss: 0.004752545617520809, Accuracy: 0.9351864010095596\n",
      "Iteration: 7808, Loss: 0.027693867683410645, Accuracy: 0.9350480524008162\n",
      "Iteration: 7872, Loss: 0.004662719089537859, Accuracy: 0.9337016310309991\n",
      "Iteration: 7936, Loss: 0.0029744552448391914, Accuracy: 0.9299636706127785\n",
      "Iteration: 8000, Loss: 0.01668616384267807, Accuracy: 0.9331202459288761\n",
      "Iteration: 8064, Loss: 0.0035609398037195206, Accuracy: 0.9293312658846844\n",
      "Iteration: 8128, Loss: 0.0025380239821970463, Accuracy: 0.9388065941166133\n",
      "Iteration: 8192, Loss: 0.002457339083775878, Accuracy: 0.9418952789856121\n",
      "Iteration: 8256, Loss: 0.003449202748015523, Accuracy: 0.9406440671009477\n",
      "Iteration: 8320, Loss: 0.014540724456310272, Accuracy: 0.9477427166420966\n",
      "Iteration: 8384, Loss: 0.0022187400609254837, Accuracy: 0.9463901332637761\n",
      "Iteration: 8448, Loss: 0.009653067216277122, Accuracy: 0.9447857101913542\n",
      "Iteration: 8512, Loss: 0.0015989230014383793, Accuracy: 0.9471720297588035\n",
      "Iteration: 8576, Loss: 0.002293938770890236, Accuracy: 0.9511653657245915\n",
      "Iteration: 8640, Loss: 0.0012264203978702426, Accuracy: 0.9509296659380198\n",
      "Iteration: 8704, Loss: 0.0030938785057514906, Accuracy: 0.9453695885022171\n",
      "Iteration: 8768, Loss: 0.0011692028492689133, Accuracy: 0.9517161142721307\n",
      "Iteration: 8832, Loss: 0.001226267428137362, Accuracy: 0.9549473650986329\n",
      "Iteration: 8896, Loss: 0.001681688823737204, Accuracy: 0.9483026464295108\n",
      "Iteration: 8960, Loss: 0.0020940881222486496, Accuracy: 0.9509790743468329\n",
      "Iteration: 9024, Loss: 0.0010716812685132027, Accuracy: 0.9530011913448106\n",
      "Iteration: 9088, Loss: 0.001700492692179978, Accuracy: 0.9523247519391589\n",
      "Iteration: 9152, Loss: 0.0015748883597552776, Accuracy: 0.9575422871566843\n",
      "Iteration: 9216, Loss: 0.0010559214279055595, Accuracy: 0.9566539171501063\n",
      "Iteration: 9280, Loss: 0.0033333245664834976, Accuracy: 0.9543994907289743\n",
      "Iteration: 9344, Loss: 0.0011167104821652174, Accuracy: 0.9540739498916082\n",
      "Iteration: 9408, Loss: 0.007962689734995365, Accuracy: 0.955388411442982\n",
      "Iteration: 9472, Loss: 0.0008115878445096314, Accuracy: 0.9581903024227358\n",
      "Iteration: 9536, Loss: 0.0026102655101567507, Accuracy: 0.9609437690814957\n",
      "Iteration: 9600, Loss: 0.0010958150960505009, Accuracy: 0.9592528591165319\n",
      "Iteration: 9664, Loss: 0.0015678663039579988, Accuracy: 0.9608608899288811\n",
      "Iteration: 9728, Loss: 0.003339634044095874, Accuracy: 0.9606474991014693\n",
      "Iteration: 9792, Loss: 0.001267214654944837, Accuracy: 0.9608709768799599\n",
      "Iteration: 9856, Loss: 0.0010139329824596643, Accuracy: 0.9633735494862776\n",
      "Iteration: 9920, Loss: 0.005877071525901556, Accuracy: 0.963298214628594\n",
      "Iteration: 9984, Loss: 0.001092358841560781, Accuracy: 0.9607347454875708\n",
      "Iteration: 10048, Loss: 0.00332907703705132, Accuracy: 0.965393958002096\n",
      "Iteration: 10112, Loss: 0.0006482864264398813, Accuracy: 0.965663249255158\n",
      "Iteration: 10176, Loss: 0.0017370112473145127, Accuracy: 0.96455309598241\n",
      "Iteration: 10240, Loss: 0.0031529690604656935, Accuracy: 0.9663682213868015\n",
      "Iteration: 10304, Loss: 0.004562987480312586, Accuracy: 0.9581867010419955\n",
      "Iteration: 10368, Loss: 0.0005909647443331778, Accuracy: 0.9653249081748072\n",
      "Iteration: 10432, Loss: 0.0019067734247073531, Accuracy: 0.9650967919151299\n",
      "Iteration: 10496, Loss: 0.0007211500778794289, Accuracy: 0.9657320749829523\n",
      "Iteration: 10560, Loss: 0.0010220427066087723, Accuracy: 0.9695462452800712\n",
      "Iteration: 10624, Loss: 0.002318602055311203, Accuracy: 0.9668998406705214\n",
      "Iteration: 10688, Loss: 0.0008628310752101243, Accuracy: 0.9704870665154886\n",
      "Saved fullModel_dr[1]_replicate4.model\n",
      "Saved W_dr[1]_replicate4.p\n",
      "1 1.0 [1.0, 1.0, 1.0]\n",
      "Saved w_dr[1]_replicate4.p\n",
      "Replicate 4 completed\n",
      "Time elapsed: 79.71875 seconds\n",
      "Training for delay range [2]...\n",
      "Iteration: 64, Loss: 0.2512087821960449, Accuracy: 0.5024035801179707\n",
      "Iteration: 128, Loss: 0.23449523746967316, Accuracy: 0.5082252989523113\n",
      "Iteration: 192, Loss: 0.21424193680286407, Accuracy: 0.5431565176695585\n",
      "Iteration: 256, Loss: 0.1329406052827835, Accuracy: 0.5893638641573489\n",
      "Iteration: 320, Loss: 0.1695948839187622, Accuracy: 0.6116004567593336\n",
      "Iteration: 384, Loss: 0.16595721244812012, Accuracy: 0.6233383547514677\n",
      "Iteration: 448, Loss: 0.1754325032234192, Accuracy: 0.6315270401537418\n",
      "Iteration: 512, Loss: 0.1798141449689865, Accuracy: 0.6347509594634175\n",
      "Iteration: 576, Loss: 0.14766810834407806, Accuracy: 0.6388184358365834\n",
      "Iteration: 640, Loss: 0.1595263034105301, Accuracy: 0.6405035746283829\n",
      "Iteration: 704, Loss: 0.1678321808576584, Accuracy: 0.643699761480093\n",
      "Iteration: 768, Loss: 0.17518973350524902, Accuracy: 0.6454855571500957\n",
      "Iteration: 832, Loss: 0.16787512600421906, Accuracy: 0.6471594050526619\n",
      "Iteration: 896, Loss: 0.18339653313159943, Accuracy: 0.6486208690330386\n",
      "Iteration: 960, Loss: 0.18344746530056, Accuracy: 0.649463982321322\n",
      "Iteration: 1024, Loss: 0.1659878045320511, Accuracy: 0.6509574772790074\n",
      "Iteration: 1088, Loss: 0.11371350288391113, Accuracy: 0.6567478477954865\n",
      "Iteration: 1152, Loss: 0.14570866525173187, Accuracy: 0.6584053579717875\n",
      "Iteration: 1216, Loss: 0.11605729907751083, Accuracy: 0.6600211933255196\n",
      "Iteration: 1280, Loss: 0.14992442727088928, Accuracy: 0.6610921104438603\n",
      "Iteration: 1344, Loss: 0.10867009311914444, Accuracy: 0.6731184208765626\n",
      "Iteration: 1408, Loss: 0.15509358048439026, Accuracy: 0.6796258995309472\n",
      "Iteration: 1472, Loss: 0.1789713352918625, Accuracy: 0.679551966721192\n",
      "Iteration: 1536, Loss: 0.16109240055084229, Accuracy: 0.6852154955267906\n",
      "Iteration: 1600, Loss: 0.07658172398805618, Accuracy: 0.6916898458730429\n",
      "Iteration: 1664, Loss: 0.1619439572095871, Accuracy: 0.6988270590081811\n",
      "Iteration: 1728, Loss: 0.15618674457073212, Accuracy: 0.7059891659300774\n",
      "Iteration: 1792, Loss: 0.1694277971982956, Accuracy: 0.7160424420144409\n",
      "Iteration: 1856, Loss: 0.15628628432750702, Accuracy: 0.714107230771333\n",
      "Iteration: 1920, Loss: 0.08470088243484497, Accuracy: 0.7281731166876853\n",
      "Iteration: 1984, Loss: 0.15208293497562408, Accuracy: 0.734544018516317\n",
      "Iteration: 2048, Loss: 0.14529332518577576, Accuracy: 0.7336247770581394\n",
      "Iteration: 2112, Loss: 0.05364743247628212, Accuracy: 0.7362644439563155\n",
      "Iteration: 2176, Loss: 0.06372659653425217, Accuracy: 0.7450580431614071\n",
      "Iteration: 2240, Loss: 0.061432916671037674, Accuracy: 0.7587750607635826\n",
      "Iteration: 2304, Loss: 0.13493774831295013, Accuracy: 0.7508691449183971\n",
      "Iteration: 2368, Loss: 0.061629798263311386, Accuracy: 0.7647104235365987\n",
      "Iteration: 2432, Loss: 0.1351575404405594, Accuracy: 0.7647885256446898\n",
      "Iteration: 2496, Loss: 0.17170733213424683, Accuracy: 0.7585077409166843\n",
      "Iteration: 2560, Loss: 0.058291058987379074, Accuracy: 0.7697887942194939\n",
      "Iteration: 2624, Loss: 0.13370336592197418, Accuracy: 0.7756236658897251\n",
      "Iteration: 2688, Loss: 0.06349249929189682, Accuracy: 0.7741856265347451\n",
      "Iteration: 2752, Loss: 0.1219351515173912, Accuracy: 0.7770205358974636\n",
      "Iteration: 2816, Loss: 0.12488150596618652, Accuracy: 0.785361154936254\n",
      "Iteration: 2880, Loss: 0.06461191177368164, Accuracy: 0.7818969709333032\n",
      "Iteration: 2944, Loss: 0.06350962817668915, Accuracy: 0.7859062708448619\n",
      "Iteration: 3008, Loss: 0.1044941321015358, Accuracy: 0.7898660232312977\n",
      "Iteration: 3072, Loss: 0.06190115213394165, Accuracy: 0.7826361942570657\n",
      "Iteration: 3136, Loss: 0.30208542943000793, Accuracy: 0.7884453688748181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3200, Loss: 0.05911080166697502, Accuracy: 0.7810221766121686\n",
      "Iteration: 3264, Loss: 0.10618456453084946, Accuracy: 0.7909490233287215\n",
      "Iteration: 3328, Loss: 0.05554682016372681, Accuracy: 0.7927868929691613\n",
      "Iteration: 3392, Loss: 0.06389352679252625, Accuracy: 0.7931512102950364\n",
      "Iteration: 3456, Loss: 0.08299332857131958, Accuracy: 0.7980336628388613\n",
      "Iteration: 3520, Loss: 0.08955386281013489, Accuracy: 0.8025243803858757\n",
      "Iteration: 3584, Loss: 0.08564230054616928, Accuracy: 0.7857188319321722\n",
      "Iteration: 3648, Loss: 0.07733608782291412, Accuracy: 0.7907474988605827\n",
      "Iteration: 3712, Loss: 0.10452544689178467, Accuracy: 0.7918482071254402\n",
      "Iteration: 3776, Loss: 0.07182463258504868, Accuracy: 0.803991733584553\n",
      "Iteration: 3840, Loss: 0.0944574847817421, Accuracy: 0.8026282330974936\n",
      "Iteration: 3904, Loss: 0.07388699054718018, Accuracy: 0.8019870149437338\n",
      "Iteration: 3968, Loss: 0.08587989956140518, Accuracy: 0.8019313209224492\n",
      "Iteration: 4032, Loss: 0.08912104368209839, Accuracy: 0.8073452387470752\n",
      "Iteration: 4096, Loss: 0.06849106401205063, Accuracy: 0.8068274175748229\n",
      "Iteration: 4160, Loss: 0.1002972349524498, Accuracy: 0.8102008716668934\n",
      "Iteration: 4224, Loss: 0.05256006494164467, Accuracy: 0.8051034766249359\n",
      "Iteration: 4288, Loss: 0.07096315920352936, Accuracy: 0.803175323177129\n",
      "Iteration: 4352, Loss: 0.0623631589114666, Accuracy: 0.8129907096736133\n",
      "Iteration: 4416, Loss: 0.08062424510717392, Accuracy: 0.8147193056065589\n",
      "Iteration: 4480, Loss: 0.08054804056882858, Accuracy: 0.8112118893768638\n",
      "Iteration: 4544, Loss: 0.07364735752344131, Accuracy: 0.8162821182049811\n",
      "Iteration: 4608, Loss: 0.07618387788534164, Accuracy: 0.8169545226264745\n",
      "Iteration: 4672, Loss: 0.06360391527414322, Accuracy: 0.8181199592072517\n",
      "Iteration: 4736, Loss: 0.08915708214044571, Accuracy: 0.8185658992733806\n",
      "Iteration: 4800, Loss: 0.09931749105453491, Accuracy: 0.818036983255297\n",
      "Iteration: 4864, Loss: 0.07951172441244125, Accuracy: 0.8152309008873999\n",
      "Iteration: 4928, Loss: 0.06685412675142288, Accuracy: 0.8203173456713557\n",
      "Iteration: 4992, Loss: 0.09475114196538925, Accuracy: 0.8245673351921141\n",
      "Iteration: 5056, Loss: 0.05911208316683769, Accuracy: 0.8108205341268331\n",
      "Iteration: 5120, Loss: 0.04062458500266075, Accuracy: 0.818402434932068\n",
      "Iteration: 5184, Loss: 0.07919894903898239, Accuracy: 0.8185203238390386\n",
      "Iteration: 5248, Loss: 0.08326523751020432, Accuracy: 0.8216757974587381\n",
      "Iteration: 5312, Loss: 0.07957225292921066, Accuracy: 0.8261449572164565\n",
      "Iteration: 5376, Loss: 0.08170988410711288, Accuracy: 0.8296741470694542\n",
      "Iteration: 5440, Loss: 0.04677462950348854, Accuracy: 0.8288337222766131\n",
      "Iteration: 5504, Loss: 0.03200162574648857, Accuracy: 0.8137157139135525\n",
      "Iteration: 5568, Loss: 0.02981923520565033, Accuracy: 0.8359962395625189\n",
      "Iteration: 5632, Loss: 0.07905716449022293, Accuracy: 0.8379441343713552\n",
      "Iteration: 5696, Loss: 0.09114792197942734, Accuracy: 0.8359827294480056\n",
      "Iteration: 5760, Loss: 0.07716488093137741, Accuracy: 0.8342046219622716\n",
      "Iteration: 5824, Loss: 0.06750393658876419, Accuracy: 0.8411014620214701\n",
      "Iteration: 5888, Loss: 0.07509806007146835, Accuracy: 0.8409693874418736\n",
      "Iteration: 5952, Loss: 0.10328146070241928, Accuracy: 0.8311851591570303\n",
      "Iteration: 6016, Loss: 0.09168826788663864, Accuracy: 0.8316041427897289\n",
      "Iteration: 6080, Loss: 0.09575609117746353, Accuracy: 0.8401696878718212\n",
      "Iteration: 6144, Loss: 0.026179885491728783, Accuracy: 0.8275601908098906\n",
      "Iteration: 6208, Loss: 0.024891404435038567, Accuracy: 0.8451049405848607\n",
      "Iteration: 6272, Loss: 0.07767187803983688, Accuracy: 0.844889962929301\n",
      "Iteration: 6336, Loss: 0.023500405251979828, Accuracy: 0.8422702220268548\n",
      "Iteration: 6400, Loss: 0.021240828558802605, Accuracy: 0.847348588402383\n",
      "Iteration: 6464, Loss: 0.03489118814468384, Accuracy: 0.8405836928868666\n",
      "Iteration: 6528, Loss: 0.09102383255958557, Accuracy: 0.8500858425395563\n",
      "Iteration: 6592, Loss: 0.09302753210067749, Accuracy: 0.8548635537736118\n",
      "Iteration: 6656, Loss: 0.07563973218202591, Accuracy: 0.8520059933653101\n",
      "Iteration: 6720, Loss: 0.1242620125412941, Accuracy: 0.8538823737762868\n",
      "Iteration: 6784, Loss: 0.044174302369356155, Accuracy: 0.8547723710071295\n",
      "Iteration: 6848, Loss: 0.0924079641699791, Accuracy: 0.8610672574723139\n",
      "Iteration: 6912, Loss: 0.0285856481641531, Accuracy: 0.8530346817569807\n",
      "Iteration: 6976, Loss: 0.011765196919441223, Accuracy: 0.8599394097691402\n",
      "Iteration: 7040, Loss: 0.09491625428199768, Accuracy: 0.8532439051195979\n",
      "Iteration: 7104, Loss: 0.075099878013134, Accuracy: 0.8506606350420043\n",
      "Iteration: 7168, Loss: 0.04656757041811943, Accuracy: 0.8533492559799924\n",
      "Iteration: 7232, Loss: 0.07503199577331543, Accuracy: 0.8463780228048563\n",
      "Iteration: 7296, Loss: 0.07966035604476929, Accuracy: 0.850329173146747\n",
      "Iteration: 7360, Loss: 0.015646839514374733, Accuracy: 0.8513633016264066\n",
      "Iteration: 7424, Loss: 0.014325405471026897, Accuracy: 0.8651410829043016\n",
      "Iteration: 7488, Loss: 0.06663347035646439, Accuracy: 0.8653825931251049\n",
      "Iteration: 7552, Loss: 0.08449975401163101, Accuracy: 0.8528624178143218\n",
      "Iteration: 7616, Loss: 0.08608683198690414, Accuracy: 0.8532726252451539\n",
      "Iteration: 7680, Loss: 0.026029005646705627, Accuracy: 0.8620990946656093\n",
      "Iteration: 7744, Loss: 0.026473259553313255, Accuracy: 0.871385750011541\n",
      "Iteration: 7808, Loss: 0.013384674675762653, Accuracy: 0.866643418208696\n",
      "Iteration: 7872, Loss: 0.03156484290957451, Accuracy: 0.8532359254313633\n",
      "Iteration: 7936, Loss: 0.013437320478260517, Accuracy: 0.8635148610919714\n",
      "Iteration: 8000, Loss: 0.0850721225142479, Accuracy: 0.8723479838808998\n",
      "Iteration: 8064, Loss: 0.32625487446784973, Accuracy: 0.8617659710580483\n",
      "Iteration: 8128, Loss: 0.025749044492840767, Accuracy: 0.8618212807923555\n",
      "Iteration: 8192, Loss: 0.08086494356393814, Accuracy: 0.862603145011235\n",
      "Iteration: 8256, Loss: 0.029775969684123993, Accuracy: 0.8582871401449665\n",
      "Iteration: 8320, Loss: 0.011604727245867252, Accuracy: 0.8544954804237932\n",
      "Iteration: 8384, Loss: 0.05216224119067192, Accuracy: 0.868990488583222\n",
      "Iteration: 8448, Loss: 0.08047696202993393, Accuracy: 0.8682422004640102\n",
      "Iteration: 8512, Loss: 0.06748303025960922, Accuracy: 0.8458525913301855\n",
      "Iteration: 8576, Loss: 0.0668792650103569, Accuracy: 0.8644405551603995\n",
      "Iteration: 8640, Loss: 0.0800873339176178, Accuracy: 0.8768293445464224\n",
      "Iteration: 8704, Loss: 0.08697571605443954, Accuracy: 0.878576162212994\n",
      "Iteration: 8768, Loss: 0.12078281491994858, Accuracy: 0.8729620695230551\n",
      "Iteration: 8832, Loss: 0.027524137869477272, Accuracy: 0.862425280676689\n",
      "Iteration: 8896, Loss: 0.041113030165433884, Accuracy: 0.8727752475533634\n",
      "Iteration: 8960, Loss: 0.08827308565378189, Accuracy: 0.8793342451099306\n",
      "Iteration: 9024, Loss: 0.043716151267290115, Accuracy: 0.8821448896196671\n",
      "Iteration: 9088, Loss: 0.02176778018474579, Accuracy: 0.87142034759745\n",
      "Iteration: 9152, Loss: 0.04265587404370308, Accuracy: 0.8768353159539402\n",
      "Iteration: 9216, Loss: 0.07601522654294968, Accuracy: 0.8768247433472425\n",
      "Iteration: 9280, Loss: 0.009896696545183659, Accuracy: 0.8740571365924552\n",
      "Iteration: 9344, Loss: 0.08948368579149246, Accuracy: 0.8789966251351871\n",
      "Iteration: 9408, Loss: 0.008784223347902298, Accuracy: 0.8760598467197269\n",
      "Iteration: 9472, Loss: 0.07773761451244354, Accuracy: 0.8829217073507607\n",
      "Iteration: 9536, Loss: 0.0908483937382698, Accuracy: 0.8875620936742052\n",
      "Iteration: 9600, Loss: 0.014640557579696178, Accuracy: 0.8809040822088718\n",
      "Iteration: 9664, Loss: 0.0043276287615299225, Accuracy: 0.8700787509442307\n",
      "Iteration: 9728, Loss: 0.015791138634085655, Accuracy: 0.8856360816862434\n",
      "Iteration: 9792, Loss: 0.02741210162639618, Accuracy: 0.8858181293471716\n",
      "Iteration: 9856, Loss: 0.007888693362474442, Accuracy: 0.8864911978016607\n",
      "Iteration: 9920, Loss: 0.024779627099633217, Accuracy: 0.889553643297404\n",
      "Iteration: 9984, Loss: 0.014328251592814922, Accuracy: 0.888106417900417\n",
      "Iteration: 10048, Loss: 0.08160118013620377, Accuracy: 0.8853626228519715\n",
      "Iteration: 10112, Loss: 0.08360099792480469, Accuracy: 0.885690089489799\n",
      "Iteration: 10176, Loss: 0.013696550391614437, Accuracy: 0.8792202189215459\n",
      "Iteration: 10240, Loss: 0.013333417475223541, Accuracy: 0.8915661321370862\n",
      "Iteration: 10304, Loss: 0.017231645062565804, Accuracy: 0.8852389295352623\n",
      "Iteration: 10368, Loss: 0.013523533940315247, Accuracy: 0.8920690451632254\n",
      "Iteration: 10432, Loss: 0.0048750233836472034, Accuracy: 0.8869390984182246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10496, Loss: 0.005672249477356672, Accuracy: 0.8836444634362124\n",
      "Iteration: 10560, Loss: 0.006657333578914404, Accuracy: 0.8811764329439029\n",
      "Iteration: 10624, Loss: 0.09627614170312881, Accuracy: 0.8854490132653154\n",
      "Iteration: 10688, Loss: 0.09438339620828629, Accuracy: 0.8924014131771401\n",
      "Iteration: 10752, Loss: 0.010037415660917759, Accuracy: 0.8878483400330879\n",
      "Iteration: 10816, Loss: 0.07773055881261826, Accuracy: 0.8933339760405943\n",
      "Iteration: 10880, Loss: 0.01658208668231964, Accuracy: 0.8981840082560666\n",
      "Iteration: 10944, Loss: 0.020950907841324806, Accuracy: 0.8945307577378117\n",
      "Iteration: 11008, Loss: 0.03192247077822685, Accuracy: 0.9000079215038568\n",
      "Iteration: 11072, Loss: 0.010853531770408154, Accuracy: 0.9003089512698352\n",
      "Iteration: 11136, Loss: 0.010801400989294052, Accuracy: 0.885333616140997\n",
      "Iteration: 11200, Loss: 0.026822611689567566, Accuracy: 0.8956790563534014\n",
      "Iteration: 11264, Loss: 0.07767704129219055, Accuracy: 0.8901939311763272\n",
      "Iteration: 11328, Loss: 0.003915648907423019, Accuracy: 0.8890064401202835\n",
      "Iteration: 11392, Loss: 0.09239766001701355, Accuracy: 0.8933810275048018\n",
      "Iteration: 11456, Loss: 0.021634722128510475, Accuracy: 0.8948115223320201\n",
      "Iteration: 11520, Loss: 0.0031369803473353386, Accuracy: 0.8945633085095324\n",
      "Iteration: 11584, Loss: 0.005197546910494566, Accuracy: 0.9001194289885461\n",
      "Iteration: 11648, Loss: 0.007505399640649557, Accuracy: 0.9064163081930019\n",
      "Iteration: 11712, Loss: 0.010056054219603539, Accuracy: 0.9105758586083539\n",
      "Iteration: 11776, Loss: 0.002214726759120822, Accuracy: 0.8924104782927316\n",
      "Iteration: 11840, Loss: 0.0030185983050614595, Accuracy: 0.8922146935365163\n",
      "Iteration: 11904, Loss: 0.009870522655546665, Accuracy: 0.9039913869928569\n",
      "Iteration: 11968, Loss: 0.010779035277664661, Accuracy: 0.9053381764097139\n",
      "Iteration: 12032, Loss: 0.06008530780673027, Accuracy: 0.8984935721382499\n",
      "Iteration: 12096, Loss: 0.007001328747719526, Accuracy: 0.9055542216519825\n",
      "Iteration: 12160, Loss: 0.013895499520003796, Accuracy: 0.908340105554089\n",
      "Iteration: 12224, Loss: 0.011885673739016056, Accuracy: 0.9070740976021625\n",
      "Iteration: 12288, Loss: 0.0024229285772889853, Accuracy: 0.9112439954187721\n",
      "Iteration: 12352, Loss: 0.01630680449306965, Accuracy: 0.9053993479465134\n",
      "Iteration: 12416, Loss: 0.007583413273096085, Accuracy: 0.9146052479627542\n",
      "Iteration: 12480, Loss: 0.008985910564661026, Accuracy: 0.9055513141793199\n",
      "Iteration: 12544, Loss: 0.013555857352912426, Accuracy: 0.9106154966866598\n",
      "Iteration: 12608, Loss: 0.12055780738592148, Accuracy: 0.9117753592436202\n",
      "Iteration: 12672, Loss: 0.00201136595569551, Accuracy: 0.9123706167447381\n",
      "Iteration: 12736, Loss: 0.0022997416090220213, Accuracy: 0.9166304960963316\n",
      "Iteration: 12800, Loss: 0.010263499803841114, Accuracy: 0.9109287892351858\n",
      "Iteration: 12864, Loss: 0.06852085143327713, Accuracy: 0.900388414884219\n",
      "Iteration: 12928, Loss: 0.0020648082718253136, Accuracy: 0.9170830081566237\n",
      "Iteration: 12992, Loss: 0.007789089810103178, Accuracy: 0.9075322935241275\n",
      "Iteration: 13056, Loss: 0.03963465988636017, Accuracy: 0.9265067883243319\n",
      "Iteration: 13120, Loss: 0.009027552790939808, Accuracy: 0.9155586414854042\n",
      "Iteration: 13184, Loss: 0.005831914488226175, Accuracy: 0.9222524882934522\n",
      "Iteration: 13248, Loss: 0.010393883101642132, Accuracy: 0.9217932592728175\n",
      "Iteration: 13312, Loss: 0.009975495748221874, Accuracy: 0.9184679603204131\n",
      "Iteration: 13376, Loss: 0.009445874020457268, Accuracy: 0.913274650927633\n",
      "Iteration: 13440, Loss: 0.003242547856643796, Accuracy: 0.9138528812327422\n",
      "Iteration: 13504, Loss: 0.11761558055877686, Accuracy: 0.9219053515116684\n",
      "Iteration: 13568, Loss: 0.13479392230510712, Accuracy: 0.9168008235283196\n",
      "Iteration: 13632, Loss: 0.011452575214207172, Accuracy: 0.9207410416565835\n",
      "Iteration: 13696, Loss: 0.016786616295576096, Accuracy: 0.9206047983607277\n",
      "Iteration: 13760, Loss: 0.006020538508892059, Accuracy: 0.9217070513404906\n",
      "Iteration: 13824, Loss: 0.005561144556850195, Accuracy: 0.9256860528257675\n",
      "Iteration: 13888, Loss: 0.008516315370798111, Accuracy: 0.9235984752885997\n",
      "Iteration: 13952, Loss: 0.008261452428996563, Accuracy: 0.9206895367242396\n",
      "Iteration: 14016, Loss: 0.009616934694349766, Accuracy: 0.923442889819853\n",
      "Iteration: 14080, Loss: 0.003489881753921509, Accuracy: 0.9338114567508455\n",
      "Iteration: 14144, Loss: 0.0045956508256495, Accuracy: 0.9230936155363452\n",
      "Iteration: 14208, Loss: 0.0013487109681591392, Accuracy: 0.9327278957061935\n",
      "Iteration: 14272, Loss: 0.010277542285621166, Accuracy: 0.9221494103549048\n",
      "Iteration: 14336, Loss: 0.0058212075382471085, Accuracy: 0.9363857481803279\n",
      "Iteration: 14400, Loss: 0.010507471859455109, Accuracy: 0.9343762973148841\n",
      "Iteration: 14464, Loss: 0.15777328610420227, Accuracy: 0.9342603187542409\n",
      "Iteration: 14528, Loss: 0.0103371012955904, Accuracy: 0.9256642221589573\n",
      "Iteration: 14592, Loss: 0.002374158473685384, Accuracy: 0.9294509431347251\n",
      "Iteration: 14656, Loss: 0.007808603346347809, Accuracy: 0.9319715497549623\n",
      "Iteration: 14720, Loss: 0.003553879214450717, Accuracy: 0.935226037807297\n",
      "Iteration: 14784, Loss: 0.007047759834676981, Accuracy: 0.9292069050716236\n",
      "Iteration: 14848, Loss: 0.012784839607775211, Accuracy: 0.9440301039430778\n",
      "Iteration: 14912, Loss: 0.004579422529786825, Accuracy: 0.9331746236712206\n",
      "Iteration: 14976, Loss: 0.01332353800535202, Accuracy: 0.9380366455588955\n",
      "Iteration: 15040, Loss: 0.008787214756011963, Accuracy: 0.947080275072949\n",
      "Iteration: 15104, Loss: 0.004983721766620874, Accuracy: 0.9418092509149574\n",
      "Iteration: 15168, Loss: 0.010818508453667164, Accuracy: 0.9318924034305383\n",
      "Iteration: 15232, Loss: 0.0036907168105244637, Accuracy: 0.9305120926292147\n",
      "Iteration: 15296, Loss: 0.0065819211304187775, Accuracy: 0.9486441237386316\n",
      "Iteration: 15360, Loss: 0.01392583828419447, Accuracy: 0.9400176692288369\n",
      "Iteration: 15424, Loss: 0.004359197337180376, Accuracy: 0.9329052635002881\n",
      "Iteration: 15488, Loss: 0.015473362989723682, Accuracy: 0.946551331988303\n",
      "Iteration: 15552, Loss: 0.03738483414053917, Accuracy: 0.938457492942689\n",
      "Iteration: 15616, Loss: 0.013415958732366562, Accuracy: 0.9373687572660856\n",
      "Iteration: 15680, Loss: 0.004034140612930059, Accuracy: 0.9401331356784794\n",
      "Iteration: 15744, Loss: 0.007520824670791626, Accuracy: 0.9444982191198505\n",
      "Iteration: 15808, Loss: 0.0033531393855810165, Accuracy: 0.9399144025810529\n",
      "Iteration: 15872, Loss: 0.25998997688293457, Accuracy: 0.9372347147145774\n",
      "Iteration: 15936, Loss: 0.0035114565398544073, Accuracy: 0.9507185294060037\n",
      "Iteration: 16000, Loss: 0.20048804581165314, Accuracy: 0.9393783062696457\n",
      "Iteration: 16064, Loss: 0.0016442755004391074, Accuracy: 0.9343636922130827\n",
      "Iteration: 16128, Loss: 0.005121144931763411, Accuracy: 0.9449678856180981\n",
      "Iteration: 16192, Loss: 0.0034856759011745453, Accuracy: 0.9458835102268495\n",
      "Iteration: 16256, Loss: 0.004001041874289513, Accuracy: 0.9482416909886524\n",
      "Iteration: 16320, Loss: 0.004092146176844835, Accuracy: 0.9396698700729758\n",
      "Iteration: 16384, Loss: 0.0011703228810802102, Accuracy: 0.9424050520756282\n",
      "Iteration: 16448, Loss: 0.004854107275605202, Accuracy: 0.943295914970804\n",
      "Iteration: 16512, Loss: 0.0003386411117389798, Accuracy: 0.9330250470375177\n",
      "Iteration: 16576, Loss: 0.004057500511407852, Accuracy: 0.9518931483034976\n",
      "Iteration: 16640, Loss: 0.004304608330130577, Accuracy: 0.9551571567135397\n",
      "Iteration: 16704, Loss: 0.006562626454979181, Accuracy: 0.9420504695735872\n",
      "Iteration: 16768, Loss: 0.0038389749825000763, Accuracy: 0.9436198752082419\n",
      "Iteration: 16832, Loss: 0.002520522801205516, Accuracy: 0.9495179186051246\n",
      "Iteration: 16896, Loss: 0.0043784542940557, Accuracy: 0.9473446011543274\n",
      "Iteration: 16960, Loss: 0.001035369816236198, Accuracy: 0.9493770064727869\n",
      "Iteration: 17024, Loss: 0.0008505024015903473, Accuracy: 0.9520412215497345\n",
      "Iteration: 17088, Loss: 0.005484003573656082, Accuracy: 0.9471657731919549\n",
      "Iteration: 17152, Loss: 0.004396392498165369, Accuracy: 0.9350451737118419\n",
      "Iteration: 17216, Loss: 0.0029683150351047516, Accuracy: 0.9541280459234258\n",
      "Iteration: 17280, Loss: 0.00047146572615019977, Accuracy: 0.9453748865926173\n",
      "Iteration: 17344, Loss: 0.00490514887496829, Accuracy: 0.9442135687568225\n",
      "Iteration: 17408, Loss: 0.0013636816293001175, Accuracy: 0.953132004418876\n",
      "Iteration: 17472, Loss: 0.003066064789891243, Accuracy: 0.9494468972261529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 17536, Loss: 0.00036455364897847176, Accuracy: 0.9573013840854401\n",
      "Iteration: 17600, Loss: 0.010295039974153042, Accuracy: 0.9495768213382689\n",
      "Iteration: 17664, Loss: 0.0021321193780750036, Accuracy: 0.9493650313233957\n",
      "Iteration: 17728, Loss: 0.0012509862426668406, Accuracy: 0.9512359136133455\n",
      "Iteration: 17792, Loss: 0.0012536338763311505, Accuracy: 0.9548112647171365\n",
      "Iteration: 17856, Loss: 0.0009933783439919353, Accuracy: 0.9518286546954187\n",
      "Iteration: 17920, Loss: 0.0020893109031021595, Accuracy: 0.9576555998355616\n",
      "Iteration: 17984, Loss: 0.002090344438329339, Accuracy: 0.9638763469702099\n",
      "Iteration: 18048, Loss: 0.0016150724841281772, Accuracy: 0.9579891611792846\n",
      "Iteration: 18112, Loss: 0.0826384648680687, Accuracy: 0.9507672626350541\n",
      "Iteration: 18176, Loss: 0.000765984645113349, Accuracy: 0.954576469535823\n",
      "Iteration: 18240, Loss: 0.0020242948085069656, Accuracy: 0.9516379708657041\n",
      "Iteration: 18304, Loss: 0.00042946101166307926, Accuracy: 0.957279379144893\n",
      "Iteration: 18368, Loss: 0.004226157441735268, Accuracy: 0.9552034780062968\n",
      "Iteration: 18432, Loss: 0.27531698346138, Accuracy: 0.9551146125450032\n",
      "Iteration: 18496, Loss: 0.0013195332139730453, Accuracy: 0.9503820467070909\n",
      "Iteration: 18560, Loss: 0.0960460901260376, Accuracy: 0.953873665217543\n",
      "Iteration: 18624, Loss: 0.0012143634958192706, Accuracy: 0.9589727542188484\n",
      "Iteration: 18688, Loss: 0.0026104908902198076, Accuracy: 0.9567943060246762\n",
      "Iteration: 18752, Loss: 0.0004445835074875504, Accuracy: 0.936593419406563\n",
      "Iteration: 18816, Loss: 0.0010574511252343655, Accuracy: 0.9556609535211464\n",
      "Iteration: 18880, Loss: 0.00206842296756804, Accuracy: 0.9590630450693425\n",
      "Iteration: 18944, Loss: 0.004999468103051186, Accuracy: 0.9673019614128862\n",
      "Iteration: 19008, Loss: 0.00023415261239279062, Accuracy: 0.9597249101352645\n",
      "Iteration: 19072, Loss: 0.002973891096189618, Accuracy: 0.9487789298291318\n",
      "Iteration: 19136, Loss: 0.11751419305801392, Accuracy: 0.956316299532773\n",
      "Iteration: 19200, Loss: 0.003840463934466243, Accuracy: 0.9599363692104816\n",
      "Iteration: 19264, Loss: 0.0008030994213186204, Accuracy: 0.9569784175546374\n",
      "Iteration: 19328, Loss: 0.00043401215225458145, Accuracy: 0.9592036711546825\n",
      "Iteration: 19392, Loss: 0.00016517048061359674, Accuracy: 0.9558936679823091\n",
      "Iteration: 19456, Loss: 0.004032251425087452, Accuracy: 0.9487252760882257\n",
      "Iteration: 19520, Loss: 0.0037988685071468353, Accuracy: 0.9616301416099304\n",
      "Iteration: 19584, Loss: 0.009477147832512856, Accuracy: 0.9460516043618554\n",
      "Iteration: 19648, Loss: 0.001988813513889909, Accuracy: 0.9352894608746283\n",
      "Iteration: 19712, Loss: 0.0037426205817610025, Accuracy: 0.9530779391498072\n",
      "Iteration: 19776, Loss: 0.0025738917756825686, Accuracy: 0.9546179105818737\n",
      "Iteration: 19840, Loss: 0.015249698422849178, Accuracy: 0.9633649442985188\n",
      "Iteration: 19904, Loss: 0.0016855275025591254, Accuracy: 0.9500151931570144\n",
      "Iteration: 19968, Loss: 0.004489592742174864, Accuracy: 0.9584635456994874\n",
      "Iteration: 20032, Loss: 0.0015731030143797398, Accuracy: 0.9626742092950735\n",
      "Iteration: 20096, Loss: 0.0031506295781582594, Accuracy: 0.9596509284310741\n",
      "Iteration: 20160, Loss: 0.0018462272128090262, Accuracy: 0.9646401530044386\n",
      "Iteration: 20224, Loss: 0.0015649861888960004, Accuracy: 0.9694942937494488\n",
      "Iteration: 20288, Loss: 0.0011117687681689858, Accuracy: 0.9671554626547731\n",
      "Iteration: 20352, Loss: 0.0005365617107599974, Accuracy: 0.9671166137995897\n",
      "Iteration: 20416, Loss: 0.1436700075864792, Accuracy: 0.9608629977738019\n",
      "Iteration: 20480, Loss: 0.0001569735904922709, Accuracy: 0.9722816225403221\n",
      "Saved fullModel_dr[2]_replicate0.model\n",
      "Saved W_dr[2]_replicate0.p\n",
      "2 0.9895833333333334 [0.984375, 0.984375, 1.0]\n",
      "Saved w_dr[2]_replicate0.p\n",
      "Replicate 0 completed\n",
      "Time elapsed: 103.984375 seconds\n",
      "Iteration: 64, Loss: 0.26828986406326294, Accuracy: 0.4990617437288165\n",
      "Iteration: 128, Loss: 0.23687629401683807, Accuracy: 0.5014393706806004\n",
      "Iteration: 192, Loss: 0.24028949439525604, Accuracy: 0.5121274711564183\n",
      "Iteration: 256, Loss: 0.1816246658563614, Accuracy: 0.5632017417810857\n",
      "Iteration: 320, Loss: 0.18526239693164825, Accuracy: 0.5985869597643614\n",
      "Iteration: 384, Loss: 0.18382419645786285, Accuracy: 0.6155088222585618\n",
      "Iteration: 448, Loss: 0.17701858282089233, Accuracy: 0.624460132792592\n",
      "Iteration: 512, Loss: 0.1754610687494278, Accuracy: 0.6315507013350725\n",
      "Iteration: 576, Loss: 0.17000024020671844, Accuracy: 0.6357346503064036\n",
      "Iteration: 640, Loss: 0.16561158001422882, Accuracy: 0.6393919815309346\n",
      "Iteration: 704, Loss: 0.17956125736236572, Accuracy: 0.6414737883023918\n",
      "Iteration: 768, Loss: 0.16462981700897217, Accuracy: 0.6437985571101308\n",
      "Iteration: 832, Loss: 0.17548315227031708, Accuracy: 0.6454131854698062\n",
      "Iteration: 896, Loss: 0.16954512894153595, Accuracy: 0.6462555876933038\n",
      "Iteration: 960, Loss: 0.17518769204616547, Accuracy: 0.6481690807268023\n",
      "Iteration: 1024, Loss: 0.16513119637966156, Accuracy: 0.6493791141547263\n",
      "Iteration: 1088, Loss: 0.16620177030563354, Accuracy: 0.6496959431096911\n",
      "Iteration: 1152, Loss: 0.16360880434513092, Accuracy: 0.6506591117940843\n",
      "Iteration: 1216, Loss: 0.17372019588947296, Accuracy: 0.6513844430446625\n",
      "Iteration: 1280, Loss: 0.17507962882518768, Accuracy: 0.6523843239992857\n",
      "Iteration: 1344, Loss: 0.17206613719463348, Accuracy: 0.653434875421226\n",
      "Iteration: 1408, Loss: 0.17397058010101318, Accuracy: 0.6532113715074956\n",
      "Iteration: 1472, Loss: 0.16699664294719696, Accuracy: 0.6544022932648659\n",
      "Iteration: 1536, Loss: 0.16521628201007843, Accuracy: 0.6547553716227412\n",
      "Iteration: 1600, Loss: 0.16709816455841064, Accuracy: 0.6550404755398631\n",
      "Iteration: 1664, Loss: 0.1665058583021164, Accuracy: 0.6554694771766663\n",
      "Iteration: 1728, Loss: 0.16442610323429108, Accuracy: 0.6539463368244469\n",
      "Iteration: 1792, Loss: 0.1721453219652176, Accuracy: 0.651442289352417\n",
      "Iteration: 1856, Loss: 0.16962915658950806, Accuracy: 0.6561140441335738\n",
      "Iteration: 1920, Loss: 0.16394005715847015, Accuracy: 0.6516238413751125\n",
      "Iteration: 1984, Loss: 0.16592662036418915, Accuracy: 0.6566274706274271\n",
      "Iteration: 2048, Loss: 0.16402649879455566, Accuracy: 0.6521917921490967\n",
      "Iteration: 2112, Loss: 0.163950115442276, Accuracy: 0.6576177347451448\n",
      "Iteration: 2176, Loss: 0.17199037969112396, Accuracy: 0.657789699267596\n",
      "Iteration: 2240, Loss: 0.16945815086364746, Accuracy: 0.6530560762621462\n",
      "Iteration: 2304, Loss: 0.17297302186489105, Accuracy: 0.6574596893042326\n",
      "Iteration: 2368, Loss: 0.16926629841327667, Accuracy: 0.6578351138159633\n",
      "Iteration: 2432, Loss: 0.17024445533752441, Accuracy: 0.6577468430623412\n",
      "Iteration: 2496, Loss: 0.16996590793132782, Accuracy: 0.6580288265831769\n",
      "Iteration: 2560, Loss: 0.16791808605194092, Accuracy: 0.6585013773292303\n",
      "Iteration: 2624, Loss: 0.1715349704027176, Accuracy: 0.6582457069307566\n",
      "Iteration: 2688, Loss: 0.16649185121059418, Accuracy: 0.6586625389754772\n",
      "Iteration: 2752, Loss: 0.1680159717798233, Accuracy: 0.6572700855322182\n",
      "Iteration: 2816, Loss: 0.1707727313041687, Accuracy: 0.6594326421618462\n",
      "Iteration: 2880, Loss: 0.17020417749881744, Accuracy: 0.6592210331000388\n",
      "Iteration: 2944, Loss: 0.1683874875307083, Accuracy: 0.6597451986745\n",
      "Iteration: 3008, Loss: 0.16290885210037231, Accuracy: 0.6599295004270971\n",
      "Iteration: 3072, Loss: 0.16923587024211884, Accuracy: 0.6602955046109855\n",
      "Iteration: 3136, Loss: 0.16578321158885956, Accuracy: 0.66026401380077\n",
      "Iteration: 3200, Loss: 0.16776005923748016, Accuracy: 0.6604938027448952\n",
      "Iteration: 3264, Loss: 0.1712319403886795, Accuracy: 0.6607882385142148\n",
      "Iteration: 3328, Loss: 0.16401584446430206, Accuracy: 0.6607461138628423\n",
      "Iteration: 3392, Loss: 0.16641689836978912, Accuracy: 0.6611559242010117\n",
      "Iteration: 3456, Loss: 0.17322170734405518, Accuracy: 0.6610781815834343\n",
      "Iteration: 3520, Loss: 0.16824877262115479, Accuracy: 0.6612739078700542\n",
      "Iteration: 3584, Loss: 0.17086422443389893, Accuracy: 0.6608046712353826\n",
      "Iteration: 3648, Loss: 0.17051367461681366, Accuracy: 0.6615114654414356\n",
      "Iteration: 3712, Loss: 0.16917861998081207, Accuracy: 0.6612018747255206\n",
      "Iteration: 3776, Loss: 0.16632616519927979, Accuracy: 0.6614698725752532\n",
      "Iteration: 3840, Loss: 0.16080065071582794, Accuracy: 0.6619111811742187\n",
      "Iteration: 3904, Loss: 0.16839343309402466, Accuracy: 0.6619009412825108\n",
      "Iteration: 3968, Loss: 0.15546277165412903, Accuracy: 0.6616981825791299\n",
      "Iteration: 4032, Loss: 0.1702771633863449, Accuracy: 0.6615926986560225\n",
      "Iteration: 4096, Loss: 0.15875224769115448, Accuracy: 0.6624225028790534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4160, Loss: 0.14884494245052338, Accuracy: 0.6628840244375169\n",
      "Iteration: 4224, Loss: 0.16177329421043396, Accuracy: 0.6632932205684483\n",
      "Iteration: 4288, Loss: 0.17362046241760254, Accuracy: 0.664428448304534\n",
      "Iteration: 4352, Loss: 0.16694442927837372, Accuracy: 0.6671431018039584\n",
      "Iteration: 4416, Loss: 0.16627180576324463, Accuracy: 0.6680340990424156\n",
      "Iteration: 4480, Loss: 0.17030000686645508, Accuracy: 0.6700658635236323\n",
      "Iteration: 4544, Loss: 0.12400775402784348, Accuracy: 0.6719429814256728\n",
      "Iteration: 4608, Loss: 0.1649673730134964, Accuracy: 0.6725317253731191\n",
      "Iteration: 4672, Loss: 0.17465491592884064, Accuracy: 0.6747894347645342\n",
      "Iteration: 4736, Loss: 0.15498264133930206, Accuracy: 0.682412491645664\n",
      "Iteration: 4800, Loss: 0.16511468589305878, Accuracy: 0.6832301029935479\n",
      "Iteration: 4864, Loss: 0.0913049578666687, Accuracy: 0.6869662259705365\n",
      "Iteration: 4928, Loss: 0.1409681886434555, Accuracy: 0.6915452838875353\n",
      "Iteration: 4992, Loss: 0.10374089330434799, Accuracy: 0.6962039589416236\n",
      "Iteration: 5056, Loss: 0.08416435867547989, Accuracy: 0.6993155188392848\n",
      "Iteration: 5120, Loss: 0.16396965086460114, Accuracy: 0.7031779561657459\n",
      "Iteration: 5184, Loss: 0.1693497747182846, Accuracy: 0.7066681964788586\n",
      "Iteration: 5248, Loss: 0.10499460250139236, Accuracy: 0.7132670823484659\n",
      "Iteration: 5312, Loss: 0.09782349318265915, Accuracy: 0.7170316972769797\n",
      "Iteration: 5376, Loss: 0.12062108516693115, Accuracy: 0.7227811268530786\n",
      "Iteration: 5440, Loss: 0.08283524960279465, Accuracy: 0.7263770629651845\n",
      "Iteration: 5504, Loss: 0.15202844142913818, Accuracy: 0.7275900493841618\n",
      "Iteration: 5568, Loss: 0.16514496505260468, Accuracy: 0.7325016383547336\n",
      "Iteration: 5632, Loss: 0.20039190351963043, Accuracy: 0.7354267309419811\n",
      "Iteration: 5696, Loss: 0.0958181619644165, Accuracy: 0.7414610763080418\n",
      "Iteration: 5760, Loss: 0.2013653963804245, Accuracy: 0.7445331041235477\n",
      "Iteration: 5824, Loss: 0.056511785835027695, Accuracy: 0.747604422736913\n",
      "Iteration: 5888, Loss: 0.050466518849134445, Accuracy: 0.7504497251939029\n",
      "Iteration: 5952, Loss: 0.0800313949584961, Accuracy: 0.751017834758386\n",
      "Iteration: 6016, Loss: 0.05439849570393562, Accuracy: 0.7587498854845762\n",
      "Iteration: 6080, Loss: 0.139773890376091, Accuracy: 0.760931892786175\n",
      "Iteration: 6144, Loss: 0.08797881007194519, Accuracy: 0.7670738452579826\n",
      "Iteration: 6208, Loss: 0.09872949123382568, Accuracy: 0.7688524378463626\n",
      "Iteration: 6272, Loss: 0.06280550360679626, Accuracy: 0.7718572451267391\n",
      "Iteration: 6336, Loss: 0.0681070014834404, Accuracy: 0.7730042154435068\n",
      "Iteration: 6400, Loss: 0.07193843275308609, Accuracy: 0.7774783130735159\n",
      "Iteration: 6464, Loss: 0.16382600367069244, Accuracy: 0.7790455045178533\n",
      "Iteration: 6528, Loss: 0.1302492469549179, Accuracy: 0.7847495793830603\n",
      "Iteration: 6592, Loss: 0.0360710583627224, Accuracy: 0.7868512005079538\n",
      "Iteration: 6656, Loss: 0.037310320883989334, Accuracy: 0.7873041527345777\n",
      "Iteration: 6720, Loss: 0.10707530379295349, Accuracy: 0.7947172587737441\n",
      "Iteration: 6784, Loss: 0.06797933578491211, Accuracy: 0.7938106830697507\n",
      "Iteration: 6848, Loss: 0.041053321212530136, Accuracy: 0.7952779217157513\n",
      "Iteration: 6912, Loss: 0.03470757231116295, Accuracy: 0.7982840123586357\n",
      "Iteration: 6976, Loss: 0.03862442448735237, Accuracy: 0.803459785412997\n",
      "Iteration: 7040, Loss: 0.057556185871362686, Accuracy: 0.802660075481981\n",
      "Iteration: 7104, Loss: 0.0765601396560669, Accuracy: 0.8059601709246635\n",
      "Iteration: 7168, Loss: 0.06703299283981323, Accuracy: 0.8082571420818567\n",
      "Iteration: 7232, Loss: 0.08536770939826965, Accuracy: 0.8125407695770264\n",
      "Iteration: 7296, Loss: 0.023665329441428185, Accuracy: 0.8131464964244515\n",
      "Iteration: 7360, Loss: 0.04875406622886658, Accuracy: 0.8133099736878648\n",
      "Iteration: 7424, Loss: 0.1322556585073471, Accuracy: 0.822026151814498\n",
      "Iteration: 7488, Loss: 0.04085950553417206, Accuracy: 0.8203173954971135\n",
      "Iteration: 7552, Loss: 0.02603650651872158, Accuracy: 0.8249965230934322\n",
      "Iteration: 7616, Loss: 0.056694407016038895, Accuracy: 0.8247310925507918\n",
      "Iteration: 7680, Loss: 0.11168915033340454, Accuracy: 0.8283865861594677\n",
      "Iteration: 7744, Loss: 0.0376417376101017, Accuracy: 0.8303703371202573\n",
      "Iteration: 7808, Loss: 0.053954314440488815, Accuracy: 0.8278957596048713\n",
      "Iteration: 7872, Loss: 0.029105057939887047, Accuracy: 0.835558699327521\n",
      "Iteration: 7936, Loss: 0.06977832317352295, Accuracy: 0.8379882532171905\n",
      "Iteration: 8000, Loss: 0.03992154821753502, Accuracy: 0.8390194509411231\n",
      "Iteration: 8064, Loss: 0.02453971467912197, Accuracy: 0.8412142206216231\n",
      "Iteration: 8128, Loss: 0.04271722957491875, Accuracy: 0.8426996759371832\n",
      "Iteration: 8192, Loss: 0.04146304354071617, Accuracy: 0.8444404925685376\n",
      "Iteration: 8256, Loss: 0.15736021101474762, Accuracy: 0.8395311164204031\n",
      "Iteration: 8320, Loss: 0.04142436757683754, Accuracy: 0.8452062018914148\n",
      "Iteration: 8384, Loss: 0.03318540379405022, Accuracy: 0.8480373495258391\n",
      "Iteration: 8448, Loss: 0.036622483283281326, Accuracy: 0.8527465537190437\n",
      "Iteration: 8512, Loss: 0.02754157967865467, Accuracy: 0.851184161612764\n",
      "Iteration: 8576, Loss: 0.014171093702316284, Accuracy: 0.8550868328893557\n",
      "Iteration: 8640, Loss: 0.009137359447777271, Accuracy: 0.856202463270165\n",
      "Iteration: 8704, Loss: 0.009219295345246792, Accuracy: 0.8600405127508566\n",
      "Iteration: 8768, Loss: 0.07272568345069885, Accuracy: 0.8550500207347795\n",
      "Iteration: 8832, Loss: 0.03991476446390152, Accuracy: 0.8603602581424639\n",
      "Iteration: 8896, Loss: 0.00806343648582697, Accuracy: 0.8615661206422374\n",
      "Iteration: 8960, Loss: 0.006661130115389824, Accuracy: 0.8593128599459305\n",
      "Iteration: 9024, Loss: 0.028050074353814125, Accuracy: 0.8680004060734063\n",
      "Iteration: 9088, Loss: 0.009220242500305176, Accuracy: 0.8710744854761288\n",
      "Iteration: 9152, Loss: 0.061678577214479446, Accuracy: 0.8711186100263149\n",
      "Iteration: 9216, Loss: 0.019721010699868202, Accuracy: 0.8737822941038758\n",
      "Iteration: 9280, Loss: 0.011414322070777416, Accuracy: 0.8749523588921875\n",
      "Iteration: 9344, Loss: 0.02576717920601368, Accuracy: 0.8772253618808463\n",
      "Iteration: 9408, Loss: 0.15616869926452637, Accuracy: 0.8751403822680004\n",
      "Iteration: 9472, Loss: 0.07538790255784988, Accuracy: 0.8719900585711002\n",
      "Iteration: 9536, Loss: 0.025739604607224464, Accuracy: 0.869567604502663\n",
      "Iteration: 9600, Loss: 0.06270918250083923, Accuracy: 0.8766521027428098\n",
      "Iteration: 9664, Loss: 0.013534589670598507, Accuracy: 0.8845946014043875\n",
      "Iteration: 9728, Loss: 0.033808138221502304, Accuracy: 0.8886045069666579\n",
      "Iteration: 9792, Loss: 0.06767343729734421, Accuracy: 0.891969709075056\n",
      "Iteration: 9856, Loss: 0.008119395934045315, Accuracy: 0.8873388118809089\n",
      "Iteration: 9920, Loss: 0.04532094672322273, Accuracy: 0.8824122720398009\n",
      "Iteration: 9984, Loss: 0.013232654891908169, Accuracy: 0.8920928979641758\n",
      "Iteration: 10048, Loss: 0.014669101685285568, Accuracy: 0.8959778196876869\n",
      "Iteration: 10112, Loss: 0.04491141438484192, Accuracy: 0.898651797499042\n",
      "Iteration: 10176, Loss: 0.008001322858035564, Accuracy: 0.8948745642555878\n",
      "Iteration: 10240, Loss: 0.02219887264072895, Accuracy: 0.8922898633754812\n",
      "Iteration: 10304, Loss: 0.020614752545952797, Accuracy: 0.8952978044981137\n",
      "Iteration: 10368, Loss: 0.04558263719081879, Accuracy: 0.8852236165548675\n",
      "Iteration: 10432, Loss: 0.014752067625522614, Accuracy: 0.8974212025059387\n",
      "Iteration: 10496, Loss: 0.0034985949750989676, Accuracy: 0.9059792915359139\n",
      "Iteration: 10560, Loss: 0.01232956349849701, Accuracy: 0.9043370130239055\n",
      "Iteration: 10624, Loss: 0.018888501450419426, Accuracy: 0.9075898512382992\n",
      "Iteration: 10688, Loss: 0.007320172619074583, Accuracy: 0.9066190258599818\n",
      "Iteration: 10752, Loss: 0.023465005680918694, Accuracy: 0.9083628045627847\n",
      "Iteration: 10816, Loss: 0.0470711886882782, Accuracy: 0.9026061112526804\n",
      "Iteration: 10880, Loss: 0.018933651968836784, Accuracy: 0.9030462561640888\n",
      "Iteration: 10944, Loss: 0.010425387881696224, Accuracy: 0.9093191915308125\n",
      "Iteration: 11008, Loss: 0.0024552447721362114, Accuracy: 0.910859155934304\n",
      "Iteration: 11072, Loss: 0.004583202302455902, Accuracy: 0.9067050092271529\n",
      "Iteration: 11136, Loss: 0.001884986530058086, Accuracy: 0.9105050767539069\n",
      "Iteration: 11200, Loss: 0.014565177261829376, Accuracy: 0.9172721662907861\n",
      "Iteration: 11264, Loss: 0.002346487483009696, Accuracy: 0.9110363628715277\n",
      "Iteration: 11328, Loss: 0.07071580737829208, Accuracy: 0.91193404677324\n",
      "Iteration: 11392, Loss: 0.0017197375418618321, Accuracy: 0.9148999776807614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 11456, Loss: 0.01266949251294136, Accuracy: 0.9108324564876966\n",
      "Iteration: 11520, Loss: 0.0016191834583878517, Accuracy: 0.9137532184831798\n",
      "Iteration: 11584, Loss: 0.014510277658700943, Accuracy: 0.9256663939158898\n",
      "Iteration: 11648, Loss: 0.017150981351733208, Accuracy: 0.9115955435263459\n",
      "Iteration: 11712, Loss: 0.009178895503282547, Accuracy: 0.9217875027679838\n",
      "Iteration: 11776, Loss: 0.003970086108893156, Accuracy: 0.9207032464328222\n",
      "Iteration: 11840, Loss: 0.003473099321126938, Accuracy: 0.9284606446453836\n",
      "Iteration: 11904, Loss: 0.009987796656787395, Accuracy: 0.9199108502652962\n",
      "Iteration: 11968, Loss: 0.00157933309674263, Accuracy: 0.9190574972599279\n",
      "Iteration: 12032, Loss: 0.02127387560904026, Accuracy: 0.9263883693492971\n",
      "Iteration: 12096, Loss: 0.17089903354644775, Accuracy: 0.9160152573895175\n",
      "Iteration: 12160, Loss: 0.02117229998111725, Accuracy: 0.9206950282095931\n",
      "Iteration: 12224, Loss: 0.009165782481431961, Accuracy: 0.927476387412753\n",
      "Iteration: 12288, Loss: 0.014345121569931507, Accuracy: 0.9359360079106409\n",
      "Iteration: 12352, Loss: 0.00286201317794621, Accuracy: 0.9120947885385249\n",
      "Iteration: 12416, Loss: 0.0018949544755741954, Accuracy: 0.9291710803518072\n",
      "Iteration: 12480, Loss: 0.009080485440790653, Accuracy: 0.9221907006576657\n",
      "Iteration: 12544, Loss: 0.0012705308618023992, Accuracy: 0.9376306702906732\n",
      "Iteration: 12608, Loss: 0.0016243504360318184, Accuracy: 0.9339154619956389\n",
      "Iteration: 12672, Loss: 0.0011408820282667875, Accuracy: 0.9256497671594843\n",
      "Iteration: 12736, Loss: 0.008546494878828526, Accuracy: 0.9372807839827146\n",
      "Iteration: 12800, Loss: 0.041640978306531906, Accuracy: 0.9368421410326846\n",
      "Iteration: 12864, Loss: 0.00141172728035599, Accuracy: 0.9295396415691357\n",
      "Iteration: 12928, Loss: 0.0023391314316540956, Accuracy: 0.9297266723588109\n",
      "Iteration: 12992, Loss: 0.0680609717965126, Accuracy: 0.9309986426960677\n",
      "Iteration: 13056, Loss: 0.00556702958419919, Accuracy: 0.919338032923406\n",
      "Iteration: 13120, Loss: 0.007200836669653654, Accuracy: 0.9343011815217324\n",
      "Iteration: 13184, Loss: 0.0011622743913903832, Accuracy: 0.9196138672996312\n",
      "Iteration: 13248, Loss: 0.001333033200353384, Accuracy: 0.9461297878006008\n",
      "Iteration: 13312, Loss: 0.01033759769052267, Accuracy: 0.9332659785286523\n",
      "Iteration: 13376, Loss: 0.020640257745981216, Accuracy: 0.9334908993041608\n",
      "Iteration: 13440, Loss: 0.0077149090357124805, Accuracy: 0.938070030650124\n",
      "Iteration: 13504, Loss: 0.0020527010783553123, Accuracy: 0.9386377179762349\n",
      "Iteration: 13568, Loss: 0.014544465579092503, Accuracy: 0.9359584239427932\n",
      "Iteration: 13632, Loss: 0.004403803031891584, Accuracy: 0.9406905755167827\n",
      "Iteration: 13696, Loss: 0.005090772639960051, Accuracy: 0.9436613459110959\n",
      "Iteration: 13760, Loss: 0.01773792691528797, Accuracy: 0.9342835464631207\n",
      "Iteration: 13824, Loss: 0.002293949481099844, Accuracy: 0.9360740800038911\n",
      "Iteration: 13888, Loss: 0.00118636607658118, Accuracy: 0.9474944601242896\n",
      "Iteration: 13952, Loss: 0.0009045960032381117, Accuracy: 0.9481843116955133\n",
      "Iteration: 14016, Loss: 0.0034092615824192762, Accuracy: 0.9413239047280513\n",
      "Iteration: 14080, Loss: 0.0006340187392197549, Accuracy: 0.9486335637047887\n",
      "Iteration: 14144, Loss: 0.0007960281218402088, Accuracy: 0.9489439208700787\n",
      "Iteration: 14208, Loss: 0.000696925853844732, Accuracy: 0.9411065013264306\n",
      "Iteration: 14272, Loss: 0.009085165336728096, Accuracy: 0.9514121124520898\n",
      "Iteration: 14336, Loss: 0.005981010850518942, Accuracy: 0.9439726868586149\n",
      "Iteration: 14400, Loss: 0.005150597542524338, Accuracy: 0.9437705560849281\n",
      "Iteration: 14464, Loss: 0.004536377266049385, Accuracy: 0.9545099186943844\n",
      "Iteration: 14528, Loss: 0.00943723414093256, Accuracy: 0.9411553138779709\n",
      "Iteration: 14592, Loss: 0.00444063451141119, Accuracy: 0.9323781119746855\n",
      "Iteration: 14656, Loss: 0.004588743671774864, Accuracy: 0.9369498576270416\n",
      "Iteration: 14720, Loss: 0.015502615831792355, Accuracy: 0.9430413127411157\n",
      "Iteration: 14784, Loss: 0.019900381565093994, Accuracy: 0.9407797123712953\n",
      "Iteration: 14848, Loss: 0.0044983006082475185, Accuracy: 0.9452987348049646\n",
      "Iteration: 14912, Loss: 0.001679114648140967, Accuracy: 0.953712546164752\n",
      "Iteration: 14976, Loss: 0.0006272519240155816, Accuracy: 0.9492890222172718\n",
      "Iteration: 15040, Loss: 0.041258323937654495, Accuracy: 0.9519898333528545\n",
      "Iteration: 15104, Loss: 0.007157599087804556, Accuracy: 0.9541819756996119\n",
      "Iteration: 15168, Loss: 0.001988567179068923, Accuracy: 0.9557082071260083\n",
      "Iteration: 15232, Loss: 0.0010919546475633979, Accuracy: 0.9615338445146335\n",
      "Iteration: 15296, Loss: 0.008997472934424877, Accuracy: 0.9559759585827123\n",
      "Iteration: 15360, Loss: 0.0004789403174072504, Accuracy: 0.952843440536526\n",
      "Iteration: 15424, Loss: 0.0001887570251710713, Accuracy: 0.9568542187480489\n",
      "Iteration: 15488, Loss: 0.00028795484104193747, Accuracy: 0.9514406401431188\n",
      "Iteration: 15552, Loss: 0.00047897337935864925, Accuracy: 0.9540245608513942\n",
      "Iteration: 15616, Loss: 0.0008061348344199359, Accuracy: 0.95321845523722\n",
      "Iteration: 15680, Loss: 0.022434184327721596, Accuracy: 0.9575435102306074\n",
      "Iteration: 15744, Loss: 0.1807929277420044, Accuracy: 0.9505018096388085\n",
      "Iteration: 15808, Loss: 0.0111577482894063, Accuracy: 0.9626896498375572\n",
      "Iteration: 15872, Loss: 0.003493795869871974, Accuracy: 0.9611981456255307\n",
      "Iteration: 15936, Loss: 0.0037017937283962965, Accuracy: 0.9622456700890325\n",
      "Iteration: 16000, Loss: 0.002564207650721073, Accuracy: 0.9571726701542502\n",
      "Iteration: 16064, Loss: 0.006074721459299326, Accuracy: 0.9520571624016156\n",
      "Iteration: 16128, Loss: 0.0005352688021957874, Accuracy: 0.9564353638998\n",
      "Iteration: 16192, Loss: 0.005545781925320625, Accuracy: 0.9577908476785524\n",
      "Iteration: 16256, Loss: 0.003223516745492816, Accuracy: 0.958874797768658\n",
      "Iteration: 16320, Loss: 0.00307618360966444, Accuracy: 0.9582017630164046\n",
      "Iteration: 16384, Loss: 0.0001623467105673626, Accuracy: 0.9599989675189136\n",
      "Iteration: 16448, Loss: 0.002960143843665719, Accuracy: 0.947316614081501\n",
      "Iteration: 16512, Loss: 0.001937355031259358, Accuracy: 0.942070275414153\n",
      "Iteration: 16576, Loss: 0.0002483221178408712, Accuracy: 0.9560656706889858\n",
      "Iteration: 16640, Loss: 0.0028409678488969803, Accuracy: 0.9581703582516639\n",
      "Iteration: 16704, Loss: 0.001658208784647286, Accuracy: 0.9634788827534067\n",
      "Iteration: 16768, Loss: 0.002684897044673562, Accuracy: 0.9611134679435054\n",
      "Iteration: 16832, Loss: 0.0011268268572166562, Accuracy: 0.9638950601656688\n",
      "Iteration: 16896, Loss: 0.0033495917450636625, Accuracy: 0.957071492979594\n",
      "Iteration: 16960, Loss: 0.0002916049270424992, Accuracy: 0.9649125415016897\n",
      "Iteration: 17024, Loss: 0.007369643542915583, Accuracy: 0.9675689478535787\n",
      "Iteration: 17088, Loss: 0.00023141712881624699, Accuracy: 0.964823463189532\n",
      "Iteration: 17152, Loss: 0.0030658047180622816, Accuracy: 0.9640219419961795\n",
      "Iteration: 17216, Loss: 0.003912009764462709, Accuracy: 0.9643035780172795\n",
      "Iteration: 17280, Loss: 0.00010170153109356761, Accuracy: 0.966680671175709\n",
      "Iteration: 17344, Loss: 0.00026472946046851575, Accuracy: 0.9687325762497494\n",
      "Iteration: 17408, Loss: 0.0013639978133141994, Accuracy: 0.9701619110419415\n",
      "Saved fullModel_dr[2]_replicate1.model\n",
      "Saved W_dr[2]_replicate1.p\n",
      "2 0.9895833333333334 [1.0, 0.96875, 1.0]\n",
      "Saved w_dr[2]_replicate1.p\n",
      "Replicate 1 completed\n",
      "Time elapsed: 123.25 seconds\n",
      "Iteration: 64, Loss: 0.23892660439014435, Accuracy: 0.5004710955545306\n",
      "Iteration: 128, Loss: 0.23560895025730133, Accuracy: 0.502082543913275\n",
      "Iteration: 192, Loss: 0.24950353801250458, Accuracy: 0.5100921080447733\n",
      "Iteration: 256, Loss: 0.19780872762203217, Accuracy: 0.5441529992967844\n",
      "Iteration: 320, Loss: 0.20589976012706757, Accuracy: 0.5894819549284875\n",
      "Iteration: 384, Loss: 0.18722987174987793, Accuracy: 0.6114098825491965\n",
      "Iteration: 448, Loss: 0.1551622599363327, Accuracy: 0.6227338458411396\n",
      "Iteration: 512, Loss: 0.15820913016796112, Accuracy: 0.6302588158287108\n",
      "Iteration: 576, Loss: 0.16485509276390076, Accuracy: 0.634868735447526\n",
      "Iteration: 640, Loss: 0.17186623811721802, Accuracy: 0.6385244773700833\n",
      "Iteration: 704, Loss: 0.16547466814517975, Accuracy: 0.6417413493618369\n",
      "Iteration: 768, Loss: 0.16493560373783112, Accuracy: 0.6435836437158287\n",
      "Iteration: 832, Loss: 0.16845476627349854, Accuracy: 0.6458559464663267\n",
      "Iteration: 896, Loss: 0.17761468887329102, Accuracy: 0.6459007631056011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 960, Loss: 0.16533710062503815, Accuracy: 0.6483274274505675\n",
      "Iteration: 1024, Loss: 0.1647823452949524, Accuracy: 0.648993284907192\n",
      "Iteration: 1088, Loss: 0.16511403024196625, Accuracy: 0.6449878923594952\n",
      "Iteration: 1152, Loss: 0.16853277385234833, Accuracy: 0.6513387463055551\n",
      "Iteration: 1216, Loss: 0.167952299118042, Accuracy: 0.6494727809913456\n",
      "Iteration: 1280, Loss: 0.15875305235385895, Accuracy: 0.6510373679921031\n",
      "Iteration: 1344, Loss: 0.17152269184589386, Accuracy: 0.6515057603828609\n",
      "Iteration: 1408, Loss: 0.16878525912761688, Accuracy: 0.6525956536643207\n",
      "Iteration: 1472, Loss: 0.1772443652153015, Accuracy: 0.6534476052038372\n",
      "Iteration: 1536, Loss: 0.1537197381258011, Accuracy: 0.6532536349259317\n",
      "Iteration: 1600, Loss: 0.14917653799057007, Accuracy: 0.6538581168279052\n",
      "Iteration: 1664, Loss: 0.1526648849248886, Accuracy: 0.6543708872050047\n",
      "Iteration: 1728, Loss: 0.1685492843389511, Accuracy: 0.6561212851665914\n",
      "Iteration: 1792, Loss: 0.15969474613666534, Accuracy: 0.6557337450794876\n",
      "Iteration: 1856, Loss: 0.1495477706193924, Accuracy: 0.6558982520364225\n",
      "Iteration: 1920, Loss: 0.13604141771793365, Accuracy: 0.6597186494618654\n",
      "Iteration: 1984, Loss: 0.14467094838619232, Accuracy: 0.6608662977814674\n",
      "Iteration: 2048, Loss: 0.1742503046989441, Accuracy: 0.6615944840013981\n",
      "Iteration: 2112, Loss: 0.14731228351593018, Accuracy: 0.6673478353768587\n",
      "Iteration: 2176, Loss: 0.1538257598876953, Accuracy: 0.667991241440177\n",
      "Iteration: 2240, Loss: 0.189022496342659, Accuracy: 0.6734696822240949\n",
      "Iteration: 2304, Loss: 0.16063706576824188, Accuracy: 0.6734400177374482\n",
      "Iteration: 2368, Loss: 0.15192462503910065, Accuracy: 0.6827552556060255\n",
      "Iteration: 2432, Loss: 0.1332578808069229, Accuracy: 0.6823268169537187\n",
      "Iteration: 2496, Loss: 0.13118146359920502, Accuracy: 0.6876446041278541\n",
      "Iteration: 2560, Loss: 0.17390231788158417, Accuracy: 0.6915471665561199\n",
      "Iteration: 2624, Loss: 0.13919413089752197, Accuracy: 0.6993624845054001\n",
      "Iteration: 2688, Loss: 0.13781951367855072, Accuracy: 0.7087975402828306\n",
      "Iteration: 2752, Loss: 0.13249622285366058, Accuracy: 0.7000919301062822\n",
      "Iteration: 2816, Loss: 0.12368828803300858, Accuracy: 0.7171574365347624\n",
      "Iteration: 2880, Loss: 0.1041722223162651, Accuracy: 0.720235132612288\n",
      "Iteration: 2944, Loss: 0.07451169937849045, Accuracy: 0.7300269026309252\n",
      "Iteration: 3008, Loss: 0.10328814387321472, Accuracy: 0.7233234585728496\n",
      "Iteration: 3072, Loss: 0.06905064731836319, Accuracy: 0.740515915909782\n",
      "Iteration: 3136, Loss: 0.2258598953485489, Accuracy: 0.7320130423177034\n",
      "Iteration: 3200, Loss: 0.11704205721616745, Accuracy: 0.7402079903986305\n",
      "Iteration: 3264, Loss: 0.11615467816591263, Accuracy: 0.7363570996094495\n",
      "Iteration: 3328, Loss: 0.11520367860794067, Accuracy: 0.7396245968993753\n",
      "Iteration: 3392, Loss: 0.11771998554468155, Accuracy: 0.7535270904190838\n",
      "Iteration: 3456, Loss: 0.07471679896116257, Accuracy: 0.7626167074777186\n",
      "Iteration: 3520, Loss: 0.07239056378602982, Accuracy: 0.7499132298398763\n",
      "Iteration: 3584, Loss: 0.06967879086732864, Accuracy: 0.7594714700244367\n",
      "Iteration: 3648, Loss: 0.0846528485417366, Accuracy: 0.7555329422466457\n",
      "Iteration: 3712, Loss: 0.07361313700675964, Accuracy: 0.7547939857468009\n",
      "Iteration: 3776, Loss: 0.1426897794008255, Accuracy: 0.7617922963108867\n",
      "Iteration: 3840, Loss: 0.20067088305950165, Accuracy: 0.752438118448481\n",
      "Iteration: 3904, Loss: 0.1466248482465744, Accuracy: 0.7557980176061392\n",
      "Iteration: 3968, Loss: 0.11152615398168564, Accuracy: 0.7662082738243043\n",
      "Iteration: 4032, Loss: 0.07052141427993774, Accuracy: 0.7726559001021087\n",
      "Iteration: 4096, Loss: 0.08441779762506485, Accuracy: 0.76832245872356\n",
      "Iteration: 4160, Loss: 0.08484696596860886, Accuracy: 0.7665888851042837\n",
      "Iteration: 4224, Loss: 0.0959649458527565, Accuracy: 0.7750809560529888\n",
      "Iteration: 4288, Loss: 0.08757003396749496, Accuracy: 0.7762701308820397\n",
      "Iteration: 4352, Loss: 0.09254991263151169, Accuracy: 0.7776699278037995\n",
      "Iteration: 4416, Loss: 0.08364540338516235, Accuracy: 0.7878990489989519\n",
      "Iteration: 4480, Loss: 0.14711670577526093, Accuracy: 0.7753145142924041\n",
      "Iteration: 4544, Loss: 0.09585592150688171, Accuracy: 0.7823079160880297\n",
      "Iteration: 4608, Loss: 0.06953422725200653, Accuracy: 0.7910349732264876\n",
      "Iteration: 4672, Loss: 0.08276767283678055, Accuracy: 0.7835359866730869\n",
      "Iteration: 4736, Loss: 0.07949278503656387, Accuracy: 0.7647480133455247\n",
      "Iteration: 4800, Loss: 0.09788692742586136, Accuracy: 0.7844751256052405\n",
      "Iteration: 4864, Loss: 0.10280368477106094, Accuracy: 0.784585009329021\n",
      "Iteration: 4928, Loss: 0.1074366644024849, Accuracy: 0.7690452057868242\n",
      "Iteration: 4992, Loss: 0.13035118579864502, Accuracy: 0.7910419711843133\n",
      "Iteration: 5056, Loss: 0.08963080495595932, Accuracy: 0.7893162481486797\n",
      "Iteration: 5120, Loss: 0.08888386934995651, Accuracy: 0.7820461874362081\n",
      "Iteration: 5184, Loss: 0.06920674443244934, Accuracy: 0.7824012383352965\n",
      "Iteration: 5248, Loss: 0.10330603271722794, Accuracy: 0.794164577499032\n",
      "Iteration: 5312, Loss: 0.10082788020372391, Accuracy: 0.7910097669810057\n",
      "Iteration: 5376, Loss: 0.094597227871418, Accuracy: 0.7868837849237025\n",
      "Iteration: 5440, Loss: 0.06907124072313309, Accuracy: 0.7969442866742611\n",
      "Iteration: 5504, Loss: 0.09910085797309875, Accuracy: 0.7869225663598627\n",
      "Iteration: 5568, Loss: 0.08543303608894348, Accuracy: 0.7901853639632463\n",
      "Iteration: 5632, Loss: 0.3989219665527344, Accuracy: 0.793505179695785\n",
      "Iteration: 5696, Loss: 0.0837753638625145, Accuracy: 0.7866440755315125\n",
      "Iteration: 5760, Loss: 0.10360883921384811, Accuracy: 0.7936444382648915\n",
      "Iteration: 5824, Loss: 0.10817557573318481, Accuracy: 0.7997030385304242\n",
      "Iteration: 5888, Loss: 0.08452600240707397, Accuracy: 0.7930250300560147\n",
      "Iteration: 5952, Loss: 0.08017802238464355, Accuracy: 0.7961509532760829\n",
      "Iteration: 6016, Loss: 0.0881505236029625, Accuracy: 0.805860992288217\n",
      "Iteration: 6080, Loss: 0.09168114513158798, Accuracy: 0.8039551819674671\n",
      "Iteration: 6144, Loss: 0.06668844074010849, Accuracy: 0.8044069143943489\n",
      "Iteration: 6208, Loss: 0.06620294600725174, Accuracy: 0.8047985334414989\n",
      "Iteration: 6272, Loss: 0.09754756838083267, Accuracy: 0.8019726322963834\n",
      "Iteration: 6336, Loss: 0.0747872069478035, Accuracy: 0.80627774563618\n",
      "Iteration: 6400, Loss: 0.10127129405736923, Accuracy: 0.8046938902698457\n",
      "Iteration: 6464, Loss: 0.06590737402439117, Accuracy: 0.7962768354918808\n",
      "Iteration: 6528, Loss: 0.1053987443447113, Accuracy: 0.8044951749034226\n",
      "Iteration: 6592, Loss: 0.06960440427064896, Accuracy: 0.8046936758328229\n",
      "Iteration: 6656, Loss: 0.09058672934770584, Accuracy: 0.7988824148196727\n",
      "Iteration: 6720, Loss: 0.06828101724386215, Accuracy: 0.8079154926817864\n",
      "Iteration: 6784, Loss: 0.09070836752653122, Accuracy: 0.8083602818660438\n",
      "Iteration: 6848, Loss: 0.06410198658704758, Accuracy: 0.8107223398983479\n",
      "Iteration: 6912, Loss: 0.06711462885141373, Accuracy: 0.8026614377740771\n",
      "Iteration: 6976, Loss: 0.07762067019939423, Accuracy: 0.8147090189158916\n",
      "Iteration: 7040, Loss: 0.07710766047239304, Accuracy: 0.8008721545338631\n",
      "Iteration: 7104, Loss: 0.06819813698530197, Accuracy: 0.8170062662102282\n",
      "Iteration: 7168, Loss: 0.0986340269446373, Accuracy: 0.8136648251675069\n",
      "Iteration: 7232, Loss: 0.09492843598127365, Accuracy: 0.7998568608891219\n",
      "Iteration: 7296, Loss: 0.06787298619747162, Accuracy: 0.8121829160954803\n",
      "Iteration: 7360, Loss: 0.09237029403448105, Accuracy: 0.8081394236069173\n",
      "Iteration: 7424, Loss: 0.09424931555986404, Accuracy: 0.8091003049630672\n",
      "Iteration: 7488, Loss: 0.19527971744537354, Accuracy: 0.8124452708289027\n",
      "Iteration: 7552, Loss: 0.06729487329721451, Accuracy: 0.8073112601414323\n",
      "Iteration: 7616, Loss: 0.07532230764627457, Accuracy: 0.8164604378398508\n",
      "Iteration: 7680, Loss: 0.3637172281742096, Accuracy: 0.8064144293311983\n",
      "Iteration: 7744, Loss: 0.058413803577423096, Accuracy: 0.8168236780911684\n",
      "Iteration: 7808, Loss: 0.10133698582649231, Accuracy: 0.8110508066602051\n",
      "Iteration: 7872, Loss: 0.05412236973643303, Accuracy: 0.8136800844222307\n",
      "Iteration: 7936, Loss: 0.10201817005872726, Accuracy: 0.8142321486957371\n",
      "Iteration: 8000, Loss: 0.08042820543050766, Accuracy: 0.8170043202117085\n",
      "Iteration: 8064, Loss: 0.060545045882463455, Accuracy: 0.8186879612039775\n",
      "Iteration: 8128, Loss: 0.08286530524492264, Accuracy: 0.8152414704672992\n",
      "Iteration: 8192, Loss: 0.07168655097484589, Accuracy: 0.8229723782278597\n",
      "Iteration: 8256, Loss: 0.0806909129023552, Accuracy: 0.8120198596734554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 8320, Loss: 0.06555059552192688, Accuracy: 0.8081855494529009\n",
      "Iteration: 8384, Loss: 0.06712698936462402, Accuracy: 0.8173868088051677\n",
      "Iteration: 8448, Loss: 0.08017072081565857, Accuracy: 0.8208903879858553\n",
      "Iteration: 8512, Loss: 0.06478753685951233, Accuracy: 0.8338076007785276\n",
      "Iteration: 8576, Loss: 0.06292663514614105, Accuracy: 0.8238513239193708\n",
      "Iteration: 8640, Loss: 0.1053994819521904, Accuracy: 0.8274225406348705\n",
      "Iteration: 8704, Loss: 0.0668063834309578, Accuracy: 0.8161964196478948\n",
      "Iteration: 8768, Loss: 0.1023995652794838, Accuracy: 0.8232738436199725\n",
      "Iteration: 8832, Loss: 0.0681542158126831, Accuracy: 0.8222886404255405\n",
      "Iteration: 8896, Loss: 0.06777404248714447, Accuracy: 0.8255357416346669\n",
      "Iteration: 8960, Loss: 0.030987707898020744, Accuracy: 0.8417756634298712\n",
      "Iteration: 9024, Loss: 0.08885648101568222, Accuracy: 0.8256050203926861\n",
      "Iteration: 9088, Loss: 0.08241575211286545, Accuracy: 0.8296334561891854\n",
      "Iteration: 9152, Loss: 0.062064480036497116, Accuracy: 0.8315862016752362\n",
      "Iteration: 9216, Loss: 0.10008793324232101, Accuracy: 0.8421365878311917\n",
      "Iteration: 9280, Loss: 0.10638388246297836, Accuracy: 0.836835247464478\n",
      "Iteration: 9344, Loss: 0.05729244649410248, Accuracy: 0.8399688163772225\n",
      "Iteration: 9408, Loss: 0.028704823926091194, Accuracy: 0.8409416475333273\n",
      "Iteration: 9472, Loss: 0.09370964020490646, Accuracy: 0.8443765611154959\n",
      "Iteration: 9536, Loss: 0.054664094001054764, Accuracy: 0.8453347354661673\n",
      "Iteration: 9600, Loss: 0.061278074979782104, Accuracy: 0.8404253252083436\n",
      "Iteration: 9664, Loss: 0.02501363307237625, Accuracy: 0.8549997004447505\n",
      "Iteration: 9728, Loss: 0.10830935090780258, Accuracy: 0.8397845886647701\n",
      "Iteration: 9792, Loss: 0.10507390648126602, Accuracy: 0.8452813618350774\n",
      "Iteration: 9856, Loss: 0.08607029169797897, Accuracy: 0.8428846296155825\n",
      "Iteration: 9920, Loss: 0.025379804894328117, Accuracy: 0.8321993557037786\n",
      "Iteration: 9984, Loss: 0.06688579171895981, Accuracy: 0.8497345226351172\n",
      "Iteration: 10048, Loss: 0.016582133248448372, Accuracy: 0.8468477363931015\n",
      "Iteration: 10112, Loss: 0.012868939898908138, Accuracy: 0.8435322971781716\n",
      "Iteration: 10176, Loss: 0.0869346633553505, Accuracy: 0.8570227683521807\n",
      "Iteration: 10240, Loss: 0.02631455473601818, Accuracy: 0.8546141480328515\n",
      "Iteration: 10304, Loss: 0.0878557562828064, Accuracy: 0.8533926664385945\n",
      "Iteration: 10368, Loss: 0.013955563306808472, Accuracy: 0.8520679970970377\n",
      "Iteration: 10432, Loss: 0.011174718849360943, Accuracy: 0.8500605782028288\n",
      "Iteration: 10496, Loss: 0.00895839836448431, Accuracy: 0.8600680688396096\n",
      "Iteration: 10560, Loss: 0.019743705168366432, Accuracy: 0.8509135025669821\n",
      "Iteration: 10624, Loss: 0.07292726635932922, Accuracy: 0.8623097926029004\n",
      "Iteration: 10688, Loss: 0.06409433484077454, Accuracy: 0.8432252847705968\n",
      "Iteration: 10752, Loss: 0.010409058071672916, Accuracy: 0.8530076820170507\n",
      "Iteration: 10816, Loss: 0.01309881079941988, Accuracy: 0.8669482848490588\n",
      "Iteration: 10880, Loss: 0.011106285266578197, Accuracy: 0.861608600767795\n",
      "Iteration: 10944, Loss: 0.015884434804320335, Accuracy: 0.8707752616610378\n",
      "Iteration: 11008, Loss: 0.018672605976462364, Accuracy: 0.8660313211148605\n",
      "Iteration: 11072, Loss: 0.07330551743507385, Accuracy: 0.8602212503319606\n",
      "Iteration: 11136, Loss: 0.025834230706095695, Accuracy: 0.8490879163146019\n",
      "Iteration: 11200, Loss: 0.013799823820590973, Accuracy: 0.8678882051608525\n",
      "Iteration: 11264, Loss: 0.06850670278072357, Accuracy: 0.8522758046165109\n",
      "Iteration: 11328, Loss: 0.06854719668626785, Accuracy: 0.8713362005655654\n",
      "Iteration: 11392, Loss: 0.008739729411900043, Accuracy: 0.865870175533928\n",
      "Iteration: 11456, Loss: 0.009736274369060993, Accuracy: 0.8635042884852737\n",
      "Iteration: 11520, Loss: 0.0342676043510437, Accuracy: 0.8568083619466051\n",
      "Iteration: 11584, Loss: 0.03703579306602478, Accuracy: 0.8664260524092242\n",
      "Iteration: 11648, Loss: 0.004895695485174656, Accuracy: 0.8770495461649261\n",
      "Iteration: 11712, Loss: 0.007372319232672453, Accuracy: 0.8750553363352083\n",
      "Iteration: 11776, Loss: 0.08677955716848373, Accuracy: 0.8688248113030568\n",
      "Iteration: 11840, Loss: 0.09835636615753174, Accuracy: 0.8738350028870627\n",
      "Iteration: 11904, Loss: 0.07532181590795517, Accuracy: 0.861051311600022\n",
      "Iteration: 11968, Loss: 0.07477182894945145, Accuracy: 0.8832290901336819\n",
      "Iteration: 12032, Loss: 0.04636493697762489, Accuracy: 0.8739296951098368\n",
      "Iteration: 12096, Loss: 0.06380976736545563, Accuracy: 0.8652970336261205\n",
      "Iteration: 12160, Loss: 0.007589798886328936, Accuracy: 0.8851624949020334\n",
      "Iteration: 12224, Loss: 0.004684825893491507, Accuracy: 0.8828296187566593\n",
      "Iteration: 12288, Loss: 0.085798479616642, Accuracy: 0.8752443657140248\n",
      "Iteration: 12352, Loss: 0.008594437502324581, Accuracy: 0.8784986241371371\n",
      "Iteration: 12416, Loss: 0.05957026779651642, Accuracy: 0.8744474963168614\n",
      "Iteration: 12480, Loss: 0.04863626882433891, Accuracy: 0.8786689967382699\n",
      "Iteration: 12544, Loss: 0.07169310748577118, Accuracy: 0.8695650706067681\n",
      "Iteration: 12608, Loss: 0.007726956158876419, Accuracy: 0.8841916450764984\n",
      "Iteration: 12672, Loss: 0.08822501450777054, Accuracy: 0.8855657852254808\n",
      "Iteration: 12736, Loss: 0.004529449623078108, Accuracy: 0.8868239264702424\n",
      "Iteration: 12800, Loss: 0.1003229022026062, Accuracy: 0.8872588434896898\n",
      "Iteration: 12864, Loss: 0.003990619909018278, Accuracy: 0.8926979124953505\n",
      "Iteration: 12928, Loss: 0.006070844363421202, Accuracy: 0.8874251166707836\n",
      "Iteration: 12992, Loss: 0.23086494207382202, Accuracy: 0.8775910948461387\n",
      "Iteration: 13056, Loss: 0.07474683225154877, Accuracy: 0.8923918599321041\n",
      "Iteration: 13120, Loss: 0.009234380908310413, Accuracy: 0.8879633787146304\n",
      "Iteration: 13184, Loss: 0.005237536504864693, Accuracy: 0.866645911388332\n",
      "Iteration: 13248, Loss: 0.008997557684779167, Accuracy: 0.8919491209671833\n",
      "Iteration: 13312, Loss: 0.0037935690488666296, Accuracy: 0.8945595614204649\n",
      "Iteration: 13376, Loss: 0.06643158197402954, Accuracy: 0.8914115408842918\n",
      "Iteration: 13440, Loss: 0.02642175555229187, Accuracy: 0.8917523800337221\n",
      "Iteration: 13504, Loss: 0.08095133304595947, Accuracy: 0.8853510376939084\n",
      "Iteration: 13568, Loss: 0.0024625479709357023, Accuracy: 0.8908432937168982\n",
      "Iteration: 13632, Loss: 0.04330819472670555, Accuracy: 0.8990172865160275\n",
      "Iteration: 13696, Loss: 0.007442555855959654, Accuracy: 0.8871483062393963\n",
      "Iteration: 13760, Loss: 0.024252884089946747, Accuracy: 0.8822641538281459\n",
      "Iteration: 13824, Loss: 0.08257045596837997, Accuracy: 0.9023035305726808\n",
      "Iteration: 13888, Loss: 0.055386874824762344, Accuracy: 0.9016952268138994\n",
      "Iteration: 13952, Loss: 0.06120499595999718, Accuracy: 0.8990089247236028\n",
      "Iteration: 14016, Loss: 0.09442510455846786, Accuracy: 0.8801495718362276\n",
      "Iteration: 14080, Loss: 0.0013597338693216443, Accuracy: 0.8891642297094222\n",
      "Iteration: 14144, Loss: 0.271744042634964, Accuracy: 0.9018252639216371\n",
      "Iteration: 14208, Loss: 0.04545212164521217, Accuracy: 0.8925132162694354\n",
      "Iteration: 14272, Loss: 0.053072649985551834, Accuracy: 0.903480591805419\n",
      "Iteration: 14336, Loss: 0.05216437205672264, Accuracy: 0.8882904163911007\n",
      "Iteration: 14400, Loss: 0.021210653707385063, Accuracy: 0.901588854030706\n",
      "Iteration: 14464, Loss: 0.07363500446081161, Accuracy: 0.9088068855635356\n",
      "Iteration: 14528, Loss: 0.04631861671805382, Accuracy: 0.8957981761195697\n",
      "Iteration: 14592, Loss: 0.014846156351268291, Accuracy: 0.9109458393068053\n",
      "Iteration: 14656, Loss: 0.018939172849059105, Accuracy: 0.9077968462079298\n",
      "Iteration: 14720, Loss: 0.004507125820964575, Accuracy: 0.9154371898621321\n",
      "Iteration: 14784, Loss: 0.0036286721006035805, Accuracy: 0.9145219914644258\n",
      "Iteration: 14848, Loss: 0.05610349401831627, Accuracy: 0.907118811912369\n",
      "Iteration: 14912, Loss: 0.06530880182981491, Accuracy: 0.9271928401722107\n",
      "Iteration: 14976, Loss: 0.004787561949342489, Accuracy: 0.9252885218011215\n",
      "Iteration: 15040, Loss: 0.15022562444210052, Accuracy: 0.9159849701973144\n",
      "Iteration: 15104, Loss: 0.006760811433196068, Accuracy: 0.9165121877158526\n",
      "Iteration: 15168, Loss: 0.044881995767354965, Accuracy: 0.9213153603195678\n",
      "Iteration: 15232, Loss: 0.05526095628738403, Accuracy: 0.9194651719008107\n",
      "Iteration: 15296, Loss: 0.004459430929273367, Accuracy: 0.9251642048766371\n",
      "Iteration: 15360, Loss: 0.0009113706764765084, Accuracy: 0.9247078192711342\n",
      "Iteration: 15424, Loss: 0.05352120101451874, Accuracy: 0.9207284713338595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 15488, Loss: 0.00868548359721899, Accuracy: 0.9169629713869654\n",
      "Iteration: 15552, Loss: 0.016788367182016373, Accuracy: 0.9261666615784634\n",
      "Iteration: 15616, Loss: 0.00674797035753727, Accuracy: 0.9207812592503615\n",
      "Iteration: 15680, Loss: 0.03860314190387726, Accuracy: 0.9255969345977064\n",
      "Iteration: 15744, Loss: 0.01728270761668682, Accuracy: 0.9256343928864226\n",
      "Iteration: 15808, Loss: 0.0060669309459626675, Accuracy: 0.9353512543311808\n",
      "Iteration: 15872, Loss: 0.02276337333023548, Accuracy: 0.9393334678316023\n",
      "Iteration: 15936, Loss: 0.00749451806768775, Accuracy: 0.9273240182374138\n",
      "Iteration: 16000, Loss: 0.000515808816999197, Accuracy: 0.9379972361493856\n",
      "Iteration: 16064, Loss: 0.0018335739150643349, Accuracy: 0.9426136788679287\n",
      "Iteration: 16128, Loss: 0.041885267943143845, Accuracy: 0.9339886535599362\n",
      "Iteration: 16192, Loss: 0.006216219160705805, Accuracy: 0.942870632148697\n",
      "Iteration: 16256, Loss: 0.004335619043558836, Accuracy: 0.939744524541311\n",
      "Iteration: 16320, Loss: 0.002199573675170541, Accuracy: 0.9452710187179036\n",
      "Iteration: 16384, Loss: 0.0038366392254829407, Accuracy: 0.9400295136438217\n",
      "Iteration: 16448, Loss: 0.0012488760985434055, Accuracy: 0.944350378238596\n",
      "Iteration: 16512, Loss: 0.009110578335821629, Accuracy: 0.9259162805392407\n",
      "Iteration: 16576, Loss: 0.030773179605603218, Accuracy: 0.9359261525096372\n",
      "Iteration: 16640, Loss: 0.006395662669092417, Accuracy: 0.9522331590706017\n",
      "Iteration: 16704, Loss: 0.0036791327875107527, Accuracy: 0.9407244945323328\n",
      "Iteration: 16768, Loss: 0.00322545669041574, Accuracy: 0.9457280703209108\n",
      "Iteration: 16832, Loss: 0.0008001409005373716, Accuracy: 0.9411581433087122\n",
      "Iteration: 16896, Loss: 0.06046531721949577, Accuracy: 0.9362546496267896\n",
      "Iteration: 16960, Loss: 0.0027149636298418045, Accuracy: 0.931879506650148\n",
      "Iteration: 17024, Loss: 0.006260823458433151, Accuracy: 0.9514677237311844\n",
      "Iteration: 17088, Loss: 0.0013772957026958466, Accuracy: 0.9452597797790077\n",
      "Iteration: 17152, Loss: 0.0009566657245159149, Accuracy: 0.9483296804392012\n",
      "Iteration: 17216, Loss: 0.0007686854805797338, Accuracy: 0.9519667075801408\n",
      "Iteration: 17280, Loss: 0.023760976269841194, Accuracy: 0.9511353546695318\n",
      "Iteration: 17344, Loss: 0.0026160471606999636, Accuracy: 0.9397495104494737\n",
      "Iteration: 17408, Loss: 0.004170980770140886, Accuracy: 0.9359882303106133\n",
      "Iteration: 17472, Loss: 0.005486045498400927, Accuracy: 0.9551535458886065\n",
      "Iteration: 17536, Loss: 0.0014852248132228851, Accuracy: 0.9460391257161973\n",
      "Iteration: 17600, Loss: 0.0005375382606871426, Accuracy: 0.9559158178599318\n",
      "Iteration: 17664, Loss: 0.0025121679063886404, Accuracy: 0.9622623800387373\n",
      "Iteration: 17728, Loss: 0.003475950099527836, Accuracy: 0.9630010826076614\n",
      "Iteration: 17792, Loss: 0.07309658080339432, Accuracy: 0.9488476857659407\n",
      "Iteration: 17856, Loss: 0.0002060670085484162, Accuracy: 0.9573855578782968\n",
      "Iteration: 17920, Loss: 0.009234007447957993, Accuracy: 0.9572279280109797\n",
      "Iteration: 17984, Loss: 0.00046605023089796305, Accuracy: 0.9479143652424682\n",
      "Iteration: 18048, Loss: 0.0028890008106827736, Accuracy: 0.9582330959965475\n",
      "Iteration: 18112, Loss: 0.0042144618928432465, Accuracy: 0.9563996507495176\n",
      "Iteration: 18176, Loss: 0.0011635037371888757, Accuracy: 0.9558849304012256\n",
      "Iteration: 18240, Loss: 0.0008167012711055577, Accuracy: 0.95648635487305\n",
      "Iteration: 18304, Loss: 0.00090070441365242, Accuracy: 0.953706345622777\n",
      "Iteration: 18368, Loss: 0.00044734799303114414, Accuracy: 0.9526671098719817\n",
      "Iteration: 18432, Loss: 0.0006874487153254449, Accuracy: 0.9687188622920075\n",
      "Iteration: 18496, Loss: 0.0018812514608725905, Accuracy: 0.9648612973833224\n",
      "Iteration: 18560, Loss: 0.0007586166611872613, Accuracy: 0.9591885050758719\n",
      "Iteration: 18624, Loss: 0.002697566756978631, Accuracy: 0.9654462882608641\n",
      "Iteration: 18688, Loss: 0.00034950030385516584, Accuracy: 0.9633545121032512\n",
      "Iteration: 18752, Loss: 0.001717828563414514, Accuracy: 0.9670658107643249\n",
      "Iteration: 18816, Loss: 0.00026408417033962905, Accuracy: 0.9638440151611576\n",
      "Iteration: 18880, Loss: 0.0037279652897268534, Accuracy: 0.9662498280376894\n",
      "Iteration: 18944, Loss: 0.005921780597418547, Accuracy: 0.959235433183494\n",
      "Iteration: 19008, Loss: 0.0026652803644537926, Accuracy: 0.9580035011167638\n",
      "Iteration: 19072, Loss: 0.0004755972477141768, Accuracy: 0.9487367248366354\n",
      "Iteration: 19136, Loss: 0.009123953059315681, Accuracy: 0.9620638816268183\n",
      "Iteration: 19200, Loss: 0.03842807188630104, Accuracy: 0.9679471600975376\n",
      "Iteration: 19264, Loss: 0.0008006238494999707, Accuracy: 0.9654212317691417\n",
      "Iteration: 19328, Loss: 0.0010901328641921282, Accuracy: 0.9653497180697741\n",
      "Iteration: 19392, Loss: 0.0008119303383864462, Accuracy: 0.9682448710082099\n",
      "Iteration: 19456, Loss: 0.001407005824148655, Accuracy: 0.9584649505704874\n",
      "Iteration: 19520, Loss: 0.0036005834117531776, Accuracy: 0.9656011269107694\n",
      "Iteration: 19584, Loss: 0.0005222901818342507, Accuracy: 0.9561207479564473\n",
      "Iteration: 19648, Loss: 0.0011496000224724412, Accuracy: 0.967419286374934\n",
      "Iteration: 19712, Loss: 0.0004909273702651262, Accuracy: 0.9658114890480647\n",
      "Iteration: 19776, Loss: 0.0005962119903415442, Accuracy: 0.9509934822999639\n",
      "Iteration: 19840, Loss: 0.000774408399593085, Accuracy: 0.9700213633332169\n",
      "Saved fullModel_dr[2]_replicate2.model\n",
      "Saved W_dr[2]_replicate2.p\n",
      "2 1.0 [1.0, 1.0, 1.0]\n",
      "Saved w_dr[2]_replicate2.p\n",
      "Replicate 2 completed\n",
      "Time elapsed: 145.46875 seconds\n",
      "Iteration: 64, Loss: 0.28695178031921387, Accuracy: 0.4994112243875861\n",
      "Iteration: 128, Loss: 0.2563808262348175, Accuracy: 0.5016610152088106\n",
      "Iteration: 192, Loss: 0.23287181556224823, Accuracy: 0.5138267204165459\n",
      "Iteration: 256, Loss: 0.186292365193367, Accuracy: 0.554118322674185\n",
      "Iteration: 320, Loss: 0.22181101143360138, Accuracy: 0.5918546528555453\n",
      "Iteration: 384, Loss: 0.19331477582454681, Accuracy: 0.6116574918851256\n",
      "Iteration: 448, Loss: 0.1607675403356552, Accuracy: 0.6236784616485238\n",
      "Iteration: 512, Loss: 0.1870521903038025, Accuracy: 0.6300504771061242\n",
      "Iteration: 576, Loss: 0.15610599517822266, Accuracy: 0.6349567859433591\n",
      "Iteration: 640, Loss: 0.18557019531726837, Accuracy: 0.6389499995857477\n",
      "Iteration: 704, Loss: 0.15732485055923462, Accuracy: 0.6412964994087815\n",
      "Iteration: 768, Loss: 0.1810808926820755, Accuracy: 0.6404034858569503\n",
      "Iteration: 832, Loss: 0.18550993502140045, Accuracy: 0.6439501619897783\n",
      "Iteration: 896, Loss: 0.1852458268404007, Accuracy: 0.6415970367379487\n",
      "Iteration: 960, Loss: 0.1561492532491684, Accuracy: 0.6452467646449804\n",
      "Iteration: 1024, Loss: 0.17772085964679718, Accuracy: 0.6479533021338284\n",
      "Iteration: 1088, Loss: 0.17239810526371002, Accuracy: 0.6497237673029304\n",
      "Iteration: 1152, Loss: 0.15442048013210297, Accuracy: 0.6507708518765867\n",
      "Iteration: 1216, Loss: 0.17649583518505096, Accuracy: 0.6511053489521146\n",
      "Iteration: 1280, Loss: 0.158517524600029, Accuracy: 0.6514051761478186\n",
      "Iteration: 1344, Loss: 0.18121589720249176, Accuracy: 0.6528273350559175\n",
      "Iteration: 1408, Loss: 0.16246503591537476, Accuracy: 0.6529376115649939\n",
      "Iteration: 1472, Loss: 0.17788994312286377, Accuracy: 0.6538739935494959\n",
      "Iteration: 1536, Loss: 0.17750467360019684, Accuracy: 0.6539269885979593\n",
      "Iteration: 1600, Loss: 0.1647353619337082, Accuracy: 0.654621057678014\n",
      "Iteration: 1664, Loss: 0.17478008568286896, Accuracy: 0.6550392154604197\n",
      "Iteration: 1728, Loss: 0.16242526471614838, Accuracy: 0.6548724505119026\n",
      "Iteration: 1792, Loss: 0.17027556896209717, Accuracy: 0.6551721785217524\n",
      "Iteration: 1856, Loss: 0.15989206731319427, Accuracy: 0.655835690908134\n",
      "Iteration: 1920, Loss: 0.1718512624502182, Accuracy: 0.6564047066494823\n",
      "Iteration: 1984, Loss: 0.17042352259159088, Accuracy: 0.6550595592707396\n",
      "Iteration: 2048, Loss: 0.17598265409469604, Accuracy: 0.6574109480716288\n",
      "Iteration: 2112, Loss: 0.16976143419742584, Accuracy: 0.6542712855152786\n",
      "Iteration: 2176, Loss: 0.1595357358455658, Accuracy: 0.6571572530083358\n",
      "Iteration: 2240, Loss: 0.1731066107749939, Accuracy: 0.656961724627763\n",
      "Iteration: 2304, Loss: 0.1702692061662674, Accuracy: 0.6579243619926274\n",
      "Iteration: 2368, Loss: 0.16458570957183838, Accuracy: 0.6575812855735421\n",
      "Iteration: 2432, Loss: 0.1619223803281784, Accuracy: 0.6577683379873633\n",
      "Iteration: 2496, Loss: 0.16784454882144928, Accuracy: 0.6534457816742361\n",
      "Iteration: 2560, Loss: 0.17198149859905243, Accuracy: 0.6578758442774415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2624, Loss: 0.17732523381710052, Accuracy: 0.6585431690327823\n",
      "Iteration: 2688, Loss: 0.16156919300556183, Accuracy: 0.659035477321595\n",
      "Iteration: 2752, Loss: 0.17864899337291718, Accuracy: 0.6588421310298145\n",
      "Iteration: 2816, Loss: 0.17104573547840118, Accuracy: 0.6592138614505529\n",
      "Iteration: 2880, Loss: 0.13404269516468048, Accuracy: 0.6594736450351775\n",
      "Iteration: 2944, Loss: 0.16753964126110077, Accuracy: 0.6597290616482496\n",
      "Iteration: 3008, Loss: 0.17139919102191925, Accuracy: 0.6611224934458733\n",
      "Iteration: 3072, Loss: 0.16952311992645264, Accuracy: 0.6606416259892285\n",
      "Iteration: 3136, Loss: 0.1156175434589386, Accuracy: 0.663269096519798\n",
      "Iteration: 3200, Loss: 0.16990356147289276, Accuracy: 0.6641248087398708\n",
      "Iteration: 3264, Loss: 0.17852061986923218, Accuracy: 0.6630051610991359\n",
      "Iteration: 3328, Loss: 0.16385352611541748, Accuracy: 0.6715726372785866\n",
      "Iteration: 3392, Loss: 0.17360317707061768, Accuracy: 0.6701938463374972\n",
      "Iteration: 3456, Loss: 0.08983578532934189, Accuracy: 0.6763617121614516\n",
      "Iteration: 3520, Loss: 0.13330714404582977, Accuracy: 0.678886404260993\n",
      "Iteration: 3584, Loss: 0.1526382714509964, Accuracy: 0.6761418380774558\n",
      "Iteration: 3648, Loss: 0.07679520547389984, Accuracy: 0.6809724536724389\n",
      "Iteration: 3712, Loss: 0.17155928909778595, Accuracy: 0.687836141558364\n",
      "Iteration: 3776, Loss: 0.14968687295913696, Accuracy: 0.6873848689720035\n",
      "Iteration: 3840, Loss: 0.1457303762435913, Accuracy: 0.6895679458975792\n",
      "Iteration: 3904, Loss: 0.14169718325138092, Accuracy: 0.6967747120652348\n",
      "Iteration: 3968, Loss: 0.1781243234872818, Accuracy: 0.7028215653263032\n",
      "Iteration: 4032, Loss: 0.13670240342617035, Accuracy: 0.7089522341266274\n",
      "Iteration: 4096, Loss: 0.13649387657642365, Accuracy: 0.709830611012876\n",
      "Iteration: 4160, Loss: 0.1810576319694519, Accuracy: 0.7172005944885314\n",
      "Iteration: 4224, Loss: 0.06866219639778137, Accuracy: 0.7150600028689951\n",
      "Iteration: 4288, Loss: 0.06058642640709877, Accuracy: 0.7143753028940409\n",
      "Iteration: 4352, Loss: 0.09764722734689713, Accuracy: 0.7271390832029283\n",
      "Iteration: 4416, Loss: 0.1971459984779358, Accuracy: 0.7257961556315422\n",
      "Iteration: 4480, Loss: 0.04585223272442818, Accuracy: 0.7329227162990719\n",
      "Iteration: 4544, Loss: 0.08732664585113525, Accuracy: 0.7324408227577806\n",
      "Iteration: 4608, Loss: 0.08790028095245361, Accuracy: 0.7369100630749017\n",
      "Iteration: 4672, Loss: 0.17196790874004364, Accuracy: 0.732961657922715\n",
      "Iteration: 4736, Loss: 0.12889832258224487, Accuracy: 0.7262962004169822\n",
      "Iteration: 4800, Loss: 0.08156145364046097, Accuracy: 0.7410354218445718\n",
      "Iteration: 4864, Loss: 0.08115782588720322, Accuracy: 0.7426305895205587\n",
      "Iteration: 4928, Loss: 0.16551773250102997, Accuracy: 0.7424331931397319\n",
      "Iteration: 4992, Loss: 0.15899360179901123, Accuracy: 0.7392009485047311\n",
      "Iteration: 5056, Loss: 0.1568385511636734, Accuracy: 0.7523572230711579\n",
      "Iteration: 5120, Loss: 0.15733025968074799, Accuracy: 0.7491058672312647\n",
      "Iteration: 5184, Loss: 0.18946778774261475, Accuracy: 0.7580125825479627\n",
      "Iteration: 5248, Loss: 0.15256206691265106, Accuracy: 0.7556503575760871\n",
      "Iteration: 5312, Loss: 0.15547792613506317, Accuracy: 0.7470494164153934\n",
      "Iteration: 5376, Loss: 0.06434979289770126, Accuracy: 0.7619623213540763\n",
      "Iteration: 5440, Loss: 0.06518218666315079, Accuracy: 0.7553976774215698\n",
      "Iteration: 5504, Loss: 0.05497847869992256, Accuracy: 0.7647171886637807\n",
      "Iteration: 5568, Loss: 0.12111715227365494, Accuracy: 0.7642465003300458\n",
      "Iteration: 5632, Loss: 0.06172354891896248, Accuracy: 0.760685070650652\n",
      "Iteration: 5696, Loss: 0.05585795268416405, Accuracy: 0.7686508516781032\n",
      "Iteration: 5760, Loss: 0.16913752257823944, Accuracy: 0.7690189650747925\n",
      "Iteration: 5824, Loss: 0.06564227491617203, Accuracy: 0.7628384663257748\n",
      "Iteration: 5888, Loss: 0.10503885895013809, Accuracy: 0.7664434406906366\n",
      "Iteration: 5952, Loss: 0.07338700443506241, Accuracy: 0.7722784348297864\n",
      "Iteration: 6016, Loss: 0.09313615411520004, Accuracy: 0.7701377894263715\n",
      "Iteration: 6080, Loss: 0.06306597590446472, Accuracy: 0.7719946063589305\n",
      "Iteration: 6144, Loss: 0.1189863383769989, Accuracy: 0.7751584409270436\n",
      "Iteration: 6208, Loss: 0.08807245641946793, Accuracy: 0.7791531223338097\n",
      "Iteration: 6272, Loss: 0.058060090988874435, Accuracy: 0.7742298361845315\n",
      "Iteration: 6336, Loss: 0.07340342551469803, Accuracy: 0.7791300788521767\n",
      "Iteration: 6400, Loss: 0.1287216991186142, Accuracy: 0.7799030593596399\n",
      "Iteration: 6464, Loss: 0.0714147761464119, Accuracy: 0.774438310880214\n",
      "Iteration: 6528, Loss: 0.07073784619569778, Accuracy: 0.7835476857144386\n",
      "Iteration: 6592, Loss: 0.11386027187108994, Accuracy: 0.7829908293206245\n",
      "Iteration: 6656, Loss: 0.1108328104019165, Accuracy: 0.7902875002473593\n",
      "Iteration: 6720, Loss: 0.06126120686531067, Accuracy: 0.785950890975073\n",
      "Iteration: 6784, Loss: 0.11176813393831253, Accuracy: 0.786340499529615\n",
      "Iteration: 6848, Loss: 0.08505290746688843, Accuracy: 0.7783314746338874\n",
      "Iteration: 6912, Loss: 0.11370769143104553, Accuracy: 0.7922029118053615\n",
      "Iteration: 6976, Loss: 0.06456189602613449, Accuracy: 0.7858184508513659\n",
      "Iteration: 7040, Loss: 0.07688309252262115, Accuracy: 0.7900845352560282\n",
      "Iteration: 7104, Loss: 0.06285153329372406, Accuracy: 0.7904073449317366\n",
      "Iteration: 7168, Loss: 0.08412814885377884, Accuracy: 0.7959977600257844\n",
      "Iteration: 7232, Loss: 0.1186363697052002, Accuracy: 0.787326782476157\n",
      "Iteration: 7296, Loss: 0.06318870931863785, Accuracy: 0.7966349394991994\n",
      "Iteration: 7360, Loss: 0.08144626021385193, Accuracy: 0.7967499797232449\n",
      "Iteration: 7424, Loss: 0.1015334501862526, Accuracy: 0.7936391648836434\n",
      "Iteration: 7488, Loss: 0.07296159118413925, Accuracy: 0.7997418746817857\n",
      "Iteration: 7552, Loss: 0.10172183066606522, Accuracy: 0.7930786088109016\n",
      "Iteration: 7616, Loss: 0.065621517598629, Accuracy: 0.7952880398370326\n",
      "Iteration: 7680, Loss: 0.07420606911182404, Accuracy: 0.7995935266371816\n",
      "Iteration: 7744, Loss: 0.28066691756248474, Accuracy: 0.7941002077423036\n",
      "Iteration: 7808, Loss: 0.09911724179983139, Accuracy: 0.802765084663406\n",
      "Iteration: 7872, Loss: 0.07541196793317795, Accuracy: 0.8022668971680105\n",
      "Iteration: 7936, Loss: 0.11037711054086685, Accuracy: 0.8011815475765616\n",
      "Iteration: 8000, Loss: 0.08464682102203369, Accuracy: 0.8028541037347168\n",
      "Iteration: 8064, Loss: 0.07711746543645859, Accuracy: 0.7910426605958492\n",
      "Iteration: 8128, Loss: 0.08331450074911118, Accuracy: 0.7968225374352187\n",
      "Iteration: 8192, Loss: 0.07598943263292313, Accuracy: 0.8059506393037736\n",
      "Iteration: 8256, Loss: 0.10157185792922974, Accuracy: 0.7986849851440638\n",
      "Iteration: 8320, Loss: 0.06682614237070084, Accuracy: 0.8063521822914481\n",
      "Iteration: 8384, Loss: 0.06864968687295914, Accuracy: 0.8049876978620887\n",
      "Iteration: 8448, Loss: 0.06853017956018448, Accuracy: 0.8053061331156641\n",
      "Iteration: 8512, Loss: 0.1069231852889061, Accuracy: 0.8075326222460717\n",
      "Iteration: 8576, Loss: 0.07778695970773697, Accuracy: 0.8058774766977876\n",
      "Iteration: 8640, Loss: 0.07021534442901611, Accuracy: 0.8046915954910219\n",
      "Iteration: 8704, Loss: 0.37050294876098633, Accuracy: 0.8053191206417978\n",
      "Iteration: 8768, Loss: 0.09222462028265, Accuracy: 0.8104725133161992\n",
      "Iteration: 8832, Loss: 0.09367550164461136, Accuracy: 0.8024234524928033\n",
      "Iteration: 8896, Loss: 0.07999562472105026, Accuracy: 0.8002561021130532\n",
      "Iteration: 8960, Loss: 0.06494513899087906, Accuracy: 0.8104954266455024\n",
      "Iteration: 9024, Loss: 0.06854566186666489, Accuracy: 0.8099824395030737\n",
      "Iteration: 9088, Loss: 0.0770709291100502, Accuracy: 0.8031448677647859\n",
      "Iteration: 9152, Loss: 0.07080965489149094, Accuracy: 0.8101898820605129\n",
      "Iteration: 9216, Loss: 0.07955596596002579, Accuracy: 0.807771980529651\n",
      "Iteration: 9280, Loss: 0.07998394221067429, Accuracy: 0.8130785417743027\n",
      "Iteration: 9344, Loss: 0.09736625105142593, Accuracy: 0.8122775794472545\n",
      "Iteration: 9408, Loss: 0.07067643105983734, Accuracy: 0.8129838346503675\n",
      "Iteration: 9472, Loss: 0.07821153849363327, Accuracy: 0.7899423998314887\n",
      "Iteration: 9536, Loss: 0.08643880486488342, Accuracy: 0.7981504995841533\n",
      "Iteration: 9600, Loss: 0.1024886891245842, Accuracy: 0.8131714793853462\n",
      "Iteration: 9664, Loss: 0.07288344949483871, Accuracy: 0.8070936012081802\n",
      "Iteration: 9728, Loss: 0.07213491201400757, Accuracy: 0.8134883081074804\n",
      "Iteration: 9792, Loss: 0.10236913710832596, Accuracy: 0.8057730398140848\n",
      "Iteration: 9856, Loss: 0.10323139280080795, Accuracy: 0.803167121950537\n",
      "Iteration: 9920, Loss: 0.0714157298207283, Accuracy: 0.8020487017929554\n",
      "Iteration: 9984, Loss: 0.09410857409238815, Accuracy: 0.8132545789703727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10048, Loss: 0.07115625590085983, Accuracy: 0.8054814983624965\n",
      "Iteration: 10112, Loss: 0.09137441962957382, Accuracy: 0.8052049197722226\n",
      "Iteration: 10176, Loss: 0.24589379131793976, Accuracy: 0.8008994762785733\n",
      "Iteration: 10240, Loss: 0.06882601976394653, Accuracy: 0.8133088375907391\n",
      "Iteration: 10304, Loss: 0.10066089779138565, Accuracy: 0.8120067149866372\n",
      "Iteration: 10368, Loss: 0.0993565022945404, Accuracy: 0.8121662568300962\n",
      "Iteration: 10432, Loss: 0.09951689094305038, Accuracy: 0.8155554959084839\n",
      "Iteration: 10496, Loss: 0.08795426040887833, Accuracy: 0.8138762644957751\n",
      "Iteration: 10560, Loss: 0.10033068805932999, Accuracy: 0.8164757522754371\n",
      "Iteration: 10624, Loss: 0.07918676733970642, Accuracy: 0.818129288032651\n",
      "Iteration: 10688, Loss: 0.06550445407629013, Accuracy: 0.8165549936238676\n",
      "Iteration: 10752, Loss: 0.08429235219955444, Accuracy: 0.8165163055527955\n",
      "Iteration: 10816, Loss: 0.0839165672659874, Accuracy: 0.8126176511868834\n",
      "Iteration: 10880, Loss: 0.09526611119508743, Accuracy: 0.8151016174815595\n",
      "Iteration: 10944, Loss: 0.06424648314714432, Accuracy: 0.8102889412548393\n",
      "Iteration: 11008, Loss: 0.08637657016515732, Accuracy: 0.8169204611331224\n",
      "Iteration: 11072, Loss: 0.07748474925756454, Accuracy: 0.8106706615071744\n",
      "Iteration: 11136, Loss: 0.07500459253787994, Accuracy: 0.8132248728070408\n",
      "Iteration: 11200, Loss: 0.07162877172231674, Accuracy: 0.8107666908763349\n",
      "Iteration: 11264, Loss: 0.088340163230896, Accuracy: 0.8123088250868022\n",
      "Iteration: 11328, Loss: 0.07198920845985413, Accuracy: 0.8194711082614958\n",
      "Iteration: 11392, Loss: 0.07216493040323257, Accuracy: 0.8139138915576041\n",
      "Iteration: 11456, Loss: 0.09934816509485245, Accuracy: 0.8195402368437499\n",
      "Iteration: 11520, Loss: 0.08673673868179321, Accuracy: 0.8194026958663017\n",
      "Iteration: 11584, Loss: 0.08549285680055618, Accuracy: 0.819087726296857\n",
      "Iteration: 11648, Loss: 0.08395266532897949, Accuracy: 0.819370245328173\n",
      "Iteration: 11712, Loss: 0.0741211399435997, Accuracy: 0.8162678417284042\n",
      "Iteration: 11776, Loss: 0.09791591763496399, Accuracy: 0.8137261297088116\n",
      "Iteration: 11840, Loss: 0.08509194850921631, Accuracy: 0.8160464612301439\n",
      "Iteration: 11904, Loss: 0.07317008823156357, Accuracy: 0.8176940886769444\n",
      "Iteration: 11968, Loss: 0.08341459184885025, Accuracy: 0.8204222193453461\n",
      "Iteration: 12032, Loss: 0.07705570012331009, Accuracy: 0.8197589691262692\n",
      "Iteration: 12096, Loss: 0.0787762850522995, Accuracy: 0.8215340918395668\n",
      "Iteration: 12160, Loss: 0.08221729844808578, Accuracy: 0.8175386381335557\n",
      "Iteration: 12224, Loss: 0.06688389182090759, Accuracy: 0.8158594453707337\n",
      "Iteration: 12288, Loss: 0.09050341695547104, Accuracy: 0.8215584151912481\n",
      "Iteration: 12352, Loss: 0.07788490504026413, Accuracy: 0.7976305307820439\n",
      "Iteration: 12416, Loss: 0.0774165689945221, Accuracy: 0.8214802667498589\n",
      "Iteration: 12480, Loss: 0.08917536586523056, Accuracy: 0.8243291110266\n",
      "Iteration: 12544, Loss: 0.08198478072881699, Accuracy: 0.8222250777762383\n",
      "Iteration: 12608, Loss: 0.08486595004796982, Accuracy: 0.8239580066874623\n",
      "Iteration: 12672, Loss: 0.08378998190164566, Accuracy: 0.8199600537773222\n",
      "Iteration: 12736, Loss: 0.08003580570220947, Accuracy: 0.8241642978973687\n",
      "Iteration: 12800, Loss: 0.07831069082021713, Accuracy: 0.8229803014546633\n",
      "Iteration: 12864, Loss: 0.07803171873092651, Accuracy: 0.8252920091617852\n",
      "Iteration: 12928, Loss: 0.05263295769691467, Accuracy: 0.825645447941497\n",
      "Iteration: 12992, Loss: 0.07800942659378052, Accuracy: 0.822367228101939\n",
      "Iteration: 13056, Loss: 0.07723146677017212, Accuracy: 0.8264060537330806\n",
      "Iteration: 13120, Loss: 0.06156044080853462, Accuracy: 0.8258795854635537\n",
      "Iteration: 13184, Loss: 0.08474072068929672, Accuracy: 0.8266675379127264\n",
      "Iteration: 13248, Loss: 0.07851697504520416, Accuracy: 0.8249966837465763\n",
      "Iteration: 13312, Loss: 0.09685281664133072, Accuracy: 0.8264091790188104\n",
      "Iteration: 13376, Loss: 0.0832243263721466, Accuracy: 0.826332691591233\n",
      "Iteration: 13440, Loss: 0.07906273752450943, Accuracy: 0.8262736150063574\n",
      "Iteration: 13504, Loss: 0.08365750312805176, Accuracy: 0.8280385984107852\n",
      "Iteration: 13568, Loss: 0.07788339257240295, Accuracy: 0.8298104088753462\n",
      "Iteration: 13632, Loss: 0.07630115747451782, Accuracy: 0.827887836843729\n",
      "Iteration: 13696, Loss: 0.3500903844833374, Accuracy: 0.8105782899074256\n",
      "Iteration: 13760, Loss: 0.08625642210245132, Accuracy: 0.8088350663892925\n",
      "Iteration: 13824, Loss: 0.06453267484903336, Accuracy: 0.8245875772554427\n",
      "Iteration: 13888, Loss: 0.060334235429763794, Accuracy: 0.8262430233880877\n",
      "Iteration: 13952, Loss: 0.0848563089966774, Accuracy: 0.8259734725579619\n",
      "Iteration: 14016, Loss: 0.053134988993406296, Accuracy: 0.829108792822808\n",
      "Iteration: 14080, Loss: 0.0876479372382164, Accuracy: 0.8251381129957736\n",
      "Iteration: 14144, Loss: 0.04755757376551628, Accuracy: 0.826803038129583\n",
      "Iteration: 14208, Loss: 0.09616205841302872, Accuracy: 0.828734923619777\n",
      "Iteration: 14272, Loss: 0.07740617543458939, Accuracy: 0.8326948089525104\n",
      "Iteration: 14336, Loss: 0.08973318338394165, Accuracy: 0.8276901823701337\n",
      "Iteration: 14400, Loss: 0.07765709608793259, Accuracy: 0.8301879777573049\n",
      "Iteration: 14464, Loss: 0.07228485494852066, Accuracy: 0.8343636669451371\n",
      "Iteration: 14528, Loss: 0.13149595260620117, Accuracy: 0.8262841172982007\n",
      "Iteration: 14592, Loss: 0.07524552941322327, Accuracy: 0.8208532640710473\n",
      "Iteration: 14656, Loss: 0.08388934284448624, Accuracy: 0.8282777831191197\n",
      "Iteration: 14720, Loss: 0.07070945203304291, Accuracy: 0.8284599353792146\n",
      "Iteration: 14784, Loss: 0.05216149985790253, Accuracy: 0.8346518240869045\n",
      "Iteration: 14848, Loss: 0.0813554897904396, Accuracy: 0.8296830768231302\n",
      "Iteration: 14912, Loss: 0.07963010668754578, Accuracy: 0.8364243395626545\n",
      "Iteration: 14976, Loss: 0.06504655629396439, Accuracy: 0.8301671366207302\n",
      "Iteration: 15040, Loss: 0.035758666694164276, Accuracy: 0.8338020824594423\n",
      "Iteration: 15104, Loss: 0.10886772722005844, Accuracy: 0.8304947530850768\n",
      "Iteration: 15168, Loss: 0.07165835052728653, Accuracy: 0.8353403371293098\n",
      "Iteration: 15232, Loss: 0.061243463307619095, Accuracy: 0.8307214176747948\n",
      "Iteration: 15296, Loss: 0.058395277708768845, Accuracy: 0.8367945589125156\n",
      "Iteration: 15360, Loss: 0.09690137952566147, Accuracy: 0.8369905311847106\n",
      "Iteration: 15424, Loss: 0.08864378929138184, Accuracy: 0.8366250786930323\n",
      "Iteration: 15488, Loss: 0.07787173986434937, Accuracy: 0.8355297145899385\n",
      "Iteration: 15552, Loss: 0.07186195254325867, Accuracy: 0.8414665623567998\n",
      "Iteration: 15616, Loss: 0.07861470431089401, Accuracy: 0.8425323134288192\n",
      "Iteration: 15680, Loss: 0.06988493353128433, Accuracy: 0.8441826475318521\n",
      "Iteration: 15744, Loss: 0.08655162900686264, Accuracy: 0.8402867481345311\n",
      "Iteration: 15808, Loss: 0.05210012197494507, Accuracy: 0.8393273593392223\n",
      "Iteration: 15872, Loss: 0.05583951249718666, Accuracy: 0.8454302928876132\n",
      "Iteration: 15936, Loss: 0.02622944302856922, Accuracy: 0.8320195749402046\n",
      "Iteration: 16000, Loss: 0.0717780739068985, Accuracy: 0.8419851151993498\n",
      "Iteration: 16064, Loss: 0.042415618896484375, Accuracy: 0.8384561203420162\n",
      "Iteration: 16128, Loss: 0.03833024576306343, Accuracy: 0.8375718793831766\n",
      "Iteration: 16192, Loss: 0.06846073269844055, Accuracy: 0.8414867327082902\n",
      "Iteration: 16256, Loss: 0.02947952412068844, Accuracy: 0.8295478123473004\n",
      "Iteration: 16320, Loss: 0.07947276532649994, Accuracy: 0.8329246657667682\n",
      "Iteration: 16384, Loss: 0.07899165153503418, Accuracy: 0.8456923727644607\n",
      "Iteration: 16448, Loss: 0.02561839111149311, Accuracy: 0.8381782611832023\n",
      "Iteration: 16512, Loss: 0.046303290873765945, Accuracy: 0.8371138302609324\n",
      "Iteration: 16576, Loss: 0.05740457773208618, Accuracy: 0.8422065344639122\n",
      "Iteration: 16640, Loss: 0.06589909642934799, Accuracy: 0.8472744625760242\n",
      "Iteration: 16704, Loss: 0.07447125762701035, Accuracy: 0.8510660459287465\n",
      "Iteration: 16768, Loss: 0.026554981246590614, Accuracy: 0.8347658737329766\n",
      "Iteration: 16832, Loss: 0.07714340835809708, Accuracy: 0.851546301972121\n",
      "Iteration: 16896, Loss: 0.07531849294900894, Accuracy: 0.8407634150935337\n",
      "Iteration: 16960, Loss: 0.04399527236819267, Accuracy: 0.8507169294171035\n",
      "Iteration: 17024, Loss: 0.09217563271522522, Accuracy: 0.8516105221351609\n",
      "Iteration: 17088, Loss: 0.06900797039270401, Accuracy: 0.8519310952397063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 17152, Loss: 0.06899425387382507, Accuracy: 0.8486060227733105\n",
      "Iteration: 17216, Loss: 0.039663609117269516, Accuracy: 0.8521499910857528\n",
      "Iteration: 17280, Loss: 0.06993304938077927, Accuracy: 0.8560423948802054\n",
      "Iteration: 17344, Loss: 0.10359492152929306, Accuracy: 0.8532595902215689\n",
      "Iteration: 17408, Loss: 0.09179031848907471, Accuracy: 0.8537334443535656\n",
      "Iteration: 17472, Loss: 0.10242093354463577, Accuracy: 0.8548552141292021\n",
      "Iteration: 17536, Loss: 0.07248634845018387, Accuracy: 0.855266087455675\n",
      "Iteration: 17600, Loss: 0.06747661530971527, Accuracy: 0.8543811986455694\n",
      "Iteration: 17664, Loss: 0.07824066281318665, Accuracy: 0.8495517633855343\n",
      "Iteration: 17728, Loss: 0.027842393144965172, Accuracy: 0.832693679491058\n",
      "Iteration: 17792, Loss: 0.07322251796722412, Accuracy: 0.8467075205408037\n",
      "Iteration: 17856, Loss: 0.036587733775377274, Accuracy: 0.8516276605660096\n",
      "Iteration: 17920, Loss: 0.09470027685165405, Accuracy: 0.8535913620144129\n",
      "Iteration: 17984, Loss: 0.02987285889685154, Accuracy: 0.8506074465112761\n",
      "Iteration: 18048, Loss: 0.02767372690141201, Accuracy: 0.8590247243409976\n",
      "Iteration: 18112, Loss: 0.07738321274518967, Accuracy: 0.8599186955252662\n",
      "Iteration: 18176, Loss: 0.025187140330672264, Accuracy: 0.8569746314315125\n",
      "Iteration: 18240, Loss: 0.06628754734992981, Accuracy: 0.8548957476159558\n",
      "Iteration: 18304, Loss: 0.10648439079523087, Accuracy: 0.8548643309623003\n",
      "Iteration: 18368, Loss: 0.02835359238088131, Accuracy: 0.8564696437679231\n",
      "Iteration: 18432, Loss: 0.027809984982013702, Accuracy: 0.862320230808109\n",
      "Iteration: 18496, Loss: 0.09686491638422012, Accuracy: 0.8607506670523435\n",
      "Iteration: 18560, Loss: 0.025200331583619118, Accuracy: 0.8604735498083755\n",
      "Iteration: 18624, Loss: 0.09364986419677734, Accuracy: 0.8627793482737616\n",
      "Iteration: 18688, Loss: 0.07654718309640884, Accuracy: 0.8565760024357587\n",
      "Iteration: 18752, Loss: 0.09183603525161743, Accuracy: 0.863569061155431\n",
      "Iteration: 18816, Loss: 0.07686588913202286, Accuracy: 0.8619402037002146\n",
      "Iteration: 18880, Loss: 0.07789993286132812, Accuracy: 0.8629514463245869\n",
      "Iteration: 18944, Loss: 0.06840044260025024, Accuracy: 0.8558158299420029\n",
      "Iteration: 19008, Loss: 0.02609509788453579, Accuracy: 0.8559056641533971\n",
      "Iteration: 19072, Loss: 0.1015147939324379, Accuracy: 0.8640520465560257\n",
      "Iteration: 19136, Loss: 0.06874794512987137, Accuracy: 0.8651976864784956\n",
      "Iteration: 19200, Loss: 0.03571945056319237, Accuracy: 0.8492342395475134\n",
      "Iteration: 19264, Loss: 0.09558412432670593, Accuracy: 0.8652409089263529\n",
      "Iteration: 19328, Loss: 0.013046993874013424, Accuracy: 0.8652612003497779\n",
      "Iteration: 19392, Loss: 0.019280465319752693, Accuracy: 0.8486470658099279\n",
      "Iteration: 19456, Loss: 0.020288901403546333, Accuracy: 0.8456399472197518\n",
      "Iteration: 19520, Loss: 0.07027262449264526, Accuracy: 0.8644155156216584\n",
      "Iteration: 19584, Loss: 0.008696451783180237, Accuracy: 0.8690628275508061\n",
      "Iteration: 19648, Loss: 0.019184669479727745, Accuracy: 0.861480986350216\n",
      "Iteration: 19712, Loss: 0.08979004621505737, Accuracy: 0.8691194236744195\n",
      "Iteration: 19776, Loss: 0.06989788264036179, Accuracy: 0.8611328236293048\n",
      "Iteration: 19840, Loss: 0.00869434978812933, Accuracy: 0.864638255268801\n",
      "Iteration: 19904, Loss: 0.018940391018986702, Accuracy: 0.8533654273487628\n",
      "Iteration: 19968, Loss: 0.019455494359135628, Accuracy: 0.8677027194644324\n",
      "Iteration: 20032, Loss: 0.07859940081834793, Accuracy: 0.8636708637350239\n",
      "Iteration: 20096, Loss: 0.10070717334747314, Accuracy: 0.8655882359598763\n",
      "Iteration: 20160, Loss: 0.01690375991165638, Accuracy: 0.8721300959005021\n",
      "Iteration: 20224, Loss: 0.0695623829960823, Accuracy: 0.8608525473391637\n",
      "Iteration: 20288, Loss: 0.09805083274841309, Accuracy: 0.858640513732098\n",
      "Iteration: 20352, Loss: 0.039771903306245804, Accuracy: 0.8649735184153542\n",
      "Iteration: 20416, Loss: 0.08986055850982666, Accuracy: 0.8710142218042165\n",
      "Iteration: 20480, Loss: 0.07843755930662155, Accuracy: 0.8682584455818869\n",
      "Iteration: 20544, Loss: 0.01484847441315651, Accuracy: 0.8682994640548714\n",
      "Iteration: 20608, Loss: 0.008178564719855785, Accuracy: 0.863184270390775\n",
      "Iteration: 20672, Loss: 0.06953758001327515, Accuracy: 0.8699002926587127\n",
      "Iteration: 20736, Loss: 0.019793657585978508, Accuracy: 0.873042585561052\n",
      "Iteration: 20800, Loss: 0.01361676026135683, Accuracy: 0.8675868051941507\n",
      "Iteration: 20864, Loss: 0.09374455362558365, Accuracy: 0.8726416001445614\n",
      "Iteration: 20928, Loss: 0.023179130628705025, Accuracy: 0.8564706207253039\n",
      "Iteration: 20992, Loss: 0.053343433886766434, Accuracy: 0.8684677394339815\n",
      "Iteration: 21056, Loss: 0.07899682968854904, Accuracy: 0.871876162069384\n",
      "Iteration: 21120, Loss: 0.0747525691986084, Accuracy: 0.8728976653655991\n",
      "Iteration: 21184, Loss: 0.09105553478002548, Accuracy: 0.8662565324921161\n",
      "Iteration: 21248, Loss: 0.07832180708646774, Accuracy: 0.8724887219723314\n",
      "Iteration: 21312, Loss: 0.09468764066696167, Accuracy: 0.8647971971076913\n",
      "Iteration: 21376, Loss: 0.075518399477005, Accuracy: 0.8535855992813595\n",
      "Iteration: 21440, Loss: 0.018136562779545784, Accuracy: 0.8415311334538274\n",
      "Iteration: 21504, Loss: 0.07262963056564331, Accuracy: 0.8557182514341548\n",
      "Iteration: 21568, Loss: 0.09343358129262924, Accuracy: 0.8707208023406565\n",
      "Iteration: 21632, Loss: 0.08755075931549072, Accuracy: 0.8718944293214008\n",
      "Iteration: 21696, Loss: 0.08097658306360245, Accuracy: 0.8708560783416033\n",
      "Iteration: 21760, Loss: 0.07943623512983322, Accuracy: 0.8748341686441563\n",
      "Iteration: 21824, Loss: 0.07629141211509705, Accuracy: 0.8748256278340705\n",
      "Iteration: 21888, Loss: 0.09290934354066849, Accuracy: 0.8707424408057705\n",
      "Iteration: 21952, Loss: 0.07800048589706421, Accuracy: 0.8755484164576046\n",
      "Iteration: 22016, Loss: 0.006074320990592241, Accuracy: 0.8700220033060759\n",
      "Iteration: 22080, Loss: 0.08937092870473862, Accuracy: 0.8728757225326262\n",
      "Iteration: 22144, Loss: 0.025950392708182335, Accuracy: 0.8751755140256137\n",
      "Iteration: 22208, Loss: 0.09467345476150513, Accuracy: 0.8776811209390871\n",
      "Iteration: 22272, Loss: 0.07720459252595901, Accuracy: 0.8758833350730129\n",
      "Iteration: 22336, Loss: 0.011717463843524456, Accuracy: 0.874032321095001\n",
      "Iteration: 22400, Loss: 0.09525156021118164, Accuracy: 0.8793303067795932\n",
      "Iteration: 22464, Loss: 0.07447528839111328, Accuracy: 0.8700974159874022\n",
      "Iteration: 22528, Loss: 0.08557760715484619, Accuracy: 0.8774539092555642\n",
      "Iteration: 22592, Loss: 0.01090050209313631, Accuracy: 0.8792764815152623\n",
      "Iteration: 22656, Loss: 0.08932801336050034, Accuracy: 0.8759462129673921\n",
      "Iteration: 22720, Loss: 0.0035963125992566347, Accuracy: 0.8741653668112122\n",
      "Iteration: 22784, Loss: 0.009753413498401642, Accuracy: 0.8730389207485132\n",
      "Iteration: 22848, Loss: 0.009997941553592682, Accuracy: 0.8755364301614463\n",
      "Iteration: 22912, Loss: 0.011252944357693195, Accuracy: 0.878014940652065\n",
      "Iteration: 22976, Loss: 0.014741018414497375, Accuracy: 0.8789166429778561\n",
      "Iteration: 23040, Loss: 0.07394295185804367, Accuracy: 0.8793105385848321\n",
      "Iteration: 23104, Loss: 0.07051993161439896, Accuracy: 0.8817360632237978\n",
      "Iteration: 23168, Loss: 0.09364348649978638, Accuracy: 0.8772008671658114\n",
      "Iteration: 23232, Loss: 0.07656244188547134, Accuracy: 0.878938167123124\n",
      "Iteration: 23296, Loss: 0.01004057377576828, Accuracy: 0.8787216622149572\n",
      "Iteration: 23360, Loss: 0.015880033373832703, Accuracy: 0.8796623720554635\n",
      "Iteration: 23424, Loss: 0.013071439228951931, Accuracy: 0.8832729260320775\n",
      "Iteration: 23488, Loss: 0.0767066478729248, Accuracy: 0.8835929402848706\n",
      "Iteration: 23552, Loss: 0.009814069606363773, Accuracy: 0.8823024831945077\n",
      "Iteration: 23616, Loss: 0.09052950888872147, Accuracy: 0.8824721855926327\n",
      "Iteration: 23680, Loss: 0.005094525869935751, Accuracy: 0.8746112727094442\n",
      "Iteration: 23744, Loss: 0.08379688113927841, Accuracy: 0.8816225235932507\n",
      "Iteration: 23808, Loss: 0.01036863774061203, Accuracy: 0.8743067974573933\n",
      "Iteration: 23872, Loss: 0.0834614709019661, Accuracy: 0.882566598651465\n",
      "Iteration: 23936, Loss: 0.08553105592727661, Accuracy: 0.8795298030017875\n",
      "Iteration: 24000, Loss: 0.009922700934112072, Accuracy: 0.7759229304501787\n",
      "Iteration: 24064, Loss: 0.07490847259759903, Accuracy: 0.8751190883340314\n",
      "Iteration: 24128, Loss: 0.07177457213401794, Accuracy: 0.8718789751874283\n",
      "Iteration: 24192, Loss: 0.004457529168576002, Accuracy: 0.8754278536653146\n",
      "Iteration: 24256, Loss: 0.009349671192467213, Accuracy: 0.8742264555185102\n",
      "Iteration: 24320, Loss: 0.07302464544773102, Accuracy: 0.8765665061073378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 24384, Loss: 0.07445143908262253, Accuracy: 0.8679324782569893\n",
      "Iteration: 24448, Loss: 0.07791810482740402, Accuracy: 0.884036595467478\n",
      "Iteration: 24512, Loss: 0.009429587982594967, Accuracy: 0.8858304494642653\n",
      "Iteration: 24576, Loss: 0.04614992067217827, Accuracy: 0.8833469427772798\n",
      "Iteration: 24640, Loss: 0.05528874322772026, Accuracy: 0.8709609775105491\n",
      "Iteration: 24704, Loss: 0.09064966440200806, Accuracy: 0.873034218500834\n",
      "Iteration: 24768, Loss: 0.008197956718504429, Accuracy: 0.882328377396334\n",
      "Iteration: 24832, Loss: 0.07162321358919144, Accuracy: 0.8690912456368096\n",
      "Iteration: 24896, Loss: 0.08332481235265732, Accuracy: 0.8838794041075744\n",
      "Iteration: 24960, Loss: 0.008448425680398941, Accuracy: 0.8815981411025859\n",
      "Iteration: 25024, Loss: 0.07376892119646072, Accuracy: 0.8888344945735298\n",
      "Iteration: 25088, Loss: 0.0031532971188426018, Accuracy: 0.8872958061983809\n",
      "Iteration: 25152, Loss: 0.09403321892023087, Accuracy: 0.8901215813821182\n",
      "Iteration: 25216, Loss: 0.0037214504554867744, Accuracy: 0.8850837268400937\n",
      "Iteration: 25280, Loss: 0.0028519807383418083, Accuracy: 0.8928684677230194\n",
      "Iteration: 25344, Loss: 0.017593974247574806, Accuracy: 0.8940704767010175\n",
      "Iteration: 25408, Loss: 0.035787422209978104, Accuracy: 0.8956546076806262\n",
      "Iteration: 25472, Loss: 0.002767216181382537, Accuracy: 0.890996128146071\n",
      "Iteration: 25536, Loss: 0.011091220192611217, Accuracy: 0.8926809859112836\n",
      "Iteration: 25600, Loss: 0.003276954172179103, Accuracy: 0.8889411881682463\n",
      "Iteration: 25664, Loss: 0.00499931164085865, Accuracy: 0.9011034442228265\n",
      "Iteration: 25728, Loss: 0.00619840482249856, Accuracy: 0.9010654730373062\n",
      "Iteration: 25792, Loss: 0.0032120489049702883, Accuracy: 0.9055295473663136\n",
      "Iteration: 25856, Loss: 0.0032203809823840857, Accuracy: 0.9006405923864804\n",
      "Iteration: 25920, Loss: 0.10444173961877823, Accuracy: 0.8978878870839253\n",
      "Iteration: 25984, Loss: 0.010867014527320862, Accuracy: 0.8933270096895285\n",
      "Iteration: 26048, Loss: 0.004083553329110146, Accuracy: 0.9020780621212907\n",
      "Iteration: 26112, Loss: 0.004766439087688923, Accuracy: 0.8976197722367942\n",
      "Iteration: 26176, Loss: 0.007535955403000116, Accuracy: 0.9024747547809966\n",
      "Iteration: 26240, Loss: 0.00541100837290287, Accuracy: 0.9082577718654647\n",
      "Iteration: 26304, Loss: 0.03131021931767464, Accuracy: 0.9081810405477881\n",
      "Iteration: 26368, Loss: 0.006106782238930464, Accuracy: 0.9078868291107938\n",
      "Iteration: 26432, Loss: 0.042652618139982224, Accuracy: 0.9128434522426687\n",
      "Iteration: 26496, Loss: 0.011194323189556599, Accuracy: 0.9048615859355778\n",
      "Iteration: 26560, Loss: 0.004730765242129564, Accuracy: 0.8960077475639991\n",
      "Iteration: 26624, Loss: 0.0773066058754921, Accuracy: 0.9070574185461737\n",
      "Iteration: 26688, Loss: 0.0969979539513588, Accuracy: 0.9037655313732103\n",
      "Iteration: 26752, Loss: 0.005808010697364807, Accuracy: 0.9001957964501344\n",
      "Iteration: 26816, Loss: 0.01216017734259367, Accuracy: 0.9117371261236258\n",
      "Iteration: 26880, Loss: 0.005192396230995655, Accuracy: 0.903812704316806\n",
      "Iteration: 26944, Loss: 0.08107221871614456, Accuracy: 0.911533328529913\n",
      "Iteration: 27008, Loss: 0.007486153393983841, Accuracy: 0.9179819070268422\n",
      "Iteration: 27072, Loss: 0.0042070383206009865, Accuracy: 0.9123879668768495\n",
      "Iteration: 27136, Loss: 0.009256110526621342, Accuracy: 0.9039283794700168\n",
      "Iteration: 27200, Loss: 0.008308213204145432, Accuracy: 0.9175970391370356\n",
      "Iteration: 27264, Loss: 0.09775374084711075, Accuracy: 0.9172949603525922\n",
      "Iteration: 27328, Loss: 0.04514317214488983, Accuracy: 0.9064451080048457\n",
      "Iteration: 27392, Loss: 0.007422649767249823, Accuracy: 0.9145686877309345\n",
      "Iteration: 27456, Loss: 0.003725060960277915, Accuracy: 0.9178854480851442\n",
      "Iteration: 27520, Loss: 0.007351396139711142, Accuracy: 0.9104594290838577\n",
      "Iteration: 27584, Loss: 0.0030497286934405565, Accuracy: 0.9165555666550063\n",
      "Iteration: 27648, Loss: 0.0015461863949894905, Accuracy: 0.9218844986753538\n",
      "Iteration: 27712, Loss: 0.006594894453883171, Accuracy: 0.9255512904492207\n",
      "Iteration: 27776, Loss: 0.006183251738548279, Accuracy: 0.9241173713817261\n",
      "Iteration: 27840, Loss: 0.003692320780828595, Accuracy: 0.9231017504935153\n",
      "Iteration: 27904, Loss: 0.016097359359264374, Accuracy: 0.9221110324142501\n",
      "Iteration: 27968, Loss: 0.5233458876609802, Accuracy: 0.9195870880503207\n",
      "Iteration: 28032, Loss: 0.03699734807014465, Accuracy: 0.919377418467775\n",
      "Iteration: 28096, Loss: 0.02940027415752411, Accuracy: 0.9278027809923515\n",
      "Iteration: 28160, Loss: 0.011060231365263462, Accuracy: 0.9304135883576237\n",
      "Iteration: 28224, Loss: 0.0024574247654527426, Accuracy: 0.9315325050847605\n",
      "Iteration: 28288, Loss: 0.015678206458687782, Accuracy: 0.9379122655955143\n",
      "Iteration: 28352, Loss: 0.002707040635868907, Accuracy: 0.9148377263627481\n",
      "Iteration: 28416, Loss: 0.006395649164915085, Accuracy: 0.9382308287313208\n",
      "Iteration: 28480, Loss: 0.0023936890065670013, Accuracy: 0.923359577631345\n",
      "Iteration: 28544, Loss: 0.005242811981588602, Accuracy: 0.9362732493900694\n",
      "Iteration: 28608, Loss: 0.013661113567650318, Accuracy: 0.9299458628811408\n",
      "Iteration: 28672, Loss: 0.017701128497719765, Accuracy: 0.9309320998727344\n",
      "Iteration: 28736, Loss: 0.05091787502169609, Accuracy: 0.9338018536218442\n",
      "Iteration: 28800, Loss: 0.003495970042422414, Accuracy: 0.919119592232164\n",
      "Iteration: 28864, Loss: 0.0030855201184749603, Accuracy: 0.9341517934808508\n",
      "Iteration: 28928, Loss: 0.005727421026676893, Accuracy: 0.9303889546135906\n",
      "Iteration: 28992, Loss: 0.003125424263998866, Accuracy: 0.928519434761256\n",
      "Iteration: 29056, Loss: 0.00567785045132041, Accuracy: 0.9399848119355738\n",
      "Iteration: 29120, Loss: 0.0029812362045049667, Accuracy: 0.9452413339458872\n",
      "Iteration: 29184, Loss: 0.012852068059146404, Accuracy: 0.9315976659709122\n",
      "Iteration: 29248, Loss: 0.010768854059278965, Accuracy: 0.9061721834877972\n",
      "Iteration: 29312, Loss: 0.00196676142513752, Accuracy: 0.9303378086187877\n",
      "Iteration: 29376, Loss: 0.0014080581022426486, Accuracy: 0.9327326841303147\n",
      "Iteration: 29440, Loss: 0.022936688736081123, Accuracy: 0.9415242838149425\n",
      "Iteration: 29504, Loss: 0.0015521803870797157, Accuracy: 0.9360968276741914\n",
      "Iteration: 29568, Loss: 0.002263937145471573, Accuracy: 0.9383172958914656\n",
      "Iteration: 29632, Loss: 0.010792344808578491, Accuracy: 0.9314238542574458\n",
      "Iteration: 29696, Loss: 0.0015928427455946803, Accuracy: 0.9403404234035406\n",
      "Iteration: 29760, Loss: 0.03814014419913292, Accuracy: 0.9330724840983748\n",
      "Iteration: 29824, Loss: 0.007238324265927076, Accuracy: 0.9481838692445308\n",
      "Iteration: 29888, Loss: 0.002050643088296056, Accuracy: 0.9317955721635371\n",
      "Iteration: 29952, Loss: 0.0069585838355124, Accuracy: 0.9463653298444115\n",
      "Iteration: 30016, Loss: 0.0030474660452455282, Accuracy: 0.9461735128425062\n",
      "Iteration: 30080, Loss: 0.04255830869078636, Accuracy: 0.9391610266466159\n",
      "Iteration: 30144, Loss: 0.0033242814242839813, Accuracy: 0.9301822482375428\n",
      "Iteration: 30208, Loss: 0.00227151857689023, Accuracy: 0.9362263527291361\n",
      "Iteration: 30272, Loss: 0.11412549018859863, Accuracy: 0.9268516428710427\n",
      "Iteration: 30336, Loss: 0.4773620069026947, Accuracy: 0.9258809530001599\n",
      "Iteration: 30400, Loss: 0.0021479427814483643, Accuracy: 0.9360285511647817\n",
      "Iteration: 30464, Loss: 0.0069839186035096645, Accuracy: 0.9463288084079977\n",
      "Iteration: 30528, Loss: 0.007423586677759886, Accuracy: 0.9448932957020588\n",
      "Iteration: 30592, Loss: 0.008203216828405857, Accuracy: 0.9447253272228409\n",
      "Iteration: 30656, Loss: 0.0028072933200746775, Accuracy: 0.9496592269279063\n",
      "Iteration: 30720, Loss: 0.002550978446379304, Accuracy: 0.9567969993222505\n",
      "Iteration: 30784, Loss: 0.0013654166832566261, Accuracy: 0.9455381988373119\n",
      "Iteration: 30848, Loss: 0.00409100204706192, Accuracy: 0.9505274949187879\n",
      "Iteration: 30912, Loss: 0.0016531869769096375, Accuracy: 0.9471065308025572\n",
      "Iteration: 30976, Loss: 0.00186627556104213, Accuracy: 0.9551421293290332\n",
      "Iteration: 31040, Loss: 0.006352244410663843, Accuracy: 0.9508443711383734\n",
      "Iteration: 31104, Loss: 0.0015019006095826626, Accuracy: 0.9548112881020643\n",
      "Iteration: 31168, Loss: 0.006687688175588846, Accuracy: 0.9498839403386228\n",
      "Iteration: 31232, Loss: 0.00736665865406394, Accuracy: 0.9476599549816456\n",
      "Iteration: 31296, Loss: 0.0007470549899153411, Accuracy: 0.9522313607740216\n",
      "Iteration: 31360, Loss: 0.0011146197794005275, Accuracy: 0.9546763585822191\n",
      "Iteration: 31424, Loss: 0.0010983222164213657, Accuracy: 0.9501260484394152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 31488, Loss: 0.0014733016723766923, Accuracy: 0.9618981162202545\n",
      "Iteration: 31552, Loss: 0.0007555143092758954, Accuracy: 0.9549998384900391\n",
      "Iteration: 31616, Loss: 0.005624173209071159, Accuracy: 0.9580550235696137\n",
      "Iteration: 31680, Loss: 0.002501020673662424, Accuracy: 0.942749625100987\n",
      "Iteration: 31744, Loss: 0.004752261098474264, Accuracy: 0.9572277961997315\n",
      "Iteration: 31808, Loss: 0.05112125352025032, Accuracy: 0.9603645766328555\n",
      "Iteration: 31872, Loss: 0.0021470498759299517, Accuracy: 0.9626022406446282\n",
      "Iteration: 31936, Loss: 0.0014893984189257026, Accuracy: 0.9597176635288633\n",
      "Iteration: 32000, Loss: 0.0011833769967779517, Accuracy: 0.9639382510795258\n",
      "Iteration: 32064, Loss: 0.0006922339089214802, Accuracy: 0.9626711564196739\n",
      "Iteration: 32128, Loss: 0.0022510632406920195, Accuracy: 0.9623956821742468\n",
      "Iteration: 32192, Loss: 0.22954918444156647, Accuracy: 0.9465027498954441\n",
      "Iteration: 32256, Loss: 0.0005550870555453002, Accuracy: 0.9514788339438383\n",
      "Iteration: 32320, Loss: 0.0011726197553798556, Accuracy: 0.9582366559479851\n",
      "Iteration: 32384, Loss: 0.0035028953570872545, Accuracy: 0.9568805631715804\n",
      "Iteration: 32448, Loss: 0.0016502179205417633, Accuracy: 0.9554217766271904\n",
      "Iteration: 32512, Loss: 0.0033233643043786287, Accuracy: 0.9605813804082572\n",
      "Iteration: 32576, Loss: 0.0008018016815185547, Accuracy: 0.9535739085404202\n",
      "Iteration: 32640, Loss: 0.000560895714443177, Accuracy: 0.9657142186479177\n",
      "Iteration: 32704, Loss: 0.0019165282137691975, Accuracy: 0.963441360698198\n",
      "Iteration: 32768, Loss: 0.003488007700070739, Accuracy: 0.959824359160848\n",
      "Iteration: 32832, Loss: 0.002620529616251588, Accuracy: 0.9618232914363034\n",
      "Iteration: 32896, Loss: 0.0005180899752303958, Accuracy: 0.9579227527719922\n",
      "Iteration: 32960, Loss: 0.00111811060924083, Accuracy: 0.9665761821379419\n",
      "Iteration: 33024, Loss: 0.0034580149222165346, Accuracy: 0.9571789415786043\n",
      "Iteration: 33088, Loss: 0.0037286581937223673, Accuracy: 0.953906723036198\n",
      "Iteration: 33152, Loss: 0.0014984174631536007, Accuracy: 0.9625346243992681\n",
      "Iteration: 33216, Loss: 0.0009396139066666365, Accuracy: 0.9600922441750299\n",
      "Iteration: 33280, Loss: 0.0017025955021381378, Accuracy: 0.9667686748580309\n",
      "Iteration: 33344, Loss: 0.003719811327755451, Accuracy: 0.9661557531362632\n",
      "Iteration: 33408, Loss: 0.0027338897343724966, Accuracy: 0.9638334451301489\n",
      "Iteration: 33472, Loss: 0.002301229164004326, Accuracy: 0.9621950700966408\n",
      "Iteration: 33536, Loss: 0.0012574372813105583, Accuracy: 0.9527685130742611\n",
      "Iteration: 33600, Loss: 0.003251056419685483, Accuracy: 0.9681920515722595\n",
      "Iteration: 33664, Loss: 0.0019150193547829986, Accuracy: 0.9653679838520475\n",
      "Iteration: 33728, Loss: 0.000437666050856933, Accuracy: 0.9657073729467811\n",
      "Iteration: 33792, Loss: 0.0018768439767882228, Accuracy: 0.9697534623264801\n",
      "Iteration: 33856, Loss: 0.001555088791064918, Accuracy: 0.9661750221712282\n",
      "Iteration: 33920, Loss: 0.01543864980340004, Accuracy: 0.9590316227113362\n",
      "Iteration: 33984, Loss: 0.0026276472490280867, Accuracy: 0.9497454294614727\n",
      "Iteration: 34048, Loss: 0.0021872855722904205, Accuracy: 0.970398581092013\n",
      "Saved fullModel_dr[2]_replicate3.model\n",
      "Saved W_dr[2]_replicate3.p\n",
      "2 0.984375 [1.0, 0.953125, 1.0]\n",
      "Saved w_dr[2]_replicate3.p\n",
      "Replicate 3 completed\n",
      "Time elapsed: 182.0625 seconds\n",
      "Iteration: 64, Loss: 0.23336374759674072, Accuracy: 0.49999259412288666\n",
      "Iteration: 128, Loss: 0.2701663076877594, Accuracy: 0.5016545881517231\n",
      "Iteration: 192, Loss: 0.22369368374347687, Accuracy: 0.5085782594978809\n",
      "Iteration: 256, Loss: 0.1793583631515503, Accuracy: 0.5414269459433854\n",
      "Iteration: 320, Loss: 0.17441217601299286, Accuracy: 0.586945132818073\n",
      "Iteration: 384, Loss: 0.2056141495704651, Accuracy: 0.6081903390586376\n",
      "Iteration: 448, Loss: 0.1854848861694336, Accuracy: 0.6201305976137519\n",
      "Iteration: 512, Loss: 0.2095915526151657, Accuracy: 0.6288570961914957\n",
      "Iteration: 576, Loss: 0.16094397008419037, Accuracy: 0.6344976322725415\n",
      "Iteration: 640, Loss: 0.18550805747509003, Accuracy: 0.6367870448157191\n",
      "Iteration: 704, Loss: 0.1331922709941864, Accuracy: 0.6407987102866173\n",
      "Iteration: 768, Loss: 0.1869220733642578, Accuracy: 0.6464781216345727\n",
      "Iteration: 832, Loss: 0.15908034145832062, Accuracy: 0.6493073650635779\n",
      "Iteration: 896, Loss: 0.15491217374801636, Accuracy: 0.6502874996513128\n",
      "Iteration: 960, Loss: 0.1544802039861679, Accuracy: 0.656751002650708\n",
      "Iteration: 1024, Loss: 0.11223021894693375, Accuracy: 0.6571435937657952\n",
      "Iteration: 1088, Loss: 0.13509465754032135, Accuracy: 0.6612293985672295\n",
      "Iteration: 1152, Loss: 0.1546630561351776, Accuracy: 0.661083260551095\n",
      "Iteration: 1216, Loss: 0.1068052276968956, Accuracy: 0.6682613487355411\n",
      "Iteration: 1280, Loss: 0.14976255595684052, Accuracy: 0.675317918881774\n",
      "Iteration: 1344, Loss: 0.1689518690109253, Accuracy: 0.6800013966858387\n",
      "Iteration: 1408, Loss: 0.14936189353466034, Accuracy: 0.6846827974077314\n",
      "Iteration: 1472, Loss: 0.1077914834022522, Accuracy: 0.6796371771488339\n",
      "Iteration: 1536, Loss: 0.16895551979541779, Accuracy: 0.6867195086088032\n",
      "Iteration: 1600, Loss: 0.14880849421024323, Accuracy: 0.6888863637577742\n",
      "Iteration: 1664, Loss: 0.10300897806882858, Accuracy: 0.6941761204507202\n",
      "Iteration: 1728, Loss: 0.16331909596920013, Accuracy: 0.6983454548753798\n",
      "Iteration: 1792, Loss: 0.08481014519929886, Accuracy: 0.7015052260830998\n",
      "Iteration: 1856, Loss: 0.16855323314666748, Accuracy: 0.7028736961074173\n",
      "Iteration: 1920, Loss: 0.09711647033691406, Accuracy: 0.7079307774547487\n",
      "Iteration: 1984, Loss: 0.16396495699882507, Accuracy: 0.7070754517335445\n",
      "Iteration: 2048, Loss: 0.15971656143665314, Accuracy: 0.7046339123044163\n",
      "Iteration: 2112, Loss: 0.09101312607526779, Accuracy: 0.7133530317805707\n",
      "Iteration: 2176, Loss: 0.07848788797855377, Accuracy: 0.715948392637074\n",
      "Iteration: 2240, Loss: 0.07367727905511856, Accuracy: 0.7194224707782269\n",
      "Iteration: 2304, Loss: 0.08846235275268555, Accuracy: 0.7170493570156395\n",
      "Iteration: 2368, Loss: 0.15262548625469208, Accuracy: 0.7227231322322041\n",
      "Iteration: 2432, Loss: 0.16734367609024048, Accuracy: 0.7264003739692271\n",
      "Iteration: 2496, Loss: 0.08841807395219803, Accuracy: 0.7187364711426198\n",
      "Iteration: 2560, Loss: 0.0829743891954422, Accuracy: 0.7308625020086765\n",
      "Iteration: 2624, Loss: 0.14882151782512665, Accuracy: 0.7305013597942889\n",
      "Iteration: 2688, Loss: 0.07401428371667862, Accuracy: 0.7266431343741715\n",
      "Iteration: 2752, Loss: 0.08549662679433823, Accuracy: 0.7251872539054602\n",
      "Iteration: 2816, Loss: 0.15531057119369507, Accuracy: 0.7312084154691547\n",
      "Iteration: 2880, Loss: 0.15586234629154205, Accuracy: 0.7376038390211761\n",
      "Iteration: 2944, Loss: 0.1446465700864792, Accuracy: 0.7378853915724903\n",
      "Iteration: 3008, Loss: 0.1376069188117981, Accuracy: 0.7382765023503453\n",
      "Iteration: 3072, Loss: 0.08025471121072769, Accuracy: 0.7354848464019597\n",
      "Iteration: 3136, Loss: 0.12890464067459106, Accuracy: 0.7403090258594602\n",
      "Iteration: 3200, Loss: 0.07662982493638992, Accuracy: 0.74051702208817\n",
      "Iteration: 3264, Loss: 0.15188616514205933, Accuracy: 0.7403287168126553\n",
      "Iteration: 3328, Loss: 0.1290980726480484, Accuracy: 0.7406647691968828\n",
      "Iteration: 3392, Loss: 0.07350467145442963, Accuracy: 0.7445481503382325\n",
      "Iteration: 3456, Loss: 0.07794291526079178, Accuracy: 0.7443169590551406\n",
      "Iteration: 3520, Loss: 0.07204428315162659, Accuracy: 0.7485881000757217\n",
      "Iteration: 3584, Loss: 0.1176711693406105, Accuracy: 0.7501084965188056\n",
      "Iteration: 3648, Loss: 0.0808897390961647, Accuracy: 0.7514741148333997\n",
      "Iteration: 3712, Loss: 0.14015716314315796, Accuracy: 0.7513755266554654\n",
      "Iteration: 3776, Loss: 0.07932525128126144, Accuracy: 0.7522504625376314\n",
      "Iteration: 3840, Loss: 0.11273594945669174, Accuracy: 0.7537950414698571\n",
      "Iteration: 3904, Loss: 0.12103103846311569, Accuracy: 0.7528454416897148\n",
      "Iteration: 3968, Loss: 0.11768447607755661, Accuracy: 0.7506528999656439\n",
      "Iteration: 4032, Loss: 0.12749828398227692, Accuracy: 0.7536503167357296\n",
      "Iteration: 4096, Loss: 0.11329548805952072, Accuracy: 0.7563106718007475\n",
      "Iteration: 4160, Loss: 0.07363429665565491, Accuracy: 0.7570105481427163\n",
      "Iteration: 4224, Loss: 0.07798229902982712, Accuracy: 0.7580583775416017\n",
      "Iteration: 4288, Loss: 0.07923280447721481, Accuracy: 0.7582198455929756\n",
      "Iteration: 4352, Loss: 0.07803411036729813, Accuracy: 0.762004112591967\n",
      "Iteration: 4416, Loss: 0.20298749208450317, Accuracy: 0.7576681193895638\n",
      "Iteration: 4480, Loss: 0.07611299306154251, Accuracy: 0.7526712659746408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4544, Loss: 0.12922003865242004, Accuracy: 0.7623975002206862\n",
      "Iteration: 4608, Loss: 0.07999024540185928, Accuracy: 0.762421059422195\n",
      "Iteration: 4672, Loss: 0.07457394897937775, Accuracy: 0.7651673750951886\n",
      "Iteration: 4736, Loss: 0.11699113249778748, Accuracy: 0.7618111472111195\n",
      "Iteration: 4800, Loss: 0.11101144552230835, Accuracy: 0.766495848307386\n",
      "Iteration: 4864, Loss: 0.07184330374002457, Accuracy: 0.7609527739696205\n",
      "Iteration: 4928, Loss: 0.07898568361997604, Accuracy: 0.7663920300547034\n",
      "Iteration: 4992, Loss: 0.12938399612903595, Accuracy: 0.7729462827555835\n",
      "Iteration: 5056, Loss: 0.021242810413241386, Accuracy: 0.7766153551638126\n",
      "Iteration: 5120, Loss: 0.036098580807447433, Accuracy: 0.7642651468049735\n",
      "Iteration: 5184, Loss: 0.11383406072854996, Accuracy: 0.7717550202505663\n",
      "Iteration: 5248, Loss: 0.2862841784954071, Accuracy: 0.7721241501858458\n",
      "Iteration: 5312, Loss: 0.1621447503566742, Accuracy: 0.7744117146357894\n",
      "Iteration: 5376, Loss: 0.10574368387460709, Accuracy: 0.7751168627291918\n",
      "Iteration: 5440, Loss: 0.07961398363113403, Accuracy: 0.7805002178065479\n",
      "Iteration: 5504, Loss: 0.10413146018981934, Accuracy: 0.7776747251627967\n",
      "Iteration: 5568, Loss: 0.10570340603590012, Accuracy: 0.7775178360752761\n",
      "Iteration: 5632, Loss: 0.06615068018436432, Accuracy: 0.7814710767706856\n",
      "Iteration: 5696, Loss: 0.10510311275720596, Accuracy: 0.7936713149538264\n",
      "Iteration: 5760, Loss: 0.12164721637964249, Accuracy: 0.782164731877856\n",
      "Iteration: 5824, Loss: 0.10775063186883926, Accuracy: 0.7866994896903634\n",
      "Iteration: 5888, Loss: 0.04970238730311394, Accuracy: 0.7930921139195561\n",
      "Iteration: 5952, Loss: 0.0783519372344017, Accuracy: 0.7848688345402479\n",
      "Iteration: 6016, Loss: 0.05145497992634773, Accuracy: 0.7886289007728919\n",
      "Iteration: 6080, Loss: 0.10784152895212173, Accuracy: 0.7896639030659571\n",
      "Iteration: 6144, Loss: 0.053188007324934006, Accuracy: 0.7916852631606162\n",
      "Iteration: 6208, Loss: 0.09703623503446579, Accuracy: 0.7895466811023653\n",
      "Iteration: 6272, Loss: 0.14334259927272797, Accuracy: 0.8023545682663098\n",
      "Iteration: 6336, Loss: 0.017900802195072174, Accuracy: 0.7893610551254824\n",
      "Iteration: 6400, Loss: 0.042071010917425156, Accuracy: 0.8020469583570957\n",
      "Iteration: 6464, Loss: 0.05181075632572174, Accuracy: 0.7980952374637127\n",
      "Iteration: 6528, Loss: 0.08157214522361755, Accuracy: 0.8004155165981501\n",
      "Iteration: 6592, Loss: 0.043915461748838425, Accuracy: 0.7993937185965478\n",
      "Iteration: 6656, Loss: 0.04098553583025932, Accuracy: 0.800835654954426\n",
      "Iteration: 6720, Loss: 0.03809524327516556, Accuracy: 0.8032666785875335\n",
      "Iteration: 6784, Loss: 0.11893045157194138, Accuracy: 0.7987297751242295\n",
      "Iteration: 6848, Loss: 0.04135425016283989, Accuracy: 0.8054076824337244\n",
      "Iteration: 6912, Loss: 0.015918148681521416, Accuracy: 0.7965563499601558\n",
      "Iteration: 6976, Loss: 0.05218818783760071, Accuracy: 0.8109544782200828\n",
      "Iteration: 7040, Loss: 0.08190836757421494, Accuracy: 0.7957191420719028\n",
      "Iteration: 7104, Loss: 0.03717449679970741, Accuracy: 0.7939390368992463\n",
      "Iteration: 7168, Loss: 0.07382740080356598, Accuracy: 0.8114247572375461\n",
      "Iteration: 7232, Loss: 0.025922531262040138, Accuracy: 0.8054460796993226\n",
      "Iteration: 7296, Loss: 0.05466938391327858, Accuracy: 0.8014953087549657\n",
      "Iteration: 7360, Loss: 0.05872024595737457, Accuracy: 0.8099984322907403\n",
      "Iteration: 7424, Loss: 0.008839125744998455, Accuracy: 0.815986578934826\n",
      "Iteration: 7488, Loss: 0.10672410577535629, Accuracy: 0.8106368746375665\n",
      "Iteration: 7552, Loss: 0.08251408487558365, Accuracy: 0.8109313320601359\n",
      "Iteration: 7616, Loss: 0.06551077961921692, Accuracy: 0.8161932969233021\n",
      "Iteration: 7680, Loss: 0.08629926294088364, Accuracy: 0.8160535268252715\n",
      "Iteration: 7744, Loss: 0.034367989748716354, Accuracy: 0.8050273825647309\n",
      "Iteration: 7808, Loss: 0.0749744102358818, Accuracy: 0.8154862177325413\n",
      "Iteration: 7872, Loss: 0.09109306335449219, Accuracy: 0.8078257510205731\n",
      "Iteration: 7936, Loss: 0.08529049903154373, Accuracy: 0.814867993700318\n",
      "Iteration: 8000, Loss: 0.029448313638567924, Accuracy: 0.8187384747434407\n",
      "Iteration: 8064, Loss: 0.07442381978034973, Accuracy: 0.814867299515754\n",
      "Iteration: 8128, Loss: 0.0737118348479271, Accuracy: 0.8080829916289076\n",
      "Iteration: 8192, Loss: 0.0855226144194603, Accuracy: 0.8238392065977678\n",
      "Iteration: 8256, Loss: 0.060665685683488846, Accuracy: 0.82377337384969\n",
      "Iteration: 8320, Loss: 0.08932918310165405, Accuracy: 0.8127332055009902\n",
      "Iteration: 8384, Loss: 0.09270741790533066, Accuracy: 0.8210439998656511\n",
      "Iteration: 8448, Loss: 0.07404745370149612, Accuracy: 0.8213269838597625\n",
      "Iteration: 8512, Loss: 0.006852959748357534, Accuracy: 0.8173401043750346\n",
      "Iteration: 8576, Loss: 0.028962599113583565, Accuracy: 0.8190358889987692\n",
      "Iteration: 8640, Loss: 0.09988892078399658, Accuracy: 0.8153817750280723\n",
      "Iteration: 8704, Loss: 0.07856994867324829, Accuracy: 0.823795337928459\n",
      "Iteration: 8768, Loss: 0.0924738273024559, Accuracy: 0.821151808835566\n",
      "Iteration: 8832, Loss: 0.027146875858306885, Accuracy: 0.823509338661097\n",
      "Iteration: 8896, Loss: 0.007806430105119944, Accuracy: 0.8301327006192878\n",
      "Iteration: 8960, Loss: 0.0850532054901123, Accuracy: 0.8293708830606192\n",
      "Iteration: 9024, Loss: 0.005968041718006134, Accuracy: 0.824478467577137\n",
      "Iteration: 9088, Loss: 0.07663267850875854, Accuracy: 0.8292530508479103\n",
      "Iteration: 9152, Loss: 0.024475380778312683, Accuracy: 0.8315836393740028\n",
      "Iteration: 9216, Loss: 0.08921325206756592, Accuracy: 0.8307633894728497\n",
      "Iteration: 9280, Loss: 0.07854325324296951, Accuracy: 0.8341204891912639\n",
      "Iteration: 9344, Loss: 0.08700009435415268, Accuracy: 0.8344677974237129\n",
      "Iteration: 9408, Loss: 0.0865669846534729, Accuracy: 0.8288748287595809\n",
      "Iteration: 9472, Loss: 0.048315200954675674, Accuracy: 0.8360543764429167\n",
      "Iteration: 9536, Loss: 0.08182280510663986, Accuracy: 0.8385357855586335\n",
      "Iteration: 9600, Loss: 0.04302018880844116, Accuracy: 0.8378226403146982\n",
      "Iteration: 9664, Loss: 0.09773805737495422, Accuracy: 0.844717210449744\n",
      "Iteration: 9728, Loss: 0.04712783172726631, Accuracy: 0.844527386710979\n",
      "Iteration: 9792, Loss: 0.09233778715133667, Accuracy: 0.8421246319776401\n",
      "Iteration: 9856, Loss: 0.009263449348509312, Accuracy: 0.8428634589072317\n",
      "Iteration: 9920, Loss: 0.017895018681883812, Accuracy: 0.8480832997011021\n",
      "Iteration: 9984, Loss: 0.027386968955397606, Accuracy: 0.8485929623711854\n",
      "Iteration: 10048, Loss: 0.020796703174710274, Accuracy: 0.8502186685218476\n",
      "Iteration: 10112, Loss: 0.09342414140701294, Accuracy: 0.8532505507464521\n",
      "Iteration: 10176, Loss: 0.028941094875335693, Accuracy: 0.8576745904283598\n",
      "Iteration: 10240, Loss: 0.07502944767475128, Accuracy: 0.8572705134865828\n",
      "Iteration: 10304, Loss: 0.010455116629600525, Accuracy: 0.8587809598539025\n",
      "Iteration: 10368, Loss: 0.07140994071960449, Accuracy: 0.8605032354826108\n",
      "Iteration: 10432, Loss: 0.02587638609111309, Accuracy: 0.8440117309219204\n",
      "Iteration: 10496, Loss: 0.0065448097884655, Accuracy: 0.8523943012114614\n",
      "Iteration: 10560, Loss: 0.00445457873865962, Accuracy: 0.8627085227635689\n",
      "Iteration: 10624, Loss: 0.014265908859670162, Accuracy: 0.8636885940795764\n",
      "Iteration: 10688, Loss: 0.08878199011087418, Accuracy: 0.8657193372491747\n",
      "Iteration: 10752, Loss: 0.008955172263085842, Accuracy: 0.8621309408335947\n",
      "Iteration: 10816, Loss: 0.01910524070262909, Accuracy: 0.8610430880216882\n",
      "Iteration: 10880, Loss: 0.07973668724298477, Accuracy: 0.8674501318018883\n",
      "Iteration: 10944, Loss: 0.009526782669126987, Accuracy: 0.8631286565214396\n",
      "Iteration: 11008, Loss: 0.07619667798280716, Accuracy: 0.8651352953747846\n",
      "Iteration: 11072, Loss: 0.012975598685443401, Accuracy: 0.8703098664991558\n",
      "Iteration: 11136, Loss: 0.01012540701776743, Accuracy: 0.8701513539999723\n",
      "Iteration: 11200, Loss: 0.015198703855276108, Accuracy: 0.8743474146467634\n",
      "Iteration: 11264, Loss: 0.07851725816726685, Accuracy: 0.873080124380067\n",
      "Iteration: 11328, Loss: 0.003895628498867154, Accuracy: 0.8712539779371582\n",
      "Iteration: 11392, Loss: 0.07784739881753922, Accuracy: 0.8727874958422035\n",
      "Iteration: 11456, Loss: 0.09769648313522339, Accuracy: 0.877248361997772\n",
      "Iteration: 11520, Loss: 0.09081090241670609, Accuracy: 0.8772696923697367\n",
      "Iteration: 11584, Loss: 0.08199319988489151, Accuracy: 0.8762352573685348\n",
      "Iteration: 11648, Loss: 0.0060804435051977634, Accuracy: 0.8762345206923783\n",
      "Iteration: 11712, Loss: 0.007410614285618067, Accuracy: 0.8740621041506529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 11776, Loss: 0.004244344774633646, Accuracy: 0.8698621831717901\n",
      "Iteration: 11840, Loss: 0.08859225362539291, Accuracy: 0.871172372251749\n",
      "Iteration: 11904, Loss: 0.07802602648735046, Accuracy: 0.8731187286321074\n",
      "Iteration: 11968, Loss: 0.008378583937883377, Accuracy: 0.8745041194488294\n",
      "Iteration: 12032, Loss: 0.006507404148578644, Accuracy: 0.8793256909120828\n",
      "Iteration: 12096, Loss: 0.003840986406430602, Accuracy: 0.8825265048653819\n",
      "Iteration: 12160, Loss: 0.005753601435571909, Accuracy: 0.8819090841570869\n",
      "Iteration: 12224, Loss: 0.08125714212656021, Accuracy: 0.8795336908078752\n",
      "Iteration: 12288, Loss: 0.0028320513665676117, Accuracy: 0.8794379846658558\n",
      "Iteration: 12352, Loss: 0.009543479420244694, Accuracy: 0.8810845986590721\n",
      "Iteration: 12416, Loss: 0.07629518210887909, Accuracy: 0.8815225081634708\n",
      "Iteration: 12480, Loss: 0.07530808448791504, Accuracy: 0.8810664482298307\n",
      "Iteration: 12544, Loss: 0.005385710392147303, Accuracy: 0.8845787320751697\n",
      "Iteration: 12608, Loss: 0.0031005199998617172, Accuracy: 0.8829241005587392\n",
      "Iteration: 12672, Loss: 0.08305171132087708, Accuracy: 0.8824828445794992\n",
      "Iteration: 12736, Loss: 0.005865468177944422, Accuracy: 0.8805028776987456\n",
      "Iteration: 12800, Loss: 0.10010931640863419, Accuracy: 0.8844693413702771\n",
      "Iteration: 12864, Loss: 0.09336534887552261, Accuracy: 0.8729310221970081\n",
      "Iteration: 12928, Loss: 0.003676836146041751, Accuracy: 0.8867430699756369\n",
      "Iteration: 12992, Loss: 0.09161613136529922, Accuracy: 0.885240180650726\n",
      "Iteration: 13056, Loss: 0.10323923081159592, Accuracy: 0.8743498178082518\n",
      "Iteration: 13120, Loss: 0.0056322007440030575, Accuracy: 0.8817164014326409\n",
      "Iteration: 13184, Loss: 0.08721214532852173, Accuracy: 0.8783982319291681\n",
      "Iteration: 13248, Loss: 0.0049766902811825275, Accuracy: 0.8854347365559079\n",
      "Iteration: 13312, Loss: 0.07899405062198639, Accuracy: 0.8871320485486649\n",
      "Iteration: 13376, Loss: 0.004402658436447382, Accuracy: 0.88793415465625\n",
      "Iteration: 13440, Loss: 0.08451930433511734, Accuracy: 0.8891243086545728\n",
      "Iteration: 13504, Loss: 0.0033832404296845198, Accuracy: 0.88903742126422\n",
      "Iteration: 13568, Loss: 0.083595871925354, Accuracy: 0.8883117304067127\n",
      "Iteration: 13632, Loss: 0.08328137546777725, Accuracy: 0.8912099291628692\n",
      "Iteration: 13696, Loss: 0.0039185876958072186, Accuracy: 0.891083151975181\n",
      "Iteration: 13760, Loss: 0.08811831474304199, Accuracy: 0.8901026057719719\n",
      "Iteration: 13824, Loss: 0.09884628653526306, Accuracy: 0.891349084675312\n",
      "Iteration: 13888, Loss: 0.07895506173372269, Accuracy: 0.8828833637817297\n",
      "Iteration: 13952, Loss: 0.00914851389825344, Accuracy: 0.8916801014565863\n",
      "Iteration: 14016, Loss: 0.006457309704273939, Accuracy: 0.8902493969653733\n",
      "Iteration: 14080, Loss: 0.08440110832452774, Accuracy: 0.892675599490758\n",
      "Iteration: 14144, Loss: 0.08686771988868713, Accuracy: 0.8914285354549065\n",
      "Iteration: 14208, Loss: 0.002040750812739134, Accuracy: 0.8931869608350098\n",
      "Iteration: 14272, Loss: 0.0882197842001915, Accuracy: 0.8938471281726379\n",
      "Iteration: 14336, Loss: 0.002062928630039096, Accuracy: 0.8933691707788967\n",
      "Iteration: 14400, Loss: 0.0029423011001199484, Accuracy: 0.8945797304040752\n",
      "Iteration: 14464, Loss: 0.08428952842950821, Accuracy: 0.8978982092812657\n",
      "Iteration: 14528, Loss: 0.08788802474737167, Accuracy: 0.8960429535945877\n",
      "Iteration: 14592, Loss: 0.0578879714012146, Accuracy: 0.8990046169201378\n",
      "Iteration: 14656, Loss: 0.004145896527916193, Accuracy: 0.8938821860065218\n",
      "Iteration: 14720, Loss: 0.08886653184890747, Accuracy: 0.8958701523079071\n",
      "Iteration: 14784, Loss: 0.0781056359410286, Accuracy: 0.895893664623145\n",
      "Iteration: 14848, Loss: 0.0010401940671727061, Accuracy: 0.8975832894502673\n",
      "Iteration: 14912, Loss: 0.0009785095462575555, Accuracy: 0.9019426649610978\n",
      "Iteration: 14976, Loss: 0.0029797463212162256, Accuracy: 0.8992525148787536\n",
      "Iteration: 15040, Loss: 0.004681222140789032, Accuracy: 0.8947727445629425\n",
      "Iteration: 15104, Loss: 0.07762443274259567, Accuracy: 0.8978551184991375\n",
      "Iteration: 15168, Loss: 0.07558409124612808, Accuracy: 0.9005289431952406\n",
      "Iteration: 15232, Loss: 0.06263967603445053, Accuracy: 0.9027163617720362\n",
      "Iteration: 15296, Loss: 0.0019519682973623276, Accuracy: 0.9020073729916476\n",
      "Iteration: 15360, Loss: 0.055836889892816544, Accuracy: 0.9011323003505822\n",
      "Iteration: 15424, Loss: 0.0006826082826592028, Accuracy: 0.8938391497067641\n",
      "Iteration: 15488, Loss: 0.09098949283361435, Accuracy: 0.9069895698630717\n",
      "Iteration: 15552, Loss: 0.03745708987116814, Accuracy: 0.9054288377228659\n",
      "Iteration: 15616, Loss: 0.0006799811962991953, Accuracy: 0.9105619626061525\n",
      "Iteration: 15680, Loss: 0.09370466321706772, Accuracy: 0.9062086939520668\n",
      "Iteration: 15744, Loss: 0.00400098180398345, Accuracy: 0.908360679197358\n",
      "Iteration: 15808, Loss: 0.09733590483665466, Accuracy: 0.9047662545053754\n",
      "Iteration: 15872, Loss: 0.005903853103518486, Accuracy: 0.908863559627207\n",
      "Iteration: 15936, Loss: 0.06994058936834335, Accuracy: 0.9125585670117289\n",
      "Iteration: 16000, Loss: 0.01098580565303564, Accuracy: 0.9124088486423716\n",
      "Iteration: 16064, Loss: 0.07037535309791565, Accuracy: 0.9072537002211902\n",
      "Iteration: 16128, Loss: 0.025785455480217934, Accuracy: 0.911765897704754\n",
      "Iteration: 16192, Loss: 0.0019805056508630514, Accuracy: 0.913664836116368\n",
      "Iteration: 16256, Loss: 0.012219652533531189, Accuracy: 0.917051916156197\n",
      "Iteration: 16320, Loss: 0.10760704427957535, Accuracy: 0.9170996345637832\n",
      "Iteration: 16384, Loss: 0.003866177750751376, Accuracy: 0.9171913186874008\n",
      "Iteration: 16448, Loss: 0.021370312198996544, Accuracy: 0.9150578617700376\n",
      "Iteration: 16512, Loss: 0.010422633029520512, Accuracy: 0.9165812655264745\n",
      "Iteration: 16576, Loss: 0.0031487010419368744, Accuracy: 0.9199568770418409\n",
      "Iteration: 16640, Loss: 0.0005507823661901057, Accuracy: 0.921539030445274\n",
      "Iteration: 16704, Loss: 0.08092642575502396, Accuracy: 0.9192804458143655\n",
      "Iteration: 16768, Loss: 0.009411669336259365, Accuracy: 0.915938263409771\n",
      "Iteration: 16832, Loss: 0.07398117333650589, Accuracy: 0.9189838698221138\n",
      "Iteration: 16896, Loss: 0.0004152027831878513, Accuracy: 0.918114951797179\n",
      "Iteration: 16960, Loss: 0.05413578078150749, Accuracy: 0.924030798181775\n",
      "Iteration: 17024, Loss: 0.016652723774313927, Accuracy: 0.9180973654874833\n",
      "Iteration: 17088, Loss: 0.0028721115086227655, Accuracy: 0.9164460357569624\n",
      "Iteration: 17152, Loss: 0.0021590276155620813, Accuracy: 0.9233093370421557\n",
      "Iteration: 17216, Loss: 0.0002879285311792046, Accuracy: 0.9163806572760222\n",
      "Iteration: 17280, Loss: 0.0004142560937907547, Accuracy: 0.9248671472159913\n",
      "Iteration: 17344, Loss: 0.006644557695835829, Accuracy: 0.9221366031852085\n",
      "Iteration: 17408, Loss: 0.00030760615481995046, Accuracy: 0.9294171300280141\n",
      "Iteration: 17472, Loss: 0.002775747561827302, Accuracy: 0.9276517877151491\n",
      "Iteration: 17536, Loss: 0.0012925774790346622, Accuracy: 0.9216213325125864\n",
      "Iteration: 17600, Loss: 0.0036421865224838257, Accuracy: 0.9247668444004375\n",
      "Iteration: 17664, Loss: 0.0016539599746465683, Accuracy: 0.9270581826276612\n",
      "Iteration: 17728, Loss: 0.0009757392690517008, Accuracy: 0.9250035424192902\n",
      "Iteration: 17792, Loss: 0.06991169601678848, Accuracy: 0.9273482186108595\n",
      "Iteration: 17856, Loss: 0.0027113475371152163, Accuracy: 0.9262833352113375\n",
      "Iteration: 17920, Loss: 0.002482948824763298, Accuracy: 0.9252836326340912\n",
      "Iteration: 17984, Loss: 0.0073791551403701305, Accuracy: 0.9286471730447374\n",
      "Iteration: 18048, Loss: 0.10053890943527222, Accuracy: 0.9174000197235728\n",
      "Iteration: 18112, Loss: 0.09143686294555664, Accuracy: 0.9264517109841108\n",
      "Iteration: 18176, Loss: 0.00048628999502398074, Accuracy: 0.9245496307266876\n",
      "Iteration: 18240, Loss: 0.00027531012892723083, Accuracy: 0.9301618667668663\n",
      "Iteration: 18304, Loss: 0.002644149586558342, Accuracy: 0.924398627190385\n",
      "Iteration: 18368, Loss: 0.0031574461609125137, Accuracy: 0.9284037284523947\n",
      "Iteration: 18432, Loss: 0.0004783444164786488, Accuracy: 0.9285358736960916\n",
      "Iteration: 18496, Loss: 0.004781130235642195, Accuracy: 0.9323687300347956\n",
      "Iteration: 18560, Loss: 0.0030977160204201937, Accuracy: 0.9300165671229479\n",
      "Iteration: 18624, Loss: 0.004513649735599756, Accuracy: 0.9166088234342169\n",
      "Iteration: 18688, Loss: 0.0002959362755063921, Accuracy: 0.9304554731352255\n",
      "Iteration: 18752, Loss: 0.06622198224067688, Accuracy: 0.9317173407471273\n",
      "Iteration: 18816, Loss: 0.008164123632013798, Accuracy: 0.9262875273052487\n",
      "Iteration: 18880, Loss: 0.00014161480066832155, Accuracy: 0.9291638096910901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 18944, Loss: 0.08020343631505966, Accuracy: 0.9327907287806738\n",
      "Iteration: 19008, Loss: 0.0002117182593792677, Accuracy: 0.9314050303946715\n",
      "Iteration: 19072, Loss: 0.01290085632354021, Accuracy: 0.932479089446133\n",
      "Iteration: 19136, Loss: 0.0011251416290178895, Accuracy: 0.9342919191840338\n",
      "Iteration: 19200, Loss: 0.004706019069999456, Accuracy: 0.9337723313074093\n",
      "Iteration: 19264, Loss: 0.00020737540035042912, Accuracy: 0.934454754460603\n",
      "Iteration: 19328, Loss: 0.04673178866505623, Accuracy: 0.9216864902628004\n",
      "Iteration: 19392, Loss: 0.005073400214314461, Accuracy: 0.9325546724430751\n",
      "Iteration: 19456, Loss: 0.00012588243407662958, Accuracy: 0.9373297894562711\n",
      "Iteration: 19520, Loss: 0.05202983692288399, Accuracy: 0.940490066233906\n",
      "Iteration: 19584, Loss: 0.00032743948395363986, Accuracy: 0.9380954582666163\n",
      "Iteration: 19648, Loss: 0.003282371908426285, Accuracy: 0.9402036206302\n",
      "Iteration: 19712, Loss: 0.004106277134269476, Accuracy: 0.943107769395283\n",
      "Iteration: 19776, Loss: 0.04232040047645569, Accuracy: 0.9443479858891806\n",
      "Iteration: 19840, Loss: 0.03571071848273277, Accuracy: 0.9350351054381463\n",
      "Iteration: 19904, Loss: 0.004362193401902914, Accuracy: 0.9428802677211934\n",
      "Iteration: 19968, Loss: 0.03587022051215172, Accuracy: 0.9474591858088388\n",
      "Iteration: 20032, Loss: 0.0009976763976737857, Accuracy: 0.9504479134193389\n",
      "Iteration: 20096, Loss: 0.0002382831444265321, Accuracy: 0.9473190472926944\n",
      "Iteration: 20160, Loss: 0.0060239736922085285, Accuracy: 0.9526549045185675\n",
      "Iteration: 20224, Loss: 0.0002244068164145574, Accuracy: 0.9521870147946174\n",
      "Iteration: 20288, Loss: 0.014611844904720783, Accuracy: 0.949379818754096\n",
      "Iteration: 20352, Loss: 0.00011958170216530561, Accuracy: 0.9563891861398588\n",
      "Iteration: 20416, Loss: 0.02160966396331787, Accuracy: 0.9547957717441022\n",
      "Iteration: 20480, Loss: 7.086685218382627e-05, Accuracy: 0.9572365206840914\n",
      "Iteration: 20544, Loss: 0.00017108376778196543, Accuracy: 0.9541348793063662\n",
      "Iteration: 20608, Loss: 0.0015130937099456787, Accuracy: 0.9526845284635783\n",
      "Iteration: 20672, Loss: 0.00030103480094112456, Accuracy: 0.957500624077511\n",
      "Iteration: 20736, Loss: 0.008022266440093517, Accuracy: 0.9608306634836481\n",
      "Iteration: 20800, Loss: 0.020718373358249664, Accuracy: 0.9539207443376654\n",
      "Iteration: 20864, Loss: 0.0028054602444171906, Accuracy: 0.9622139371567755\n",
      "Iteration: 20928, Loss: 0.0031163229141384363, Accuracy: 0.9592052110965597\n",
      "Iteration: 20992, Loss: 0.012384943664073944, Accuracy: 0.9654080741311191\n",
      "Iteration: 21056, Loss: 0.00181413849350065, Accuracy: 0.9618225828380673\n",
      "Iteration: 21120, Loss: 0.0013025837251916528, Accuracy: 0.9688123348314548\n",
      "Iteration: 21184, Loss: 0.00018911757797468454, Accuracy: 0.9677209197034244\n",
      "Iteration: 21248, Loss: 0.002234863815829158, Accuracy: 0.9689674362816731\n",
      "Iteration: 21312, Loss: 0.0012758219381794333, Accuracy: 0.9658031325016054\n",
      "Iteration: 21376, Loss: 4.697520853369497e-05, Accuracy: 0.9662299358315067\n",
      "Iteration: 21440, Loss: 0.0008379053906537592, Accuracy: 0.966341262748756\n",
      "Iteration: 21504, Loss: 0.006436772644519806, Accuracy: 0.9715062763862079\n",
      "Saved fullModel_dr[2]_replicate4.model\n",
      "Saved W_dr[2]_replicate4.p\n",
      "2 1.0 [1.0, 1.0, 1.0]\n",
      "Saved w_dr[2]_replicate4.p\n",
      "Replicate 4 completed\n",
      "Time elapsed: 204.046875 seconds\n",
      "Training for delay range [3]...\n",
      "Iteration: 64, Loss: 0.251760870218277, Accuracy: 0.49960603239014745\n",
      "Iteration: 128, Loss: 0.2578113079071045, Accuracy: 0.5012236936017871\n",
      "Iteration: 192, Loss: 0.22755710780620575, Accuracy: 0.5097590764053166\n",
      "Iteration: 256, Loss: 0.1973218470811844, Accuracy: 0.5436591007746756\n",
      "Iteration: 320, Loss: 0.19502408802509308, Accuracy: 0.5790684749372303\n",
      "Iteration: 384, Loss: 0.171316996216774, Accuracy: 0.5982795464806259\n",
      "Iteration: 448, Loss: 0.17710484564304352, Accuracy: 0.6146950563415885\n",
      "Iteration: 512, Loss: 0.1636834591627121, Accuracy: 0.622856454923749\n",
      "Iteration: 576, Loss: 0.16284523904323578, Accuracy: 0.6298113819211721\n",
      "Iteration: 640, Loss: 0.1743864268064499, Accuracy: 0.6357033676467836\n",
      "Iteration: 704, Loss: 0.13730774819850922, Accuracy: 0.6401101131923497\n",
      "Iteration: 768, Loss: 0.20174427330493927, Accuracy: 0.6447049048729241\n",
      "Iteration: 832, Loss: 0.14686867594718933, Accuracy: 0.6458981060422957\n",
      "Iteration: 896, Loss: 0.14315509796142578, Accuracy: 0.6517500672489405\n",
      "Iteration: 960, Loss: 0.12261565774679184, Accuracy: 0.6582368337549269\n",
      "Iteration: 1024, Loss: 0.13894684612751007, Accuracy: 0.6596976034343243\n",
      "Iteration: 1088, Loss: 0.1424490064382553, Accuracy: 0.6652296050451696\n",
      "Iteration: 1152, Loss: 0.12915842235088348, Accuracy: 0.6628315490670502\n",
      "Iteration: 1216, Loss: 0.12869904935359955, Accuracy: 0.6628114068880677\n",
      "Iteration: 1280, Loss: 0.20416004955768585, Accuracy: 0.669829458463937\n",
      "Iteration: 1344, Loss: 0.12298420071601868, Accuracy: 0.6726676528342068\n",
      "Iteration: 1408, Loss: 0.10919928550720215, Accuracy: 0.6722601475194097\n",
      "Iteration: 1472, Loss: 0.11559992283582687, Accuracy: 0.6718761492520571\n",
      "Iteration: 1536, Loss: 0.1260884702205658, Accuracy: 0.6740348851308227\n",
      "Iteration: 1600, Loss: 0.14654278755187988, Accuracy: 0.6751498035155237\n",
      "Iteration: 1664, Loss: 0.1238274872303009, Accuracy: 0.6809554002247751\n",
      "Iteration: 1728, Loss: 0.19424907863140106, Accuracy: 0.6833157385699451\n",
      "Iteration: 1792, Loss: 0.10164790600538254, Accuracy: 0.6808640300296247\n",
      "Iteration: 1856, Loss: 0.15072105824947357, Accuracy: 0.6820436646230519\n",
      "Iteration: 1920, Loss: 0.18862998485565186, Accuracy: 0.6879922389052808\n",
      "Iteration: 1984, Loss: 0.1916673183441162, Accuracy: 0.6882347785867751\n",
      "Iteration: 2048, Loss: 0.12870989739894867, Accuracy: 0.6892245193012059\n",
      "Iteration: 2112, Loss: 0.25930604338645935, Accuracy: 0.6871660321485251\n",
      "Iteration: 2176, Loss: 0.09472749382257462, Accuracy: 0.6934128296561539\n",
      "Iteration: 2240, Loss: 0.10441990941762924, Accuracy: 0.6949134145397693\n",
      "Iteration: 2304, Loss: 0.15061940252780914, Accuracy: 0.6958163275849074\n",
      "Iteration: 2368, Loss: 0.10694002360105515, Accuracy: 0.6968566747382283\n",
      "Iteration: 2432, Loss: 0.15146370232105255, Accuracy: 0.6836605488788337\n",
      "Iteration: 2496, Loss: 0.19277991354465485, Accuracy: 0.6978991981595755\n",
      "Iteration: 2560, Loss: 0.09792601317167282, Accuracy: 0.6984740097541362\n",
      "Iteration: 2624, Loss: 0.09508582204580307, Accuracy: 0.7022513730917126\n",
      "Iteration: 2688, Loss: 0.18442578613758087, Accuracy: 0.7038291955832392\n",
      "Iteration: 2752, Loss: 0.1795540452003479, Accuracy: 0.7051823621150106\n",
      "Iteration: 2816, Loss: 0.15799210965633392, Accuracy: 0.6995478593744338\n",
      "Iteration: 2880, Loss: 0.15094831585884094, Accuracy: 0.7056544667575508\n",
      "Iteration: 2944, Loss: 0.1024981141090393, Accuracy: 0.7025615046732128\n",
      "Iteration: 3008, Loss: 0.09980154782533646, Accuracy: 0.7035147214774042\n",
      "Iteration: 3072, Loss: 0.09645608067512512, Accuracy: 0.7059472436085343\n",
      "Iteration: 3136, Loss: 0.18323355913162231, Accuracy: 0.7096502080094069\n",
      "Iteration: 3200, Loss: 0.178319051861763, Accuracy: 0.7058899262920022\n",
      "Iteration: 3264, Loss: 0.17490677535533905, Accuracy: 0.7036886238493025\n",
      "Iteration: 3328, Loss: 0.1607595533132553, Accuracy: 0.7001398529391736\n",
      "Iteration: 3392, Loss: 0.17456839978694916, Accuracy: 0.7109270363580436\n",
      "Iteration: 3456, Loss: 0.15785126388072968, Accuracy: 0.6992984246462584\n",
      "Iteration: 3520, Loss: 0.0966782346367836, Accuracy: 0.7076650753151625\n",
      "Iteration: 3584, Loss: 0.0938364639878273, Accuracy: 0.7121250377967954\n",
      "Iteration: 3648, Loss: 0.09378581494092941, Accuracy: 0.7133263542782515\n",
      "Iteration: 3712, Loss: 0.1628703624010086, Accuracy: 0.7127861939370632\n",
      "Iteration: 3776, Loss: 0.09157352894544601, Accuracy: 0.7116512185893953\n",
      "Iteration: 3840, Loss: 0.09239869564771652, Accuracy: 0.7145923478528857\n",
      "Iteration: 3904, Loss: 0.1782681792974472, Accuracy: 0.7160110431723297\n",
      "Iteration: 3968, Loss: 0.1587551087141037, Accuracy: 0.7165047822054476\n",
      "Iteration: 4032, Loss: 0.09168394654989243, Accuracy: 0.7155301081947982\n",
      "Iteration: 4096, Loss: 0.15718592703342438, Accuracy: 0.7042728471569717\n",
      "Iteration: 4160, Loss: 0.08748088032007217, Accuracy: 0.7121765338815749\n",
      "Iteration: 4224, Loss: 0.16347083449363708, Accuracy: 0.7076990031637251\n",
      "Iteration: 4288, Loss: 0.09173688292503357, Accuracy: 0.7127390881069005\n",
      "Iteration: 4352, Loss: 0.32399821281433105, Accuracy: 0.7115255414973944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4416, Loss: 0.15972714126110077, Accuracy: 0.7158617859240621\n",
      "Iteration: 4480, Loss: 0.16167503595352173, Accuracy: 0.7175079819280654\n",
      "Iteration: 4544, Loss: 0.1627090573310852, Accuracy: 0.7179348329082131\n",
      "Iteration: 4608, Loss: 0.28316599130630493, Accuracy: 0.7116310314740986\n",
      "Iteration: 4672, Loss: 0.16030830144882202, Accuracy: 0.7150340829975903\n",
      "Iteration: 4736, Loss: 0.17170947790145874, Accuracy: 0.7129858874250203\n",
      "Iteration: 4800, Loss: 0.16296476125717163, Accuracy: 0.719919137423858\n",
      "Iteration: 4864, Loss: 0.17683684825897217, Accuracy: 0.7070622493047267\n",
      "Iteration: 4928, Loss: 0.1646789163351059, Accuracy: 0.7196728871203959\n",
      "Iteration: 4992, Loss: 0.1782006174325943, Accuracy: 0.7160075092688203\n",
      "Iteration: 5056, Loss: 0.09184730798006058, Accuracy: 0.7195407003164291\n",
      "Iteration: 5120, Loss: 0.17450827360153198, Accuracy: 0.7188236888032407\n",
      "Iteration: 5184, Loss: 0.09025754779577255, Accuracy: 0.7235487285070121\n",
      "Iteration: 5248, Loss: 0.163222998380661, Accuracy: 0.7186056755017489\n",
      "Iteration: 5312, Loss: 0.28389838337898254, Accuracy: 0.7198641798458993\n",
      "Iteration: 5376, Loss: 0.17673708498477936, Accuracy: 0.7205949453637004\n",
      "Iteration: 5440, Loss: 0.09069528430700302, Accuracy: 0.7222060540225357\n",
      "Iteration: 5504, Loss: 0.0892755463719368, Accuracy: 0.7195219665300101\n",
      "Iteration: 5568, Loss: 0.08781203627586365, Accuracy: 0.7175986773800105\n",
      "Iteration: 5632, Loss: 0.15899451076984406, Accuracy: 0.7180395438335836\n",
      "Iteration: 5696, Loss: 0.17368823289871216, Accuracy: 0.7236615833826363\n",
      "Iteration: 5760, Loss: 0.16538818180561066, Accuracy: 0.7225507120601833\n",
      "Iteration: 5824, Loss: 0.08861485123634338, Accuracy: 0.7236868524923921\n",
      "Iteration: 5888, Loss: 0.16705895960330963, Accuracy: 0.7256870854180306\n",
      "Iteration: 5952, Loss: 0.08961832523345947, Accuracy: 0.7214937803801149\n",
      "Iteration: 6016, Loss: 0.169602632522583, Accuracy: 0.7259532737080008\n",
      "Iteration: 6080, Loss: 0.08653027564287186, Accuracy: 0.7202820021193475\n",
      "Iteration: 6144, Loss: 0.0882139578461647, Accuracy: 0.7238122231792659\n",
      "Iteration: 6208, Loss: 0.16372431814670563, Accuracy: 0.7233505896292627\n",
      "Iteration: 6272, Loss: 0.17014576494693756, Accuracy: 0.7248984889592975\n",
      "Iteration: 6336, Loss: 0.0891871228814125, Accuracy: 0.7218447711784393\n",
      "Iteration: 6400, Loss: 0.09101659804582596, Accuracy: 0.7227002060972154\n",
      "Iteration: 6464, Loss: 0.17400580644607544, Accuracy: 0.7266415467020124\n",
      "Iteration: 6528, Loss: 0.1749248057603836, Accuracy: 0.7227572726551443\n",
      "Iteration: 6592, Loss: 0.08844244480133057, Accuracy: 0.7273416710086167\n",
      "Iteration: 6656, Loss: 0.08715066313743591, Accuracy: 0.7263857421930879\n",
      "Iteration: 6720, Loss: 0.17277590930461884, Accuracy: 0.7197856835555285\n",
      "Iteration: 6784, Loss: 0.16736139357089996, Accuracy: 0.7273011223878711\n",
      "Iteration: 6848, Loss: 0.1651429533958435, Accuracy: 0.7217031030450016\n",
      "Iteration: 6912, Loss: 0.16993539035320282, Accuracy: 0.7270440051797777\n",
      "Iteration: 6976, Loss: 0.17385073006153107, Accuracy: 0.725466804811731\n",
      "Iteration: 7040, Loss: 0.08640085905790329, Accuracy: 0.7257920058909804\n",
      "Iteration: 7104, Loss: 0.08972766995429993, Accuracy: 0.7274595573544502\n",
      "Iteration: 7168, Loss: 0.08523785322904587, Accuracy: 0.7303001480177045\n",
      "Iteration: 7232, Loss: 0.08882126212120056, Accuracy: 0.7253458735067397\n",
      "Iteration: 7296, Loss: 0.16207173466682434, Accuracy: 0.719674332998693\n",
      "Iteration: 7360, Loss: 0.17721028625965118, Accuracy: 0.7271055430173874\n",
      "Iteration: 7424, Loss: 0.09248317033052444, Accuracy: 0.7279456423129886\n",
      "Iteration: 7488, Loss: 0.16148741543293, Accuracy: 0.7322942598257214\n",
      "Iteration: 7552, Loss: 0.08328133076429367, Accuracy: 0.7320491296704859\n",
      "Iteration: 7616, Loss: 0.17081968486309052, Accuracy: 0.730186986271292\n",
      "Iteration: 7680, Loss: 0.16218091547489166, Accuracy: 0.7263570441864431\n",
      "Iteration: 7744, Loss: 0.09082136303186417, Accuracy: 0.7322811151389033\n",
      "Iteration: 7808, Loss: 0.09673263877630234, Accuracy: 0.7255230029113591\n",
      "Iteration: 7872, Loss: 0.09128841012716293, Accuracy: 0.7310258601792157\n",
      "Iteration: 7936, Loss: 0.17250831425189972, Accuracy: 0.7340171919204295\n",
      "Iteration: 8000, Loss: 0.17021046578884125, Accuracy: 0.732183754676953\n",
      "Iteration: 8064, Loss: 0.15416781604290009, Accuracy: 0.73140674456954\n",
      "Iteration: 8128, Loss: 0.16347824037075043, Accuracy: 0.7262638406828046\n",
      "Iteration: 8192, Loss: 0.17514871060848236, Accuracy: 0.7329829095397145\n",
      "Iteration: 8256, Loss: 0.15469999611377716, Accuracy: 0.7336088016163558\n",
      "Iteration: 8320, Loss: 0.08316497504711151, Accuracy: 0.7284843686502427\n",
      "Iteration: 8384, Loss: 0.08597961813211441, Accuracy: 0.7204251161310822\n",
      "Iteration: 8448, Loss: 0.15696479380130768, Accuracy: 0.7300178306177258\n",
      "Iteration: 8512, Loss: 0.16992895305156708, Accuracy: 0.7290650154463947\n",
      "Iteration: 8576, Loss: 0.08903755992650986, Accuracy: 0.7254654576536268\n",
      "Iteration: 8640, Loss: 0.1460067629814148, Accuracy: 0.7336926856078207\n",
      "Iteration: 8704, Loss: 0.16139595210552216, Accuracy: 0.7353134877048433\n",
      "Iteration: 8768, Loss: 0.1509629189968109, Accuracy: 0.7371105519123375\n",
      "Iteration: 8832, Loss: 0.1537020057439804, Accuracy: 0.7279748544096947\n",
      "Iteration: 8896, Loss: 0.085212342441082, Accuracy: 0.7382614237722009\n",
      "Iteration: 8960, Loss: 0.1409110128879547, Accuracy: 0.7360012801364064\n",
      "Iteration: 9024, Loss: 0.133340522646904, Accuracy: 0.7395362018141896\n",
      "Iteration: 9088, Loss: 0.17902745306491852, Accuracy: 0.7391192330978811\n",
      "Iteration: 9152, Loss: 0.14154013991355896, Accuracy: 0.7387662848923355\n",
      "Iteration: 9216, Loss: 0.08161469548940659, Accuracy: 0.7395900529809296\n",
      "Iteration: 9280, Loss: 0.08269201964139938, Accuracy: 0.7361690492834896\n",
      "Iteration: 9344, Loss: 0.07853464037179947, Accuracy: 0.7421206093858927\n",
      "Iteration: 9408, Loss: 0.15809106826782227, Accuracy: 0.7433864285703748\n",
      "Iteration: 9472, Loss: 0.08812733739614487, Accuracy: 0.7455548970028758\n",
      "Iteration: 9536, Loss: 0.1246664822101593, Accuracy: 0.7409162167459726\n",
      "Iteration: 9600, Loss: 0.12874646484851837, Accuracy: 0.747244618833065\n",
      "Iteration: 9664, Loss: 0.0800323560833931, Accuracy: 0.7472243525553495\n",
      "Iteration: 9728, Loss: 0.14065515995025635, Accuracy: 0.749068962642923\n",
      "Iteration: 9792, Loss: 0.09031137079000473, Accuracy: 0.7507706775795668\n",
      "Iteration: 9856, Loss: 0.13502874970436096, Accuracy: 0.7502644269261509\n",
      "Iteration: 9920, Loss: 0.08145042508840561, Accuracy: 0.7560662047471851\n",
      "Iteration: 9984, Loss: 0.0798872858285904, Accuracy: 0.7519195294007659\n",
      "Iteration: 10048, Loss: 0.09663403779268265, Accuracy: 0.7452129500452429\n",
      "Iteration: 10112, Loss: 0.25721514225006104, Accuracy: 0.7437594858929515\n",
      "Iteration: 10176, Loss: 0.10147703438997269, Accuracy: 0.7566912572365254\n",
      "Iteration: 10240, Loss: 0.11822613328695297, Accuracy: 0.753705469192937\n",
      "Iteration: 10304, Loss: 0.11552441120147705, Accuracy: 0.7569260327145457\n",
      "Iteration: 10368, Loss: 0.10828877240419388, Accuracy: 0.7683085126336664\n",
      "Iteration: 10432, Loss: 0.09003082662820816, Accuracy: 0.7704505990259349\n",
      "Iteration: 10496, Loss: 0.10866526514291763, Accuracy: 0.7694760477170348\n",
      "Iteration: 10560, Loss: 0.08699426054954529, Accuracy: 0.7629224716220051\n",
      "Iteration: 10624, Loss: 0.09152800589799881, Accuracy: 0.7668830512557179\n",
      "Iteration: 10688, Loss: 0.12106764316558838, Accuracy: 0.7620402832981199\n",
      "Iteration: 10752, Loss: 0.0844130739569664, Accuracy: 0.7767822595778853\n",
      "Iteration: 10816, Loss: 0.08950936794281006, Accuracy: 0.7697850719559938\n",
      "Iteration: 10880, Loss: 0.09975764900445938, Accuracy: 0.7758480773773044\n",
      "Iteration: 10944, Loss: 0.09472184628248215, Accuracy: 0.7753225492779166\n",
      "Iteration: 11008, Loss: 0.08548424392938614, Accuracy: 0.7813756829127669\n",
      "Iteration: 11072, Loss: 0.09317561239004135, Accuracy: 0.7812305898405612\n",
      "Iteration: 11136, Loss: 0.08955126255750656, Accuracy: 0.7748904940672219\n",
      "Iteration: 11200, Loss: 0.09313791990280151, Accuracy: 0.7784875822253525\n",
      "Iteration: 11264, Loss: 0.08558112382888794, Accuracy: 0.7845556635875255\n",
      "Iteration: 11328, Loss: 0.09324090927839279, Accuracy: 0.7886100499890745\n",
      "Iteration: 11392, Loss: 0.09151703119277954, Accuracy: 0.7888602553866804\n",
      "Iteration: 11456, Loss: 0.09042543172836304, Accuracy: 0.7801214365754277\n",
      "Iteration: 11520, Loss: 0.09003139287233353, Accuracy: 0.7874696408398449\n",
      "Iteration: 11584, Loss: 0.09343892335891724, Accuracy: 0.7905040031764656\n",
      "Iteration: 11648, Loss: 0.08185133337974548, Accuracy: 0.7965706537943333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 11712, Loss: 0.08711066097021103, Accuracy: 0.7892269617877901\n",
      "Iteration: 11776, Loss: 0.07955604046583176, Accuracy: 0.7980643280316144\n",
      "Iteration: 11840, Loss: 0.081209696829319, Accuracy: 0.7945297530386597\n",
      "Iteration: 11904, Loss: 0.08790986984968185, Accuracy: 0.7921324549242854\n",
      "Iteration: 11968, Loss: 0.09468889236450195, Accuracy: 0.7952644603792578\n",
      "Iteration: 12032, Loss: 0.0846722349524498, Accuracy: 0.7990994991268963\n",
      "Iteration: 12096, Loss: 0.08767858892679214, Accuracy: 0.7890022059436888\n",
      "Iteration: 12160, Loss: 0.08278830349445343, Accuracy: 0.7952624729368836\n",
      "Iteration: 12224, Loss: 0.08569648861885071, Accuracy: 0.8038724893704057\n",
      "Iteration: 12288, Loss: 0.0817122533917427, Accuracy: 0.7986537381075323\n",
      "Iteration: 12352, Loss: 0.08495686203241348, Accuracy: 0.8025901091750711\n",
      "Iteration: 12416, Loss: 0.097256600856781, Accuracy: 0.7952696839347482\n",
      "Iteration: 12480, Loss: 0.08382873982191086, Accuracy: 0.8028372547123581\n",
      "Iteration: 12544, Loss: 0.08712473511695862, Accuracy: 0.7976913021411747\n",
      "Iteration: 12608, Loss: 0.09030449390411377, Accuracy: 0.7777282290626317\n",
      "Iteration: 12672, Loss: 0.08370950073003769, Accuracy: 0.7967933774925768\n",
      "Iteration: 12736, Loss: 0.08508502691984177, Accuracy: 0.7964845618698746\n",
      "Iteration: 12800, Loss: 0.08112525194883347, Accuracy: 0.7996659909840673\n",
      "Iteration: 12864, Loss: 0.08281421661376953, Accuracy: 0.8035335438326001\n",
      "Iteration: 12928, Loss: 0.08168122917413712, Accuracy: 0.8006149944849312\n",
      "Iteration: 12992, Loss: 0.08617442101240158, Accuracy: 0.8052276028320193\n",
      "Iteration: 13056, Loss: 0.08663639426231384, Accuracy: 0.8084987851325423\n",
      "Iteration: 13120, Loss: 0.0903732106089592, Accuracy: 0.8068578222300857\n",
      "Iteration: 13184, Loss: 0.08485609292984009, Accuracy: 0.8045764376875013\n",
      "Iteration: 13248, Loss: 0.08413409441709518, Accuracy: 0.8051790180616081\n",
      "Iteration: 13312, Loss: 0.08285553753376007, Accuracy: 0.8047957336530089\n",
      "Iteration: 13376, Loss: 0.09121795743703842, Accuracy: 0.8073221270460635\n",
      "Iteration: 13440, Loss: 0.08843224495649338, Accuracy: 0.7980836441274732\n",
      "Iteration: 13504, Loss: 0.08662408590316772, Accuracy: 0.8066558102145791\n",
      "Iteration: 13568, Loss: 0.09313894063234329, Accuracy: 0.807572832563892\n",
      "Iteration: 13632, Loss: 0.0825938954949379, Accuracy: 0.7969695995561779\n",
      "Iteration: 13696, Loss: 0.07730305194854736, Accuracy: 0.802995432401076\n",
      "Iteration: 13760, Loss: 0.08517292886972427, Accuracy: 0.8136779558844864\n",
      "Iteration: 13824, Loss: 0.08425962924957275, Accuracy: 0.8056748404633254\n",
      "Iteration: 13888, Loss: 0.07795417308807373, Accuracy: 0.8117748012300581\n",
      "Iteration: 13952, Loss: 0.08816173672676086, Accuracy: 0.8101734956726432\n",
      "Iteration: 14016, Loss: 0.08446511626243591, Accuracy: 0.810311992187053\n",
      "Iteration: 14080, Loss: 0.08817311376333237, Accuracy: 0.7952817033510655\n",
      "Iteration: 14144, Loss: 0.08250366151332855, Accuracy: 0.8011788143776357\n",
      "Iteration: 14208, Loss: 0.08419352024793625, Accuracy: 0.8071730833034962\n",
      "Iteration: 14272, Loss: 0.08272623270750046, Accuracy: 0.8118259613402188\n",
      "Iteration: 14336, Loss: 0.08771178871393204, Accuracy: 0.8073992440477014\n",
      "Iteration: 14400, Loss: 0.08520156890153885, Accuracy: 0.8112045836169273\n",
      "Iteration: 14464, Loss: 0.07849391549825668, Accuracy: 0.8085929329972714\n",
      "Iteration: 14528, Loss: 0.08570900559425354, Accuracy: 0.8083009889815003\n",
      "Iteration: 14592, Loss: 0.08586189895868301, Accuracy: 0.808439779561013\n",
      "Iteration: 14656, Loss: 0.09235504269599915, Accuracy: 0.8096326591912657\n",
      "Iteration: 14720, Loss: 0.08457943052053452, Accuracy: 0.8055255084764212\n",
      "Iteration: 14784, Loss: 0.08297692239284515, Accuracy: 0.8144167154096067\n",
      "Iteration: 14848, Loss: 0.08216580748558044, Accuracy: 0.8152332222089171\n",
      "Iteration: 14912, Loss: 0.0828089788556099, Accuracy: 0.8146163860801607\n",
      "Iteration: 14976, Loss: 0.08571959286928177, Accuracy: 0.8073533782735467\n",
      "Iteration: 15040, Loss: 0.08307965099811554, Accuracy: 0.8087363981176168\n",
      "Iteration: 15104, Loss: 0.08591111749410629, Accuracy: 0.8103568607475609\n",
      "Iteration: 15168, Loss: 0.08130133152008057, Accuracy: 0.814602229045704\n",
      "Iteration: 15232, Loss: 0.08175589144229889, Accuracy: 0.8095335830003023\n",
      "Iteration: 15296, Loss: 0.08200176805257797, Accuracy: 0.8163643183652312\n",
      "Iteration: 15360, Loss: 0.08071516454219818, Accuracy: 0.8158636756706983\n",
      "Iteration: 15424, Loss: 0.08987585455179214, Accuracy: 0.8138450598344207\n",
      "Iteration: 15488, Loss: 0.08154022693634033, Accuracy: 0.8133536735549569\n",
      "Iteration: 15552, Loss: 0.08318521082401276, Accuracy: 0.8014829109888524\n",
      "Iteration: 15616, Loss: 0.08225768804550171, Accuracy: 0.8176428424194455\n",
      "Iteration: 15680, Loss: 0.08484602719545364, Accuracy: 0.8126938019413501\n",
      "Iteration: 15744, Loss: 0.08458483219146729, Accuracy: 0.8079158158507198\n",
      "Iteration: 15808, Loss: 0.08665567636489868, Accuracy: 0.8159877683501691\n",
      "Iteration: 15872, Loss: 0.08304262161254883, Accuracy: 0.8082904843613505\n",
      "Iteration: 15936, Loss: 0.08533888310194016, Accuracy: 0.815107790986076\n",
      "Iteration: 16000, Loss: 0.0858175978064537, Accuracy: 0.799483650829643\n",
      "Iteration: 16064, Loss: 0.08506214618682861, Accuracy: 0.8024851384107023\n",
      "Iteration: 16128, Loss: 0.08193147927522659, Accuracy: 0.8059856237377971\n",
      "Iteration: 16192, Loss: 0.08011635392904282, Accuracy: 0.8135462382342666\n",
      "Iteration: 16256, Loss: 0.0822843536734581, Accuracy: 0.8187867323867977\n",
      "Iteration: 16320, Loss: 0.08228005468845367, Accuracy: 0.815926592098549\n",
      "Iteration: 16384, Loss: 0.08490043878555298, Accuracy: 0.8152394297067076\n",
      "Iteration: 16448, Loss: 0.0850173830986023, Accuracy: 0.8153920224867761\n",
      "Iteration: 16512, Loss: 0.08160223811864853, Accuracy: 0.8018399025313556\n",
      "Iteration: 16576, Loss: 0.08155062049627304, Accuracy: 0.8200933593325317\n",
      "Iteration: 16640, Loss: 0.09760275483131409, Accuracy: 0.8119276314973831\n",
      "Iteration: 16704, Loss: 0.08313259482383728, Accuracy: 0.8187617361545563\n",
      "Iteration: 16768, Loss: 0.08111488074064255, Accuracy: 0.8197220156434923\n",
      "Iteration: 16832, Loss: 0.08129383623600006, Accuracy: 0.8131926057394594\n",
      "Iteration: 16896, Loss: 0.0857488214969635, Accuracy: 0.8171077172737569\n",
      "Iteration: 16960, Loss: 0.08427569270133972, Accuracy: 0.8160543036647141\n",
      "Iteration: 17024, Loss: 0.31240224838256836, Accuracy: 0.806362119037658\n",
      "Iteration: 17088, Loss: 0.19433672726154327, Accuracy: 0.8066322230733931\n",
      "Iteration: 17152, Loss: 0.08348561078310013, Accuracy: 0.8159813622478396\n",
      "Iteration: 17216, Loss: 0.08540821820497513, Accuracy: 0.8180756636429578\n",
      "Iteration: 17280, Loss: 0.087639220058918, Accuracy: 0.8185268840752542\n",
      "Iteration: 17344, Loss: 0.08548837900161743, Accuracy: 0.8190495863091201\n",
      "Iteration: 17408, Loss: 0.08588055521249771, Accuracy: 0.8169258432462811\n",
      "Iteration: 17472, Loss: 0.08256407827138901, Accuracy: 0.8204715691972524\n",
      "Iteration: 17536, Loss: 0.08836832642555237, Accuracy: 0.8154733246192336\n",
      "Iteration: 17600, Loss: 0.08286941796541214, Accuracy: 0.8208903491031379\n",
      "Iteration: 17664, Loss: 0.0870543122291565, Accuracy: 0.8189152586273849\n",
      "Iteration: 17728, Loss: 0.08271247893571854, Accuracy: 0.8196306896861643\n",
      "Iteration: 17792, Loss: 0.08209532499313354, Accuracy: 0.8204481340944767\n",
      "Iteration: 17856, Loss: 0.08486143499612808, Accuracy: 0.8220673084724694\n",
      "Iteration: 17920, Loss: 0.3205074965953827, Accuracy: 0.8152710846625268\n",
      "Iteration: 17984, Loss: 0.0886046290397644, Accuracy: 0.815763927763328\n",
      "Iteration: 18048, Loss: 0.08596739917993546, Accuracy: 0.8168658250942826\n",
      "Iteration: 18112, Loss: 0.08515843003988266, Accuracy: 0.817423265427351\n",
      "Iteration: 18176, Loss: 0.08121439069509506, Accuracy: 0.8205172279849648\n",
      "Iteration: 18240, Loss: 0.08033395558595657, Accuracy: 0.8222197240684181\n",
      "Iteration: 18304, Loss: 0.08250753581523895, Accuracy: 0.8150175493210554\n",
      "Iteration: 18368, Loss: 0.08647981286048889, Accuracy: 0.8116347577888519\n",
      "Iteration: 18432, Loss: 0.08501417189836502, Accuracy: 0.8193736486136913\n",
      "Iteration: 18496, Loss: 0.08129574358463287, Accuracy: 0.8178410045802593\n",
      "Iteration: 18560, Loss: 0.08458275347948074, Accuracy: 0.8194711680989712\n",
      "Iteration: 18624, Loss: 0.077924944460392, Accuracy: 0.8026461615227163\n",
      "Iteration: 18688, Loss: 0.08835828304290771, Accuracy: 0.821244299877435\n",
      "Iteration: 18752, Loss: 0.08880272507667542, Accuracy: 0.8156018003355712\n",
      "Iteration: 18816, Loss: 0.08841028064489365, Accuracy: 0.8140467265620828\n",
      "Iteration: 18880, Loss: 0.08198953419923782, Accuracy: 0.8218155354261398\n",
      "Iteration: 18944, Loss: 0.08381757885217667, Accuracy: 0.8210431037005037\n",
      "Iteration: 19008, Loss: 0.08502593636512756, Accuracy: 0.8133583953604102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 19072, Loss: 0.08845598250627518, Accuracy: 0.8206031899899244\n",
      "Iteration: 19136, Loss: 0.08408424258232117, Accuracy: 0.8194271931424737\n",
      "Iteration: 19200, Loss: 0.1792794018983841, Accuracy: 0.8014718352351338\n",
      "Iteration: 19264, Loss: 0.09376052767038345, Accuracy: 0.8005993652623147\n",
      "Iteration: 19328, Loss: 0.08126593381166458, Accuracy: 0.8221299834549427\n",
      "Iteration: 19392, Loss: 0.08259475976228714, Accuracy: 0.8160704837646335\n",
      "Iteration: 19456, Loss: 0.08573751896619797, Accuracy: 0.8169231121428311\n",
      "Iteration: 19520, Loss: 0.0826418399810791, Accuracy: 0.8118766425177455\n",
      "Iteration: 19584, Loss: 0.08708593994379044, Accuracy: 0.8199575557373464\n",
      "Iteration: 19648, Loss: 0.08495008945465088, Accuracy: 0.8164991962257773\n",
      "Iteration: 19712, Loss: 0.08371623605489731, Accuracy: 0.8218278102576733\n",
      "Iteration: 19776, Loss: 0.08230633288621902, Accuracy: 0.817402713233605\n",
      "Iteration: 19840, Loss: 0.08150767534971237, Accuracy: 0.8174634203314781\n",
      "Iteration: 19904, Loss: 0.08570486307144165, Accuracy: 0.8187516289763153\n",
      "Iteration: 19968, Loss: 0.08250982314348221, Accuracy: 0.822930752299726\n",
      "Iteration: 20032, Loss: 0.08469294756650925, Accuracy: 0.8238304238766432\n",
      "Iteration: 20096, Loss: 0.08493384718894958, Accuracy: 0.8163710713852197\n",
      "Iteration: 20160, Loss: 0.08779547363519669, Accuracy: 0.8233957155607641\n",
      "Iteration: 20224, Loss: 0.07908054441213608, Accuracy: 0.817346507217735\n",
      "Iteration: 20288, Loss: 0.08547968417406082, Accuracy: 0.8220528098754585\n",
      "Iteration: 20352, Loss: 0.08216547220945358, Accuracy: 0.8206517759244889\n",
      "Iteration: 20416, Loss: 0.08453354239463806, Accuracy: 0.8230775974225253\n",
      "Iteration: 20480, Loss: 0.23085105419158936, Accuracy: 0.8057061498984694\n",
      "Iteration: 20544, Loss: 0.08091696351766586, Accuracy: 0.8176778657361865\n",
      "Iteration: 20608, Loss: 0.08545031398534775, Accuracy: 0.8174644035752863\n",
      "Iteration: 20672, Loss: 0.08164236694574356, Accuracy: 0.8194384395610541\n",
      "Iteration: 20736, Loss: 0.0841820016503334, Accuracy: 0.8154542555566877\n",
      "Iteration: 20800, Loss: 0.08700446039438248, Accuracy: 0.8191941517870873\n",
      "Iteration: 20864, Loss: 0.08001712709665298, Accuracy: 0.8166971912141889\n",
      "Iteration: 20928, Loss: 0.08414843678474426, Accuracy: 0.8183019328862429\n",
      "Iteration: 20992, Loss: 0.08518480509519577, Accuracy: 0.8132147251162678\n",
      "Iteration: 21056, Loss: 0.08430930972099304, Accuracy: 0.8208192915190011\n",
      "Iteration: 21120, Loss: 0.08444272726774216, Accuracy: 0.8140049166977406\n",
      "Iteration: 21184, Loss: 0.08397871255874634, Accuracy: 0.8111998601816595\n",
      "Iteration: 21248, Loss: 0.08314553648233414, Accuracy: 0.8199656903743744\n",
      "Iteration: 21312, Loss: 0.08283629268407822, Accuracy: 0.8227781590539962\n",
      "Iteration: 21376, Loss: 0.08637857437133789, Accuracy: 0.8226181792560965\n",
      "Iteration: 21440, Loss: 0.0860498771071434, Accuracy: 0.8235791539773345\n",
      "Iteration: 21504, Loss: 0.08226712793111801, Accuracy: 0.815390074858442\n",
      "Iteration: 21568, Loss: 0.08235833048820496, Accuracy: 0.8229799056425691\n",
      "Iteration: 21632, Loss: 0.08270087838172913, Accuracy: 0.8240259415470064\n",
      "Iteration: 21696, Loss: 0.08410707861185074, Accuracy: 0.8240812900476158\n",
      "Iteration: 21760, Loss: 0.08095010370016098, Accuracy: 0.8231198485009372\n",
      "Iteration: 21824, Loss: 0.08410920947790146, Accuracy: 0.819208497647196\n",
      "Iteration: 21888, Loss: 0.08356889337301254, Accuracy: 0.8096464041154832\n",
      "Iteration: 21952, Loss: 0.08421656489372253, Accuracy: 0.8191937752999365\n",
      "Iteration: 22016, Loss: 0.08130286633968353, Accuracy: 0.8242920890916139\n",
      "Iteration: 22080, Loss: 0.08216918259859085, Accuracy: 0.8229589345864952\n",
      "Iteration: 22144, Loss: 0.08271010965108871, Accuracy: 0.8235167737584561\n",
      "Iteration: 22208, Loss: 0.08525872975587845, Accuracy: 0.8237637234851718\n",
      "Iteration: 22272, Loss: 0.08039853721857071, Accuracy: 0.8231336085591465\n",
      "Iteration: 22336, Loss: 0.08350298553705215, Accuracy: 0.8239536129403859\n",
      "Iteration: 22400, Loss: 0.08256887644529343, Accuracy: 0.8233823727350682\n",
      "Iteration: 22464, Loss: 0.08649137616157532, Accuracy: 0.8229800823610276\n",
      "Iteration: 22528, Loss: 0.08569363504648209, Accuracy: 0.8210521633736789\n",
      "Iteration: 22592, Loss: 0.0868319496512413, Accuracy: 0.8114617180544883\n",
      "Iteration: 22656, Loss: 0.08482091873884201, Accuracy: 0.8222423633560538\n",
      "Iteration: 22720, Loss: 0.07985569536685944, Accuracy: 0.8254198455251753\n",
      "Iteration: 22784, Loss: 0.08328299969434738, Accuracy: 0.8246335657313466\n",
      "Iteration: 22848, Loss: 0.08189062774181366, Accuracy: 0.82351458305493\n",
      "Iteration: 22912, Loss: 0.08599401265382767, Accuracy: 0.8231666241772473\n",
      "Iteration: 22976, Loss: 0.08349829912185669, Accuracy: 0.8257800824940205\n",
      "Iteration: 23040, Loss: 0.07910669595003128, Accuracy: 0.8191761334892362\n",
      "Iteration: 23104, Loss: 0.08519212156534195, Accuracy: 0.8243201558943838\n",
      "Iteration: 23168, Loss: 0.08987290412187576, Accuracy: 0.8146067745983601\n",
      "Iteration: 23232, Loss: 0.08424326032400131, Accuracy: 0.8085863096639514\n",
      "Iteration: 23296, Loss: 0.08507173508405685, Accuracy: 0.815816176822409\n",
      "Iteration: 23360, Loss: 0.0809406191110611, Accuracy: 0.8234758614562452\n",
      "Iteration: 23424, Loss: 0.08590119332075119, Accuracy: 0.8255948717705905\n",
      "Iteration: 23488, Loss: 0.0886974111199379, Accuracy: 0.8204877485986799\n",
      "Iteration: 23552, Loss: 0.08429963141679764, Accuracy: 0.8130237783771008\n",
      "Iteration: 23616, Loss: 0.0854136273264885, Accuracy: 0.8208280152175575\n",
      "Iteration: 23680, Loss: 0.0815080851316452, Accuracy: 0.8171204167883843\n",
      "Iteration: 23744, Loss: 0.08684618026018143, Accuracy: 0.825584291247651\n",
      "Iteration: 23808, Loss: 0.08616077154874802, Accuracy: 0.8223782018758357\n",
      "Iteration: 23872, Loss: 0.08283359557390213, Accuracy: 0.820745212957263\n",
      "Iteration: 23936, Loss: 0.08144856989383698, Accuracy: 0.8246906022541225\n",
      "Iteration: 24000, Loss: 0.08427810668945312, Accuracy: 0.8177605655509979\n",
      "Iteration: 24064, Loss: 0.08394846320152283, Accuracy: 0.8243260441813618\n",
      "Iteration: 24128, Loss: 0.08300808072090149, Accuracy: 0.8253862597048283\n",
      "Iteration: 24192, Loss: 0.08504590392112732, Accuracy: 0.8252019027713686\n",
      "Iteration: 24256, Loss: 0.08329077810049057, Accuracy: 0.8185923853889108\n",
      "Iteration: 24320, Loss: 0.08662480115890503, Accuracy: 0.8163238554261625\n",
      "Iteration: 24384, Loss: 0.08644560724496841, Accuracy: 0.8221378806047142\n",
      "Iteration: 24448, Loss: 0.07904387265443802, Accuracy: 0.8250248073600233\n",
      "Iteration: 24512, Loss: 0.08378449082374573, Accuracy: 0.8249779352918267\n",
      "Iteration: 24576, Loss: 0.08345503360033035, Accuracy: 0.8251668771263212\n",
      "Iteration: 24640, Loss: 0.09240474551916122, Accuracy: 0.8250602893531322\n",
      "Iteration: 24704, Loss: 0.08607181906700134, Accuracy: 0.8138427347876132\n",
      "Iteration: 24768, Loss: 0.08525922149419785, Accuracy: 0.8184051434509456\n",
      "Iteration: 24832, Loss: 0.08470968157052994, Accuracy: 0.8234010057058185\n",
      "Iteration: 24896, Loss: 0.13039733469486237, Accuracy: 0.818153778091073\n",
      "Iteration: 24960, Loss: 0.08045876771211624, Accuracy: 0.8182133769150823\n",
      "Iteration: 25024, Loss: 0.08232217282056808, Accuracy: 0.8197703077457845\n",
      "Iteration: 25088, Loss: 0.0910177007317543, Accuracy: 0.815626977942884\n",
      "Iteration: 25152, Loss: 0.08181176334619522, Accuracy: 0.8252754895947874\n",
      "Iteration: 25216, Loss: 0.0817289873957634, Accuracy: 0.819752759533003\n",
      "Iteration: 25280, Loss: 0.08554709702730179, Accuracy: 0.8238356462679803\n",
      "Iteration: 25344, Loss: 0.08485593646764755, Accuracy: 0.8177901012822986\n",
      "Iteration: 25408, Loss: 0.08328995853662491, Accuracy: 0.8240571299102157\n",
      "Iteration: 25472, Loss: 0.08481212705373764, Accuracy: 0.8222336985636503\n",
      "Iteration: 25536, Loss: 0.08492586016654968, Accuracy: 0.8226958024315536\n",
      "Iteration: 25600, Loss: 0.08579527586698532, Accuracy: 0.8242594788316637\n",
      "Iteration: 25664, Loss: 0.0914662554860115, Accuracy: 0.8222412099130452\n",
      "Iteration: 25728, Loss: 0.08691390603780746, Accuracy: 0.8268073748331517\n",
      "Iteration: 25792, Loss: 0.08301211148500443, Accuracy: 0.8229755570646375\n",
      "Iteration: 25856, Loss: 0.08774472028017044, Accuracy: 0.821734024444595\n",
      "Iteration: 25920, Loss: 0.08527722954750061, Accuracy: 0.8247500522993505\n",
      "Iteration: 25984, Loss: 0.09001169353723526, Accuracy: 0.8265081937424839\n",
      "Iteration: 26048, Loss: 0.08198216557502747, Accuracy: 0.8252759531605989\n",
      "Iteration: 26112, Loss: 0.07938192039728165, Accuracy: 0.8187320174183697\n",
      "Iteration: 26176, Loss: 0.08241043239831924, Accuracy: 0.8268137734849006\n",
      "Iteration: 26240, Loss: 0.11927791684865952, Accuracy: 0.8256210274994373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 26304, Loss: 0.08853622525930405, Accuracy: 0.8269163281656802\n",
      "Iteration: 26368, Loss: 0.08134337514638901, Accuracy: 0.82121048332192\n",
      "Iteration: 26432, Loss: 0.0838809385895729, Accuracy: 0.8207949032075703\n",
      "Iteration: 26496, Loss: 0.08232387900352478, Accuracy: 0.807578083826229\n",
      "Iteration: 26560, Loss: 0.0778057798743248, Accuracy: 0.8122064098715782\n",
      "Iteration: 26624, Loss: 0.08547087758779526, Accuracy: 0.8242247798480093\n",
      "Iteration: 26688, Loss: 0.09055125713348389, Accuracy: 0.8223577418830246\n",
      "Iteration: 26752, Loss: 0.08596932142972946, Accuracy: 0.818662301870063\n",
      "Iteration: 26816, Loss: 0.08047723025083542, Accuracy: 0.8192482539452612\n",
      "Iteration: 26880, Loss: 0.08459696173667908, Accuracy: 0.8188676440622658\n",
      "Iteration: 26944, Loss: 0.09043607115745544, Accuracy: 0.8175015840679407\n",
      "Iteration: 27008, Loss: 0.08616369962692261, Accuracy: 0.8265413243789226\n",
      "Iteration: 27072, Loss: 0.08212541788816452, Accuracy: 0.8206961138639599\n",
      "Iteration: 27136, Loss: 0.08065373450517654, Accuracy: 0.8221012300346047\n",
      "Iteration: 27200, Loss: 0.07761949300765991, Accuracy: 0.8270524977706373\n",
      "Iteration: 27264, Loss: 0.08745195716619492, Accuracy: 0.8259278228506446\n",
      "Iteration: 27328, Loss: 0.08927176147699356, Accuracy: 0.825549385510385\n",
      "Iteration: 27392, Loss: 0.09350871294736862, Accuracy: 0.8261069566942751\n",
      "Iteration: 27456, Loss: 0.08987269550561905, Accuracy: 0.8097852666396648\n",
      "Iteration: 27520, Loss: 0.07768716663122177, Accuracy: 0.8259141605813056\n",
      "Iteration: 27584, Loss: 0.08183567970991135, Accuracy: 0.8267187639139593\n",
      "Iteration: 27648, Loss: 0.07740114629268646, Accuracy: 0.8206285673659295\n",
      "Iteration: 27712, Loss: 0.07903692871332169, Accuracy: 0.8255620992276818\n",
      "Iteration: 27776, Loss: 0.08294203132390976, Accuracy: 0.8266824895981699\n",
      "Iteration: 27840, Loss: 0.41552069783210754, Accuracy: 0.8216768142301589\n",
      "Iteration: 27904, Loss: 0.08157086372375488, Accuracy: 0.8244706701952964\n",
      "Iteration: 27968, Loss: 0.08515305072069168, Accuracy: 0.8193760255817324\n",
      "Iteration: 28032, Loss: 0.08402159065008163, Accuracy: 0.8254619098734111\n",
      "Iteration: 28096, Loss: 0.09096842259168625, Accuracy: 0.8119166281539947\n",
      "Iteration: 28160, Loss: 0.0879896804690361, Accuracy: 0.8186682597734034\n",
      "Iteration: 28224, Loss: 0.33600685000419617, Accuracy: 0.8185458783991635\n",
      "Iteration: 28288, Loss: 0.08428577333688736, Accuracy: 0.819977943552658\n",
      "Iteration: 28352, Loss: 0.07915546000003815, Accuracy: 0.8264405422378331\n",
      "Iteration: 28416, Loss: 0.08124461770057678, Accuracy: 0.8268788200803101\n",
      "Iteration: 28480, Loss: 0.08348122984170914, Accuracy: 0.8273623781278729\n",
      "Iteration: 28544, Loss: 0.08309890329837799, Accuracy: 0.8262724282685667\n",
      "Iteration: 28608, Loss: 0.08260675519704819, Accuracy: 0.8276423187926412\n",
      "Iteration: 28672, Loss: 0.08194810152053833, Accuracy: 0.8256783853285015\n",
      "Iteration: 28736, Loss: 0.08256684988737106, Accuracy: 0.8265423686243594\n",
      "Iteration: 28800, Loss: 0.08237052708864212, Accuracy: 0.8269678468350321\n",
      "Iteration: 28864, Loss: 0.08588895201683044, Accuracy: 0.8228072829078883\n",
      "Iteration: 28928, Loss: 0.08278585225343704, Accuracy: 0.8268837539944798\n",
      "Iteration: 28992, Loss: 0.08628728240728378, Accuracy: 0.8265429334715009\n",
      "Iteration: 29056, Loss: 0.08339384198188782, Accuracy: 0.8270410788245499\n",
      "Iteration: 29120, Loss: 0.08407410979270935, Accuracy: 0.8278154458384961\n",
      "Iteration: 29184, Loss: 0.08945850282907486, Accuracy: 0.8268051480408758\n",
      "Iteration: 29248, Loss: 0.08048807829618454, Accuracy: 0.8265198757871985\n",
      "Iteration: 29312, Loss: 0.0859701856970787, Accuracy: 0.8272988148964942\n",
      "Iteration: 29376, Loss: 0.08121603727340698, Accuracy: 0.8274995344690979\n",
      "Iteration: 29440, Loss: 0.07919862121343613, Accuracy: 0.8267738714348525\n",
      "Iteration: 29504, Loss: 0.08225942403078079, Accuracy: 0.8281941611785442\n",
      "Iteration: 29568, Loss: 0.08202063292264938, Accuracy: 0.8275928657967597\n",
      "Iteration: 29632, Loss: 0.07714945077896118, Accuracy: 0.8263191869482398\n",
      "Iteration: 29696, Loss: 0.08370751887559891, Accuracy: 0.8162747155874968\n",
      "Iteration: 29760, Loss: 0.08149979263544083, Accuracy: 0.8177357171662152\n",
      "Iteration: 29824, Loss: 0.08702703565359116, Accuracy: 0.826575884828344\n",
      "Iteration: 29888, Loss: 0.08737596124410629, Accuracy: 0.8268857337534428\n",
      "Iteration: 29952, Loss: 0.08756575733423233, Accuracy: 0.8253066539764404\n",
      "Iteration: 30016, Loss: 0.08784747123718262, Accuracy: 0.8276155947241932\n",
      "Iteration: 30080, Loss: 0.08741789311170578, Accuracy: 0.8208931405097246\n",
      "Iteration: 30144, Loss: 0.07984500378370285, Accuracy: 0.826888483716175\n",
      "Iteration: 30208, Loss: 0.08209794759750366, Accuracy: 0.8247202110942453\n",
      "Iteration: 30272, Loss: 0.08676903694868088, Accuracy: 0.8261156864464283\n",
      "Iteration: 30336, Loss: 0.08718377351760864, Accuracy: 0.8182531192433089\n",
      "Iteration: 30400, Loss: 0.08245094865560532, Accuracy: 0.8084760622587055\n",
      "Iteration: 30464, Loss: 0.08080243319272995, Accuracy: 0.8286119634285569\n",
      "Iteration: 30528, Loss: 0.08779272437095642, Accuracy: 0.8212010553106666\n",
      "Iteration: 30592, Loss: 0.08457362651824951, Accuracy: 0.8273504991084337\n",
      "Iteration: 30656, Loss: 0.08603012561798096, Accuracy: 0.827134737977758\n",
      "Iteration: 30720, Loss: 0.08444524556398392, Accuracy: 0.8260996961034834\n",
      "Iteration: 30784, Loss: 0.08369076997041702, Accuracy: 0.8274697277229279\n",
      "Iteration: 30848, Loss: 0.0820709764957428, Accuracy: 0.8279750109650195\n",
      "Iteration: 30912, Loss: 0.08593734353780746, Accuracy: 0.8217183453962207\n",
      "Iteration: 30976, Loss: 0.0853780210018158, Accuracy: 0.8267345288768411\n",
      "Iteration: 31040, Loss: 0.08763575553894043, Accuracy: 0.8262752089649439\n",
      "Iteration: 31104, Loss: 0.16455478966236115, Accuracy: 0.81970493379049\n",
      "Iteration: 31168, Loss: 0.0966571494936943, Accuracy: 0.8214703837875277\n",
      "Iteration: 31232, Loss: 0.08386200666427612, Accuracy: 0.8278668986167759\n",
      "Iteration: 31296, Loss: 0.0916980728507042, Accuracy: 0.8272632418666035\n",
      "Iteration: 31360, Loss: 0.08361771702766418, Accuracy: 0.8281817331444472\n",
      "Iteration: 31424, Loss: 0.083370141685009, Accuracy: 0.8238680094946176\n",
      "Iteration: 31488, Loss: 0.08422479033470154, Accuracy: 0.8276320025324821\n",
      "Iteration: 31552, Loss: 0.08529433608055115, Accuracy: 0.8180084733758122\n",
      "Iteration: 31616, Loss: 0.07451024651527405, Accuracy: 0.8206268188077956\n",
      "Iteration: 31680, Loss: 0.08506137132644653, Accuracy: 0.8266898454166949\n",
      "Iteration: 31744, Loss: 0.0734623447060585, Accuracy: 0.8202785516623408\n",
      "Iteration: 31808, Loss: 0.08797692507505417, Accuracy: 0.8234793397132307\n",
      "Iteration: 31872, Loss: 0.08305586874485016, Accuracy: 0.8268052709754556\n",
      "Iteration: 31936, Loss: 0.08330275863409042, Accuracy: 0.8240504879504442\n",
      "Iteration: 32000, Loss: 0.07527878135442734, Accuracy: 0.8266797384712845\n",
      "Iteration: 32064, Loss: 0.08075300604104996, Accuracy: 0.8271105312742293\n",
      "Iteration: 32128, Loss: 0.08805817365646362, Accuracy: 0.8271245171781629\n",
      "Iteration: 32192, Loss: 0.08454042673110962, Accuracy: 0.8274345954414457\n",
      "Iteration: 32256, Loss: 0.08145912736654282, Accuracy: 0.8273420610930771\n",
      "Iteration: 32320, Loss: 0.0815402939915657, Accuracy: 0.8261649932246655\n",
      "Iteration: 32384, Loss: 0.08208274096250534, Accuracy: 0.8291068240068853\n",
      "Iteration: 32448, Loss: 0.08226717263460159, Accuracy: 0.8285088092088699\n",
      "Iteration: 32512, Loss: 0.08420625329017639, Accuracy: 0.8295731234829873\n",
      "Iteration: 32576, Loss: 0.07628657668828964, Accuracy: 0.8192017411347479\n",
      "Iteration: 32640, Loss: 0.07748113572597504, Accuracy: 0.8226228833664209\n",
      "Iteration: 32704, Loss: 0.08141474425792694, Accuracy: 0.8208022431936115\n",
      "Iteration: 32768, Loss: 0.07880102097988129, Accuracy: 0.8258256339468062\n",
      "Iteration: 32832, Loss: 0.08419353514909744, Accuracy: 0.8185393109451979\n",
      "Iteration: 32896, Loss: 0.0910545215010643, Accuracy: 0.8226123857311904\n",
      "Iteration: 32960, Loss: 0.08494075387716293, Accuracy: 0.8251647292636335\n",
      "Iteration: 33024, Loss: 0.08998831361532211, Accuracy: 0.8269659986253828\n",
      "Iteration: 33088, Loss: 0.08437982201576233, Accuracy: 0.8251611408777535\n",
      "Iteration: 33152, Loss: 0.07833245396614075, Accuracy: 0.8206781381741166\n",
      "Iteration: 33216, Loss: 0.08236812800168991, Accuracy: 0.8269507775548846\n",
      "Iteration: 33280, Loss: 0.08333593606948853, Accuracy: 0.8229248062707484\n",
      "Iteration: 33344, Loss: 0.09347600489854813, Accuracy: 0.8265701739583164\n",
      "Iteration: 33408, Loss: 0.07892172783613205, Accuracy: 0.8280227608047426\n",
      "Iteration: 33472, Loss: 0.08917131274938583, Accuracy: 0.8278504945337772\n",
      "Iteration: 33536, Loss: 0.08275290578603745, Accuracy: 0.8226453065872192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 33600, Loss: 0.08952918648719788, Accuracy: 0.8273570979945362\n",
      "Iteration: 33664, Loss: 0.08089619874954224, Accuracy: 0.8257695187348872\n",
      "Iteration: 33728, Loss: 0.08210420608520508, Accuracy: 0.815181114943698\n",
      "Iteration: 33792, Loss: 0.08772342652082443, Accuracy: 0.8266136860474944\n",
      "Iteration: 33856, Loss: 0.07852765172719955, Accuracy: 0.8275626364629716\n",
      "Iteration: 33920, Loss: 0.07560039311647415, Accuracy: 0.8286395859904587\n",
      "Iteration: 33984, Loss: 0.08036323636770248, Accuracy: 0.8227809143718332\n",
      "Iteration: 34048, Loss: 0.06480909883975983, Accuracy: 0.8154469358269125\n",
      "Iteration: 34112, Loss: 0.08767864853143692, Accuracy: 0.8289734534919262\n",
      "Iteration: 34176, Loss: 0.08056105673313141, Accuracy: 0.8277528854086995\n",
      "Iteration: 34240, Loss: 0.0885743498802185, Accuracy: 0.8293614913709462\n",
      "Iteration: 34304, Loss: 0.08733213692903519, Accuracy: 0.8287788550369442\n",
      "Iteration: 34368, Loss: 0.06837931275367737, Accuracy: 0.8303705223370343\n",
      "Iteration: 34432, Loss: 0.06799355894327164, Accuracy: 0.8240508616436273\n",
      "Iteration: 34496, Loss: 0.09976205229759216, Accuracy: 0.8196587178390473\n",
      "Iteration: 34560, Loss: 0.06569021940231323, Accuracy: 0.8196539108175784\n",
      "Iteration: 34624, Loss: 0.07491852343082428, Accuracy: 0.8286124023143202\n",
      "Iteration: 34688, Loss: 0.07052070647478104, Accuracy: 0.8319539157673717\n",
      "Iteration: 34752, Loss: 0.06624867767095566, Accuracy: 0.8261173295322806\n",
      "Iteration: 34816, Loss: 0.09168503433465958, Accuracy: 0.8287173917051405\n",
      "Iteration: 34880, Loss: 0.06188644841313362, Accuracy: 0.8229818639811128\n",
      "Iteration: 34944, Loss: 0.0746191218495369, Accuracy: 0.830587673233822\n",
      "Iteration: 35008, Loss: 0.09089240431785583, Accuracy: 0.8294879531022161\n",
      "Iteration: 35072, Loss: 0.08791620284318924, Accuracy: 0.8313344223424792\n",
      "Iteration: 35136, Loss: 0.0506126768887043, Accuracy: 0.8303893606644124\n",
      "Iteration: 35200, Loss: 0.06459945440292358, Accuracy: 0.8209976067300886\n",
      "Iteration: 35264, Loss: 0.08959128707647324, Accuracy: 0.8295115574728698\n",
      "Iteration: 35328, Loss: 0.08970669656991959, Accuracy: 0.8217703367117792\n",
      "Iteration: 35392, Loss: 0.04949351027607918, Accuracy: 0.823426625225693\n",
      "Iteration: 35456, Loss: 0.058752626180648804, Accuracy: 0.8332000533118844\n",
      "Iteration: 35520, Loss: 0.06901805847883224, Accuracy: 0.8225132168736309\n",
      "Iteration: 35584, Loss: 0.04818451777100563, Accuracy: 0.8327354434877634\n",
      "Iteration: 35648, Loss: 0.05610150098800659, Accuracy: 0.8349500193726271\n",
      "Iteration: 35712, Loss: 0.07140486687421799, Accuracy: 0.8290878327097744\n",
      "Iteration: 35776, Loss: 0.09703067690134048, Accuracy: 0.8317777325864881\n",
      "Iteration: 35840, Loss: 0.0964825451374054, Accuracy: 0.8280248842202127\n",
      "Iteration: 35904, Loss: 0.0834578350186348, Accuracy: 0.8320182531606406\n",
      "Iteration: 35968, Loss: 0.044402990490198135, Accuracy: 0.8333901969017461\n",
      "Iteration: 36032, Loss: 0.09721239656209946, Accuracy: 0.8341197934933007\n",
      "Iteration: 36096, Loss: 0.08618801832199097, Accuracy: 0.8306661176029593\n",
      "Iteration: 36160, Loss: 0.03623050078749657, Accuracy: 0.8311045502778143\n",
      "Iteration: 36224, Loss: 0.11451784521341324, Accuracy: 0.8354609169764444\n",
      "Iteration: 36288, Loss: 0.1418146938085556, Accuracy: 0.8376404143637046\n",
      "Iteration: 36352, Loss: 0.05059629678726196, Accuracy: 0.8385458623524755\n",
      "Iteration: 36416, Loss: 0.08205939084291458, Accuracy: 0.8389951853314415\n",
      "Iteration: 36480, Loss: 0.092450350522995, Accuracy: 0.842329213861376\n",
      "Iteration: 36544, Loss: 0.12959234416484833, Accuracy: 0.8344257891876623\n",
      "Iteration: 36608, Loss: 0.045870084315538406, Accuracy: 0.8337760134600103\n",
      "Iteration: 36672, Loss: 0.05530823394656181, Accuracy: 0.8354075275128707\n",
      "Iteration: 36736, Loss: 0.06752227991819382, Accuracy: 0.8338607364566997\n",
      "Iteration: 36800, Loss: 0.07734280079603195, Accuracy: 0.8404063392663375\n",
      "Iteration: 36864, Loss: 0.09574321657419205, Accuracy: 0.8432047532405704\n",
      "Iteration: 36928, Loss: 0.05505921319127083, Accuracy: 0.8420960389776155\n",
      "Iteration: 36992, Loss: 0.047457460314035416, Accuracy: 0.8389439533930272\n",
      "Iteration: 37056, Loss: 0.09858455508947372, Accuracy: 0.8308243652572855\n",
      "Iteration: 37120, Loss: 0.04984542727470398, Accuracy: 0.8404717821395025\n",
      "Iteration: 37184, Loss: 0.06883200258016586, Accuracy: 0.8384681746829301\n",
      "Iteration: 37248, Loss: 0.04401494562625885, Accuracy: 0.8473072767956182\n",
      "Iteration: 37312, Loss: 0.027849435806274414, Accuracy: 0.8444484813371673\n",
      "Iteration: 37376, Loss: 0.062332019209861755, Accuracy: 0.8447037709411234\n",
      "Iteration: 37440, Loss: 0.027242323383688927, Accuracy: 0.8450644165277481\n",
      "Iteration: 37504, Loss: 0.03651122376322746, Accuracy: 0.8446803922997788\n",
      "Iteration: 37568, Loss: 0.06262428313493729, Accuracy: 0.8408941446105018\n",
      "Iteration: 37632, Loss: 0.036414504051208496, Accuracy: 0.8442710393574089\n",
      "Iteration: 37696, Loss: 0.10639149695634842, Accuracy: 0.8439864268293604\n",
      "Iteration: 37760, Loss: 0.082452192902565, Accuracy: 0.8443069483619183\n",
      "Iteration: 37824, Loss: 0.09270017594099045, Accuracy: 0.8505713260965422\n",
      "Iteration: 37888, Loss: 0.07642772793769836, Accuracy: 0.844741327688098\n",
      "Iteration: 37952, Loss: 0.1042008176445961, Accuracy: 0.8495473534567282\n",
      "Iteration: 38016, Loss: 0.03792039677500725, Accuracy: 0.850639266660437\n",
      "Iteration: 38080, Loss: 0.022318201139569283, Accuracy: 0.8533105002716184\n",
      "Iteration: 38144, Loss: 0.03492442145943642, Accuracy: 0.8549109944142401\n",
      "Iteration: 38208, Loss: 0.10356263071298599, Accuracy: 0.8562977815745398\n",
      "Iteration: 38272, Loss: 0.020928213372826576, Accuracy: 0.8523622003849596\n",
      "Iteration: 38336, Loss: 0.10188104957342148, Accuracy: 0.8434373807394877\n",
      "Iteration: 38400, Loss: 0.026596246287226677, Accuracy: 0.8544354982441291\n",
      "Iteration: 38464, Loss: 0.0756722241640091, Accuracy: 0.8493109503760934\n",
      "Iteration: 38528, Loss: 0.030563222244381905, Accuracy: 0.8480086299823597\n",
      "Iteration: 38592, Loss: 0.09932457655668259, Accuracy: 0.8497369325486943\n",
      "Iteration: 38656, Loss: 0.019644206389784813, Accuracy: 0.8580743734491989\n",
      "Iteration: 38720, Loss: 0.10714737325906754, Accuracy: 0.8551310962066054\n",
      "Iteration: 38784, Loss: 0.08639533072710037, Accuracy: 0.8549151647603139\n",
      "Iteration: 38848, Loss: 0.08683376759290695, Accuracy: 0.8542762424331158\n",
      "Iteration: 38912, Loss: 0.015697961673140526, Accuracy: 0.8612417759140953\n",
      "Iteration: 38976, Loss: 0.014471575617790222, Accuracy: 0.8524819675367326\n",
      "Iteration: 39040, Loss: 0.05789704620838165, Accuracy: 0.8645115472609177\n",
      "Iteration: 39104, Loss: 0.024314716458320618, Accuracy: 0.8653478292981163\n",
      "Iteration: 39168, Loss: 0.08262697607278824, Accuracy: 0.8587743741227314\n",
      "Iteration: 39232, Loss: 0.013952814973890781, Accuracy: 0.8581174280261621\n",
      "Iteration: 39296, Loss: 0.06757450848817825, Accuracy: 0.8629704613704234\n",
      "Iteration: 39360, Loss: 0.015279966406524181, Accuracy: 0.8609000134747475\n",
      "Iteration: 39424, Loss: 0.08442186564207077, Accuracy: 0.8582037196028978\n",
      "Iteration: 39488, Loss: 0.03289937600493431, Accuracy: 0.8522745654918253\n",
      "Iteration: 39552, Loss: 0.08408350497484207, Accuracy: 0.8659316702978685\n",
      "Iteration: 39616, Loss: 0.06343766301870346, Accuracy: 0.8629140137927607\n",
      "Iteration: 39680, Loss: 0.014763726852834225, Accuracy: 0.8607842532219365\n",
      "Iteration: 39744, Loss: 0.10787353664636612, Accuracy: 0.8616879993351176\n",
      "Iteration: 39808, Loss: 0.07181371003389359, Accuracy: 0.8645346876583062\n",
      "Iteration: 39872, Loss: 0.013423108495771885, Accuracy: 0.8666338198818266\n",
      "Iteration: 39936, Loss: 0.09234396368265152, Accuracy: 0.8664905907353386\n",
      "Iteration: 40000, Loss: 0.0654379203915596, Accuracy: 0.8666924746939912\n",
      "Iteration: 40064, Loss: 0.0670236349105835, Accuracy: 0.8677601097151637\n",
      "Iteration: 40128, Loss: 0.10694580525159836, Accuracy: 0.8510497852694243\n",
      "Iteration: 40192, Loss: 0.015325426124036312, Accuracy: 0.8683257502270862\n",
      "Iteration: 40256, Loss: 0.01609293557703495, Accuracy: 0.8654974613455124\n",
      "Iteration: 40320, Loss: 0.06192786991596222, Accuracy: 0.8621901905280538\n",
      "Iteration: 40384, Loss: 0.07955559343099594, Accuracy: 0.8692027251236141\n",
      "Iteration: 40448, Loss: 0.10402049869298935, Accuracy: 0.8409716409514658\n",
      "Iteration: 40512, Loss: 0.08235258609056473, Accuracy: 0.854670217668172\n",
      "Iteration: 40576, Loss: 0.012194293551146984, Accuracy: 0.8677033657440916\n",
      "Iteration: 40640, Loss: 0.014054573141038418, Accuracy: 0.8682673339499161\n",
      "Iteration: 40704, Loss: 0.08286081999540329, Accuracy: 0.8605339797213674\n",
      "Iteration: 40768, Loss: 0.10366714745759964, Accuracy: 0.8704869620269164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 40832, Loss: 0.05985246226191521, Accuracy: 0.8705148768494837\n",
      "Iteration: 40896, Loss: 0.012184664607048035, Accuracy: 0.8710919793811627\n",
      "Iteration: 40960, Loss: 0.06796134263277054, Accuracy: 0.8685729035641998\n",
      "Iteration: 41024, Loss: 0.0071437605656683445, Accuracy: 0.8677032116102055\n",
      "Iteration: 41088, Loss: 0.02043859101831913, Accuracy: 0.8687857177574188\n",
      "Iteration: 41152, Loss: 0.011770106852054596, Accuracy: 0.867393487598747\n",
      "Iteration: 41216, Loss: 0.06973502039909363, Accuracy: 0.8678324583452195\n",
      "Iteration: 41280, Loss: 0.09456264227628708, Accuracy: 0.8645281493663788\n",
      "Iteration: 41344, Loss: 0.10663009434938431, Accuracy: 0.8701701528043486\n",
      "Iteration: 41408, Loss: 0.09179703146219254, Accuracy: 0.8654973157681525\n",
      "Iteration: 41472, Loss: 0.09955618530511856, Accuracy: 0.8730729459202848\n",
      "Iteration: 41536, Loss: 0.009904329665005207, Accuracy: 0.8765503010945395\n",
      "Iteration: 41600, Loss: 0.015492639504373074, Accuracy: 0.8743512444198132\n",
      "Iteration: 41664, Loss: 0.08979093283414841, Accuracy: 0.8795129830250517\n",
      "Iteration: 41728, Loss: 0.050153959542512894, Accuracy: 0.8541095027467236\n",
      "Iteration: 41792, Loss: 0.12306005507707596, Accuracy: 0.8760134128388017\n",
      "Iteration: 41856, Loss: 0.07087505608797073, Accuracy: 0.8657845293637365\n",
      "Iteration: 41920, Loss: 0.22854198515415192, Accuracy: 0.8704764267895371\n",
      "Iteration: 41984, Loss: 0.027371378615498543, Accuracy: 0.8720960052451119\n",
      "Iteration: 42048, Loss: 0.0764031633734703, Accuracy: 0.8803365983767435\n",
      "Iteration: 42112, Loss: 0.07492787390947342, Accuracy: 0.8735027880757116\n",
      "Iteration: 42176, Loss: 0.011037242598831654, Accuracy: 0.8680885602370836\n",
      "Iteration: 42240, Loss: 0.007581923622637987, Accuracy: 0.8754970941226929\n",
      "Iteration: 42304, Loss: 0.06324814260005951, Accuracy: 0.8754330326919444\n",
      "Iteration: 42368, Loss: 0.07934016734361649, Accuracy: 0.8729965866077691\n",
      "Iteration: 42432, Loss: 0.010708258487284184, Accuracy: 0.8630683686351404\n",
      "Iteration: 42496, Loss: 0.09025582671165466, Accuracy: 0.8804020082461648\n",
      "Iteration: 42560, Loss: 0.007981053553521633, Accuracy: 0.880526342894882\n",
      "Iteration: 42624, Loss: 0.008132116869091988, Accuracy: 0.8846416366286576\n",
      "Iteration: 42688, Loss: 0.07442130893468857, Accuracy: 0.8806954824831337\n",
      "Iteration: 42752, Loss: 0.0742964893579483, Accuracy: 0.8768086083000526\n",
      "Iteration: 42816, Loss: 0.009752548299729824, Accuracy: 0.8833945786464028\n",
      "Iteration: 42880, Loss: 0.046417172998189926, Accuracy: 0.8795030272449367\n",
      "Iteration: 42944, Loss: 0.0659916028380394, Accuracy: 0.8707388445618562\n",
      "Iteration: 43008, Loss: 0.011358335614204407, Accuracy: 0.8875087789492682\n",
      "Iteration: 43072, Loss: 0.055188003927469254, Accuracy: 0.8829948984202929\n",
      "Iteration: 43136, Loss: 0.07871809601783752, Accuracy: 0.8793386294855736\n",
      "Iteration: 43200, Loss: 0.04761870205402374, Accuracy: 0.8865508829476312\n",
      "Iteration: 43264, Loss: 0.0960206389427185, Accuracy: 0.8885179118951783\n",
      "Iteration: 43328, Loss: 0.07709623128175735, Accuracy: 0.8865632993984036\n",
      "Iteration: 43392, Loss: 0.005798425991088152, Accuracy: 0.8807283843052574\n",
      "Iteration: 43456, Loss: 0.05291059613227844, Accuracy: 0.8858512793667614\n",
      "Iteration: 43520, Loss: 0.08465155214071274, Accuracy: 0.8839638634235598\n",
      "Iteration: 43584, Loss: 0.03402870520949364, Accuracy: 0.8871587364701554\n",
      "Iteration: 43648, Loss: 0.052230045199394226, Accuracy: 0.8915973158436827\n",
      "Iteration: 43712, Loss: 0.055394262075424194, Accuracy: 0.8911947687156498\n",
      "Iteration: 43776, Loss: 0.08022802323102951, Accuracy: 0.8938182821148075\n",
      "Iteration: 43840, Loss: 0.03996957093477249, Accuracy: 0.8930569872027263\n",
      "Iteration: 43904, Loss: 0.005899192299693823, Accuracy: 0.8877166638267227\n",
      "Iteration: 43968, Loss: 0.044639527797698975, Accuracy: 0.8882168083800934\n",
      "Iteration: 44032, Loss: 0.05967235937714577, Accuracy: 0.8960000115330331\n",
      "Iteration: 44096, Loss: 0.030956590548157692, Accuracy: 0.88012249476742\n",
      "Iteration: 44160, Loss: 0.00500968424603343, Accuracy: 0.8979803010588512\n",
      "Iteration: 44224, Loss: 0.004731819964945316, Accuracy: 0.8974722850834951\n",
      "Iteration: 44288, Loss: 0.03334176540374756, Accuracy: 0.8868774068250787\n",
      "Iteration: 44352, Loss: 0.06896153837442398, Accuracy: 0.8917353405850008\n",
      "Iteration: 44416, Loss: 0.005391155835241079, Accuracy: 0.8944557690410875\n",
      "Iteration: 44480, Loss: 0.006168457213789225, Accuracy: 0.9009915691567585\n",
      "Iteration: 44544, Loss: 0.03629949688911438, Accuracy: 0.8986904731427785\n",
      "Iteration: 44608, Loss: 0.007334117311984301, Accuracy: 0.9031829051382374\n",
      "Iteration: 44672, Loss: 0.0590222030878067, Accuracy: 0.9033586816221941\n",
      "Iteration: 44736, Loss: 0.04020334407687187, Accuracy: 0.9012540691182949\n",
      "Iteration: 44800, Loss: 0.021434428170323372, Accuracy: 0.8988147243799176\n",
      "Iteration: 44864, Loss: 0.0033242760691791773, Accuracy: 0.9047133984277025\n",
      "Iteration: 44928, Loss: 0.0044622402638196945, Accuracy: 0.9067945096467156\n",
      "Iteration: 44992, Loss: 0.007099719252437353, Accuracy: 0.9029759814729914\n",
      "Iteration: 45056, Loss: 0.004008053336292505, Accuracy: 0.9041526403161697\n",
      "Iteration: 45120, Loss: 0.004154392518103123, Accuracy: 0.9028137956629507\n",
      "Iteration: 45184, Loss: 0.0029832019936293364, Accuracy: 0.8957993840740528\n",
      "Iteration: 45248, Loss: 0.003525850595906377, Accuracy: 0.9138829386502039\n",
      "Iteration: 45312, Loss: 0.05078892037272453, Accuracy: 0.9100400501047261\n",
      "Iteration: 45376, Loss: 0.003908603452146053, Accuracy: 0.9132288252003491\n",
      "Iteration: 45440, Loss: 0.014729262329638004, Accuracy: 0.9106724138255231\n",
      "Iteration: 45504, Loss: 0.0031860368326306343, Accuracy: 0.9144142222066876\n",
      "Iteration: 45568, Loss: 0.023216672241687775, Accuracy: 0.9118269089085516\n",
      "Iteration: 45632, Loss: 0.004404129926115274, Accuracy: 0.9104581587598659\n",
      "Iteration: 45696, Loss: 0.00324244168587029, Accuracy: 0.9097600337991025\n",
      "Iteration: 45760, Loss: 0.0026450033765286207, Accuracy: 0.9123453801148571\n",
      "Iteration: 45824, Loss: 0.003759883577004075, Accuracy: 0.9178344978427049\n",
      "Iteration: 45888, Loss: 0.06211923435330391, Accuracy: 0.923577910696622\n",
      "Iteration: 45952, Loss: 0.003683466464281082, Accuracy: 0.9096276168711483\n",
      "Iteration: 46016, Loss: 0.0014852993190288544, Accuracy: 0.9202838494966272\n",
      "Iteration: 46080, Loss: 0.003356441855430603, Accuracy: 0.921838206006214\n",
      "Iteration: 46144, Loss: 0.0038742965552955866, Accuracy: 0.9224677140300628\n",
      "Iteration: 46208, Loss: 0.0021421583369374275, Accuracy: 0.9175909666810185\n",
      "Iteration: 46272, Loss: 0.01471117977052927, Accuracy: 0.9218985177576542\n",
      "Iteration: 46336, Loss: 0.0027178358286619186, Accuracy: 0.9178917867830023\n",
      "Iteration: 46400, Loss: 0.025125227868556976, Accuracy: 0.9232722478918731\n",
      "Iteration: 46464, Loss: 0.004552644677460194, Accuracy: 0.9116863299859688\n",
      "Iteration: 46528, Loss: 0.0024182782508432865, Accuracy: 0.9173373712401371\n",
      "Iteration: 46592, Loss: 0.013644794933497906, Accuracy: 0.9296357999555767\n",
      "Iteration: 46656, Loss: 0.010034694336354733, Accuracy: 0.9207542139338329\n",
      "Iteration: 46720, Loss: 0.03826814144849777, Accuracy: 0.9189204102440272\n",
      "Iteration: 46784, Loss: 0.006824346259236336, Accuracy: 0.9305493571737316\n",
      "Iteration: 46848, Loss: 0.01117072906345129, Accuracy: 0.9323745347792283\n",
      "Iteration: 46912, Loss: 0.008872984908521175, Accuracy: 0.9278369661478791\n",
      "Iteration: 46976, Loss: 0.03572680056095123, Accuracy: 0.921633504825877\n",
      "Iteration: 47040, Loss: 0.0016477616736665368, Accuracy: 0.9345921762287617\n",
      "Iteration: 47104, Loss: 0.0020686215721070766, Accuracy: 0.933595224225428\n",
      "Iteration: 47168, Loss: 0.015661902725696564, Accuracy: 0.9348097477923147\n",
      "Iteration: 47232, Loss: 0.002300228225067258, Accuracy: 0.9347525311459322\n",
      "Iteration: 47296, Loss: 0.007456991821527481, Accuracy: 0.93285883939825\n",
      "Iteration: 47360, Loss: 0.002258204622194171, Accuracy: 0.9325597939605359\n",
      "Iteration: 47424, Loss: 0.0012605615193024278, Accuracy: 0.9298020307614934\n",
      "Iteration: 47488, Loss: 0.0029074158519506454, Accuracy: 0.9297384958190378\n",
      "Iteration: 47552, Loss: 0.0021493632812052965, Accuracy: 0.9389296872541308\n",
      "Iteration: 47616, Loss: 0.02001572586596012, Accuracy: 0.9349499887612183\n",
      "Iteration: 47680, Loss: 0.0043651992455124855, Accuracy: 0.931702381640207\n",
      "Iteration: 47744, Loss: 0.014844360761344433, Accuracy: 0.9432513143110555\n",
      "Iteration: 47808, Loss: 0.001550238928757608, Accuracy: 0.941963609366212\n",
      "Iteration: 47872, Loss: 0.011766956187784672, Accuracy: 0.9404601253918372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 47936, Loss: 0.0037589978892356157, Accuracy: 0.9427924986812286\n",
      "Iteration: 48000, Loss: 0.058601509779691696, Accuracy: 0.936782600969309\n",
      "Iteration: 48064, Loss: 0.012943985871970654, Accuracy: 0.9422475215687882\n",
      "Iteration: 48128, Loss: 0.01635880582034588, Accuracy: 0.9444193147355691\n",
      "Iteration: 48192, Loss: 0.0012333854101598263, Accuracy: 0.9462359808385372\n",
      "Iteration: 48256, Loss: 0.00097778404597193, Accuracy: 0.9432690210815053\n",
      "Iteration: 48320, Loss: 0.005742573644965887, Accuracy: 0.9475104935991112\n",
      "Iteration: 48384, Loss: 0.0012748097069561481, Accuracy: 0.9432293807622045\n",
      "Iteration: 48448, Loss: 0.011816306971013546, Accuracy: 0.9476965700159781\n",
      "Iteration: 48512, Loss: 0.0013371027307584882, Accuracy: 0.9448942067683674\n",
      "Iteration: 48576, Loss: 0.006767313461750746, Accuracy: 0.9509617545991205\n",
      "Iteration: 48640, Loss: 0.005363323260098696, Accuracy: 0.9489447462838143\n",
      "Iteration: 48704, Loss: 0.0026349618565291166, Accuracy: 0.9513542805361794\n",
      "Iteration: 48768, Loss: 0.001108908443711698, Accuracy: 0.9523057914630044\n",
      "Iteration: 48832, Loss: 0.006662559229880571, Accuracy: 0.9363449781376403\n",
      "Iteration: 48896, Loss: 0.005256317555904388, Accuracy: 0.9282605097396299\n",
      "Iteration: 48960, Loss: 0.06368332356214523, Accuracy: 0.9449784972384805\n",
      "Iteration: 49024, Loss: 0.0007709295023232698, Accuracy: 0.9502656292170286\n",
      "Iteration: 49088, Loss: 0.005966495722532272, Accuracy: 0.9486902076314436\n",
      "Iteration: 49152, Loss: 0.0005604913458228111, Accuracy: 0.948865817321348\n",
      "Iteration: 49216, Loss: 0.0076579381711781025, Accuracy: 0.9401800573104993\n",
      "Iteration: 49280, Loss: 0.004601266235113144, Accuracy: 0.9524843971448718\n",
      "Iteration: 49344, Loss: 0.004791211802512407, Accuracy: 0.9442490843357518\n",
      "Iteration: 49408, Loss: 0.0003082767070736736, Accuracy: 0.9492939661140554\n",
      "Iteration: 49472, Loss: 0.005452033132314682, Accuracy: 0.952384361444274\n",
      "Iteration: 49536, Loss: 0.014343584887683392, Accuracy: 0.9505870236316696\n",
      "Iteration: 49600, Loss: 0.0040867929346859455, Accuracy: 0.9515973379457137\n",
      "Iteration: 49664, Loss: 0.007078904192894697, Accuracy: 0.9561575472034747\n",
      "Iteration: 49728, Loss: 0.0011821143561974168, Accuracy: 0.9559271473699482\n",
      "Iteration: 49792, Loss: 0.002322518965229392, Accuracy: 0.9413767586811446\n",
      "Iteration: 49856, Loss: 0.010072936303913593, Accuracy: 0.9377124664606526\n",
      "Iteration: 49920, Loss: 0.0024874552618712187, Accuracy: 0.9471438210894121\n",
      "Iteration: 49984, Loss: 0.0035192377399653196, Accuracy: 0.9551344413775951\n",
      "Iteration: 50048, Loss: 0.014959010295569897, Accuracy: 0.9362037054088432\n",
      "Iteration: 50112, Loss: 0.003649483434855938, Accuracy: 0.9516770254849689\n",
      "Iteration: 50176, Loss: 0.0015181360067799687, Accuracy: 0.9530049853783567\n",
      "Iteration: 50240, Loss: 0.007008374202996492, Accuracy: 0.9575168261071667\n",
      "Iteration: 50304, Loss: 0.0019085491076111794, Accuracy: 0.9536324693035567\n",
      "Iteration: 50368, Loss: 0.000584049616008997, Accuracy: 0.9571892200910952\n",
      "Iteration: 50432, Loss: 0.0009715083870105445, Accuracy: 0.9589337514044018\n",
      "Iteration: 50496, Loss: 0.000593259057495743, Accuracy: 0.9556733395875199\n",
      "Iteration: 50560, Loss: 0.0008083002758212388, Accuracy: 0.9580515556590399\n",
      "Iteration: 50624, Loss: 0.0006872406229376793, Accuracy: 0.9607145755144302\n",
      "Iteration: 50688, Loss: 0.0005205846973694861, Accuracy: 0.9613157635612879\n",
      "Iteration: 50752, Loss: 0.003464452689513564, Accuracy: 0.9524738332547713\n",
      "Iteration: 50816, Loss: 0.003184329718351364, Accuracy: 0.964407759020105\n",
      "Iteration: 50880, Loss: 0.002550926525145769, Accuracy: 0.9508114565396681\n",
      "Iteration: 50944, Loss: 0.0005794005119241774, Accuracy: 0.9516520825418411\n",
      "Iteration: 51008, Loss: 0.0006808638572692871, Accuracy: 0.9605088671378326\n",
      "Iteration: 51072, Loss: 0.003468375885859132, Accuracy: 0.9646109282621183\n",
      "Iteration: 51136, Loss: 0.0006661138613708317, Accuracy: 0.9576446257560747\n",
      "Iteration: 51200, Loss: 0.009936933405697346, Accuracy: 0.9598010742629413\n",
      "Iteration: 51264, Loss: 0.0012411444913595915, Accuracy: 0.9591303638590034\n",
      "Iteration: 51328, Loss: 0.0005855331546626985, Accuracy: 0.9583217154431622\n",
      "Iteration: 51392, Loss: 0.0002020277315750718, Accuracy: 0.9618510298314504\n",
      "Iteration: 51456, Loss: 0.0019875613506883383, Accuracy: 0.9645248765300494\n",
      "Iteration: 51520, Loss: 0.001297278213314712, Accuracy: 0.9659993665845832\n",
      "Iteration: 51584, Loss: 0.0003914893604815006, Accuracy: 0.9499359167384682\n",
      "Iteration: 51648, Loss: 0.0018019657582044601, Accuracy: 0.960026357723109\n",
      "Iteration: 51712, Loss: 0.004957572091370821, Accuracy: 0.9617939494710299\n",
      "Iteration: 51776, Loss: 0.003272075206041336, Accuracy: 0.9636057269235607\n",
      "Iteration: 51840, Loss: 0.0025573286693543196, Accuracy: 0.952616341994144\n",
      "Iteration: 51904, Loss: 0.005217003170400858, Accuracy: 0.9558135231491178\n",
      "Iteration: 51968, Loss: 0.0014041784452274442, Accuracy: 0.9606814875878626\n",
      "Iteration: 52032, Loss: 0.00290130078792572, Accuracy: 0.9502554601058364\n",
      "Iteration: 52096, Loss: 0.000665965722873807, Accuracy: 0.9489326566326781\n",
      "Iteration: 52160, Loss: 0.0035629768390208483, Accuracy: 0.962678534880979\n",
      "Iteration: 52224, Loss: 0.002478491747751832, Accuracy: 0.9654344966984354\n",
      "Iteration: 52288, Loss: 0.0007715997635386884, Accuracy: 0.9661845307273325\n",
      "Iteration: 52352, Loss: 0.0018885111203417182, Accuracy: 0.9579881299869157\n",
      "Iteration: 52416, Loss: 0.0030577806755900383, Accuracy: 0.9672009836504003\n",
      "Iteration: 52480, Loss: 0.0011826272821053863, Accuracy: 0.9678354765928816\n",
      "Iteration: 52544, Loss: 0.0014791219728067517, Accuracy: 0.9637171980721178\n",
      "Iteration: 52608, Loss: 0.00044728361535817385, Accuracy: 0.9687822594860336\n",
      "Iteration: 52672, Loss: 0.001192065654322505, Accuracy: 0.9706523197091883\n",
      "Saved fullModel_dr[3]_replicate0.model\n",
      "Saved W_dr[3]_replicate0.p\n",
      "3 1.0 [1.0, 1.0, 1.0]\n",
      "Saved w_dr[3]_replicate0.p\n",
      "Replicate 0 completed\n",
      "Time elapsed: 261.921875 seconds\n",
      "Iteration: 64, Loss: 0.2562578618526459, Accuracy: 0.5007283301092684\n",
      "Iteration: 128, Loss: 0.279343843460083, Accuracy: 0.4989686347544193\n",
      "Iteration: 192, Loss: 0.2618285119533539, Accuracy: 0.4993997123092413\n",
      "Iteration: 256, Loss: 0.24848179519176483, Accuracy: 0.5001445040106773\n",
      "Iteration: 320, Loss: 0.24701142311096191, Accuracy: 0.4997917520813644\n",
      "Iteration: 384, Loss: 0.25320830941200256, Accuracy: 0.49974502390250564\n",
      "Iteration: 448, Loss: 0.24226851761341095, Accuracy: 0.5039981440640986\n",
      "Iteration: 512, Loss: 0.23372046649456024, Accuracy: 0.5244503603316844\n",
      "Iteration: 576, Loss: 0.15173904597759247, Accuracy: 0.5736296051181853\n",
      "Iteration: 640, Loss: 0.17841219902038574, Accuracy: 0.6010466306470335\n",
      "Iteration: 704, Loss: 0.16567760705947876, Accuracy: 0.6156712286174297\n",
      "Iteration: 768, Loss: 0.17231164872646332, Accuracy: 0.625225555151701\n",
      "Iteration: 832, Loss: 0.14852865040302277, Accuracy: 0.630675024818629\n",
      "Iteration: 896, Loss: 0.1634320765733719, Accuracy: 0.6373843741603196\n",
      "Iteration: 960, Loss: 0.17290373146533966, Accuracy: 0.6435645539313555\n",
      "Iteration: 1024, Loss: 0.17080797255039215, Accuracy: 0.6451606769114733\n",
      "Iteration: 1088, Loss: 0.1758468747138977, Accuracy: 0.6485882941633463\n",
      "Iteration: 1152, Loss: 0.1648666262626648, Accuracy: 0.652845848351717\n",
      "Iteration: 1216, Loss: 0.15724624693393707, Accuracy: 0.6580450618639588\n",
      "Iteration: 1280, Loss: 0.15902109444141388, Accuracy: 0.6599892349913716\n",
      "Iteration: 1344, Loss: 0.1499902755022049, Accuracy: 0.666478758212179\n",
      "Iteration: 1408, Loss: 0.1651490479707718, Accuracy: 0.6716458876617253\n",
      "Iteration: 1472, Loss: 0.1598481684923172, Accuracy: 0.6730405054986477\n",
      "Iteration: 1536, Loss: 0.1448451727628708, Accuracy: 0.6808947715908289\n",
      "Iteration: 1600, Loss: 0.1278568059206009, Accuracy: 0.6847506952472031\n",
      "Iteration: 1664, Loss: 0.14953473210334778, Accuracy: 0.6873090206645429\n",
      "Iteration: 1728, Loss: 0.12670199573040009, Accuracy: 0.6840344737283885\n",
      "Iteration: 1792, Loss: 0.13703413307666779, Accuracy: 0.6971196476370096\n",
      "Iteration: 1856, Loss: 0.12345293164253235, Accuracy: 0.7040856783278286\n",
      "Iteration: 1920, Loss: 0.13101230561733246, Accuracy: 0.7133017994929105\n",
      "Iteration: 1984, Loss: 0.09811580926179886, Accuracy: 0.7124758171848953\n",
      "Iteration: 2048, Loss: 0.11465934664011002, Accuracy: 0.7197115204762667\n",
      "Iteration: 2112, Loss: 0.11831878870725632, Accuracy: 0.7255955499131233\n",
      "Iteration: 2176, Loss: 0.09079581499099731, Accuracy: 0.7294208963867277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2240, Loss: 0.12245099991559982, Accuracy: 0.7354780309833586\n",
      "Iteration: 2304, Loss: 0.15683598816394806, Accuracy: 0.7373417029157281\n",
      "Iteration: 2368, Loss: 0.0852184072136879, Accuracy: 0.7343076022807509\n",
      "Iteration: 2432, Loss: 0.08469612151384354, Accuracy: 0.7450611714739352\n",
      "Iteration: 2496, Loss: 0.1016990914940834, Accuracy: 0.7495786079671234\n",
      "Iteration: 2560, Loss: 0.11291990429162979, Accuracy: 0.7511454790364951\n",
      "Iteration: 2624, Loss: 0.11360940337181091, Accuracy: 0.7442701449617743\n",
      "Iteration: 2688, Loss: 0.11764097958803177, Accuracy: 0.748451359802857\n",
      "Iteration: 2752, Loss: 0.09109282493591309, Accuracy: 0.7583440693560988\n",
      "Iteration: 2816, Loss: 0.10171988606452942, Accuracy: 0.7530626619700342\n",
      "Iteration: 2880, Loss: 0.07940912246704102, Accuracy: 0.7487256000749767\n",
      "Iteration: 2944, Loss: 0.07694198191165924, Accuracy: 0.7689173265825957\n",
      "Iteration: 3008, Loss: 0.08999080210924149, Accuracy: 0.7624633773230016\n",
      "Iteration: 3072, Loss: 0.07810872048139572, Accuracy: 0.7675806393381208\n",
      "Iteration: 3136, Loss: 0.07861103117465973, Accuracy: 0.7612946475856006\n",
      "Iteration: 3200, Loss: 0.07828449457883835, Accuracy: 0.7659350435715169\n",
      "Iteration: 3264, Loss: 0.07739385962486267, Accuracy: 0.7668507175985724\n",
      "Iteration: 3328, Loss: 0.2584410011768341, Accuracy: 0.7712584147229791\n",
      "Iteration: 3392, Loss: 0.08504386991262436, Accuracy: 0.7787541460711509\n",
      "Iteration: 3456, Loss: 0.0991252064704895, Accuracy: 0.7654353941325098\n",
      "Iteration: 3520, Loss: 0.1006576344370842, Accuracy: 0.7575302105396986\n",
      "Iteration: 3584, Loss: 0.09975365549325943, Accuracy: 0.7782004652544856\n",
      "Iteration: 3648, Loss: 0.10022326558828354, Accuracy: 0.765416971873492\n",
      "Iteration: 3712, Loss: 0.07804668694734573, Accuracy: 0.7742317859083414\n",
      "Iteration: 3776, Loss: 0.10812868922948837, Accuracy: 0.7829395721200854\n",
      "Iteration: 3840, Loss: 0.09094219654798508, Accuracy: 0.7698467450682074\n",
      "Iteration: 3904, Loss: 0.08927083760499954, Accuracy: 0.7815721274819225\n",
      "Iteration: 3968, Loss: 0.07713804394006729, Accuracy: 0.7800744713749737\n",
      "Iteration: 4032, Loss: 0.08217015117406845, Accuracy: 0.7803701902739704\n",
      "Iteration: 4096, Loss: 0.08013741672039032, Accuracy: 0.7732885393779725\n",
      "Iteration: 4160, Loss: 0.10546091943979263, Accuracy: 0.7810182315297425\n",
      "Iteration: 4224, Loss: 0.0860830545425415, Accuracy: 0.7795000874903053\n",
      "Iteration: 4288, Loss: 0.0982411727309227, Accuracy: 0.791896466165781\n",
      "Iteration: 4352, Loss: 0.08726229518651962, Accuracy: 0.7935690253507346\n",
      "Iteration: 4416, Loss: 0.09945590049028397, Accuracy: 0.7915592333301902\n",
      "Iteration: 4480, Loss: 0.0874318853020668, Accuracy: 0.7895695269107819\n",
      "Iteration: 4544, Loss: 0.07885508239269257, Accuracy: 0.7931445252615958\n",
      "Iteration: 4608, Loss: 0.09241928905248642, Accuracy: 0.7787006830330938\n",
      "Iteration: 4672, Loss: 0.08795112371444702, Accuracy: 0.7806307531427592\n",
      "Iteration: 4736, Loss: 0.08986130356788635, Accuracy: 0.7955905424896628\n",
      "Iteration: 4800, Loss: 0.09500030428171158, Accuracy: 0.7845077170059085\n",
      "Iteration: 4864, Loss: 0.08118685334920883, Accuracy: 0.7892450012732297\n",
      "Iteration: 4928, Loss: 0.08346209675073624, Accuracy: 0.7941402134019881\n",
      "Iteration: 4992, Loss: 0.09681428223848343, Accuracy: 0.7930144376587123\n",
      "Iteration: 5056, Loss: 0.08746125549077988, Accuracy: 0.7925463824067265\n",
      "Iteration: 5120, Loss: 0.09093759208917618, Accuracy: 0.7909457781352103\n",
      "Iteration: 5184, Loss: 0.09415337443351746, Accuracy: 0.7814179782290012\n",
      "Iteration: 5248, Loss: 0.10372710227966309, Accuracy: 0.7985655029769987\n",
      "Iteration: 5312, Loss: 0.08345195651054382, Accuracy: 0.798753592884168\n",
      "Iteration: 5376, Loss: 0.08330202847719193, Accuracy: 0.7903792343568057\n",
      "Iteration: 5440, Loss: 0.08161704987287521, Accuracy: 0.7849001633003354\n",
      "Iteration: 5504, Loss: 0.09321471303701401, Accuracy: 0.7913661738857627\n",
      "Iteration: 5568, Loss: 0.09514948725700378, Accuracy: 0.8011689053382725\n",
      "Iteration: 5632, Loss: 0.096648208796978, Accuracy: 0.8006426563952118\n",
      "Iteration: 5696, Loss: 0.07997260987758636, Accuracy: 0.8057513174135238\n",
      "Iteration: 5760, Loss: 0.08037175983190536, Accuracy: 0.7959088401403278\n",
      "Iteration: 5824, Loss: 0.084989033639431, Accuracy: 0.8003480490297079\n",
      "Iteration: 5888, Loss: 0.08400825411081314, Accuracy: 0.8054311433807015\n",
      "Iteration: 5952, Loss: 0.08229907602071762, Accuracy: 0.7915406960528344\n",
      "Iteration: 6016, Loss: 0.0870676338672638, Accuracy: 0.8007132329512388\n",
      "Iteration: 6080, Loss: 0.08293715864419937, Accuracy: 0.8000061439815909\n",
      "Iteration: 6144, Loss: 0.10163185000419617, Accuracy: 0.7988038321491331\n",
      "Iteration: 6208, Loss: 0.07931233942508698, Accuracy: 0.8005348516162485\n",
      "Iteration: 6272, Loss: 0.08239223808050156, Accuracy: 0.8036134627182037\n",
      "Iteration: 6336, Loss: 0.09120143204927444, Accuracy: 0.8035869961604476\n",
      "Iteration: 6400, Loss: 0.09492162615060806, Accuracy: 0.8046462964266539\n",
      "Iteration: 6464, Loss: 0.08720896393060684, Accuracy: 0.8015068150125444\n",
      "Iteration: 6528, Loss: 0.23213112354278564, Accuracy: 0.8058884947095066\n",
      "Iteration: 6592, Loss: 0.0901346206665039, Accuracy: 0.802349696168676\n",
      "Iteration: 6656, Loss: 0.08948948979377747, Accuracy: 0.8116827795747668\n",
      "Iteration: 6720, Loss: 0.08387422561645508, Accuracy: 0.8084631108213216\n",
      "Iteration: 6784, Loss: 0.08041886985301971, Accuracy: 0.7957970034331083\n",
      "Iteration: 6848, Loss: 0.27140918374061584, Accuracy: 0.792236796580255\n",
      "Iteration: 6912, Loss: 0.08622048050165176, Accuracy: 0.7859330649953336\n",
      "Iteration: 6976, Loss: 0.08653377741575241, Accuracy: 0.795714319916442\n",
      "Iteration: 7040, Loss: 0.08434370160102844, Accuracy: 0.7912013104651123\n",
      "Iteration: 7104, Loss: 0.3785566985607147, Accuracy: 0.7963768243789673\n",
      "Iteration: 7168, Loss: 0.08480537682771683, Accuracy: 0.8126907462719828\n",
      "Iteration: 7232, Loss: 0.09446999430656433, Accuracy: 0.7967118059750646\n",
      "Iteration: 7296, Loss: 0.08353111892938614, Accuracy: 0.8128438773564994\n",
      "Iteration: 7360, Loss: 0.08781815320253372, Accuracy: 0.7978136294987053\n",
      "Iteration: 7424, Loss: 0.08237486332654953, Accuracy: 0.813316305866465\n",
      "Iteration: 7488, Loss: 0.08611129969358444, Accuracy: 0.8118485482409596\n",
      "Iteration: 7552, Loss: 0.08281821012496948, Accuracy: 0.8082963596098125\n",
      "Iteration: 7616, Loss: 0.08459803462028503, Accuracy: 0.8075590210501105\n",
      "Iteration: 7680, Loss: 0.08156125992536545, Accuracy: 0.8124259952455759\n",
      "Iteration: 7744, Loss: 0.08453500270843506, Accuracy: 0.8057659284677356\n",
      "Iteration: 7808, Loss: 0.2869899272918701, Accuracy: 0.8063789494335651\n",
      "Iteration: 7872, Loss: 0.08357059210538864, Accuracy: 0.8027533572167158\n",
      "Iteration: 7936, Loss: 0.08304346352815628, Accuracy: 0.8150879424065351\n",
      "Iteration: 8000, Loss: 0.0857074186205864, Accuracy: 0.8025650912895799\n",
      "Iteration: 8064, Loss: 0.08480779081583023, Accuracy: 0.8080302448943257\n",
      "Iteration: 8128, Loss: 0.0840914323925972, Accuracy: 0.8126974750775844\n",
      "Iteration: 8192, Loss: 0.0833774209022522, Accuracy: 0.8134872170630842\n",
      "Iteration: 8256, Loss: 0.08268618583679199, Accuracy: 0.8159646759741008\n",
      "Iteration: 8320, Loss: 0.08383644372224808, Accuracy: 0.8152245790697634\n",
      "Iteration: 8384, Loss: 0.08586462587118149, Accuracy: 0.8126955521292984\n",
      "Iteration: 8448, Loss: 0.0830083116889, Accuracy: 0.810841241851449\n",
      "Iteration: 8512, Loss: 0.08739256113767624, Accuracy: 0.8158414892386645\n",
      "Iteration: 8576, Loss: 0.08387383818626404, Accuracy: 0.8034188949968666\n",
      "Iteration: 8640, Loss: 0.08045721799135208, Accuracy: 0.8166935965418816\n",
      "Iteration: 8704, Loss: 0.08090496063232422, Accuracy: 0.8086006611119956\n",
      "Iteration: 8768, Loss: 0.08504074811935425, Accuracy: 0.8097641461063176\n",
      "Iteration: 8832, Loss: 0.0840258076786995, Accuracy: 0.8147689630277455\n",
      "Iteration: 8896, Loss: 0.08628041297197342, Accuracy: 0.8157768668606877\n",
      "Iteration: 8960, Loss: 0.08238533139228821, Accuracy: 0.816487108822912\n",
      "Iteration: 9024, Loss: 0.0844137892127037, Accuracy: 0.8109030602499843\n",
      "Iteration: 9088, Loss: 0.08868681639432907, Accuracy: 0.8124027429148555\n",
      "Iteration: 9152, Loss: 0.08522999286651611, Accuracy: 0.8100392206106335\n",
      "Iteration: 9216, Loss: 0.08563009649515152, Accuracy: 0.8076351841446012\n",
      "Iteration: 9280, Loss: 0.08327678591012955, Accuracy: 0.7998784179799259\n",
      "Iteration: 9344, Loss: 0.08511141687631607, Accuracy: 0.8186385107692331\n",
      "Iteration: 9408, Loss: 0.08565313369035721, Accuracy: 0.8125253254547715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 9472, Loss: 0.08552107959985733, Accuracy: 0.8040272651705891\n",
      "Iteration: 9536, Loss: 0.08259157836437225, Accuracy: 0.8154969615861773\n",
      "Iteration: 9600, Loss: 0.08577468991279602, Accuracy: 0.8104931360576302\n",
      "Iteration: 9664, Loss: 0.0846158042550087, Accuracy: 0.8053277018480003\n",
      "Iteration: 9728, Loss: 0.09004547446966171, Accuracy: 0.8174396033864468\n",
      "Iteration: 9792, Loss: 0.08220910280942917, Accuracy: 0.8187270590569824\n",
      "Iteration: 9856, Loss: 0.08497899025678635, Accuracy: 0.8183666893746704\n",
      "Iteration: 9920, Loss: 0.085236556828022, Accuracy: 0.8019462658558041\n",
      "Iteration: 9984, Loss: 0.0818093940615654, Accuracy: 0.8110962507780641\n",
      "Iteration: 10048, Loss: 0.08236599713563919, Accuracy: 0.8142594024538994\n",
      "Iteration: 10112, Loss: 0.08493097871541977, Accuracy: 0.8142945768777281\n",
      "Iteration: 10176, Loss: 0.08332071453332901, Accuracy: 0.818229899276048\n",
      "Iteration: 10240, Loss: 0.08472108095884323, Accuracy: 0.8194095559883863\n",
      "Iteration: 10304, Loss: 0.08562138676643372, Accuracy: 0.8195327951107174\n",
      "Iteration: 10368, Loss: 0.08393436670303345, Accuracy: 0.8200611348729581\n",
      "Iteration: 10432, Loss: 0.08291060477495193, Accuracy: 0.814611435867846\n",
      "Iteration: 10496, Loss: 0.08489617705345154, Accuracy: 0.8201467785984278\n",
      "Iteration: 10560, Loss: 0.08195656538009644, Accuracy: 0.8199656251817942\n",
      "Iteration: 10624, Loss: 0.0850796103477478, Accuracy: 0.8181343066971749\n",
      "Iteration: 10688, Loss: 0.08461302518844604, Accuracy: 0.8209158405661583\n",
      "Iteration: 10752, Loss: 0.08395052701234818, Accuracy: 0.8201676560565829\n",
      "Iteration: 10816, Loss: 0.08272997289896011, Accuracy: 0.819164406042546\n",
      "Iteration: 10880, Loss: 0.08214152604341507, Accuracy: 0.8136811964213848\n",
      "Iteration: 10944, Loss: 0.08286409825086594, Accuracy: 0.8208965586964041\n",
      "Iteration: 11008, Loss: 0.08481714129447937, Accuracy: 0.8094903901219368\n",
      "Iteration: 11072, Loss: 0.08478183299303055, Accuracy: 0.8044361115898937\n",
      "Iteration: 11136, Loss: 0.08541180938482285, Accuracy: 0.8212460319045931\n",
      "Iteration: 11200, Loss: 0.08317866921424866, Accuracy: 0.8212061210069805\n",
      "Iteration: 11264, Loss: 0.08650078624486923, Accuracy: 0.8091020833235234\n",
      "Iteration: 11328, Loss: 0.08483854681253433, Accuracy: 0.8123568769078702\n",
      "Iteration: 11392, Loss: 0.08654264360666275, Accuracy: 0.8153756086248904\n",
      "Iteration: 11456, Loss: 0.08484507352113724, Accuracy: 0.8194008022546768\n",
      "Iteration: 11520, Loss: 0.0838630199432373, Accuracy: 0.8208627491258085\n",
      "Iteration: 11584, Loss: 0.08207341283559799, Accuracy: 0.811069879680872\n",
      "Iteration: 11648, Loss: 0.08508500456809998, Accuracy: 0.8162906568031758\n",
      "Iteration: 11712, Loss: 0.0834280475974083, Accuracy: 0.8089028596878052\n",
      "Iteration: 11776, Loss: 0.08384758979082108, Accuracy: 0.8056104360148311\n",
      "Iteration: 11840, Loss: 0.08609958738088608, Accuracy: 0.8222104641608894\n",
      "Iteration: 11904, Loss: 0.08571935445070267, Accuracy: 0.8119341738056391\n",
      "Iteration: 11968, Loss: 0.0831405371427536, Accuracy: 0.8183663208037615\n",
      "Iteration: 12032, Loss: 0.08345452696084976, Accuracy: 0.8216873831115663\n",
      "Iteration: 12096, Loss: 0.08269750326871872, Accuracy: 0.8215107733849436\n",
      "Iteration: 12160, Loss: 0.08278366178274155, Accuracy: 0.8226765431463718\n",
      "Iteration: 12224, Loss: 0.08679170161485672, Accuracy: 0.8205242301337421\n",
      "Iteration: 12288, Loss: 0.08379161357879639, Accuracy: 0.8165382433217019\n",
      "Iteration: 12352, Loss: 0.08408064395189285, Accuracy: 0.8224172526970506\n",
      "Iteration: 12416, Loss: 0.08358440548181534, Accuracy: 0.8093701521866024\n",
      "Iteration: 12480, Loss: 0.0855003073811531, Accuracy: 0.815797769697383\n",
      "Iteration: 12544, Loss: 0.08429789543151855, Accuracy: 0.8138168936129659\n",
      "Iteration: 12608, Loss: 0.08387736231088638, Accuracy: 0.8175651843193918\n",
      "Iteration: 12672, Loss: 0.0836525484919548, Accuracy: 0.811229839688167\n",
      "Iteration: 12736, Loss: 0.08527276664972305, Accuracy: 0.816400486510247\n",
      "Iteration: 12800, Loss: 0.08563322573900223, Accuracy: 0.8166880325879902\n",
      "Iteration: 12864, Loss: 0.08221402764320374, Accuracy: 0.8214810518547893\n",
      "Iteration: 12928, Loss: 0.08144436031579971, Accuracy: 0.8160027479752898\n",
      "Iteration: 12992, Loss: 0.08534616231918335, Accuracy: 0.8168640756048262\n",
      "Iteration: 13056, Loss: 0.08762247115373611, Accuracy: 0.8220503774937242\n",
      "Iteration: 13120, Loss: 0.08515775203704834, Accuracy: 0.8228685499634594\n",
      "Iteration: 13184, Loss: 0.083622045814991, Accuracy: 0.8176242620684206\n",
      "Iteration: 13248, Loss: 0.0828511044383049, Accuracy: 0.8230238505639136\n",
      "Iteration: 13312, Loss: 0.08549311012029648, Accuracy: 0.7949804065283388\n",
      "Iteration: 13376, Loss: 0.08379864692687988, Accuracy: 0.811880697729066\n",
      "Iteration: 13440, Loss: 0.07961297035217285, Accuracy: 0.8101591905578971\n",
      "Iteration: 13504, Loss: 0.08019772171974182, Accuracy: 0.8165617431513965\n",
      "Iteration: 13568, Loss: 0.08480071276426315, Accuracy: 0.819415659410879\n",
      "Iteration: 13632, Loss: 0.08421910554170609, Accuracy: 0.8217170075513422\n",
      "Iteration: 13696, Loss: 0.08503512293100357, Accuracy: 0.8227394542191178\n",
      "Iteration: 13760, Loss: 0.08679527789354324, Accuracy: 0.823492809664458\n",
      "Iteration: 13824, Loss: 0.08419793844223022, Accuracy: 0.8104595360346138\n",
      "Iteration: 13888, Loss: 0.08057501167058945, Accuracy: 0.8023147222120315\n",
      "Iteration: 13952, Loss: 0.08557874709367752, Accuracy: 0.8177703665569425\n",
      "Iteration: 14016, Loss: 0.08665118366479874, Accuracy: 0.8171359747648239\n",
      "Iteration: 14080, Loss: 0.08745419234037399, Accuracy: 0.8221122049726546\n",
      "Iteration: 14144, Loss: 0.08433223515748978, Accuracy: 0.8222375186160207\n",
      "Iteration: 14208, Loss: 0.08016743510961533, Accuracy: 0.8230939502827823\n",
      "Iteration: 14272, Loss: 0.08197448402643204, Accuracy: 0.8229352512862533\n",
      "Iteration: 14336, Loss: 0.0860769972205162, Accuracy: 0.8219743585214019\n",
      "Iteration: 14400, Loss: 0.08436509221792221, Accuracy: 0.8226028364151716\n",
      "Iteration: 14464, Loss: 0.08196759968996048, Accuracy: 0.8235038181301206\n",
      "Iteration: 14528, Loss: 0.08230338245630264, Accuracy: 0.8236247897148132\n",
      "Iteration: 14592, Loss: 0.0860385000705719, Accuracy: 0.8216775229666382\n",
      "Iteration: 14656, Loss: 0.08597633242607117, Accuracy: 0.822913235751912\n",
      "Iteration: 14720, Loss: 0.08384387940168381, Accuracy: 0.823866059537977\n",
      "Iteration: 14784, Loss: 0.08428537100553513, Accuracy: 0.8230238817632198\n",
      "Iteration: 14848, Loss: 0.08287615329027176, Accuracy: 0.8241749948356301\n",
      "Iteration: 14912, Loss: 0.08701279014348984, Accuracy: 0.8139124342706054\n",
      "Iteration: 14976, Loss: 0.08080177754163742, Accuracy: 0.8233735368121415\n",
      "Iteration: 15040, Loss: 0.08229662477970123, Accuracy: 0.8164080467540771\n",
      "Iteration: 15104, Loss: 0.08682334423065186, Accuracy: 0.8200440751388669\n",
      "Iteration: 15168, Loss: 0.0859275758266449, Accuracy: 0.822278801817447\n",
      "Iteration: 15232, Loss: 0.08485826849937439, Accuracy: 0.81611587270163\n",
      "Iteration: 15296, Loss: 0.08358827978372574, Accuracy: 0.8031529961153865\n",
      "Iteration: 15360, Loss: 0.08510176092386246, Accuracy: 0.8142722283955663\n",
      "Iteration: 15424, Loss: 0.08532989770174026, Accuracy: 0.8135450286790729\n",
      "Iteration: 15488, Loss: 0.08429747819900513, Accuracy: 0.8239672819618136\n",
      "Iteration: 15552, Loss: 0.08327356725931168, Accuracy: 0.8236069369595498\n",
      "Iteration: 15616, Loss: 0.08511227369308472, Accuracy: 0.8220285603310913\n",
      "Iteration: 15680, Loss: 0.0845077633857727, Accuracy: 0.824640111066401\n",
      "Iteration: 15744, Loss: 0.08449151366949081, Accuracy: 0.82018534373492\n",
      "Iteration: 15808, Loss: 0.08649127930402756, Accuracy: 0.8212724542245269\n",
      "Iteration: 15872, Loss: 0.0834592804312706, Accuracy: 0.8223460796289146\n",
      "Iteration: 15936, Loss: 0.08233214169740677, Accuracy: 0.8228705930523574\n",
      "Iteration: 16000, Loss: 0.08546983450651169, Accuracy: 0.8207060045097023\n",
      "Iteration: 16064, Loss: 0.08327582478523254, Accuracy: 0.8199634444899857\n",
      "Iteration: 16128, Loss: 0.086090087890625, Accuracy: 0.8249189823400229\n",
      "Iteration: 16192, Loss: 0.0844365581870079, Accuracy: 0.825320242671296\n",
      "Iteration: 16256, Loss: 0.0834788903594017, Accuracy: 0.8249254559632391\n",
      "Iteration: 16320, Loss: 0.08194738626480103, Accuracy: 0.8250956311821938\n",
      "Iteration: 16384, Loss: 0.0833219513297081, Accuracy: 0.8248354983516037\n",
      "Iteration: 16448, Loss: 0.08435508608818054, Accuracy: 0.8251124154776335\n",
      "Iteration: 16512, Loss: 0.0853181704878807, Accuracy: 0.8207709221169353\n",
      "Iteration: 16576, Loss: 0.08400372415781021, Accuracy: 0.8240279655437917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 16640, Loss: 0.08327923715114594, Accuracy: 0.8253110719379038\n",
      "Iteration: 16704, Loss: 0.08341272920370102, Accuracy: 0.8212620713748038\n",
      "Iteration: 16768, Loss: 0.08519032597541809, Accuracy: 0.8241954485420138\n",
      "Iteration: 16832, Loss: 0.08252578973770142, Accuracy: 0.8252948357257992\n",
      "Iteration: 16896, Loss: 0.08275171369314194, Accuracy: 0.8238462365698069\n",
      "Iteration: 16960, Loss: 0.0848049446940422, Accuracy: 0.8247785838320851\n",
      "Iteration: 17024, Loss: 0.08136611431837082, Accuracy: 0.8255378296598792\n",
      "Iteration: 17088, Loss: 0.08162176609039307, Accuracy: 0.8249741590116173\n",
      "Iteration: 17152, Loss: 0.08385926485061646, Accuracy: 0.8254248325247318\n",
      "Iteration: 17216, Loss: 0.08464512228965759, Accuracy: 0.8259469540789723\n",
      "Iteration: 17280, Loss: 0.08376557379961014, Accuracy: 0.8260503108613193\n",
      "Iteration: 17344, Loss: 0.0828588530421257, Accuracy: 0.8211017390713096\n",
      "Iteration: 17408, Loss: 0.08615922182798386, Accuracy: 0.8249234608374536\n",
      "Iteration: 17472, Loss: 0.08720584958791733, Accuracy: 0.8257948067039251\n",
      "Iteration: 17536, Loss: 0.08191338926553726, Accuracy: 0.8210238569881767\n",
      "Iteration: 17600, Loss: 0.08458930253982544, Accuracy: 0.8166970876045525\n",
      "Iteration: 17664, Loss: 0.0838753953576088, Accuracy: 0.806069673737511\n",
      "Iteration: 17728, Loss: 0.08290521055459976, Accuracy: 0.8024283023551106\n",
      "Iteration: 17792, Loss: 0.08207089453935623, Accuracy: 0.8210172920953482\n",
      "Iteration: 17856, Loss: 0.08178595453500748, Accuracy: 0.8254207593854517\n",
      "Iteration: 17920, Loss: 0.08247341960668564, Accuracy: 0.820456190733239\n",
      "Iteration: 17984, Loss: 0.08446262031793594, Accuracy: 0.8208057703450322\n",
      "Iteration: 18048, Loss: 0.08588940650224686, Accuracy: 0.8062384049408138\n",
      "Iteration: 18112, Loss: 0.08437269926071167, Accuracy: 0.8253711846191436\n",
      "Iteration: 18176, Loss: 0.08834933489561081, Accuracy: 0.8169746317435056\n",
      "Iteration: 18240, Loss: 0.08589715510606766, Accuracy: 0.8253785418346524\n",
      "Iteration: 18304, Loss: 0.08545529842376709, Accuracy: 0.8246158226393163\n",
      "Iteration: 18368, Loss: 0.08515813946723938, Accuracy: 0.825208138441667\n",
      "Iteration: 18432, Loss: 0.08556505292654037, Accuracy: 0.8199911518022418\n",
      "Iteration: 18496, Loss: 0.08679181337356567, Accuracy: 0.8256130169611424\n",
      "Iteration: 18560, Loss: 0.08414382487535477, Accuracy: 0.8258716801647097\n",
      "Iteration: 18624, Loss: 0.08749023079872131, Accuracy: 0.8253783560357988\n",
      "Iteration: 18688, Loss: 0.08289604634046555, Accuracy: 0.825775487581268\n",
      "Iteration: 18752, Loss: 0.08421626687049866, Accuracy: 0.8257174186874181\n",
      "Iteration: 18816, Loss: 0.08367049694061279, Accuracy: 0.8261789821553975\n",
      "Iteration: 18880, Loss: 0.0855584517121315, Accuracy: 0.8262695260345936\n",
      "Iteration: 18944, Loss: 0.08457943052053452, Accuracy: 0.8264907395932823\n",
      "Iteration: 19008, Loss: 0.0830104872584343, Accuracy: 0.7952154914382845\n",
      "Iteration: 19072, Loss: 0.08690550178289413, Accuracy: 0.8051576185971498\n",
      "Iteration: 19136, Loss: 0.08618585020303726, Accuracy: 0.8261328199878335\n",
      "Iteration: 19200, Loss: 0.0836656391620636, Accuracy: 0.8198272676672786\n",
      "Iteration: 19264, Loss: 0.08512640744447708, Accuracy: 0.8190877521410584\n",
      "Iteration: 19328, Loss: 0.08350980281829834, Accuracy: 0.8233168802689761\n",
      "Iteration: 19392, Loss: 0.08357855677604675, Accuracy: 0.8184116636402905\n",
      "Iteration: 19456, Loss: 0.08442774415016174, Accuracy: 0.8247754143085331\n",
      "Iteration: 19520, Loss: 0.08293775469064713, Accuracy: 0.8256993535906076\n",
      "Iteration: 19584, Loss: 0.08433199673891068, Accuracy: 0.8209027333650738\n",
      "Iteration: 19648, Loss: 0.08330768346786499, Accuracy: 0.8259538854472339\n",
      "Iteration: 19712, Loss: 0.08457431942224503, Accuracy: 0.825543523998931\n",
      "Iteration: 19776, Loss: 0.0840984582901001, Accuracy: 0.8246774571016431\n",
      "Iteration: 19840, Loss: 0.08275892585515976, Accuracy: 0.8265024137217551\n",
      "Iteration: 19904, Loss: 0.08475762605667114, Accuracy: 0.8262091148644686\n",
      "Iteration: 19968, Loss: 0.08314066380262375, Accuracy: 0.8259429116733372\n",
      "Iteration: 20032, Loss: 0.0833905041217804, Accuracy: 0.8264736125711352\n",
      "Iteration: 20096, Loss: 0.08350565284490585, Accuracy: 0.826672880910337\n",
      "Iteration: 20160, Loss: 0.08522390574216843, Accuracy: 0.8263704332057387\n",
      "Iteration: 20224, Loss: 0.083973728120327, Accuracy: 0.8234544179867953\n",
      "Iteration: 20288, Loss: 0.08487243205308914, Accuracy: 0.813926175236702\n",
      "Iteration: 20352, Loss: 0.08537620306015015, Accuracy: 0.8204504596069455\n",
      "Iteration: 20416, Loss: 0.08452219516038895, Accuracy: 0.8255404594819993\n",
      "Iteration: 20480, Loss: 0.08282160013914108, Accuracy: 0.8260700961109251\n",
      "Iteration: 20544, Loss: 0.08566945791244507, Accuracy: 0.8215163270942867\n",
      "Iteration: 20608, Loss: 0.08264248818159103, Accuracy: 0.826082291547209\n",
      "Iteration: 20672, Loss: 0.08438446372747421, Accuracy: 0.8219772421289235\n",
      "Iteration: 20736, Loss: 0.08674758672714233, Accuracy: 0.8268296085298061\n",
      "Iteration: 20800, Loss: 0.08043332397937775, Accuracy: 0.8265542229637504\n",
      "Iteration: 20864, Loss: 0.08279382437467575, Accuracy: 0.8260182847734541\n",
      "Iteration: 20928, Loss: 0.08182904869318008, Accuracy: 0.8212819122709334\n",
      "Iteration: 20992, Loss: 0.08587916940450668, Accuracy: 0.8221664316952229\n",
      "Iteration: 21056, Loss: 0.08377303928136826, Accuracy: 0.8264601670671254\n",
      "Iteration: 21120, Loss: 0.08131909370422363, Accuracy: 0.8255547299049795\n",
      "Iteration: 21184, Loss: 0.08165089040994644, Accuracy: 0.8261241829022765\n",
      "Iteration: 21248, Loss: 0.08293527364730835, Accuracy: 0.8259290521964431\n",
      "Iteration: 21312, Loss: 0.08377450704574585, Accuracy: 0.8262778662610799\n",
      "Iteration: 21376, Loss: 0.08628663420677185, Accuracy: 0.8266191722359508\n",
      "Iteration: 21440, Loss: 0.08354196697473526, Accuracy: 0.8265219607856125\n",
      "Iteration: 21504, Loss: 0.08392540365457535, Accuracy: 0.8271445124410093\n",
      "Iteration: 21568, Loss: 0.08443605154752731, Accuracy: 0.8267544456757605\n",
      "Iteration: 21632, Loss: 0.08409151434898376, Accuracy: 0.8212265113834292\n",
      "Iteration: 21696, Loss: 0.08259677141904831, Accuracy: 0.8269008158240467\n",
      "Iteration: 21760, Loss: 0.0841163620352745, Accuracy: 0.82724998309277\n",
      "Iteration: 21824, Loss: 0.08117415755987167, Accuracy: 0.8258935005869716\n",
      "Iteration: 21888, Loss: 0.08478815108537674, Accuracy: 0.8268722156062722\n",
      "Iteration: 21952, Loss: 0.08479931205511093, Accuracy: 0.8266817950643599\n",
      "Iteration: 22016, Loss: 0.08349748700857162, Accuracy: 0.8273172222543508\n",
      "Iteration: 22080, Loss: 0.08361297100782394, Accuracy: 0.8269290784373879\n",
      "Iteration: 22144, Loss: 0.08305124938488007, Accuracy: 0.8272909400984645\n",
      "Iteration: 22208, Loss: 0.08380541205406189, Accuracy: 0.8276250094641\n",
      "Iteration: 22272, Loss: 0.08401042968034744, Accuracy: 0.826404731022194\n",
      "Iteration: 22336, Loss: 0.0831209272146225, Accuracy: 0.827390604885295\n",
      "Iteration: 22400, Loss: 0.08416616171598434, Accuracy: 0.8271823257673532\n",
      "Iteration: 22464, Loss: 0.08427489548921585, Accuracy: 0.8261493109166622\n",
      "Iteration: 22528, Loss: 0.08434923738241196, Accuracy: 0.8224634109064937\n",
      "Iteration: 22592, Loss: 0.08489177376031876, Accuracy: 0.827636199304834\n",
      "Iteration: 22656, Loss: 0.08410783857107162, Accuracy: 0.8272286283317953\n",
      "Iteration: 22720, Loss: 0.08886920660734177, Accuracy: 0.8266375011298805\n",
      "Iteration: 22784, Loss: 0.08309219777584076, Accuracy: 0.8277033786289394\n",
      "Iteration: 22848, Loss: 0.08270926773548126, Accuracy: 0.8279530927538872\n",
      "Iteration: 22912, Loss: 0.08366555720567703, Accuracy: 0.8273522309027612\n",
      "Iteration: 22976, Loss: 0.08331848680973053, Accuracy: 0.8281188914552331\n",
      "Iteration: 23040, Loss: 0.08370205014944077, Accuracy: 0.8276521123480052\n",
      "Iteration: 23104, Loss: 0.08281903713941574, Accuracy: 0.8281449936330318\n",
      "Iteration: 23168, Loss: 0.08531711250543594, Accuracy: 0.8283042020630091\n",
      "Iteration: 23232, Loss: 0.08300663530826569, Accuracy: 0.8279529316350818\n",
      "Iteration: 23296, Loss: 0.0833522379398346, Accuracy: 0.8282182174734771\n",
      "Iteration: 23360, Loss: 0.08690660446882248, Accuracy: 0.8279377790167928\n",
      "Iteration: 23424, Loss: 0.08127400279045105, Accuracy: 0.8283418407663703\n",
      "Iteration: 23488, Loss: 0.08338960260152817, Accuracy: 0.8283667666837573\n",
      "Iteration: 23552, Loss: 0.08265148848295212, Accuracy: 0.8281815713271499\n",
      "Iteration: 23616, Loss: 0.08229639381170273, Accuracy: 0.8283660761080682\n",
      "Iteration: 23680, Loss: 0.085360087454319, Accuracy: 0.8280642807949334\n",
      "Iteration: 23744, Loss: 0.08462575078010559, Accuracy: 0.8233052017167211\n",
      "Iteration: 23808, Loss: 0.08441898226737976, Accuracy: 0.8255304624326527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 23872, Loss: 0.08590835332870483, Accuracy: 0.82854850939475\n",
      "Iteration: 23936, Loss: 0.08441952615976334, Accuracy: 0.8277413917239755\n",
      "Iteration: 24000, Loss: 0.08571034669876099, Accuracy: 0.8283810229040682\n",
      "Iteration: 24064, Loss: 0.08609578013420105, Accuracy: 0.8142851735465229\n",
      "Iteration: 24128, Loss: 0.08748894929885864, Accuracy: 0.8212468069978058\n",
      "Iteration: 24192, Loss: 0.0853327289223671, Accuracy: 0.8188253780826926\n",
      "Iteration: 24256, Loss: 0.08494926244020462, Accuracy: 0.8217450315132737\n",
      "Iteration: 24320, Loss: 0.08457937836647034, Accuracy: 0.8234460190869868\n",
      "Iteration: 24384, Loss: 0.08441999554634094, Accuracy: 0.8287152792327106\n",
      "Iteration: 24448, Loss: 0.08470464497804642, Accuracy: 0.8288077700417489\n",
      "Iteration: 24512, Loss: 0.08140096068382263, Accuracy: 0.8235103592742234\n",
      "Iteration: 24576, Loss: 0.08320131152868271, Accuracy: 0.824053150601685\n",
      "Iteration: 24640, Loss: 0.08446314930915833, Accuracy: 0.8254646460991353\n",
      "Iteration: 24704, Loss: 0.0841437578201294, Accuracy: 0.828671240247786\n",
      "Iteration: 24768, Loss: 0.08297654986381531, Accuracy: 0.828546006930992\n",
      "Iteration: 24832, Loss: 0.0836017057299614, Accuracy: 0.8248002657201141\n",
      "Iteration: 24896, Loss: 0.08463045209646225, Accuracy: 0.8201074711978436\n",
      "Iteration: 24960, Loss: 0.08458676934242249, Accuracy: 0.8232401767745614\n",
      "Iteration: 25024, Loss: 0.08429526537656784, Accuracy: 0.8188470469322056\n",
      "Iteration: 25088, Loss: 0.0825209841132164, Accuracy: 0.8284628409892321\n",
      "Iteration: 25152, Loss: 0.08252377063035965, Accuracy: 0.8192466450855136\n",
      "Iteration: 25216, Loss: 0.0823368951678276, Accuracy: 0.8278659929055721\n",
      "Iteration: 25280, Loss: 0.08085284382104874, Accuracy: 0.8226826062891632\n",
      "Iteration: 25344, Loss: 0.08549702912569046, Accuracy: 0.8278037088457495\n",
      "Iteration: 25408, Loss: 0.08140925318002701, Accuracy: 0.8283243437763304\n",
      "Iteration: 25472, Loss: 0.08453559875488281, Accuracy: 0.8208167536649853\n",
      "Iteration: 25536, Loss: 0.08700177818536758, Accuracy: 0.8259490425698459\n",
      "Iteration: 25600, Loss: 0.08453816920518875, Accuracy: 0.8271161608863622\n",
      "Iteration: 25664, Loss: 0.07967156171798706, Accuracy: 0.8282849043607712\n",
      "Iteration: 25728, Loss: 0.08132833242416382, Accuracy: 0.8228709946852177\n",
      "Iteration: 25792, Loss: 0.08206234872341156, Accuracy: 0.8238118339795619\n",
      "Iteration: 25856, Loss: 0.08468971401453018, Accuracy: 0.8245026990771294\n",
      "Iteration: 25920, Loss: 0.08445444703102112, Accuracy: 0.8265702878125012\n",
      "Iteration: 25984, Loss: 0.0830836370587349, Accuracy: 0.8285115438047796\n",
      "Iteration: 26048, Loss: 0.09044978022575378, Accuracy: 0.8284048645291477\n",
      "Iteration: 26112, Loss: 0.08216012269258499, Accuracy: 0.8286632972303778\n",
      "Iteration: 26176, Loss: 0.08468977361917496, Accuracy: 0.8281339278910309\n",
      "Iteration: 26240, Loss: 0.08245359361171722, Accuracy: 0.8287431297358125\n",
      "Iteration: 26304, Loss: 0.08151447027921677, Accuracy: 0.8284092487301677\n",
      "Iteration: 26368, Loss: 0.08679293841123581, Accuracy: 0.8285756148397923\n",
      "Iteration: 26432, Loss: 0.08534900099039078, Accuracy: 0.8148982629645616\n",
      "Iteration: 26496, Loss: 0.08487400412559509, Accuracy: 0.8189405049197376\n",
      "Iteration: 26560, Loss: 0.08312543481588364, Accuracy: 0.8226778616663069\n",
      "Iteration: 26624, Loss: 0.08928050845861435, Accuracy: 0.8225973662920296\n",
      "Iteration: 26688, Loss: 0.08453793078660965, Accuracy: 0.8283963447902352\n",
      "Iteration: 26752, Loss: 0.08560163527727127, Accuracy: 0.8284002407453954\n",
      "Iteration: 26816, Loss: 0.08388546109199524, Accuracy: 0.8281644566450268\n",
      "Iteration: 26880, Loss: 0.08374935388565063, Accuracy: 0.8283445569686592\n",
      "Iteration: 26944, Loss: 0.08518742769956589, Accuracy: 0.8278629316482693\n",
      "Iteration: 27008, Loss: 0.08200328797101974, Accuracy: 0.828674484975636\n",
      "Iteration: 27072, Loss: 0.08628785610198975, Accuracy: 0.82850795192644\n",
      "Iteration: 27136, Loss: 0.08647062629461288, Accuracy: 0.8276491402648389\n",
      "Iteration: 27200, Loss: 0.08210042119026184, Accuracy: 0.8285219711251557\n",
      "Iteration: 27264, Loss: 0.08636054396629333, Accuracy: 0.8288557378109545\n",
      "Iteration: 27328, Loss: 0.08398991078138351, Accuracy: 0.8290697007905692\n",
      "Iteration: 27392, Loss: 0.08093484491109848, Accuracy: 0.821820214856416\n",
      "Iteration: 27456, Loss: 0.08257776498794556, Accuracy: 0.8286073126364499\n",
      "Iteration: 27520, Loss: 0.08296694606542587, Accuracy: 0.825698820175603\n",
      "Iteration: 27584, Loss: 0.08964744210243225, Accuracy: 0.8162247559521347\n",
      "Iteration: 27648, Loss: 0.08734964579343796, Accuracy: 0.8285319383721799\n",
      "Iteration: 27712, Loss: 0.07966189831495285, Accuracy: 0.8238257237244397\n",
      "Iteration: 27776, Loss: 0.08894612640142441, Accuracy: 0.8271013139747083\n",
      "Iteration: 27840, Loss: 0.0862870141863823, Accuracy: 0.821479274192825\n",
      "Iteration: 27904, Loss: 0.08563526719808578, Accuracy: 0.8035357273183763\n",
      "Iteration: 27968, Loss: 0.08337188512086868, Accuracy: 0.8266307055018842\n",
      "Iteration: 28032, Loss: 0.08519327640533447, Accuracy: 0.823148783063516\n",
      "Iteration: 28096, Loss: 0.08067501336336136, Accuracy: 0.8272985450457782\n",
      "Iteration: 28160, Loss: 0.09261489659547806, Accuracy: 0.8209210231434554\n",
      "Iteration: 28224, Loss: 0.08314390480518341, Accuracy: 0.8169930675067008\n",
      "Iteration: 28288, Loss: 0.07951922714710236, Accuracy: 0.8174900403246284\n",
      "Iteration: 28352, Loss: 0.07790208607912064, Accuracy: 0.8167159976437688\n",
      "Iteration: 28416, Loss: 0.08640065789222717, Accuracy: 0.8279415811412036\n",
      "Iteration: 28480, Loss: 0.0862896665930748, Accuracy: 0.8278594946023077\n",
      "Iteration: 28544, Loss: 0.08725902438163757, Accuracy: 0.8279710642527789\n",
      "Iteration: 28608, Loss: 0.08306900411844254, Accuracy: 0.8284924412146211\n",
      "Iteration: 28672, Loss: 0.08531295508146286, Accuracy: 0.82789555657655\n",
      "Iteration: 28736, Loss: 0.09098124504089355, Accuracy: 0.8239696871023625\n",
      "Iteration: 28800, Loss: 0.08279382437467575, Accuracy: 0.8175025421660393\n",
      "Iteration: 28864, Loss: 0.08044464141130447, Accuracy: 0.827377452282235\n",
      "Iteration: 28928, Loss: 0.0810462161898613, Accuracy: 0.8283139360137284\n",
      "Iteration: 28992, Loss: 0.08737123012542725, Accuracy: 0.8231933515053242\n",
      "Iteration: 29056, Loss: 0.08456382900476456, Accuracy: 0.8225113917142153\n",
      "Iteration: 29120, Loss: 0.08348079770803452, Accuracy: 0.8180390573106706\n",
      "Iteration: 29184, Loss: 0.08507582545280457, Accuracy: 0.8201719534117728\n",
      "Iteration: 29248, Loss: 0.08313439041376114, Accuracy: 0.8275539835449308\n",
      "Iteration: 29312, Loss: 0.091183602809906, Accuracy: 0.827839104225859\n",
      "Iteration: 29376, Loss: 0.08220263570547104, Accuracy: 0.823440479580313\n",
      "Iteration: 29440, Loss: 0.08419280499219894, Accuracy: 0.8273695486132056\n",
      "Iteration: 29504, Loss: 0.08146724849939346, Accuracy: 0.8283958814572543\n",
      "Iteration: 29568, Loss: 0.08329203724861145, Accuracy: 0.8270940089132637\n",
      "Iteration: 29632, Loss: 0.07983414083719254, Accuracy: 0.8275083983317018\n",
      "Iteration: 29696, Loss: 0.0855039581656456, Accuracy: 0.8287011866923422\n",
      "Iteration: 29760, Loss: 0.08433689922094345, Accuracy: 0.8289731268305331\n",
      "Iteration: 29824, Loss: 0.08419955521821976, Accuracy: 0.8290659980848432\n",
      "Iteration: 29888, Loss: 0.09340345114469528, Accuracy: 0.8184778797440231\n",
      "Iteration: 29952, Loss: 0.08529237657785416, Accuracy: 0.8277985935565084\n",
      "Iteration: 30016, Loss: 0.08269892632961273, Accuracy: 0.8281917560379952\n",
      "Iteration: 30080, Loss: 0.09347141534090042, Accuracy: 0.8258872942533344\n",
      "Iteration: 30144, Loss: 0.08359389752149582, Accuracy: 0.828539352864027\n",
      "Iteration: 30208, Loss: 0.07483120262622833, Accuracy: 0.8255029846914113\n",
      "Iteration: 30272, Loss: 0.08646661788225174, Accuracy: 0.8257626611739397\n",
      "Iteration: 30336, Loss: 0.08132988214492798, Accuracy: 0.8235073718242347\n",
      "Iteration: 30400, Loss: 0.07906182110309601, Accuracy: 0.8278372692875564\n",
      "Iteration: 30464, Loss: 0.08250043541193008, Accuracy: 0.8286521180998534\n",
      "Iteration: 30528, Loss: 0.07248877733945847, Accuracy: 0.8287487144116312\n",
      "Iteration: 30592, Loss: 0.08655151724815369, Accuracy: 0.8288055134471506\n",
      "Iteration: 30656, Loss: 0.09099101275205612, Accuracy: 0.8282019519247115\n",
      "Iteration: 30720, Loss: 0.0839376375079155, Accuracy: 0.8285288820043206\n",
      "Iteration: 30784, Loss: 0.08843686431646347, Accuracy: 0.8190035431180149\n",
      "Iteration: 30848, Loss: 0.08168027549982071, Accuracy: 0.8212019775528461\n",
      "Iteration: 30912, Loss: 0.08341813832521439, Accuracy: 0.8282167478464544\n",
      "Iteration: 30976, Loss: 0.07781410962343216, Accuracy: 0.8267232486978173\n",
      "Iteration: 31040, Loss: 0.08425126224756241, Accuracy: 0.8284436024259776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 31104, Loss: 0.08448374271392822, Accuracy: 0.8288929255213588\n",
      "Iteration: 31168, Loss: 0.08427146077156067, Accuracy: 0.828475744696334\n",
      "Iteration: 31232, Loss: 0.08511322736740112, Accuracy: 0.8287224054802209\n",
      "Iteration: 31296, Loss: 0.08836137503385544, Accuracy: 0.8285946466494352\n",
      "Iteration: 31360, Loss: 0.08227750658988953, Accuracy: 0.828836165368557\n",
      "Iteration: 31424, Loss: 0.0886756107211113, Accuracy: 0.8282858151942492\n",
      "Iteration: 31488, Loss: 0.08437744528055191, Accuracy: 0.8291398454457521\n",
      "Iteration: 31552, Loss: 0.08039573580026627, Accuracy: 0.8232786012813449\n",
      "Iteration: 31616, Loss: 0.08472022414207458, Accuracy: 0.7976977897342294\n",
      "Iteration: 31680, Loss: 0.08346859365701675, Accuracy: 0.8290644763037562\n",
      "Iteration: 31744, Loss: 0.0821443647146225, Accuracy: 0.8276555861812085\n",
      "Iteration: 31808, Loss: 0.08388867974281311, Accuracy: 0.8286414570175111\n",
      "Iteration: 31872, Loss: 0.08502840250730515, Accuracy: 0.8288131689187139\n",
      "Iteration: 31936, Loss: 0.08300416171550751, Accuracy: 0.8290600397158414\n",
      "Iteration: 32000, Loss: 0.08543597906827927, Accuracy: 0.8278390518389642\n",
      "Iteration: 32064, Loss: 0.08288015425205231, Accuracy: 0.8288998859934509\n",
      "Iteration: 32128, Loss: 0.08458135277032852, Accuracy: 0.8286163660231978\n",
      "Iteration: 32192, Loss: 0.08195357769727707, Accuracy: 0.8292045898269862\n",
      "Iteration: 32256, Loss: 0.0831919014453888, Accuracy: 0.8286693631671369\n",
      "Iteration: 32320, Loss: 0.07539064437150955, Accuracy: 0.8279886187519878\n",
      "Iteration: 32384, Loss: 0.08302228897809982, Accuracy: 0.8182625942863524\n",
      "Iteration: 32448, Loss: 0.0851002112030983, Accuracy: 0.8284924430772662\n",
      "Iteration: 32512, Loss: 0.09538164734840393, Accuracy: 0.8281937311403453\n",
      "Iteration: 32576, Loss: 0.08540355414152145, Accuracy: 0.8281558435410261\n",
      "Iteration: 32640, Loss: 0.08337200433015823, Accuracy: 0.8293921265285462\n",
      "Iteration: 32704, Loss: 0.08434569835662842, Accuracy: 0.8265212581027299\n",
      "Iteration: 32768, Loss: 0.08296951651573181, Accuracy: 0.8291413935367018\n",
      "Iteration: 32832, Loss: 0.08258789777755737, Accuracy: 0.8235275964252651\n",
      "Iteration: 32896, Loss: 0.08249495178461075, Accuracy: 0.8291202748659998\n",
      "Iteration: 32960, Loss: 0.23646874725818634, Accuracy: 0.8259262819774449\n",
      "Iteration: 33024, Loss: 0.08317584544420242, Accuracy: 0.821695317979902\n",
      "Iteration: 33088, Loss: 0.08559615164995193, Accuracy: 0.8232779649551958\n",
      "Iteration: 33152, Loss: 0.08566763252019882, Accuracy: 0.8290350246243179\n",
      "Iteration: 33216, Loss: 0.0891270861029625, Accuracy: 0.8292263927869499\n",
      "Iteration: 33280, Loss: 0.08552190661430359, Accuracy: 0.8279652593191713\n",
      "Iteration: 33344, Loss: 0.08389416337013245, Accuracy: 0.8295062510296702\n",
      "Iteration: 33408, Loss: 0.082146055996418, Accuracy: 0.8291511749848723\n",
      "Iteration: 33472, Loss: 0.07982944697141647, Accuracy: 0.8295157027896494\n",
      "Iteration: 33536, Loss: 0.08432009071111679, Accuracy: 0.8249752414412796\n",
      "Iteration: 33600, Loss: 0.08483899384737015, Accuracy: 0.8296703260857612\n",
      "Iteration: 33664, Loss: 0.08680566400289536, Accuracy: 0.8185722546186298\n",
      "Iteration: 33728, Loss: 0.09507111459970474, Accuracy: 0.8162525221705437\n",
      "Iteration: 33792, Loss: 0.08473248034715652, Accuracy: 0.8015007958747447\n",
      "Iteration: 33856, Loss: 0.0999772921204567, Accuracy: 0.8273460427299142\n",
      "Iteration: 33920, Loss: 0.08540675044059753, Accuracy: 0.8288379639852792\n",
      "Iteration: 33984, Loss: 0.07712188363075256, Accuracy: 0.8296670422423631\n",
      "Iteration: 34048, Loss: 0.08249229937791824, Accuracy: 0.8289650196675211\n",
      "Iteration: 34112, Loss: 0.08060736209154129, Accuracy: 0.8226951865945011\n",
      "Iteration: 34176, Loss: 0.09301958233118057, Accuracy: 0.8285845639184117\n",
      "Iteration: 34240, Loss: 0.08435016870498657, Accuracy: 0.8295480669476092\n",
      "Iteration: 34304, Loss: 0.08380666375160217, Accuracy: 0.8290295314509422\n",
      "Iteration: 34368, Loss: 0.08532948046922684, Accuracy: 0.8289990208577365\n",
      "Iteration: 34432, Loss: 0.07684492319822311, Accuracy: 0.829801193671301\n",
      "Iteration: 34496, Loss: 0.08194182068109512, Accuracy: 0.8296765030827373\n",
      "Iteration: 34560, Loss: 0.08597179502248764, Accuracy: 0.8287826937157661\n",
      "Iteration: 34624, Loss: 0.085235096514225, Accuracy: 0.8281893855892122\n",
      "Iteration: 34688, Loss: 0.08637938648462296, Accuracy: 0.8109361629467458\n",
      "Iteration: 34752, Loss: 0.0874333456158638, Accuracy: 0.8293106416240335\n",
      "Iteration: 34816, Loss: 0.08359900116920471, Accuracy: 0.8291923853103071\n",
      "Iteration: 34880, Loss: 0.08523399382829666, Accuracy: 0.8296972352545708\n",
      "Iteration: 34944, Loss: 0.0821179673075676, Accuracy: 0.8285268032923341\n",
      "Iteration: 35008, Loss: 0.08140385895967484, Accuracy: 0.8097756791394204\n",
      "Iteration: 35072, Loss: 0.0825740322470665, Accuracy: 0.8239919850602746\n",
      "Iteration: 35136, Loss: 0.08577239513397217, Accuracy: 0.8248826060444117\n",
      "Iteration: 35200, Loss: 0.09596096724271774, Accuracy: 0.8291023289784789\n",
      "Iteration: 35264, Loss: 0.08763884752988815, Accuracy: 0.8296201233752072\n",
      "Iteration: 35328, Loss: 0.0876992717385292, Accuracy: 0.8293275195173919\n",
      "Iteration: 35392, Loss: 0.08788751810789108, Accuracy: 0.8293235234450549\n",
      "Iteration: 35456, Loss: 0.08368135243654251, Accuracy: 0.823405773146078\n",
      "Iteration: 35520, Loss: 0.08273936063051224, Accuracy: 0.8260982970241457\n",
      "Iteration: 35584, Loss: 0.07582756131887436, Accuracy: 0.829083516029641\n",
      "Iteration: 35648, Loss: 0.08596555143594742, Accuracy: 0.8279073152225465\n",
      "Iteration: 35712, Loss: 0.08450395613908768, Accuracy: 0.8273080920334905\n",
      "Iteration: 35776, Loss: 0.08698717504739761, Accuracy: 0.8292608561459929\n",
      "Iteration: 35840, Loss: 0.07425100356340408, Accuracy: 0.8288525179959834\n",
      "Iteration: 35904, Loss: 0.08568931370973587, Accuracy: 0.8257418235298246\n",
      "Iteration: 35968, Loss: 0.08144873380661011, Accuracy: 0.824338102247566\n",
      "Iteration: 36032, Loss: 0.08124171197414398, Accuracy: 0.8251911283005029\n",
      "Iteration: 36096, Loss: 0.08914325386285782, Accuracy: 0.8300610256846994\n",
      "Iteration: 36160, Loss: 0.07946423441171646, Accuracy: 0.8303436450660229\n",
      "Iteration: 36224, Loss: 0.08232948929071426, Accuracy: 0.8153885116335005\n",
      "Iteration: 36288, Loss: 0.08449382334947586, Accuracy: 0.8282830959651619\n",
      "Iteration: 36352, Loss: 0.08672734349966049, Accuracy: 0.830078006722033\n",
      "Iteration: 36416, Loss: 0.08009802550077438, Accuracy: 0.8306176657788455\n",
      "Iteration: 36480, Loss: 0.08369982242584229, Accuracy: 0.8296126835048199\n",
      "Iteration: 36544, Loss: 0.0798463448882103, Accuracy: 0.8301818321924657\n",
      "Iteration: 36608, Loss: 0.08110625296831131, Accuracy: 0.8292534537613392\n",
      "Iteration: 36672, Loss: 0.07088861614465714, Accuracy: 0.828360166400671\n",
      "Iteration: 36736, Loss: 0.08069947361946106, Accuracy: 0.8283396207261831\n",
      "Iteration: 36800, Loss: 0.08641558140516281, Accuracy: 0.8302479670383036\n",
      "Iteration: 36864, Loss: 0.07741843909025192, Accuracy: 0.8305824080016464\n",
      "Iteration: 36928, Loss: 0.07886163145303726, Accuracy: 0.8168646146077663\n",
      "Iteration: 36992, Loss: 0.07245489209890366, Accuracy: 0.8272673736792058\n",
      "Iteration: 37056, Loss: 0.08384398370981216, Accuracy: 0.8310740320011973\n",
      "Iteration: 37120, Loss: 0.07113271206617355, Accuracy: 0.8252495969645679\n",
      "Iteration: 37184, Loss: 0.07657747715711594, Accuracy: 0.8288739146664739\n",
      "Iteration: 37248, Loss: 0.08217489719390869, Accuracy: 0.8215909211430699\n",
      "Iteration: 37312, Loss: 0.09375635534524918, Accuracy: 0.8300311458297074\n",
      "Iteration: 37376, Loss: 0.08112996816635132, Accuracy: 0.8209085224661976\n",
      "Iteration: 37440, Loss: 0.08563742786645889, Accuracy: 0.8258537140209228\n",
      "Iteration: 37504, Loss: 0.09230265021324158, Accuracy: 0.8286543616559356\n",
      "Iteration: 37568, Loss: 0.059921976178884506, Accuracy: 0.8314081057906151\n",
      "Iteration: 37632, Loss: 0.08821382373571396, Accuracy: 0.8201152756810188\n",
      "Iteration: 37696, Loss: 0.08294416218996048, Accuracy: 0.8299246041569859\n",
      "Iteration: 37760, Loss: 0.08137606829404831, Accuracy: 0.8298717418219894\n",
      "Iteration: 37824, Loss: 0.08636518567800522, Accuracy: 0.8304057132918388\n",
      "Iteration: 37888, Loss: 0.060833290219306946, Accuracy: 0.8324893803801388\n",
      "Iteration: 37952, Loss: 0.08372189849615097, Accuracy: 0.8322455212473869\n",
      "Iteration: 38016, Loss: 0.07953128963708878, Accuracy: 0.8320812003221363\n",
      "Iteration: 38080, Loss: 0.07994993776082993, Accuracy: 0.8249804556835443\n",
      "Iteration: 38144, Loss: 0.08289927989244461, Accuracy: 0.8315307905431837\n",
      "Iteration: 38208, Loss: 0.07553249597549438, Accuracy: 0.825701188063249\n",
      "Iteration: 38272, Loss: 0.08997263759374619, Accuracy: 0.8306814047973603\n",
      "Iteration: 38336, Loss: 0.0863095223903656, Accuracy: 0.8308267870452255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 38400, Loss: 0.07763827592134476, Accuracy: 0.832448344444856\n",
      "Iteration: 38464, Loss: 0.08564936369657516, Accuracy: 0.833256107987836\n",
      "Iteration: 38528, Loss: 0.07995849847793579, Accuracy: 0.8314644095953554\n",
      "Iteration: 38592, Loss: 0.09747482091188431, Accuracy: 0.8300668548326939\n",
      "Iteration: 38656, Loss: 0.08830513805150986, Accuracy: 0.8320096835959703\n",
      "Iteration: 38720, Loss: 0.0904422178864479, Accuracy: 0.8323266487568617\n",
      "Iteration: 38784, Loss: 0.08892133086919785, Accuracy: 0.8342187425587326\n",
      "Iteration: 38848, Loss: 0.07509032636880875, Accuracy: 0.8317522360011935\n",
      "Iteration: 38912, Loss: 0.06522700935602188, Accuracy: 0.8349754477385432\n",
      "Iteration: 38976, Loss: 0.05112692341208458, Accuracy: 0.8311479291878641\n",
      "Iteration: 39040, Loss: 0.0783117264509201, Accuracy: 0.8333283786196262\n",
      "Iteration: 39104, Loss: 0.10169676691293716, Accuracy: 0.8295097933150828\n",
      "Iteration: 39168, Loss: 0.0798288881778717, Accuracy: 0.8191321061458439\n",
      "Iteration: 39232, Loss: 0.08102913945913315, Accuracy: 0.8264285980258137\n",
      "Iteration: 39296, Loss: 0.04704597592353821, Accuracy: 0.8336147444788367\n",
      "Iteration: 39360, Loss: 0.09397859126329422, Accuracy: 0.833905256120488\n",
      "Iteration: 39424, Loss: 0.06814286857843399, Accuracy: 0.8334544922690839\n",
      "Iteration: 39488, Loss: 0.050707992166280746, Accuracy: 0.828319578198716\n",
      "Iteration: 39552, Loss: 0.09204500168561935, Accuracy: 0.8359883176162839\n",
      "Iteration: 39616, Loss: 0.076393723487854, Accuracy: 0.8252100418321788\n",
      "Iteration: 39680, Loss: 0.05307832732796669, Accuracy: 0.8315485927741975\n",
      "Iteration: 39744, Loss: 0.07419733703136444, Accuracy: 0.8346889906097203\n",
      "Iteration: 39808, Loss: 0.05335967242717743, Accuracy: 0.8220240127993748\n",
      "Iteration: 39872, Loss: 0.07436039298772812, Accuracy: 0.8303956154268235\n",
      "Iteration: 39936, Loss: 0.09744226932525635, Accuracy: 0.8258433199953288\n",
      "Iteration: 40000, Loss: 0.07856037467718124, Accuracy: 0.8321668060962111\n",
      "Iteration: 40064, Loss: 0.052006203681230545, Accuracy: 0.8348463996080682\n",
      "Iteration: 40128, Loss: 0.08021090924739838, Accuracy: 0.8241683865198866\n",
      "Iteration: 40192, Loss: 0.09387525916099548, Accuracy: 0.8176088001346216\n",
      "Iteration: 40256, Loss: 0.09850653260946274, Accuracy: 0.8358273155754432\n",
      "Iteration: 40320, Loss: 0.0983569547533989, Accuracy: 0.8352357562398538\n",
      "Iteration: 40384, Loss: 0.09691166877746582, Accuracy: 0.8329345067031682\n",
      "Iteration: 40448, Loss: 0.08921343833208084, Accuracy: 0.8340529793640599\n",
      "Iteration: 40512, Loss: 0.07113411277532578, Accuracy: 0.8312056752620265\n",
      "Iteration: 40576, Loss: 0.10910714417695999, Accuracy: 0.8348141600145027\n",
      "Iteration: 40640, Loss: 0.08681830018758774, Accuracy: 0.8376547737279907\n",
      "Iteration: 40704, Loss: 0.08282028138637543, Accuracy: 0.8380871936678886\n",
      "Iteration: 40768, Loss: 0.07190998643636703, Accuracy: 0.8371145823039114\n",
      "Iteration: 40832, Loss: 0.054446231573820114, Accuracy: 0.8355885016499087\n",
      "Iteration: 40896, Loss: 0.09390804916620255, Accuracy: 0.8338790783891454\n",
      "Iteration: 40960, Loss: 0.07372759282588959, Accuracy: 0.8379286725539714\n",
      "Iteration: 41024, Loss: 0.09367676824331284, Accuracy: 0.8397923186421394\n",
      "Iteration: 41088, Loss: 0.06322705000638962, Accuracy: 0.8310284790350124\n",
      "Iteration: 41152, Loss: 0.07931250333786011, Accuracy: 0.8381435519549996\n",
      "Iteration: 41216, Loss: 0.0934743583202362, Accuracy: 0.8376712710596621\n",
      "Iteration: 41280, Loss: 0.0434737354516983, Accuracy: 0.8403749953722581\n",
      "Iteration: 41344, Loss: 0.0746561586856842, Accuracy: 0.8390188241610304\n",
      "Iteration: 41408, Loss: 0.04343688115477562, Accuracy: 0.8368070513242856\n",
      "Iteration: 41472, Loss: 0.0347394123673439, Accuracy: 0.8316844897344708\n",
      "Iteration: 41536, Loss: 0.08088698238134384, Accuracy: 0.8343288085889071\n",
      "Iteration: 41600, Loss: 0.037495207041502, Accuracy: 0.8341938452795148\n",
      "Iteration: 41664, Loss: 0.09526047855615616, Accuracy: 0.8405178611865267\n",
      "Iteration: 41728, Loss: 0.030210884287953377, Accuracy: 0.8403520683059469\n",
      "Iteration: 41792, Loss: 0.0705188512802124, Accuracy: 0.8406762190861627\n",
      "Iteration: 41856, Loss: 0.0987035259604454, Accuracy: 0.8346474902937189\n",
      "Iteration: 41920, Loss: 0.07584045082330704, Accuracy: 0.8144896224839613\n",
      "Iteration: 41984, Loss: 0.06314612925052643, Accuracy: 0.8327684751711786\n",
      "Iteration: 42048, Loss: 0.054256509989500046, Accuracy: 0.841481919400394\n",
      "Iteration: 42112, Loss: 0.07459195703268051, Accuracy: 0.8398461363976821\n",
      "Iteration: 42176, Loss: 0.07187309116125107, Accuracy: 0.8434158985037357\n",
      "Iteration: 42240, Loss: 0.09476593881845474, Accuracy: 0.840002543409355\n",
      "Iteration: 42304, Loss: 0.034888479858636856, Accuracy: 0.8389286183519289\n",
      "Iteration: 42368, Loss: 0.0956464633345604, Accuracy: 0.8362709431676194\n",
      "Iteration: 42432, Loss: 0.0944443866610527, Accuracy: 0.8401120025664568\n",
      "Iteration: 42496, Loss: 0.08750999718904495, Accuracy: 0.8369785284157842\n",
      "Iteration: 42560, Loss: 0.0874587669968605, Accuracy: 0.8440482774749398\n",
      "Iteration: 42624, Loss: 0.0955146849155426, Accuracy: 0.8403664277866483\n",
      "Iteration: 42688, Loss: 0.09445562213659286, Accuracy: 0.8414533104514703\n",
      "Iteration: 42752, Loss: 0.07752306014299393, Accuracy: 0.8444944439688697\n",
      "Iteration: 42816, Loss: 0.07368675619363785, Accuracy: 0.8357116781407967\n",
      "Iteration: 42880, Loss: 0.09668552130460739, Accuracy: 0.8341034923214465\n",
      "Iteration: 42944, Loss: 0.09801775217056274, Accuracy: 0.84457315527834\n",
      "Iteration: 43008, Loss: 0.08785197883844376, Accuracy: 0.846183328772895\n",
      "Iteration: 43072, Loss: 0.09434808045625687, Accuracy: 0.8438737150281668\n",
      "Iteration: 43136, Loss: 0.023753905668854713, Accuracy: 0.844520176644437\n",
      "Iteration: 43200, Loss: 0.03272930905222893, Accuracy: 0.8362792376428843\n",
      "Iteration: 43264, Loss: 0.09399733692407608, Accuracy: 0.8426834177225828\n",
      "Iteration: 43328, Loss: 0.023067599162459373, Accuracy: 0.8470337396720424\n",
      "Iteration: 43392, Loss: 0.07312973588705063, Accuracy: 0.8470869389129803\n",
      "Iteration: 43456, Loss: 0.0977492704987526, Accuracy: 0.8379254611209035\n",
      "Iteration: 43520, Loss: 0.08483908325433731, Accuracy: 0.843738793162629\n",
      "Iteration: 43584, Loss: 0.07359086722135544, Accuracy: 0.8417929768329486\n",
      "Iteration: 43648, Loss: 0.024850958958268166, Accuracy: 0.8456965740770102\n",
      "Iteration: 43712, Loss: 0.09668833017349243, Accuracy: 0.8435577813070267\n",
      "Iteration: 43776, Loss: 0.07451827079057693, Accuracy: 0.835860618040897\n",
      "Iteration: 43840, Loss: 0.09270528703927994, Accuracy: 0.8462115862639621\n",
      "Iteration: 43904, Loss: 0.02513873390853405, Accuracy: 0.8425896196858957\n",
      "Iteration: 43968, Loss: 0.07282551378011703, Accuracy: 0.8455316316103563\n",
      "Iteration: 44032, Loss: 0.09155642241239548, Accuracy: 0.8436447822023183\n",
      "Iteration: 44096, Loss: 0.09214511513710022, Accuracy: 0.8482733867131174\n",
      "Iteration: 44160, Loss: 0.07498020678758621, Accuracy: 0.8443354585906491\n",
      "Iteration: 44224, Loss: 0.07880770415067673, Accuracy: 0.8474000209243968\n",
      "Iteration: 44288, Loss: 0.07291224598884583, Accuracy: 0.8474086736096069\n",
      "Iteration: 44352, Loss: 0.022702718153595924, Accuracy: 0.8417279003188014\n",
      "Iteration: 44416, Loss: 0.07586533576250076, Accuracy: 0.8441975493915379\n",
      "Iteration: 44480, Loss: 0.088358573615551, Accuracy: 0.8373319128295407\n",
      "Iteration: 44544, Loss: 0.0910678505897522, Accuracy: 0.8496001340681687\n",
      "Iteration: 44608, Loss: 0.07201077044010162, Accuracy: 0.8471652262378484\n",
      "Iteration: 44672, Loss: 0.07856032997369766, Accuracy: 0.8406846189172938\n",
      "Iteration: 44736, Loss: 0.07497915625572205, Accuracy: 0.842365447897464\n",
      "Iteration: 44800, Loss: 0.09418060630559921, Accuracy: 0.8448815827723593\n",
      "Iteration: 44864, Loss: 0.07131325453519821, Accuracy: 0.8522296336013824\n",
      "Iteration: 44928, Loss: 0.07456759363412857, Accuracy: 0.8376919431611896\n",
      "Iteration: 44992, Loss: 0.06102953478693962, Accuracy: 0.8491850710706785\n",
      "Iteration: 45056, Loss: 0.07479489594697952, Accuracy: 0.8435579946963117\n",
      "Iteration: 45120, Loss: 0.09447479248046875, Accuracy: 0.8447058320743963\n",
      "Iteration: 45184, Loss: 0.09401848912239075, Accuracy: 0.8472518951166421\n",
      "Iteration: 45248, Loss: 0.09707976132631302, Accuracy: 0.83831565186847\n",
      "Iteration: 45312, Loss: 0.015576597303152084, Accuracy: 0.8504726904211566\n",
      "Iteration: 45376, Loss: 0.08882928639650345, Accuracy: 0.8479132128413767\n",
      "Iteration: 45440, Loss: 0.07978034764528275, Accuracy: 0.8498944444581866\n",
      "Iteration: 45504, Loss: 0.08859772235155106, Accuracy: 0.850848853122443\n",
      "Iteration: 45568, Loss: 0.016289399936795235, Accuracy: 0.8473363248631358\n",
      "Iteration: 45632, Loss: 0.019806204363703728, Accuracy: 0.8502969982801005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 45696, Loss: 0.04927287995815277, Accuracy: 0.8518562054960057\n",
      "Iteration: 45760, Loss: 0.08848810940980911, Accuracy: 0.8419263769173995\n",
      "Iteration: 45824, Loss: 0.06702985614538193, Accuracy: 0.8590829673921689\n",
      "Iteration: 45888, Loss: 0.06606056541204453, Accuracy: 0.8484028107486665\n",
      "Iteration: 45952, Loss: 0.010913312435150146, Accuracy: 0.8538740155054256\n",
      "Iteration: 46016, Loss: 0.10140720009803772, Accuracy: 0.8525470802560449\n",
      "Iteration: 46080, Loss: 0.00977678969502449, Accuracy: 0.8591058288002387\n",
      "Iteration: 46144, Loss: 0.01876932382583618, Accuracy: 0.8583283563493751\n",
      "Iteration: 46208, Loss: 0.07227064669132233, Accuracy: 0.855412668781355\n",
      "Iteration: 46272, Loss: 0.06549617648124695, Accuracy: 0.8627408398897387\n",
      "Iteration: 46336, Loss: 0.01415459718555212, Accuracy: 0.8694866870064288\n",
      "Iteration: 46400, Loss: 0.05307576060295105, Accuracy: 0.8683731482597068\n",
      "Iteration: 46464, Loss: 0.039100583642721176, Accuracy: 0.8658631111029536\n",
      "Iteration: 46528, Loss: 0.07247789204120636, Accuracy: 0.8696097288629971\n",
      "Iteration: 46592, Loss: 0.08139869570732117, Accuracy: 0.8686331495409831\n",
      "Iteration: 46656, Loss: 0.09554121643304825, Accuracy: 0.8713911946979351\n",
      "Iteration: 46720, Loss: 0.07470650225877762, Accuracy: 0.8738737705280073\n",
      "Iteration: 46784, Loss: 0.04173703491687775, Accuracy: 0.8621948248473927\n",
      "Iteration: 46848, Loss: 0.07566054165363312, Accuracy: 0.8742205182788894\n",
      "Iteration: 46912, Loss: 0.011151998303830624, Accuracy: 0.8766139124636538\n",
      "Iteration: 46976, Loss: 0.005026896949857473, Accuracy: 0.8677669776952825\n",
      "Iteration: 47040, Loss: 0.01313632819801569, Accuracy: 0.8826677589677274\n",
      "Iteration: 47104, Loss: 0.07395639270544052, Accuracy: 0.8800817406154238\n",
      "Iteration: 47168, Loss: 0.006961406674236059, Accuracy: 0.8724828409031034\n",
      "Iteration: 47232, Loss: 0.01459474116563797, Accuracy: 0.8832031607162207\n",
      "Iteration: 47296, Loss: 0.08193426579236984, Accuracy: 0.8726634260383435\n",
      "Iteration: 47360, Loss: 0.0911945030093193, Accuracy: 0.8782538884552196\n",
      "Iteration: 47424, Loss: 0.08267930150032043, Accuracy: 0.8823543916223571\n",
      "Iteration: 47488, Loss: 0.008925518952310085, Accuracy: 0.885284767660778\n",
      "Iteration: 47552, Loss: 0.007137279957532883, Accuracy: 0.8767815387109295\n",
      "Iteration: 47616, Loss: 0.025120487436652184, Accuracy: 0.8742953477776609\n",
      "Iteration: 47680, Loss: 0.004225033801048994, Accuracy: 0.8704812714131549\n",
      "Iteration: 47744, Loss: 0.09091200679540634, Accuracy: 0.8822144296718761\n",
      "Iteration: 47808, Loss: 0.009143526665866375, Accuracy: 0.8784334496303927\n",
      "Iteration: 47872, Loss: 0.04403094947338104, Accuracy: 0.8799804680165835\n",
      "Iteration: 47936, Loss: 0.02948138304054737, Accuracy: 0.8854203053633682\n",
      "Iteration: 48000, Loss: 0.01651393622159958, Accuracy: 0.8794413289870135\n",
      "Iteration: 48064, Loss: 0.010018163360655308, Accuracy: 0.8789148035866674\n",
      "Iteration: 48128, Loss: 0.012999395839869976, Accuracy: 0.8841750221909024\n",
      "Iteration: 48192, Loss: 0.08605761080980301, Accuracy: 0.8860882522712927\n",
      "Iteration: 48256, Loss: 0.003656016429886222, Accuracy: 0.8862775865418371\n",
      "Iteration: 48320, Loss: 0.08409769088029861, Accuracy: 0.8768290577281732\n",
      "Iteration: 48384, Loss: 0.08123081177473068, Accuracy: 0.8890829321171623\n",
      "Iteration: 48448, Loss: 0.0909476950764656, Accuracy: 0.8841405202983879\n",
      "Iteration: 48512, Loss: 0.0015266634291037917, Accuracy: 0.8885073382407427\n",
      "Iteration: 48576, Loss: 0.03871377184987068, Accuracy: 0.8903347727609798\n",
      "Iteration: 48640, Loss: 0.09356951713562012, Accuracy: 0.8874209437344689\n",
      "Iteration: 48704, Loss: 0.008734324015676975, Accuracy: 0.8852094892645255\n",
      "Iteration: 48768, Loss: 0.09412067383527756, Accuracy: 0.8868841618532315\n",
      "Iteration: 48832, Loss: 0.0014701689360663295, Accuracy: 0.8909435205569025\n",
      "Iteration: 48896, Loss: 0.08515217155218124, Accuracy: 0.8820908234920353\n",
      "Iteration: 48960, Loss: 0.07172972708940506, Accuracy: 0.8822271017124876\n",
      "Iteration: 49024, Loss: 0.0027289753779768944, Accuracy: 0.8749887153389864\n",
      "Iteration: 49088, Loss: 0.0020077060908079147, Accuracy: 0.881891957600601\n",
      "Iteration: 49152, Loss: 0.06775704026222229, Accuracy: 0.8915329319715966\n",
      "Iteration: 49216, Loss: 0.39759719371795654, Accuracy: 0.8875370766036212\n",
      "Iteration: 49280, Loss: 0.002820168621838093, Accuracy: 0.8923125007131603\n",
      "Iteration: 49344, Loss: 0.009891770780086517, Accuracy: 0.8912548618100118\n",
      "Iteration: 49408, Loss: 0.07931428402662277, Accuracy: 0.8929838638287038\n",
      "Iteration: 49472, Loss: 0.0028041296172887087, Accuracy: 0.8916515751625411\n",
      "Iteration: 49536, Loss: 0.08000318706035614, Accuracy: 0.8923200882563833\n",
      "Iteration: 49600, Loss: 0.08928046375513077, Accuracy: 0.8931677035870962\n",
      "Iteration: 49664, Loss: 0.0030370717868208885, Accuracy: 0.8803495575848501\n",
      "Iteration: 49728, Loss: 0.08469998091459274, Accuracy: 0.891074787301477\n",
      "Iteration: 49792, Loss: 0.03770073503255844, Accuracy: 0.8906110069656279\n",
      "Iteration: 49856, Loss: 0.0021771618630737066, Accuracy: 0.8889580086979549\n",
      "Iteration: 49920, Loss: 0.003935591783374548, Accuracy: 0.8928180312504992\n",
      "Iteration: 49984, Loss: 0.0036666374653577805, Accuracy: 0.8941672662622295\n",
      "Iteration: 50048, Loss: 0.0016998866340145469, Accuracy: 0.8955938942672219\n",
      "Iteration: 50112, Loss: 0.07679519802331924, Accuracy: 0.8902398044592701\n",
      "Iteration: 50176, Loss: 0.0928196832537651, Accuracy: 0.8907710904604755\n",
      "Iteration: 50240, Loss: 0.08523884415626526, Accuracy: 0.8915653137955815\n",
      "Iteration: 50304, Loss: 0.002101394347846508, Accuracy: 0.8915620128100272\n",
      "Iteration: 50368, Loss: 0.09584855288267136, Accuracy: 0.8882664549164474\n",
      "Iteration: 50432, Loss: 0.0018892735242843628, Accuracy: 0.8961359038075898\n",
      "Iteration: 50496, Loss: 0.08554065227508545, Accuracy: 0.8936902548011858\n",
      "Iteration: 50560, Loss: 0.004389140754938126, Accuracy: 0.8806620845280122\n",
      "Iteration: 50624, Loss: 0.08545144647359848, Accuracy: 0.8924738499335945\n",
      "Iteration: 50688, Loss: 0.0796976163983345, Accuracy: 0.8967070009093732\n",
      "Iteration: 50752, Loss: 0.001828372129239142, Accuracy: 0.8925069760589395\n",
      "Iteration: 50816, Loss: 0.0008370926952920854, Accuracy: 0.8960763742215931\n",
      "Iteration: 50880, Loss: 0.0011939893011003733, Accuracy: 0.8976250816776883\n",
      "Iteration: 50944, Loss: 0.0841677188873291, Accuracy: 0.8964240066416096\n",
      "Iteration: 51008, Loss: 0.08141782134771347, Accuracy: 0.8954375741886906\n",
      "Iteration: 51072, Loss: 0.0008872730541042984, Accuracy: 0.8976497270050459\n",
      "Iteration: 51136, Loss: 0.01007242500782013, Accuracy: 0.8977649541920982\n",
      "Iteration: 51200, Loss: 0.08846066147089005, Accuracy: 0.8943301640101708\n",
      "Iteration: 51264, Loss: 0.0011502671986818314, Accuracy: 0.8901353194378316\n",
      "Iteration: 51328, Loss: 0.08176674693822861, Accuracy: 0.8933367284480482\n",
      "Iteration: 51392, Loss: 0.08289436250925064, Accuracy: 0.8802947326621506\n",
      "Iteration: 51456, Loss: 0.047314729541540146, Accuracy: 0.8939874382922426\n",
      "Iteration: 51520, Loss: 0.0006256684428080916, Accuracy: 0.8938029093260411\n",
      "Iteration: 51584, Loss: 0.08562178164720535, Accuracy: 0.8922033876879141\n",
      "Iteration: 51648, Loss: 0.08355789631605148, Accuracy: 0.8904895465821028\n",
      "Iteration: 51712, Loss: 0.0011773782316595316, Accuracy: 0.8985343718086369\n",
      "Iteration: 51776, Loss: 0.0919332504272461, Accuracy: 0.8944323158648331\n",
      "Iteration: 51840, Loss: 0.09885787963867188, Accuracy: 0.8909453550877515\n",
      "Iteration: 51904, Loss: 0.10331853479146957, Accuracy: 0.8944405814690981\n",
      "Iteration: 51968, Loss: 0.0707952231168747, Accuracy: 0.9009257553261705\n",
      "Iteration: 52032, Loss: 0.0011541928397491574, Accuracy: 0.9028731726575643\n",
      "Iteration: 52096, Loss: 0.09622189402580261, Accuracy: 0.892983859666856\n",
      "Iteration: 52160, Loss: 0.00198483862914145, Accuracy: 0.9022455587983131\n",
      "Iteration: 52224, Loss: 0.0008615162223577499, Accuracy: 0.9039605804719031\n",
      "Iteration: 52288, Loss: 0.004814759362488985, Accuracy: 0.9038832759833895\n",
      "Iteration: 52352, Loss: 0.0008986794273369014, Accuracy: 0.9078376078396104\n",
      "Iteration: 52416, Loss: 0.06370481848716736, Accuracy: 0.9040421363315545\n",
      "Iteration: 52480, Loss: 0.0035691335797309875, Accuracy: 0.912078511697473\n",
      "Iteration: 52544, Loss: 0.005218347534537315, Accuracy: 0.9147913847409654\n",
      "Iteration: 52608, Loss: 0.005841307807713747, Accuracy: 0.9106172622268787\n",
      "Iteration: 52672, Loss: 0.035920627415180206, Accuracy: 0.9050303605617955\n",
      "Iteration: 52736, Loss: 0.003794790944084525, Accuracy: 0.9139935928396881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 52800, Loss: 0.07409984618425369, Accuracy: 0.9160122950706864\n",
      "Iteration: 52864, Loss: 0.0005402543465606868, Accuracy: 0.926740289767622\n",
      "Iteration: 52928, Loss: 0.00030042376602068543, Accuracy: 0.9237790101469727\n",
      "Iteration: 52992, Loss: 0.0039384071715176105, Accuracy: 0.9236119820852764\n",
      "Iteration: 53056, Loss: 0.07489369809627533, Accuracy: 0.9237147709354758\n",
      "Iteration: 53120, Loss: 0.012650656513869762, Accuracy: 0.9272078701615101\n",
      "Iteration: 53184, Loss: 0.0007948825950734317, Accuracy: 0.9244605631829472\n",
      "Iteration: 53248, Loss: 0.0005491534830071032, Accuracy: 0.9237953141564503\n",
      "Iteration: 53312, Loss: 0.03441094979643822, Accuracy: 0.9310105927579571\n",
      "Iteration: 53376, Loss: 0.005127600394189358, Accuracy: 0.9394049831316806\n",
      "Iteration: 53440, Loss: 0.0006246650009416044, Accuracy: 0.9357452332624234\n",
      "Iteration: 53504, Loss: 0.0004369582748040557, Accuracy: 0.9457856276276289\n",
      "Iteration: 53568, Loss: 0.00502958195284009, Accuracy: 0.9360074170981534\n",
      "Iteration: 53632, Loss: 0.0021164552308619022, Accuracy: 0.9348226973233977\n",
      "Iteration: 53696, Loss: 0.0004355234559625387, Accuracy: 0.9373522248206427\n",
      "Iteration: 53760, Loss: 0.007225165609270334, Accuracy: 0.9492933467263356\n",
      "Iteration: 53824, Loss: 0.006019755732268095, Accuracy: 0.94938276548055\n",
      "Iteration: 53888, Loss: 0.000417388480855152, Accuracy: 0.9486241020640591\n",
      "Iteration: 53952, Loss: 0.0002971329085994512, Accuracy: 0.9560832844581455\n",
      "Iteration: 54016, Loss: 0.0006060712621547282, Accuracy: 0.9527764937811298\n",
      "Iteration: 54080, Loss: 0.011934573762118816, Accuracy: 0.939680623851018\n",
      "Iteration: 54144, Loss: 0.004085810389369726, Accuracy: 0.9476591054699384\n",
      "Iteration: 54208, Loss: 0.010881751775741577, Accuracy: 0.9445213407743722\n",
      "Iteration: 54272, Loss: 0.00024371636391151696, Accuracy: 0.9555680424964521\n",
      "Iteration: 54336, Loss: 0.00033802539110183716, Accuracy: 0.9572830111501389\n",
      "Iteration: 54400, Loss: 0.0029296844732016325, Accuracy: 0.9549216859595617\n",
      "Iteration: 54464, Loss: 0.00600576912984252, Accuracy: 0.9585617921547964\n",
      "Iteration: 54528, Loss: 0.00034851953387260437, Accuracy: 0.9543118679284817\n",
      "Iteration: 54592, Loss: 0.000100721612398047, Accuracy: 0.958071223773004\n",
      "Iteration: 54656, Loss: 0.0003238158824387938, Accuracy: 0.9635145654174266\n",
      "Iteration: 54720, Loss: 0.0010198568925261497, Accuracy: 0.9431590315507492\n",
      "Iteration: 54784, Loss: 0.013886422850191593, Accuracy: 0.9595113021205179\n",
      "Iteration: 54848, Loss: 0.00036515810643322766, Accuracy: 0.9638550992676755\n",
      "Iteration: 54912, Loss: 0.0001832784473663196, Accuracy: 0.9600804366200464\n",
      "Iteration: 54976, Loss: 0.0041592963971197605, Accuracy: 0.9653505144960945\n",
      "Iteration: 55040, Loss: 0.002728051505982876, Accuracy: 0.9578064559755148\n",
      "Iteration: 55104, Loss: 0.004902643617242575, Accuracy: 0.9641452601645142\n",
      "Iteration: 55168, Loss: 0.004245778080075979, Accuracy: 0.9638927916676039\n",
      "Iteration: 55232, Loss: 0.011993874795734882, Accuracy: 0.9634173276863294\n",
      "Iteration: 55296, Loss: 0.0028813062235713005, Accuracy: 0.9651729983525001\n",
      "Iteration: 55360, Loss: 0.0002987153420690447, Accuracy: 0.9533561276184628\n",
      "Iteration: 55424, Loss: 0.0006057303980924189, Accuracy: 0.9707686485853628\n",
      "Saved fullModel_dr[3]_replicate1.model\n",
      "Saved W_dr[3]_replicate1.p\n",
      "3 1.0 [1.0, 1.0, 1.0]\n",
      "Saved w_dr[3]_replicate1.p\n",
      "Replicate 1 completed\n",
      "Time elapsed: 329.859375 seconds\n",
      "Iteration: 64, Loss: 0.24665386974811554, Accuracy: 0.49990220880135894\n",
      "Iteration: 128, Loss: 0.26950517296791077, Accuracy: 0.5003115111030638\n",
      "Iteration: 192, Loss: 0.25197526812553406, Accuracy: 0.5014661150053144\n",
      "Iteration: 256, Loss: 0.24711249768733978, Accuracy: 0.509506749920547\n",
      "Iteration: 320, Loss: 0.19123075902462006, Accuracy: 0.5489626629278064\n",
      "Iteration: 384, Loss: 0.18449284136295319, Accuracy: 0.5957497810013592\n",
      "Iteration: 448, Loss: 0.19157953560352325, Accuracy: 0.6185655184090137\n",
      "Iteration: 512, Loss: 0.21684487164020538, Accuracy: 0.6271832040511072\n",
      "Iteration: 576, Loss: 0.17463898658752441, Accuracy: 0.6349343154579401\n",
      "Iteration: 640, Loss: 0.15474165976047516, Accuracy: 0.6405581538565457\n",
      "Iteration: 704, Loss: 0.16760475933551788, Accuracy: 0.6437643123790622\n",
      "Iteration: 768, Loss: 0.15112309157848358, Accuracy: 0.6495409929193556\n",
      "Iteration: 832, Loss: 0.1472482532262802, Accuracy: 0.6525544761680067\n",
      "Iteration: 896, Loss: 0.14692752063274384, Accuracy: 0.6540283760987222\n",
      "Iteration: 960, Loss: 0.16404733061790466, Accuracy: 0.6588725266046822\n",
      "Iteration: 1024, Loss: 0.14938302338123322, Accuracy: 0.6623311056755483\n",
      "Iteration: 1088, Loss: 0.19305162131786346, Accuracy: 0.6671810341067612\n",
      "Iteration: 1152, Loss: 0.15535831451416016, Accuracy: 0.6697275987826288\n",
      "Iteration: 1216, Loss: 0.1512872576713562, Accuracy: 0.6721039065159857\n",
      "Iteration: 1280, Loss: 0.14959649741649628, Accuracy: 0.6756495190784335\n",
      "Iteration: 1344, Loss: 0.10075225681066513, Accuracy: 0.6814103126525879\n",
      "Iteration: 1408, Loss: 0.09721972793340683, Accuracy: 0.681016440037638\n",
      "Iteration: 1472, Loss: 0.13472916185855865, Accuracy: 0.6893669641576707\n",
      "Iteration: 1536, Loss: 0.19036398828029633, Accuracy: 0.6923885154537857\n",
      "Iteration: 1600, Loss: 0.11404410004615784, Accuracy: 0.6944606485776603\n",
      "Iteration: 1664, Loss: 0.15522794425487518, Accuracy: 0.6956536809448153\n",
      "Iteration: 1728, Loss: 0.1367155909538269, Accuracy: 0.7024151259101927\n",
      "Iteration: 1792, Loss: 0.10974189639091492, Accuracy: 0.7007218818180263\n",
      "Iteration: 1856, Loss: 0.13578413426876068, Accuracy: 0.7101932873483747\n",
      "Iteration: 1920, Loss: 0.10551679879426956, Accuracy: 0.7141227121464908\n",
      "Iteration: 1984, Loss: 0.11395213752985, Accuracy: 0.7142629863228649\n",
      "Iteration: 2048, Loss: 0.10837003588676453, Accuracy: 0.7139473003335297\n",
      "Iteration: 2112, Loss: 0.13619843125343323, Accuracy: 0.7220180758740753\n",
      "Iteration: 2176, Loss: 0.08259917795658112, Accuracy: 0.7254307018592954\n",
      "Iteration: 2240, Loss: 0.08350785821676254, Accuracy: 0.723379751201719\n",
      "Iteration: 2304, Loss: 0.1330675631761551, Accuracy: 0.7212226644624025\n",
      "Iteration: 2368, Loss: 0.12604738771915436, Accuracy: 0.7242811352480203\n",
      "Iteration: 2432, Loss: 0.0845678448677063, Accuracy: 0.7361518843099475\n",
      "Iteration: 2496, Loss: 0.1014934554696083, Accuracy: 0.7442701414693147\n",
      "Iteration: 2560, Loss: 0.10799574851989746, Accuracy: 0.7435569274239242\n",
      "Iteration: 2624, Loss: 0.15852904319763184, Accuracy: 0.7382213249802589\n",
      "Iteration: 2688, Loss: 0.09963420778512955, Accuracy: 0.7443383005447686\n",
      "Iteration: 2752, Loss: 0.14591892063617706, Accuracy: 0.7455259419512004\n",
      "Iteration: 2816, Loss: 0.12601183354854584, Accuracy: 0.7556992920581251\n",
      "Iteration: 2880, Loss: 0.10981900244951248, Accuracy: 0.7519129710271955\n",
      "Iteration: 2944, Loss: 0.12671886384487152, Accuracy: 0.7524551264941692\n",
      "Iteration: 3008, Loss: 0.08206000924110413, Accuracy: 0.7544627848546952\n",
      "Iteration: 3072, Loss: 0.08531896024942398, Accuracy: 0.7604017150588334\n",
      "Iteration: 3136, Loss: 0.11838803440332413, Accuracy: 0.7565024516079575\n",
      "Iteration: 3200, Loss: 0.0976385846734047, Accuracy: 0.7536313170567155\n",
      "Iteration: 3264, Loss: 0.10967379808425903, Accuracy: 0.7597020706161857\n",
      "Iteration: 3328, Loss: 0.09886360168457031, Accuracy: 0.7617870261892676\n",
      "Iteration: 3392, Loss: 0.07057429850101471, Accuracy: 0.7688979774247855\n",
      "Iteration: 3456, Loss: 0.08285368233919144, Accuracy: 0.7713662120513618\n",
      "Iteration: 3520, Loss: 0.12065169960260391, Accuracy: 0.7670373886357993\n",
      "Iteration: 3584, Loss: 0.07955798506736755, Accuracy: 0.7714870802592486\n",
      "Iteration: 3648, Loss: 0.13093611598014832, Accuracy: 0.762916129315272\n",
      "Iteration: 3712, Loss: 0.09723997116088867, Accuracy: 0.7690424614120275\n",
      "Iteration: 3776, Loss: 0.07102086395025253, Accuracy: 0.783234357368201\n",
      "Iteration: 3840, Loss: 0.07854428887367249, Accuracy: 0.7779214621987194\n",
      "Iteration: 3904, Loss: 0.07733041793107986, Accuracy: 0.7799040132667869\n",
      "Iteration: 3968, Loss: 0.10579794645309448, Accuracy: 0.7739877414423972\n",
      "Iteration: 4032, Loss: 0.06441181153059006, Accuracy: 0.7788653518073261\n",
      "Iteration: 4096, Loss: 0.07222184538841248, Accuracy: 0.7840777051169425\n",
      "Iteration: 4160, Loss: 0.07247158885002136, Accuracy: 0.7660499138291925\n",
      "Iteration: 4224, Loss: 0.11962137371301651, Accuracy: 0.785704139387235\n",
      "Iteration: 4288, Loss: 0.11518121510744095, Accuracy: 0.7853532782755792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4352, Loss: 0.1010415330529213, Accuracy: 0.7955904630944133\n",
      "Iteration: 4416, Loss: 0.05535599961876869, Accuracy: 0.7902975163888186\n",
      "Iteration: 4480, Loss: 0.07089933753013611, Accuracy: 0.7930941635277122\n",
      "Iteration: 4544, Loss: 0.07482155412435532, Accuracy: 0.7912050483282655\n",
      "Iteration: 4608, Loss: 0.07834302634000778, Accuracy: 0.7945695691742003\n",
      "Iteration: 4672, Loss: 0.02044006995856762, Accuracy: 0.8009486356750131\n",
      "Iteration: 4736, Loss: 0.11587297916412354, Accuracy: 0.7956936717964709\n",
      "Iteration: 4800, Loss: 0.14346283674240112, Accuracy: 0.8032651828834787\n",
      "Iteration: 4864, Loss: 0.07709448784589767, Accuracy: 0.8009328943444416\n",
      "Iteration: 4928, Loss: 0.10563699156045914, Accuracy: 0.810105299577117\n",
      "Iteration: 4992, Loss: 0.10106227546930313, Accuracy: 0.8080447175307199\n",
      "Iteration: 5056, Loss: 0.09799864143133163, Accuracy: 0.8082402931759134\n",
      "Iteration: 5120, Loss: 0.10048806667327881, Accuracy: 0.8072631349787116\n",
      "Iteration: 5184, Loss: 0.10987186431884766, Accuracy: 0.8111211839132011\n",
      "Iteration: 5248, Loss: 0.06637706607580185, Accuracy: 0.8158450404880568\n",
      "Iteration: 5312, Loss: 0.03536379709839821, Accuracy: 0.8204521595034748\n",
      "Iteration: 5376, Loss: 0.05370825156569481, Accuracy: 0.8235208629630506\n",
      "Iteration: 5440, Loss: 0.0374285988509655, Accuracy: 0.8158102651359513\n",
      "Iteration: 5504, Loss: 0.0481516532599926, Accuracy: 0.8300784962484613\n",
      "Iteration: 5568, Loss: 0.029213478788733482, Accuracy: 0.8429684803122655\n",
      "Iteration: 5632, Loss: 0.09879448264837265, Accuracy: 0.8229593801079318\n",
      "Iteration: 5696, Loss: 0.09700792282819748, Accuracy: 0.8303563938243315\n",
      "Iteration: 5760, Loss: 0.06876695901155472, Accuracy: 0.846252592978999\n",
      "Iteration: 5824, Loss: 0.04930998012423515, Accuracy: 0.8369674005080014\n",
      "Iteration: 5888, Loss: 0.08228179067373276, Accuracy: 0.835659422329627\n",
      "Iteration: 5952, Loss: 0.04943045973777771, Accuracy: 0.8440941593144089\n",
      "Iteration: 6016, Loss: 0.03519105538725853, Accuracy: 0.8496750701451674\n",
      "Iteration: 6080, Loss: 0.10984239727258682, Accuracy: 0.8457313248654827\n",
      "Iteration: 6144, Loss: 0.014499018900096416, Accuracy: 0.857996458071284\n",
      "Iteration: 6208, Loss: 0.06389351934194565, Accuracy: 0.8549977350048721\n",
      "Iteration: 6272, Loss: 0.03142545744776726, Accuracy: 0.8598062075907364\n",
      "Iteration: 6336, Loss: 0.0193841103464365, Accuracy: 0.8627250607823953\n",
      "Iteration: 6400, Loss: 0.019884027540683746, Accuracy: 0.8675157187972218\n",
      "Iteration: 6464, Loss: 0.04009314998984337, Accuracy: 0.8734448424074799\n",
      "Iteration: 6528, Loss: 0.03222670778632164, Accuracy: 0.8675479900557548\n",
      "Iteration: 6592, Loss: 0.060109224170446396, Accuracy: 0.8630527034401894\n",
      "Iteration: 6656, Loss: 0.07884691655635834, Accuracy: 0.8682868004543707\n",
      "Iteration: 6720, Loss: 0.054677318781614304, Accuracy: 0.8714236166561022\n",
      "Iteration: 6784, Loss: 0.041240692138671875, Accuracy: 0.8777758112410083\n",
      "Iteration: 6848, Loss: 0.06715714931488037, Accuracy: 0.8759513966506347\n",
      "Iteration: 6912, Loss: 0.02543388307094574, Accuracy: 0.8826935906545259\n",
      "Iteration: 6976, Loss: 0.009598015807569027, Accuracy: 0.8802186192478985\n",
      "Iteration: 7040, Loss: 0.02552821673452854, Accuracy: 0.8807834451436065\n",
      "Iteration: 7104, Loss: 0.014588904567062855, Accuracy: 0.8754343789769337\n",
      "Iteration: 7168, Loss: 0.03359631076455116, Accuracy: 0.8794527684804052\n",
      "Iteration: 7232, Loss: 0.017086336389183998, Accuracy: 0.8864004003116861\n",
      "Iteration: 7296, Loss: 0.020472221076488495, Accuracy: 0.8873363175662234\n",
      "Iteration: 7360, Loss: 0.027775170281529427, Accuracy: 0.8939911548513919\n",
      "Iteration: 7424, Loss: 0.006168684456497431, Accuracy: 0.8856117441901006\n",
      "Iteration: 7488, Loss: 0.01346359308809042, Accuracy: 0.8951964660664089\n",
      "Iteration: 7552, Loss: 0.015708163380622864, Accuracy: 0.8940934081911109\n",
      "Iteration: 7616, Loss: 0.008125378750264645, Accuracy: 0.8937872884562239\n",
      "Iteration: 7680, Loss: 0.016636906191706657, Accuracy: 0.9013122344040312\n",
      "Iteration: 7744, Loss: 0.01842958852648735, Accuracy: 0.9012066346476786\n",
      "Iteration: 7808, Loss: 0.014918133616447449, Accuracy: 0.9018011426087469\n",
      "Iteration: 7872, Loss: 0.06598952412605286, Accuracy: 0.9020510667469352\n",
      "Iteration: 7936, Loss: 0.007286986336112022, Accuracy: 0.9075412735110149\n",
      "Iteration: 8000, Loss: 0.009447007440030575, Accuracy: 0.9081285780994222\n",
      "Iteration: 8064, Loss: 0.011110159568488598, Accuracy: 0.9136063574114814\n",
      "Iteration: 8128, Loss: 0.005273379385471344, Accuracy: 0.9156476131174713\n",
      "Iteration: 8192, Loss: 0.021462155506014824, Accuracy: 0.9096155563020147\n",
      "Iteration: 8256, Loss: 0.004043970722705126, Accuracy: 0.9166037068935111\n",
      "Iteration: 8320, Loss: 0.006725717335939407, Accuracy: 0.9150808433187194\n",
      "Iteration: 8384, Loss: 0.007001069840043783, Accuracy: 0.9212229875265621\n",
      "Iteration: 8448, Loss: 0.008700278587639332, Accuracy: 0.9229525725240819\n",
      "Iteration: 8512, Loss: 0.0035836186725646257, Accuracy: 0.9207441703183576\n",
      "Iteration: 8576, Loss: 0.005500272382050753, Accuracy: 0.9193058693199418\n",
      "Iteration: 8640, Loss: 0.002500290749594569, Accuracy: 0.9161823901231401\n",
      "Iteration: 8704, Loss: 0.0038678955752402544, Accuracy: 0.9225198913482018\n",
      "Iteration: 8768, Loss: 0.0036977084819227457, Accuracy: 0.9118714802898467\n",
      "Iteration: 8832, Loss: 0.002933463780209422, Accuracy: 0.9245641230954789\n",
      "Iteration: 8896, Loss: 0.011504259891808033, Accuracy: 0.9245160021819174\n",
      "Iteration: 8960, Loss: 0.008557937107980251, Accuracy: 0.925935412698891\n",
      "Iteration: 9024, Loss: 0.018526650965213776, Accuracy: 0.9250937285833061\n",
      "Iteration: 9088, Loss: 0.0034516341984272003, Accuracy: 0.9247714199591428\n",
      "Iteration: 9152, Loss: 0.0037461556494235992, Accuracy: 0.9309169117477722\n",
      "Iteration: 9216, Loss: 0.4494689404964447, Accuracy: 0.9193696113070473\n",
      "Iteration: 9280, Loss: 0.02096838504076004, Accuracy: 0.9343226137862075\n",
      "Iteration: 9344, Loss: 0.00229138252325356, Accuracy: 0.9192723580054007\n",
      "Iteration: 9408, Loss: 0.007677436340600252, Accuracy: 0.936226012185216\n",
      "Iteration: 9472, Loss: 0.012914580292999744, Accuracy: 0.9341105727653485\n",
      "Iteration: 9536, Loss: 0.005192936863750219, Accuracy: 0.9355257239076309\n",
      "Iteration: 9600, Loss: 0.006116080563515425, Accuracy: 0.9392763398354873\n",
      "Iteration: 9664, Loss: 0.01195546705275774, Accuracy: 0.9379911734140478\n",
      "Iteration: 9728, Loss: 0.0020444386173039675, Accuracy: 0.9414586022612639\n",
      "Iteration: 9792, Loss: 0.009523549117147923, Accuracy: 0.9444269866799004\n",
      "Iteration: 9856, Loss: 0.009220052510499954, Accuracy: 0.9468468357808888\n",
      "Iteration: 9920, Loss: 0.0035341971088200808, Accuracy: 0.947041472652927\n",
      "Iteration: 9984, Loss: 0.03323335200548172, Accuracy: 0.9436874569219071\n",
      "Iteration: 10048, Loss: 0.0023829189594835043, Accuracy: 0.9369415559340268\n",
      "Iteration: 10112, Loss: 0.002996864728629589, Accuracy: 0.930231358477613\n",
      "Iteration: 10176, Loss: 0.009597287513315678, Accuracy: 0.9364863144000992\n",
      "Iteration: 10240, Loss: 0.005581750068813562, Accuracy: 0.9457372592296451\n",
      "Iteration: 10304, Loss: 0.0017484560376033187, Accuracy: 0.9468575567007065\n",
      "Iteration: 10368, Loss: 0.008346444927155972, Accuracy: 0.9499835701135453\n",
      "Iteration: 10432, Loss: 0.005294967908412218, Accuracy: 0.9467560338671319\n",
      "Iteration: 10496, Loss: 0.0011561965802684426, Accuracy: 0.9485586217197124\n",
      "Iteration: 10560, Loss: 0.0022391655948013067, Accuracy: 0.9471389432437718\n",
      "Iteration: 10624, Loss: 0.00870972778648138, Accuracy: 0.9499022545351181\n",
      "Iteration: 10688, Loss: 0.004355792421847582, Accuracy: 0.9498724846052937\n",
      "Iteration: 10752, Loss: 0.004541866481304169, Accuracy: 0.9515140310977586\n",
      "Iteration: 10816, Loss: 0.00386446132324636, Accuracy: 0.9548817866598256\n",
      "Iteration: 10880, Loss: 0.003050023689866066, Accuracy: 0.9514503270329442\n",
      "Iteration: 10944, Loss: 0.002792229875922203, Accuracy: 0.9492418298323173\n",
      "Iteration: 11008, Loss: 0.00225520390085876, Accuracy: 0.9503883250872605\n",
      "Iteration: 11072, Loss: 0.004203787073493004, Accuracy: 0.9584794878319371\n",
      "Iteration: 11136, Loss: 0.0010651791235432029, Accuracy: 0.9508728520886507\n",
      "Iteration: 11200, Loss: 0.0047111897729337215, Accuracy: 0.9549789559387136\n",
      "Iteration: 11264, Loss: 0.001937619410455227, Accuracy: 0.9431000328040682\n",
      "Iteration: 11328, Loss: 0.006727563217282295, Accuracy: 0.9547030205430929\n",
      "Iteration: 11392, Loss: 0.000946537300478667, Accuracy: 0.9599292403290747\n",
      "Iteration: 11456, Loss: 0.0021822380367666483, Accuracy: 0.9563087223214097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 11520, Loss: 0.009294484741985798, Accuracy: 0.9580107388610486\n",
      "Iteration: 11584, Loss: 0.011896793730556965, Accuracy: 0.9545766151277348\n",
      "Iteration: 11648, Loss: 0.0007351590902544558, Accuracy: 0.9541686943848617\n",
      "Iteration: 11712, Loss: 0.021745974197983742, Accuracy: 0.9553209770820104\n",
      "Iteration: 11776, Loss: 0.0018085666233673692, Accuracy: 0.9628840479272185\n",
      "Iteration: 11840, Loss: 0.005942696239799261, Accuracy: 0.9636984831740847\n",
      "Iteration: 11904, Loss: 0.0025337899569422007, Accuracy: 0.958452842081897\n",
      "Iteration: 11968, Loss: 0.0030891040805727243, Accuracy: 0.9495085186499637\n",
      "Iteration: 12032, Loss: 0.004154978785663843, Accuracy: 0.9606055125186685\n",
      "Iteration: 12096, Loss: 0.00323416106402874, Accuracy: 0.9645891546533676\n",
      "Iteration: 12160, Loss: 0.0026024121325463057, Accuracy: 0.9633958689228166\n",
      "Iteration: 12224, Loss: 0.0007767036440782249, Accuracy: 0.9685751050565159\n",
      "Iteration: 12288, Loss: 0.0024197890888899565, Accuracy: 0.9681309577281354\n",
      "Iteration: 12352, Loss: 0.0015084162587299943, Accuracy: 0.967625834629871\n",
      "Iteration: 12416, Loss: 0.00047855032607913017, Accuracy: 0.9703378271078691\n",
      "Saved fullModel_dr[3]_replicate2.model\n",
      "Saved W_dr[3]_replicate2.p\n",
      "3 1.0 [1.0, 1.0, 1.0]\n",
      "Saved w_dr[3]_replicate2.p\n",
      "Replicate 2 completed\n",
      "Time elapsed: 343.5625 seconds\n",
      "Iteration: 64, Loss: 0.2787221372127533, Accuracy: 0.49926349939778447\n",
      "Iteration: 128, Loss: 0.23302052915096283, Accuracy: 0.5033775488846004\n",
      "Iteration: 192, Loss: 0.2259688377380371, Accuracy: 0.5269469167105854\n",
      "Iteration: 256, Loss: 0.17603974044322968, Accuracy: 0.5719281057827175\n",
      "Iteration: 320, Loss: 0.19122080504894257, Accuracy: 0.5987714775837958\n",
      "Iteration: 384, Loss: 0.18707890808582306, Accuracy: 0.6149255223572254\n",
      "Iteration: 448, Loss: 0.16004161536693573, Accuracy: 0.6236822437494993\n",
      "Iteration: 512, Loss: 0.16509486734867096, Accuracy: 0.6291077099740505\n",
      "Iteration: 576, Loss: 0.1705658882856369, Accuracy: 0.6332873967476189\n",
      "Iteration: 640, Loss: 0.16157574951648712, Accuracy: 0.6373011246323586\n",
      "Iteration: 704, Loss: 0.16239957511425018, Accuracy: 0.6410357356071472\n",
      "Iteration: 768, Loss: 0.17059747874736786, Accuracy: 0.6425317511893809\n",
      "Iteration: 832, Loss: 0.1707180291414261, Accuracy: 0.6448787678964436\n",
      "Iteration: 896, Loss: 0.17843042314052582, Accuracy: 0.6436793124303222\n",
      "Iteration: 960, Loss: 0.16144543886184692, Accuracy: 0.642727789003402\n",
      "Iteration: 1024, Loss: 0.16741329431533813, Accuracy: 0.6486391089856625\n",
      "Iteration: 1088, Loss: 0.1738658994436264, Accuracy: 0.6502272435463965\n",
      "Iteration: 1152, Loss: 0.16883955895900726, Accuracy: 0.6528407745063305\n",
      "Iteration: 1216, Loss: 0.17015604674816132, Accuracy: 0.6530434209853411\n",
      "Iteration: 1280, Loss: 0.178466334939003, Accuracy: 0.6542016039602458\n",
      "Iteration: 1344, Loss: 0.14058245718479156, Accuracy: 0.6558659025467932\n",
      "Iteration: 1408, Loss: 0.16458743810653687, Accuracy: 0.6609577964991331\n",
      "Iteration: 1472, Loss: 0.14365896582603455, Accuracy: 0.6627917946316302\n",
      "Iteration: 1536, Loss: 0.1364198476076126, Accuracy: 0.6682729651220143\n",
      "Iteration: 1600, Loss: 0.16018007695674896, Accuracy: 0.6749821826815605\n",
      "Iteration: 1664, Loss: 0.2121240645647049, Accuracy: 0.67759665613994\n",
      "Iteration: 1728, Loss: 0.1848924607038498, Accuracy: 0.6721311346627772\n",
      "Iteration: 1792, Loss: 0.16333134472370148, Accuracy: 0.6843610964715481\n",
      "Iteration: 1856, Loss: 0.11700164526700974, Accuracy: 0.6829612669534981\n",
      "Iteration: 1920, Loss: 0.1386597901582718, Accuracy: 0.6876050597056746\n",
      "Iteration: 1984, Loss: 0.1119517982006073, Accuracy: 0.6899846489541233\n",
      "Iteration: 2048, Loss: 0.11525871604681015, Accuracy: 0.7015868593007326\n",
      "Iteration: 2112, Loss: 0.11759582906961441, Accuracy: 0.7005560328252614\n",
      "Iteration: 2176, Loss: 0.09057249873876572, Accuracy: 0.7004614812321961\n",
      "Iteration: 2240, Loss: 0.11274708062410355, Accuracy: 0.7085123632568866\n",
      "Iteration: 2304, Loss: 0.08393677324056625, Accuracy: 0.7066138295922428\n",
      "Iteration: 2368, Loss: 0.1460983008146286, Accuracy: 0.7173840999603271\n",
      "Iteration: 2432, Loss: 0.09130904078483582, Accuracy: 0.7252463083714247\n",
      "Iteration: 2496, Loss: 0.24023045599460602, Accuracy: 0.7211760783102363\n",
      "Iteration: 2560, Loss: 0.1448790282011032, Accuracy: 0.7214098125696182\n",
      "Iteration: 2624, Loss: 0.11214057356119156, Accuracy: 0.7245149642694741\n",
      "Iteration: 2688, Loss: 0.0942106544971466, Accuracy: 0.737123453989625\n",
      "Iteration: 2752, Loss: 0.08284928649663925, Accuracy: 0.7348886106628925\n",
      "Iteration: 2816, Loss: 0.07735419273376465, Accuracy: 0.7410961447749287\n",
      "Iteration: 2880, Loss: 0.13102246820926666, Accuracy: 0.7441823754925281\n",
      "Iteration: 2944, Loss: 0.16617681086063385, Accuracy: 0.7530536430422217\n",
      "Iteration: 3008, Loss: 0.09725277870893478, Accuracy: 0.7487337836064398\n",
      "Iteration: 3072, Loss: 0.1788550764322281, Accuracy: 0.7611402156762779\n",
      "Iteration: 3136, Loss: 0.10717727988958359, Accuracy: 0.7494691447354853\n",
      "Iteration: 3200, Loss: 0.10161521285772324, Accuracy: 0.7557494495995343\n",
      "Iteration: 3264, Loss: 0.09612827748060226, Accuracy: 0.7476108607370406\n",
      "Iteration: 3328, Loss: 0.14506807923316956, Accuracy: 0.7547323820181191\n",
      "Iteration: 3392, Loss: 0.10434887558221817, Accuracy: 0.759102476760745\n",
      "Iteration: 3456, Loss: 0.12193745374679565, Accuracy: 0.7658995457459241\n",
      "Iteration: 3520, Loss: 0.07767776399850845, Accuracy: 0.7730783699080348\n",
      "Iteration: 3584, Loss: 0.07908821105957031, Accuracy: 0.7682507182471454\n",
      "Iteration: 3648, Loss: 0.082447849214077, Accuracy: 0.7584073680918664\n",
      "Iteration: 3712, Loss: 0.09819096326828003, Accuracy: 0.7698100835550576\n",
      "Iteration: 3776, Loss: 0.07323919981718063, Accuracy: 0.7771118213422596\n",
      "Iteration: 3840, Loss: 0.09942241758108139, Accuracy: 0.7766243822406977\n",
      "Iteration: 3904, Loss: 0.0750250443816185, Accuracy: 0.7744057532399893\n",
      "Iteration: 3968, Loss: 0.10442811250686646, Accuracy: 0.770734659396112\n",
      "Iteration: 4032, Loss: 0.10440083593130112, Accuracy: 0.7762472350150347\n",
      "Iteration: 4096, Loss: 0.10564450174570084, Accuracy: 0.7786941663362086\n",
      "Iteration: 4160, Loss: 0.07885512709617615, Accuracy: 0.7577866395004094\n",
      "Iteration: 4224, Loss: 0.09315613657236099, Accuracy: 0.7675887297373265\n",
      "Iteration: 4288, Loss: 0.08947066217660904, Accuracy: 0.7618785458616912\n",
      "Iteration: 4352, Loss: 0.08805791288614273, Accuracy: 0.771684518782422\n",
      "Iteration: 4416, Loss: 0.08055026084184647, Accuracy: 0.7875684837345034\n",
      "Iteration: 4480, Loss: 0.08724696189165115, Accuracy: 0.7757167047820985\n",
      "Iteration: 4544, Loss: 0.10691218823194504, Accuracy: 0.7777835833840072\n",
      "Iteration: 4608, Loss: 0.08206627517938614, Accuracy: 0.7666899387259036\n",
      "Iteration: 4672, Loss: 0.09070152044296265, Accuracy: 0.7930184556171298\n",
      "Iteration: 4736, Loss: 0.0701989009976387, Accuracy: 0.7901211413554847\n",
      "Iteration: 4800, Loss: 0.07230637222528458, Accuracy: 0.7861148722004145\n",
      "Iteration: 4864, Loss: 0.07877113670110703, Accuracy: 0.7887756214477122\n",
      "Iteration: 4928, Loss: 0.13811345398426056, Accuracy: 0.7896322798915207\n",
      "Iteration: 4992, Loss: 0.08732680231332779, Accuracy: 0.7877929424867034\n",
      "Iteration: 5056, Loss: 0.0811411440372467, Accuracy: 0.7907049264758825\n",
      "Iteration: 5120, Loss: 0.09267575293779373, Accuracy: 0.788137923926115\n",
      "Iteration: 5184, Loss: 0.09386542439460754, Accuracy: 0.7951709202025086\n",
      "Iteration: 5248, Loss: 0.07319073379039764, Accuracy: 0.7926061851903796\n",
      "Iteration: 5312, Loss: 0.08929482102394104, Accuracy: 0.7943775064777583\n",
      "Iteration: 5376, Loss: 0.1144261583685875, Accuracy: 0.797650219174102\n",
      "Iteration: 5440, Loss: 0.07156073302030563, Accuracy: 0.7853880594484508\n",
      "Iteration: 5504, Loss: 0.0842827558517456, Accuracy: 0.7815604906063527\n",
      "Iteration: 5568, Loss: 0.08170238882303238, Accuracy: 0.8006440047174692\n",
      "Iteration: 5632, Loss: 0.07403293251991272, Accuracy: 0.7935101494658738\n",
      "Iteration: 5696, Loss: 0.06707818061113358, Accuracy: 0.8029450890608132\n",
      "Iteration: 5760, Loss: 0.07306544482707977, Accuracy: 0.7917252816259861\n",
      "Iteration: 5824, Loss: 0.07240331918001175, Accuracy: 0.8033154045697302\n",
      "Iteration: 5888, Loss: 0.05938339605927467, Accuracy: 0.801906470907852\n",
      "Iteration: 5952, Loss: 0.07037761062383652, Accuracy: 0.8045899828430265\n",
      "Iteration: 6016, Loss: 0.1072114035487175, Accuracy: 0.7994593097828329\n",
      "Iteration: 6080, Loss: 0.07629971951246262, Accuracy: 0.8014813063200563\n",
      "Iteration: 6144, Loss: 0.09599736332893372, Accuracy: 0.7833491938654333\n",
      "Iteration: 6208, Loss: 0.061201293021440506, Accuracy: 0.8089590764138848\n",
      "Iteration: 6272, Loss: 0.05633987486362457, Accuracy: 0.8122604112140834\n",
      "Iteration: 6336, Loss: 0.05246767774224281, Accuracy: 0.7979327493812889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 6400, Loss: 0.06962383538484573, Accuracy: 0.8119944653008133\n",
      "Iteration: 6464, Loss: 0.05159665271639824, Accuracy: 0.8099879841320217\n",
      "Iteration: 6528, Loss: 0.059045787900686264, Accuracy: 0.8209090905729681\n",
      "Iteration: 6592, Loss: 0.11087984591722488, Accuracy: 0.7982315130066127\n",
      "Iteration: 6656, Loss: 0.040447793900966644, Accuracy: 0.809525273507461\n",
      "Iteration: 6720, Loss: 0.04820690676569939, Accuracy: 0.8134132781997323\n",
      "Iteration: 6784, Loss: 0.045942410826683044, Accuracy: 0.7991222704295069\n",
      "Iteration: 6848, Loss: 0.11395270377397537, Accuracy: 0.8188954233191907\n",
      "Iteration: 6912, Loss: 0.06533687561750412, Accuracy: 0.8095222164411098\n",
      "Iteration: 6976, Loss: 0.03924478217959404, Accuracy: 0.8275783306453377\n",
      "Iteration: 7040, Loss: 0.054874565452337265, Accuracy: 0.8190858694724739\n",
      "Iteration: 7104, Loss: 0.03718563914299011, Accuracy: 0.812834842945449\n",
      "Iteration: 7168, Loss: 0.051260825246572495, Accuracy: 0.8187353662215173\n",
      "Iteration: 7232, Loss: 0.03613223880529404, Accuracy: 0.8107770718634129\n",
      "Iteration: 7296, Loss: 0.03428978845477104, Accuracy: 0.8176789205754176\n",
      "Iteration: 7360, Loss: 0.048708733171224594, Accuracy: 0.8210871580522507\n",
      "Iteration: 7424, Loss: 0.056676074862480164, Accuracy: 0.8135089739225805\n",
      "Iteration: 7488, Loss: 0.05859393998980522, Accuracy: 0.8252566837472841\n",
      "Iteration: 7552, Loss: 0.2302970141172409, Accuracy: 0.8186728456057608\n",
      "Iteration: 7616, Loss: 0.102957583963871, Accuracy: 0.8196094410959631\n",
      "Iteration: 7680, Loss: 0.09180662035942078, Accuracy: 0.8254685202846304\n",
      "Iteration: 7744, Loss: 0.05154852569103241, Accuracy: 0.8331727151526138\n",
      "Iteration: 7808, Loss: 0.05785006657242775, Accuracy: 0.8365012547001243\n",
      "Iteration: 7872, Loss: 0.0819254219532013, Accuracy: 0.845146028790623\n",
      "Iteration: 7936, Loss: 0.07178202271461487, Accuracy: 0.8398516299203038\n",
      "Iteration: 8000, Loss: 0.13465416431427002, Accuracy: 0.8452894776128232\n",
      "Iteration: 8064, Loss: 0.055147718638181686, Accuracy: 0.8299600860336795\n",
      "Iteration: 8128, Loss: 0.028601348400115967, Accuracy: 0.8413527064258233\n",
      "Iteration: 8192, Loss: 0.0663868710398674, Accuracy: 0.8336111408425495\n",
      "Iteration: 8256, Loss: 0.0582299567759037, Accuracy: 0.8273462211946025\n",
      "Iteration: 8320, Loss: 0.1303849220275879, Accuracy: 0.8335086179431528\n",
      "Iteration: 8384, Loss: 0.17141808569431305, Accuracy: 0.8314264604123309\n",
      "Iteration: 8448, Loss: 0.033173978328704834, Accuracy: 0.8518753002863377\n",
      "Iteration: 8512, Loss: 0.12882348895072937, Accuracy: 0.8493953119032085\n",
      "Iteration: 8576, Loss: 0.04797671362757683, Accuracy: 0.8217315598158166\n",
      "Iteration: 8640, Loss: 0.049448031932115555, Accuracy: 0.8475345172919333\n",
      "Iteration: 8704, Loss: 0.014992871321737766, Accuracy: 0.8336036163382232\n",
      "Iteration: 8768, Loss: 0.028607895597815514, Accuracy: 0.8527126938570291\n",
      "Iteration: 8832, Loss: 0.10221359133720398, Accuracy: 0.8335743624484167\n",
      "Iteration: 8896, Loss: 0.019334129989147186, Accuracy: 0.8402903967071325\n",
      "Iteration: 8960, Loss: 0.020308317616581917, Accuracy: 0.8425165473017842\n",
      "Iteration: 9024, Loss: 0.02458236925303936, Accuracy: 0.8506038690684363\n",
      "Iteration: 9088, Loss: 0.1198548972606659, Accuracy: 0.8349009789526463\n",
      "Iteration: 9152, Loss: 0.016982007771730423, Accuracy: 0.8457135957432911\n",
      "Iteration: 9216, Loss: 0.025768017396330833, Accuracy: 0.8447409453801811\n",
      "Iteration: 9280, Loss: 0.015553728677332401, Accuracy: 0.8450175754260272\n",
      "Iteration: 9344, Loss: 0.12174796313047409, Accuracy: 0.8508760228287429\n",
      "Iteration: 9408, Loss: 0.11689561605453491, Accuracy: 0.8582117040641606\n",
      "Iteration: 9472, Loss: 0.028815386816859245, Accuracy: 0.84729679801967\n",
      "Iteration: 9536, Loss: 0.011997890658676624, Accuracy: 0.8523439035052434\n",
      "Iteration: 9600, Loss: 0.10346850752830505, Accuracy: 0.8460686056641862\n",
      "Iteration: 9664, Loss: 0.06834007799625397, Accuracy: 0.8490875666029751\n",
      "Iteration: 9728, Loss: 0.06116003170609474, Accuracy: 0.8512680379208177\n",
      "Iteration: 9792, Loss: 0.034177884459495544, Accuracy: 0.8554737309459597\n",
      "Iteration: 9856, Loss: 0.061143871396780014, Accuracy: 0.854661330813542\n",
      "Iteration: 9920, Loss: 0.012223128229379654, Accuracy: 0.8606164918746799\n",
      "Iteration: 9984, Loss: 0.018271429464221, Accuracy: 0.8585444169584662\n",
      "Iteration: 10048, Loss: 0.08731500059366226, Accuracy: 0.8502720310352743\n",
      "Iteration: 10112, Loss: 0.01672324165701866, Accuracy: 0.8527008933015168\n",
      "Iteration: 10176, Loss: 0.1054985299706459, Accuracy: 0.8532187312375754\n",
      "Iteration: 10240, Loss: 0.0116150276735425, Accuracy: 0.861252082278952\n",
      "Iteration: 10304, Loss: 0.013924562372267246, Accuracy: 0.8573342026211321\n",
      "Iteration: 10368, Loss: 0.10281965136528015, Accuracy: 0.8394303075037897\n",
      "Iteration: 10432, Loss: 0.050191015005111694, Accuracy: 0.8435565861873329\n",
      "Iteration: 10496, Loss: 0.10315979272127151, Accuracy: 0.8603621998336166\n",
      "Iteration: 10560, Loss: 0.09942447394132614, Accuracy: 0.8614476532675326\n",
      "Iteration: 10624, Loss: 0.008915621787309647, Accuracy: 0.8469647250603884\n",
      "Iteration: 10688, Loss: 0.009116311557590961, Accuracy: 0.8634194362093695\n",
      "Iteration: 10752, Loss: 0.0951678529381752, Accuracy: 0.8630284058745019\n",
      "Iteration: 10816, Loss: 0.07138130813837051, Accuracy: 0.8660607774509117\n",
      "Iteration: 10880, Loss: 0.010143685154616833, Accuracy: 0.859193196578417\n",
      "Iteration: 10944, Loss: 0.10423895716667175, Accuracy: 0.8550797437201254\n",
      "Iteration: 11008, Loss: 0.05967998132109642, Accuracy: 0.8591578622581437\n",
      "Iteration: 11072, Loss: 0.014401275664567947, Accuracy: 0.8604616555967368\n",
      "Iteration: 11136, Loss: 0.06837362796068192, Accuracy: 0.8600807485636324\n",
      "Iteration: 11200, Loss: 0.01973172277212143, Accuracy: 0.849749218497891\n",
      "Iteration: 11264, Loss: 0.006671999115496874, Accuracy: 0.863258620200213\n",
      "Iteration: 11328, Loss: 0.007321761455386877, Accuracy: 0.8579445406212471\n",
      "Iteration: 11392, Loss: 0.013549844734370708, Accuracy: 0.8598918541683815\n",
      "Iteration: 11456, Loss: 0.0689176544547081, Accuracy: 0.8685857452219352\n",
      "Iteration: 11520, Loss: 0.00730903772637248, Accuracy: 0.8727570716873743\n",
      "Iteration: 11584, Loss: 0.11078231781721115, Accuracy: 0.8614345799433067\n",
      "Iteration: 11648, Loss: 0.07326272875070572, Accuracy: 0.8504171235836111\n",
      "Iteration: 11712, Loss: 0.10717508941888809, Accuracy: 0.8502949348767288\n",
      "Iteration: 11776, Loss: 0.09423419833183289, Accuracy: 0.8647065732511692\n",
      "Iteration: 11840, Loss: 0.10411543399095535, Accuracy: 0.8753573702415451\n",
      "Iteration: 11904, Loss: 0.031759023666381836, Accuracy: 0.8723549809074029\n",
      "Iteration: 11968, Loss: 0.0769876167178154, Accuracy: 0.8544580346206203\n",
      "Iteration: 12032, Loss: 0.0056573785841465, Accuracy: 0.8772980383364484\n",
      "Iteration: 12096, Loss: 0.06772207468748093, Accuracy: 0.8636891439091414\n",
      "Iteration: 12160, Loss: 0.06151413917541504, Accuracy: 0.8702637656242587\n",
      "Iteration: 12224, Loss: 0.07586628943681717, Accuracy: 0.8611784111708403\n",
      "Iteration: 12288, Loss: 0.008570806123316288, Accuracy: 0.8720536844339222\n",
      "Iteration: 12352, Loss: 0.007369292434304953, Accuracy: 0.8775335482205264\n",
      "Iteration: 12416, Loss: 0.07082553952932358, Accuracy: 0.873345427098684\n",
      "Iteration: 12480, Loss: 0.07068415731191635, Accuracy: 0.8670860348502174\n",
      "Iteration: 12544, Loss: 0.007809481117874384, Accuracy: 0.8681519508245401\n",
      "Iteration: 12608, Loss: 0.09770041704177856, Accuracy: 0.8677548990817741\n",
      "Iteration: 12672, Loss: 0.004140782635658979, Accuracy: 0.8749944876180962\n",
      "Iteration: 12736, Loss: 0.03083319403231144, Accuracy: 0.8738106383243576\n",
      "Iteration: 12800, Loss: 0.041525792330503464, Accuracy: 0.8652313366765156\n",
      "Iteration: 12864, Loss: 0.006101928651332855, Accuracy: 0.8781773585942574\n",
      "Iteration: 12928, Loss: 0.004130326211452484, Accuracy: 0.8804362420341931\n",
      "Iteration: 12992, Loss: 0.07453277707099915, Accuracy: 0.8773712913389318\n",
      "Iteration: 13056, Loss: 0.006691787391901016, Accuracy: 0.8738372112275101\n",
      "Iteration: 13120, Loss: 0.009746306575834751, Accuracy: 0.8691699348273687\n",
      "Iteration: 13184, Loss: 0.010952380485832691, Accuracy: 0.8687005080282688\n",
      "Iteration: 13248, Loss: 0.05010007694363594, Accuracy: 0.8730176087119617\n",
      "Iteration: 13312, Loss: 0.006602000445127487, Accuracy: 0.8856013479526155\n",
      "Iteration: 13376, Loss: 0.045427754521369934, Accuracy: 0.8873174616601318\n",
      "Iteration: 13440, Loss: 0.005228583235293627, Accuracy: 0.874908649129793\n",
      "Iteration: 13504, Loss: 0.0053052580915391445, Accuracy: 0.8826344304834493\n",
      "Iteration: 13568, Loss: 0.09475600719451904, Accuracy: 0.8787219166988507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 13632, Loss: 0.013623252511024475, Accuracy: 0.8914071180042811\n",
      "Iteration: 13696, Loss: 0.006158795207738876, Accuracy: 0.8905294881551526\n",
      "Iteration: 13760, Loss: 0.11569669842720032, Accuracy: 0.8801309596165083\n",
      "Iteration: 13824, Loss: 0.007050158455967903, Accuracy: 0.8775567270931788\n",
      "Iteration: 13888, Loss: 0.007160764653235674, Accuracy: 0.8928445696365088\n",
      "Iteration: 13952, Loss: 0.0032389929983764887, Accuracy: 0.8870502484496683\n",
      "Iteration: 14016, Loss: 0.011748547665774822, Accuracy: 0.8914357233443297\n",
      "Iteration: 14080, Loss: 0.004811782855540514, Accuracy: 0.8905359993805178\n",
      "Iteration: 14144, Loss: 0.09331527352333069, Accuracy: 0.891460077255033\n",
      "Iteration: 14208, Loss: 0.07295183092355728, Accuracy: 0.9005248778848909\n",
      "Iteration: 14272, Loss: 0.009263366460800171, Accuracy: 0.8931298172101378\n",
      "Iteration: 14336, Loss: 0.05927582085132599, Accuracy: 0.9031532668159343\n",
      "Iteration: 14400, Loss: 0.0861906036734581, Accuracy: 0.9066704788710922\n",
      "Iteration: 14464, Loss: 0.06537463515996933, Accuracy: 0.890389806998428\n",
      "Iteration: 14528, Loss: 0.016358034685254097, Accuracy: 0.8983638365752995\n",
      "Iteration: 14592, Loss: 0.0045249746181070805, Accuracy: 0.8978383847279474\n",
      "Iteration: 14656, Loss: 0.07126325368881226, Accuracy: 0.8961554815177806\n",
      "Iteration: 14720, Loss: 0.02273760922253132, Accuracy: 0.9022394329367671\n",
      "Iteration: 14784, Loss: 0.005058189854025841, Accuracy: 0.9062783601111732\n",
      "Iteration: 14848, Loss: 0.0033726186957210302, Accuracy: 0.9048540442890953\n",
      "Iteration: 14912, Loss: 0.004363508429378271, Accuracy: 0.8994317753531504\n",
      "Iteration: 14976, Loss: 0.021973080933094025, Accuracy: 0.8922932289424352\n",
      "Iteration: 15040, Loss: 0.016810832545161247, Accuracy: 0.899499706865754\n",
      "Iteration: 15104, Loss: 0.0021727767307311296, Accuracy: 0.9086191939131822\n",
      "Iteration: 15168, Loss: 0.025315916165709496, Accuracy: 0.902071801800048\n",
      "Iteration: 15232, Loss: 0.0061144717037677765, Accuracy: 0.913838095322717\n",
      "Iteration: 15296, Loss: 0.010284778662025928, Accuracy: 0.9190745876985602\n",
      "Iteration: 15360, Loss: 0.09686016291379929, Accuracy: 0.9104351144924294\n",
      "Iteration: 15424, Loss: 0.0057371542789042, Accuracy: 0.9142162784701213\n",
      "Iteration: 15488, Loss: 0.009014594368636608, Accuracy: 0.919899237487698\n",
      "Iteration: 15552, Loss: 0.004288956988602877, Accuracy: 0.9207629101874772\n",
      "Iteration: 15616, Loss: 0.06473113596439362, Accuracy: 0.9217046886624303\n",
      "Iteration: 15680, Loss: 0.006303355563431978, Accuracy: 0.9252517643617466\n",
      "Iteration: 15744, Loss: 0.006381370592862368, Accuracy: 0.9230412575416267\n",
      "Iteration: 15808, Loss: 0.006292086560279131, Accuracy: 0.9233788686979096\n",
      "Iteration: 15872, Loss: 0.007334686815738678, Accuracy: 0.9277326600567903\n",
      "Iteration: 15936, Loss: 0.006431924644857645, Accuracy: 0.9245315656880848\n",
      "Iteration: 16000, Loss: 0.005279176402837038, Accuracy: 0.8998844877933152\n",
      "Iteration: 16064, Loss: 0.0020989771001040936, Accuracy: 0.9291973866056651\n",
      "Iteration: 16128, Loss: 0.022066399455070496, Accuracy: 0.9296869060781319\n",
      "Iteration: 16192, Loss: 0.013954821042716503, Accuracy: 0.9376416224986315\n",
      "Iteration: 16256, Loss: 0.0020450903102755547, Accuracy: 0.9201546047988813\n",
      "Iteration: 16320, Loss: 0.006734407041221857, Accuracy: 0.9387273397878744\n",
      "Iteration: 16384, Loss: 0.07050015777349472, Accuracy: 0.9290165102283936\n",
      "Iteration: 16448, Loss: 0.0026850865688174963, Accuracy: 0.932825770432828\n",
      "Iteration: 16512, Loss: 0.0036917319521307945, Accuracy: 0.9478428060538135\n",
      "Iteration: 16576, Loss: 0.0028440195601433516, Accuracy: 0.9423135372926481\n",
      "Iteration: 16640, Loss: 0.003547855420038104, Accuracy: 0.9408693114528432\n",
      "Iteration: 16704, Loss: 0.023739242926239967, Accuracy: 0.93093733661226\n",
      "Iteration: 16768, Loss: 0.0012427715118974447, Accuracy: 0.9303383445658255\n",
      "Iteration: 16832, Loss: 0.01250330451875925, Accuracy: 0.9354775854153559\n",
      "Iteration: 16896, Loss: 0.0023295090068131685, Accuracy: 0.942420275619952\n",
      "Iteration: 16960, Loss: 0.0038035225588828325, Accuracy: 0.9514054021274205\n",
      "Iteration: 17024, Loss: 0.006231821607798338, Accuracy: 0.9545846643450204\n",
      "Iteration: 17088, Loss: 0.0021356497891247272, Accuracy: 0.9519506371871103\n",
      "Iteration: 17152, Loss: 0.003307690843939781, Accuracy: 0.9522528958914336\n",
      "Iteration: 17216, Loss: 0.0021765397395938635, Accuracy: 0.9448583301855251\n",
      "Iteration: 17280, Loss: 0.0039028783794492483, Accuracy: 0.942105444642948\n",
      "Iteration: 17344, Loss: 0.004419668577611446, Accuracy: 0.9480255451635458\n",
      "Iteration: 17408, Loss: 0.001059774192981422, Accuracy: 0.9511081942764577\n",
      "Iteration: 17472, Loss: 0.006720879580825567, Accuracy: 0.9452673680789303\n",
      "Iteration: 17536, Loss: 0.002821260131895542, Accuracy: 0.9319030431215651\n",
      "Iteration: 17600, Loss: 0.003363095922395587, Accuracy: 0.955232083942974\n",
      "Iteration: 17664, Loss: 0.0023262028116732836, Accuracy: 0.9493059684755281\n",
      "Iteration: 17728, Loss: 0.0012288150610402226, Accuracy: 0.9319960563734639\n",
      "Iteration: 17792, Loss: 0.0010241576237604022, Accuracy: 0.9457970161165576\n",
      "Iteration: 17856, Loss: 0.002853855723515153, Accuracy: 0.9438390590657946\n",
      "Iteration: 17920, Loss: 0.003459605621173978, Accuracy: 0.9527958332328126\n",
      "Iteration: 17984, Loss: 0.07230302691459656, Accuracy: 0.9559339468250982\n",
      "Iteration: 18048, Loss: 0.0008902571280486882, Accuracy: 0.9590475664590485\n",
      "Iteration: 18112, Loss: 0.0010534740285947919, Accuracy: 0.9548066847783048\n",
      "Iteration: 18176, Loss: 0.12106764316558838, Accuracy: 0.954873496259097\n",
      "Iteration: 18240, Loss: 0.002679952187463641, Accuracy: 0.9506045676243957\n",
      "Iteration: 18304, Loss: 0.002442829543724656, Accuracy: 0.9552637107553892\n",
      "Iteration: 18368, Loss: 0.010981608182191849, Accuracy: 0.9503538750868756\n",
      "Iteration: 18432, Loss: 0.001364676165394485, Accuracy: 0.9586637307074852\n",
      "Iteration: 18496, Loss: 0.002823258750140667, Accuracy: 0.9672430479113245\n",
      "Iteration: 18560, Loss: 0.0009775626240298152, Accuracy: 0.9614928494265769\n",
      "Iteration: 18624, Loss: 0.0005320411291904747, Accuracy: 0.9539937171211932\n",
      "Iteration: 18688, Loss: 0.016059959307312965, Accuracy: 0.9548247362254187\n",
      "Iteration: 18752, Loss: 0.0023857138585299253, Accuracy: 0.9626213629817357\n",
      "Iteration: 18816, Loss: 0.0006522138719446957, Accuracy: 0.9525643924571341\n",
      "Iteration: 18880, Loss: 0.0016873596468940377, Accuracy: 0.9651633016619598\n",
      "Iteration: 18944, Loss: 0.0012754997005686164, Accuracy: 0.9547909434186295\n",
      "Iteration: 19008, Loss: 0.0012660459615290165, Accuracy: 0.95810599080869\n",
      "Iteration: 19072, Loss: 0.0018723029643297195, Accuracy: 0.9627436309237964\n",
      "Iteration: 19136, Loss: 0.0005383683019317687, Accuracy: 0.9655747774959309\n",
      "Iteration: 19200, Loss: 0.0027830004692077637, Accuracy: 0.9540527500939788\n",
      "Iteration: 19264, Loss: 0.0032089140731841326, Accuracy: 0.9717082864808617\n",
      "Saved fullModel_dr[3]_replicate3.model\n",
      "Saved W_dr[3]_replicate3.p\n",
      "3 0.9947916666666666 [1.0, 0.984375, 1.0]\n",
      "Saved w_dr[3]_replicate3.p\n",
      "Replicate 3 completed\n",
      "Time elapsed: 364.640625 seconds\n",
      "Iteration: 64, Loss: 0.27464228868484497, Accuracy: 0.49834031891077757\n",
      "Iteration: 128, Loss: 0.2439005821943283, Accuracy: 0.49934597592800856\n",
      "Iteration: 192, Loss: 0.2571277320384979, Accuracy: 0.5002994476817548\n",
      "Iteration: 256, Loss: 0.24048148095607758, Accuracy: 0.49881867272779346\n",
      "Iteration: 320, Loss: 0.2510583698749542, Accuracy: 0.5000674114562571\n",
      "Iteration: 384, Loss: 0.23282724618911743, Accuracy: 0.5036024744622409\n",
      "Iteration: 448, Loss: 0.18375523388385773, Accuracy: 0.5279434840194881\n",
      "Iteration: 512, Loss: 0.16634303331375122, Accuracy: 0.5711022266186774\n",
      "Iteration: 576, Loss: 0.15528932213783264, Accuracy: 0.6005657967180014\n",
      "Iteration: 640, Loss: 0.2001025229692459, Accuracy: 0.6148646157234907\n",
      "Iteration: 704, Loss: 0.17028744518756866, Accuracy: 0.6255226908251643\n",
      "Iteration: 768, Loss: 0.18061621487140656, Accuracy: 0.6296092863194644\n",
      "Iteration: 832, Loss: 0.1677626520395279, Accuracy: 0.6355926711112261\n",
      "Iteration: 896, Loss: 0.16477860510349274, Accuracy: 0.638435676228255\n",
      "Iteration: 960, Loss: 0.18675176799297333, Accuracy: 0.6411895179189742\n",
      "Iteration: 1024, Loss: 0.17108209431171417, Accuracy: 0.6382820126600564\n",
      "Iteration: 1088, Loss: 0.15151004493236542, Accuracy: 0.6444347663782537\n",
      "Iteration: 1152, Loss: 0.1851622611284256, Accuracy: 0.6463889316655695\n",
      "Iteration: 1216, Loss: 0.1585487276315689, Accuracy: 0.6479734061285853\n",
      "Iteration: 1280, Loss: 0.17542965710163116, Accuracy: 0.6489405008032918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1344, Loss: 0.16005368530750275, Accuracy: 0.6495404290035367\n",
      "Iteration: 1408, Loss: 0.1749534159898758, Accuracy: 0.6504215355962515\n",
      "Iteration: 1472, Loss: 0.1765366643667221, Accuracy: 0.6509683961048722\n",
      "Iteration: 1536, Loss: 0.17828138172626495, Accuracy: 0.6518280417658389\n",
      "Iteration: 1600, Loss: 0.17289382219314575, Accuracy: 0.6526696127839386\n",
      "Iteration: 1664, Loss: 0.17866607010364532, Accuracy: 0.6530677760019898\n",
      "Iteration: 1728, Loss: 0.16232554614543915, Accuracy: 0.6535979905165732\n",
      "Iteration: 1792, Loss: 0.1748015433549881, Accuracy: 0.654065647162497\n",
      "Iteration: 1856, Loss: 0.1732267141342163, Accuracy: 0.6539764911867678\n",
      "Iteration: 1920, Loss: 0.1654025763273239, Accuracy: 0.6547198598273098\n",
      "Iteration: 1984, Loss: 0.17257346212863922, Accuracy: 0.6551745608448982\n",
      "Iteration: 2048, Loss: 0.1725008487701416, Accuracy: 0.6555927358567715\n",
      "Iteration: 2112, Loss: 0.17017270624637604, Accuracy: 0.6559266760013998\n",
      "Iteration: 2176, Loss: 0.17323113977909088, Accuracy: 0.6562250042334199\n",
      "Iteration: 2240, Loss: 0.16350704431533813, Accuracy: 0.6567921261303127\n",
      "Iteration: 2304, Loss: 0.1717594861984253, Accuracy: 0.6568229268305004\n",
      "Iteration: 2368, Loss: 0.17003832757472992, Accuracy: 0.6571103064343333\n",
      "Iteration: 2432, Loss: 0.17381222546100616, Accuracy: 0.6574845421127975\n",
      "Iteration: 2496, Loss: 0.16449512541294098, Accuracy: 0.6578660975210369\n",
      "Iteration: 2560, Loss: 0.16889315843582153, Accuracy: 0.657709697727114\n",
      "Iteration: 2624, Loss: 0.1689976304769516, Accuracy: 0.6583531065843999\n",
      "Iteration: 2688, Loss: 0.16978450119495392, Accuracy: 0.6587519436143339\n",
      "Iteration: 2752, Loss: 0.16942787170410156, Accuracy: 0.6586318206973374\n",
      "Iteration: 2816, Loss: 0.16888852417469025, Accuracy: 0.6583378054201603\n",
      "Iteration: 2880, Loss: 0.1687525510787964, Accuracy: 0.6592689203098416\n",
      "Iteration: 2944, Loss: 0.17103154957294464, Accuracy: 0.6591738322749734\n",
      "Iteration: 3008, Loss: 0.16819144785404205, Accuracy: 0.659438160713762\n",
      "Iteration: 3072, Loss: 0.1688491553068161, Accuracy: 0.659759153611958\n",
      "Iteration: 3136, Loss: 0.16764546930789948, Accuracy: 0.6597859431058168\n",
      "Iteration: 3200, Loss: 0.16761212050914764, Accuracy: 0.6553062284365296\n",
      "Iteration: 3264, Loss: 0.16577313840389252, Accuracy: 0.6595369027927518\n",
      "Iteration: 3328, Loss: 0.16907106339931488, Accuracy: 0.6599792591296136\n",
      "Iteration: 3392, Loss: 0.16349752247333527, Accuracy: 0.6583553780801594\n",
      "Iteration: 3456, Loss: 0.16550205647945404, Accuracy: 0.6604757960885763\n",
      "Iteration: 3520, Loss: 0.17007045447826385, Accuracy: 0.6607025251723826\n",
      "Iteration: 3584, Loss: 0.1715420037508011, Accuracy: 0.6602223115041852\n",
      "Iteration: 3648, Loss: 0.17493455111980438, Accuracy: 0.6600954812020063\n",
      "Iteration: 3712, Loss: 0.17085207998752594, Accuracy: 0.6606608126312494\n",
      "Iteration: 3776, Loss: 0.16858471930027008, Accuracy: 0.6609534774906933\n",
      "Iteration: 3840, Loss: 0.1668366938829422, Accuracy: 0.6607952523045242\n",
      "Iteration: 3904, Loss: 0.16625350713729858, Accuracy: 0.6613598484545946\n",
      "Iteration: 3968, Loss: 0.16953177750110626, Accuracy: 0.6609899811446667\n",
      "Iteration: 4032, Loss: 0.1687907725572586, Accuracy: 0.6614439999684691\n",
      "Iteration: 4096, Loss: 0.16859805583953857, Accuracy: 0.66125134145841\n",
      "Iteration: 4160, Loss: 0.16889072954654694, Accuracy: 0.6613160520792007\n",
      "Iteration: 4224, Loss: 0.17101448774337769, Accuracy: 0.6613911017775536\n",
      "Iteration: 4288, Loss: 0.17431068420410156, Accuracy: 0.6610127566382289\n",
      "Iteration: 4352, Loss: 0.1664455235004425, Accuracy: 0.661592997610569\n",
      "Iteration: 4416, Loss: 0.17169559001922607, Accuracy: 0.6614475976675749\n",
      "Iteration: 4480, Loss: 0.16618554294109344, Accuracy: 0.6619280851446092\n",
      "Iteration: 4544, Loss: 0.16934458911418915, Accuracy: 0.6620238982141018\n",
      "Iteration: 4608, Loss: 0.16966760158538818, Accuracy: 0.6616463493555784\n",
      "Iteration: 4672, Loss: 0.16309374570846558, Accuracy: 0.6620192909613252\n",
      "Iteration: 4736, Loss: 0.17616041004657745, Accuracy: 0.6615094230510294\n",
      "Iteration: 4800, Loss: 0.16559483110904694, Accuracy: 0.6622457131743431\n",
      "Iteration: 4864, Loss: 0.1656772941350937, Accuracy: 0.6620522774755955\n",
      "Iteration: 4928, Loss: 0.1689109355211258, Accuracy: 0.6623619818128645\n",
      "Iteration: 4992, Loss: 0.1671009063720703, Accuracy: 0.6619251407682896\n",
      "Iteration: 5056, Loss: 0.1684824675321579, Accuracy: 0.661516984924674\n",
      "Iteration: 5120, Loss: 0.16418351233005524, Accuracy: 0.6624393546953797\n",
      "Iteration: 5184, Loss: 0.16759765148162842, Accuracy: 0.6623723530210555\n",
      "Iteration: 5248, Loss: 0.16203027963638306, Accuracy: 0.6625116006471217\n",
      "Iteration: 5312, Loss: 0.17326945066452026, Accuracy: 0.6624904540367424\n",
      "Iteration: 5376, Loss: 0.1646919697523117, Accuracy: 0.6623865566216409\n",
      "Iteration: 5440, Loss: 0.1649227738380432, Accuracy: 0.6628298736177385\n",
      "Iteration: 5504, Loss: 0.17106278240680695, Accuracy: 0.663434183690697\n",
      "Iteration: 5568, Loss: 0.17586065828800201, Accuracy: 0.6646929681301117\n",
      "Iteration: 5632, Loss: 0.17648249864578247, Accuracy: 0.6662713913246989\n",
      "Iteration: 5696, Loss: 0.13905055820941925, Accuracy: 0.6658131284639239\n",
      "Iteration: 5760, Loss: 0.19566726684570312, Accuracy: 0.6673288461752236\n",
      "Iteration: 5824, Loss: 0.12739010155200958, Accuracy: 0.6698061213828623\n",
      "Iteration: 5888, Loss: 0.19402694702148438, Accuracy: 0.6719334414228797\n",
      "Iteration: 5952, Loss: 0.16422085464000702, Accuracy: 0.673780185636133\n",
      "Iteration: 6016, Loss: 0.14397574961185455, Accuracy: 0.67685612058267\n",
      "Iteration: 6080, Loss: 0.1572146862745285, Accuracy: 0.6785207176581025\n",
      "Iteration: 6144, Loss: 0.09802514314651489, Accuracy: 0.6834677523002028\n",
      "Iteration: 6208, Loss: 0.09014913439750671, Accuracy: 0.6856260905042291\n",
      "Iteration: 6272, Loss: 0.15924139320850372, Accuracy: 0.6883612002711743\n",
      "Iteration: 6336, Loss: 0.18025068938732147, Accuracy: 0.6900772815570235\n",
      "Iteration: 6400, Loss: 0.17197783291339874, Accuracy: 0.6797239000443369\n",
      "Iteration: 6464, Loss: 0.1681462526321411, Accuracy: 0.688505828846246\n",
      "Iteration: 6528, Loss: 0.13261599838733673, Accuracy: 0.6891842314507812\n",
      "Iteration: 6592, Loss: 0.0796150490641594, Accuracy: 0.6949752804357558\n",
      "Iteration: 6656, Loss: 0.14100025594234467, Accuracy: 0.6890200469642878\n",
      "Iteration: 6720, Loss: 0.08256945759057999, Accuracy: 0.6938685639761388\n",
      "Iteration: 6784, Loss: 0.15555085241794586, Accuracy: 0.6907211926300079\n",
      "Iteration: 6848, Loss: 0.1794867068529129, Accuracy: 0.7044001491740346\n",
      "Iteration: 6912, Loss: 0.07534633576869965, Accuracy: 0.705109839560464\n",
      "Iteration: 6976, Loss: 0.07417261600494385, Accuracy: 0.7072346024215221\n",
      "Iteration: 7040, Loss: 0.17634744942188263, Accuracy: 0.6977942832745612\n",
      "Iteration: 7104, Loss: 0.062471356242895126, Accuracy: 0.711299128131941\n",
      "Iteration: 7168, Loss: 0.07022373378276825, Accuracy: 0.7121343491598964\n",
      "Iteration: 7232, Loss: 0.07565868645906448, Accuracy: 0.7023474713787436\n",
      "Iteration: 7296, Loss: 0.1416097730398178, Accuracy: 0.7145657401997596\n",
      "Iteration: 7360, Loss: 0.1324574202299118, Accuracy: 0.718327852897346\n",
      "Iteration: 7424, Loss: 0.14789670705795288, Accuracy: 0.7198464339599013\n",
      "Iteration: 7488, Loss: 0.1442948579788208, Accuracy: 0.7180703713092953\n",
      "Iteration: 7552, Loss: 0.05974673852324486, Accuracy: 0.7215977986343205\n",
      "Iteration: 7616, Loss: 0.20918084681034088, Accuracy: 0.7139833352994174\n",
      "Iteration: 7680, Loss: 0.06019648537039757, Accuracy: 0.7255427043419331\n",
      "Iteration: 7744, Loss: 0.05536247789859772, Accuracy: 0.7304565827362239\n",
      "Iteration: 7808, Loss: 0.09276637434959412, Accuracy: 0.72749965172261\n",
      "Iteration: 7872, Loss: 0.06326786428689957, Accuracy: 0.726025843527168\n",
      "Iteration: 7936, Loss: 0.0920337438583374, Accuracy: 0.7433779102284461\n",
      "Iteration: 8000, Loss: 0.05579257011413574, Accuracy: 0.7232843257952482\n",
      "Iteration: 8064, Loss: 0.05645948648452759, Accuracy: 0.734013831242919\n",
      "Iteration: 8128, Loss: 0.1390504688024521, Accuracy: 0.7351048309355974\n",
      "Iteration: 8192, Loss: 0.05762175843119621, Accuracy: 0.7360547215212137\n",
      "Iteration: 8256, Loss: 0.08825460821390152, Accuracy: 0.7395878285169601\n",
      "Iteration: 8320, Loss: 0.13447067141532898, Accuracy: 0.7461880114860833\n",
      "Iteration: 8384, Loss: 0.07893719524145126, Accuracy: 0.747451558476314\n",
      "Iteration: 8448, Loss: 0.14296673238277435, Accuracy: 0.7380632893182337\n",
      "Iteration: 8512, Loss: 0.2738824188709259, Accuracy: 0.748934940667823\n",
      "Iteration: 8576, Loss: 0.11960014700889587, Accuracy: 0.7468070501927286\n",
      "Iteration: 8640, Loss: 0.1262015551328659, Accuracy: 0.7549912882968783\n",
      "Iteration: 8704, Loss: 0.09026899188756943, Accuracy: 0.7530451719649136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 8768, Loss: 0.06251584738492966, Accuracy: 0.7574993963353336\n",
      "Iteration: 8832, Loss: 0.06710182875394821, Accuracy: 0.747704524314031\n",
      "Iteration: 8896, Loss: 0.19674257934093475, Accuracy: 0.7435735876206309\n",
      "Iteration: 8960, Loss: 0.06371799856424332, Accuracy: 0.7535907332785428\n",
      "Iteration: 9024, Loss: 0.06565404683351517, Accuracy: 0.7642836805898696\n",
      "Iteration: 9088, Loss: 0.07023929804563522, Accuracy: 0.7652522528078407\n",
      "Iteration: 9152, Loss: 0.07280275970697403, Accuracy: 0.7699705876875669\n",
      "Iteration: 9216, Loss: 0.11276835203170776, Accuracy: 0.7758583473041654\n",
      "Iteration: 9280, Loss: 0.1105555072426796, Accuracy: 0.7638758688699454\n",
      "Iteration: 9344, Loss: 0.09932778030633926, Accuracy: 0.7681540057528764\n",
      "Iteration: 9408, Loss: 0.08301190286874771, Accuracy: 0.7596859759651124\n",
      "Iteration: 9472, Loss: 0.07844354212284088, Accuracy: 0.7687973193824291\n",
      "Iteration: 9536, Loss: 0.10881155729293823, Accuracy: 0.7738242188934237\n",
      "Iteration: 9600, Loss: 0.11062797158956528, Accuracy: 0.76109982538037\n",
      "Iteration: 9664, Loss: 0.09919243305921555, Accuracy: 0.7654699273407459\n",
      "Iteration: 9728, Loss: 0.1130065843462944, Accuracy: 0.756508068414405\n",
      "Iteration: 9792, Loss: 0.07506970316171646, Accuracy: 0.772880972828716\n",
      "Iteration: 9856, Loss: 0.07171399891376495, Accuracy: 0.7754859530832618\n",
      "Iteration: 9920, Loss: 0.09867242723703384, Accuracy: 0.774353411514312\n",
      "Iteration: 9984, Loss: 0.07162298262119293, Accuracy: 0.7722591392230242\n",
      "Iteration: 10048, Loss: 0.10110217332839966, Accuracy: 0.7822788329795003\n",
      "Iteration: 10112, Loss: 0.08748284727334976, Accuracy: 0.7829238779377192\n",
      "Iteration: 10176, Loss: 0.10145431756973267, Accuracy: 0.7777108927257359\n",
      "Iteration: 10240, Loss: 0.09969150274991989, Accuracy: 0.7831242824904621\n",
      "Iteration: 10304, Loss: 0.09806182980537415, Accuracy: 0.7897689745295793\n",
      "Iteration: 10368, Loss: 0.09007292985916138, Accuracy: 0.7939539009239525\n",
      "Iteration: 10432, Loss: 0.09386102110147476, Accuracy: 0.795726123964414\n",
      "Iteration: 10496, Loss: 0.07699224352836609, Accuracy: 0.7899606148712337\n",
      "Iteration: 10560, Loss: 0.09450576454401016, Accuracy: 0.7909476892091334\n",
      "Iteration: 10624, Loss: 0.0920163094997406, Accuracy: 0.7898538012523204\n",
      "Iteration: 10688, Loss: 0.09377827495336533, Accuracy: 0.7928666940424591\n",
      "Iteration: 10752, Loss: 0.07684396207332611, Accuracy: 0.7756806323304772\n",
      "Iteration: 10816, Loss: 0.0776171162724495, Accuracy: 0.7847009673714638\n",
      "Iteration: 10880, Loss: 0.0821516290307045, Accuracy: 0.792172331828624\n",
      "Iteration: 10944, Loss: 0.07539833337068558, Accuracy: 0.787889898288995\n",
      "Iteration: 11008, Loss: 0.07842713594436646, Accuracy: 0.7994757678825408\n",
      "Iteration: 11072, Loss: 0.09436696022748947, Accuracy: 0.8012918406166136\n",
      "Iteration: 11136, Loss: 0.12329327315092087, Accuracy: 0.7946860897354782\n",
      "Iteration: 11200, Loss: 0.08843237161636353, Accuracy: 0.7943934281356633\n",
      "Iteration: 11264, Loss: 0.09656357765197754, Accuracy: 0.7844506911933422\n",
      "Iteration: 11328, Loss: 0.09436716884374619, Accuracy: 0.7949532435741276\n",
      "Iteration: 11392, Loss: 0.07724440842866898, Accuracy: 0.8033159931655973\n",
      "Iteration: 11456, Loss: 0.07653529196977615, Accuracy: 0.7865864485502243\n",
      "Iteration: 11520, Loss: 0.07926686108112335, Accuracy: 0.7997675221413374\n",
      "Iteration: 11584, Loss: 0.09064663201570511, Accuracy: 0.8031227230094373\n",
      "Iteration: 11648, Loss: 0.07645163685083389, Accuracy: 0.7928895247168839\n",
      "Iteration: 11712, Loss: 0.07023432105779648, Accuracy: 0.797407116740942\n",
      "Iteration: 11776, Loss: 0.0867186114192009, Accuracy: 0.8048607599921525\n",
      "Iteration: 11840, Loss: 0.06308557093143463, Accuracy: 0.8023250394035131\n",
      "Iteration: 11904, Loss: 0.0819244310259819, Accuracy: 0.8049783343449235\n",
      "Iteration: 11968, Loss: 0.07143062353134155, Accuracy: 0.7993232004810125\n",
      "Iteration: 12032, Loss: 0.07927192002534866, Accuracy: 0.8130794777534902\n",
      "Iteration: 12096, Loss: 0.08001398295164108, Accuracy: 0.8085530938114971\n",
      "Iteration: 12160, Loss: 0.08063773810863495, Accuracy: 0.805214713094756\n",
      "Iteration: 12224, Loss: 0.07446250319480896, Accuracy: 0.8107092762365937\n",
      "Iteration: 12288, Loss: 0.09442341327667236, Accuracy: 0.8066706182435155\n",
      "Iteration: 12352, Loss: 0.08301018923521042, Accuracy: 0.8158395597711205\n",
      "Iteration: 12416, Loss: 0.07672371715307236, Accuracy: 0.8096189491916448\n",
      "Iteration: 12480, Loss: 0.05024852231144905, Accuracy: 0.8174224044196308\n",
      "Iteration: 12544, Loss: 0.08479330688714981, Accuracy: 0.8186011402867734\n",
      "Iteration: 12608, Loss: 0.09032963961362839, Accuracy: 0.8187991387676448\n",
      "Iteration: 12672, Loss: 0.08519066125154495, Accuracy: 0.8210702028591186\n",
      "Iteration: 12736, Loss: 0.0799197405576706, Accuracy: 0.8231239563319832\n",
      "Iteration: 12800, Loss: 0.08991235494613647, Accuracy: 0.819213634589687\n",
      "Iteration: 12864, Loss: 0.07827702909708023, Accuracy: 0.820221031550318\n",
      "Iteration: 12928, Loss: 0.09786844253540039, Accuracy: 0.8243091502226889\n",
      "Iteration: 12992, Loss: 0.03166297823190689, Accuracy: 0.813224065117538\n",
      "Iteration: 13056, Loss: 0.08123735338449478, Accuracy: 0.8018529124092311\n",
      "Iteration: 13120, Loss: 0.06320098787546158, Accuracy: 0.8196748625487089\n",
      "Iteration: 13184, Loss: 0.08382271975278854, Accuracy: 0.8207675346639007\n",
      "Iteration: 13248, Loss: 0.03338348865509033, Accuracy: 0.8232864148449153\n",
      "Iteration: 13312, Loss: 0.10170628875494003, Accuracy: 0.8169808380771428\n",
      "Iteration: 13376, Loss: 0.2959919273853302, Accuracy: 0.8211665506241843\n",
      "Iteration: 13440, Loss: 0.02764410339295864, Accuracy: 0.8206972484476864\n",
      "Iteration: 13504, Loss: 0.05161692574620247, Accuracy: 0.8325560536468402\n",
      "Iteration: 13568, Loss: 0.02097027748823166, Accuracy: 0.8385198712348938\n",
      "Iteration: 13632, Loss: 0.08624669909477234, Accuracy: 0.818411091924645\n",
      "Iteration: 13696, Loss: 0.027941875159740448, Accuracy: 0.8335761311464012\n",
      "Iteration: 13760, Loss: 0.025110214948654175, Accuracy: 0.8400854547508061\n",
      "Iteration: 13824, Loss: 0.021855784580111504, Accuracy: 0.8328323031309992\n",
      "Iteration: 13888, Loss: 0.043767768889665604, Accuracy: 0.8261534332996234\n",
      "Iteration: 13952, Loss: 0.028426192700862885, Accuracy: 0.8419302795082331\n",
      "Iteration: 14016, Loss: 0.021788552403450012, Accuracy: 0.8371777862776071\n",
      "Iteration: 14080, Loss: 0.09554475545883179, Accuracy: 0.8461730492999777\n",
      "Iteration: 14144, Loss: 0.27100440859794617, Accuracy: 0.8357471458148211\n",
      "Iteration: 14208, Loss: 0.013754885643720627, Accuracy: 0.834709394373931\n",
      "Iteration: 14272, Loss: 0.010888233780860901, Accuracy: 0.8387983898865059\n",
      "Iteration: 14336, Loss: 0.08046605437994003, Accuracy: 0.8510468318127096\n",
      "Iteration: 14400, Loss: 0.16214396059513092, Accuracy: 0.8453057842561975\n",
      "Iteration: 14464, Loss: 0.09025634080171585, Accuracy: 0.8442669882206246\n",
      "Iteration: 14528, Loss: 0.014383241534233093, Accuracy: 0.8518343101022765\n",
      "Iteration: 14592, Loss: 0.008369476534426212, Accuracy: 0.8523565289797261\n",
      "Iteration: 14656, Loss: 0.014771242626011372, Accuracy: 0.8592801442136988\n",
      "Iteration: 14720, Loss: 0.042192086577415466, Accuracy: 0.8520982881309465\n",
      "Iteration: 14784, Loss: 0.006914738565683365, Accuracy: 0.856003177119419\n",
      "Iteration: 14848, Loss: 0.006974268704652786, Accuracy: 0.8578326674760319\n",
      "Iteration: 14912, Loss: 0.08532602339982986, Accuracy: 0.8615558154415339\n",
      "Iteration: 14976, Loss: 0.08936566859483719, Accuracy: 0.8566278198850341\n",
      "Iteration: 15040, Loss: 0.016068508848547935, Accuracy: 0.8499419902800582\n",
      "Iteration: 15104, Loss: 0.08782127499580383, Accuracy: 0.8591576454928145\n",
      "Iteration: 15168, Loss: 0.07713892310857773, Accuracy: 0.8680967889376916\n",
      "Iteration: 15232, Loss: 0.010537401773035526, Accuracy: 0.8572252731537446\n",
      "Iteration: 15296, Loss: 0.08070673793554306, Accuracy: 0.8514065889758058\n",
      "Iteration: 15360, Loss: 0.15290610492229462, Accuracy: 0.8628707849420607\n",
      "Iteration: 15424, Loss: 0.009036439470946789, Accuracy: 0.8696013895096257\n",
      "Iteration: 15488, Loss: 0.0736975446343422, Accuracy: 0.8632139676483348\n",
      "Iteration: 15552, Loss: 0.06268869340419769, Accuracy: 0.8645220995531417\n",
      "Iteration: 15616, Loss: 0.06600009649991989, Accuracy: 0.869870402792003\n",
      "Iteration: 15680, Loss: 0.004360694903880358, Accuracy: 0.8657061421545222\n",
      "Iteration: 15744, Loss: 0.004196546971797943, Accuracy: 0.8570062334183604\n",
      "Iteration: 15808, Loss: 0.009515363723039627, Accuracy: 0.8704403875162825\n",
      "Iteration: 15872, Loss: 0.08386334776878357, Accuracy: 0.8747024094918743\n",
      "Iteration: 15936, Loss: 0.08860331028699875, Accuracy: 0.8747932209516875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 16000, Loss: 0.06323809176683426, Accuracy: 0.8756656259065494\n",
      "Iteration: 16064, Loss: 0.004654707387089729, Accuracy: 0.8804851226159371\n",
      "Iteration: 16128, Loss: 0.0026667180936783552, Accuracy: 0.8711065716343\n",
      "Iteration: 16192, Loss: 0.016377221792936325, Accuracy: 0.8729288000031374\n",
      "Iteration: 16256, Loss: 0.09789424389600754, Accuracy: 0.8783063350711018\n",
      "Iteration: 16320, Loss: 0.02135748229920864, Accuracy: 0.8738182340748608\n",
      "Iteration: 16384, Loss: 0.0043155415914952755, Accuracy: 0.8728397997911088\n",
      "Iteration: 16448, Loss: 0.08692560344934464, Accuracy: 0.8752483992720954\n",
      "Iteration: 16512, Loss: 0.014236030168831348, Accuracy: 0.8815234857611358\n",
      "Iteration: 16576, Loss: 0.08532357215881348, Accuracy: 0.8714241473935544\n",
      "Iteration: 16640, Loss: 0.08929327875375748, Accuracy: 0.8809358622529544\n",
      "Iteration: 16704, Loss: 0.003902531461790204, Accuracy: 0.8688734655152075\n",
      "Iteration: 16768, Loss: 0.0043980758637189865, Accuracy: 0.8795358699862845\n",
      "Iteration: 16832, Loss: 0.12004553526639938, Accuracy: 0.8525009340955876\n",
      "Iteration: 16896, Loss: 0.006475517991930246, Accuracy: 0.8795459623797797\n",
      "Iteration: 16960, Loss: 0.08598317950963974, Accuracy: 0.8833021579193883\n",
      "Iteration: 17024, Loss: 0.004825308453291655, Accuracy: 0.892998555500526\n",
      "Iteration: 17088, Loss: 0.004149222746491432, Accuracy: 0.8914787950343452\n",
      "Iteration: 17152, Loss: 0.003009755164384842, Accuracy: 0.8908148323534988\n",
      "Iteration: 17216, Loss: 0.003014200134202838, Accuracy: 0.8723802929162048\n",
      "Iteration: 17280, Loss: 0.002589874668046832, Accuracy: 0.883476511342451\n",
      "Iteration: 17344, Loss: 0.0806017741560936, Accuracy: 0.8915173718123697\n",
      "Iteration: 17408, Loss: 0.08658018708229065, Accuracy: 0.897333838918712\n",
      "Iteration: 17472, Loss: 0.004377135541290045, Accuracy: 0.88405355962459\n",
      "Iteration: 17536, Loss: 0.006346765905618668, Accuracy: 0.8923398777842522\n",
      "Iteration: 17600, Loss: 0.14105725288391113, Accuracy: 0.8893727904651314\n",
      "Iteration: 17664, Loss: 0.011161615140736103, Accuracy: 0.8986475522979163\n",
      "Iteration: 17728, Loss: 0.07890254259109497, Accuracy: 0.8815996087505482\n",
      "Iteration: 17792, Loss: 0.08457242697477341, Accuracy: 0.8988103196606971\n",
      "Iteration: 17856, Loss: 0.002365976572036743, Accuracy: 0.8882707514276262\n",
      "Iteration: 17920, Loss: 0.002903029089793563, Accuracy: 0.8891962274210528\n",
      "Iteration: 17984, Loss: 0.018104108050465584, Accuracy: 0.8674778917338699\n",
      "Iteration: 18048, Loss: 0.08642274886369705, Accuracy: 0.8929023849777877\n",
      "Iteration: 18112, Loss: 0.0030513021629303694, Accuracy: 0.8988664509379305\n",
      "Iteration: 18176, Loss: 0.0017225468764081597, Accuracy: 0.8877913765609264\n",
      "Iteration: 18240, Loss: 0.004259113222360611, Accuracy: 0.8956960690265987\n",
      "Iteration: 18304, Loss: 0.0021326488349586725, Accuracy: 0.8996925943065435\n",
      "Iteration: 18368, Loss: 0.08507078140974045, Accuracy: 0.8943364824226592\n",
      "Iteration: 18432, Loss: 0.001588868792168796, Accuracy: 0.8996508940763306\n",
      "Iteration: 18496, Loss: 0.0017866321140900254, Accuracy: 0.8884459868131671\n",
      "Iteration: 18560, Loss: 0.007696943357586861, Accuracy: 0.896582429704722\n",
      "Iteration: 18624, Loss: 0.0016058761393651366, Accuracy: 0.9047283342806622\n",
      "Iteration: 18688, Loss: 0.0021116549614816904, Accuracy: 0.9114904539019335\n",
      "Iteration: 18752, Loss: 0.002007814822718501, Accuracy: 0.90396994506591\n",
      "Iteration: 18816, Loss: 0.04411976411938667, Accuracy: 0.8806722195004113\n",
      "Iteration: 18880, Loss: 0.00149145454633981, Accuracy: 0.9016252899018582\n",
      "Iteration: 18944, Loss: 0.0020364252850413322, Accuracy: 0.9020119595224969\n",
      "Iteration: 19008, Loss: 0.004942784551531076, Accuracy: 0.9027243374148384\n",
      "Iteration: 19072, Loss: 0.0014251070097088814, Accuracy: 0.8817383481073193\n",
      "Iteration: 19136, Loss: 0.06754960119724274, Accuracy: 0.9161199329246301\n",
      "Iteration: 19200, Loss: 0.0017168071353808045, Accuracy: 0.8990648257895373\n",
      "Iteration: 19264, Loss: 0.002306639915332198, Accuracy: 0.9131788423110265\n",
      "Iteration: 19328, Loss: 0.002225078409537673, Accuracy: 0.8898705159372184\n",
      "Iteration: 19392, Loss: 0.0013493058504536748, Accuracy: 0.8937566818494815\n",
      "Iteration: 19456, Loss: 0.005727775394916534, Accuracy: 0.9163947999477386\n",
      "Iteration: 19520, Loss: 0.0707109346985817, Accuracy: 0.9031941236753482\n",
      "Iteration: 19584, Loss: 0.10247448831796646, Accuracy: 0.9098542919382453\n",
      "Iteration: 19648, Loss: 0.003252040594816208, Accuracy: 0.908654731902061\n",
      "Iteration: 19712, Loss: 0.06369943171739578, Accuracy: 0.9092949795303866\n",
      "Iteration: 19776, Loss: 0.0018335947534069419, Accuracy: 0.9033699863648508\n",
      "Iteration: 19840, Loss: 0.08413568139076233, Accuracy: 0.90949487828766\n",
      "Iteration: 19904, Loss: 0.0015302523970603943, Accuracy: 0.916541799204424\n",
      "Iteration: 19968, Loss: 0.004060850944370031, Accuracy: 0.9095339506748132\n",
      "Iteration: 20032, Loss: 0.09185076504945755, Accuracy: 0.9150222996831872\n",
      "Iteration: 20096, Loss: 0.04243256151676178, Accuracy: 0.9110961539845448\n",
      "Iteration: 20160, Loss: 0.002051224932074547, Accuracy: 0.9134412481507752\n",
      "Iteration: 20224, Loss: 0.0012213063891977072, Accuracy: 0.9189656169328373\n",
      "Iteration: 20288, Loss: 0.2202940583229065, Accuracy: 0.8978978560480755\n",
      "Iteration: 20352, Loss: 0.004767196252942085, Accuracy: 0.8912870186613873\n",
      "Iteration: 20416, Loss: 0.10159653425216675, Accuracy: 0.9198323363962118\n",
      "Iteration: 20480, Loss: 0.010372270829975605, Accuracy: 0.9095759530318901\n",
      "Iteration: 20544, Loss: 0.0030679500196129084, Accuracy: 0.929126857110532\n",
      "Iteration: 20608, Loss: 0.051173899322748184, Accuracy: 0.9245753737632185\n",
      "Iteration: 20672, Loss: 0.002217441564425826, Accuracy: 0.9165976495714858\n",
      "Iteration: 20736, Loss: 0.00464656762778759, Accuracy: 0.9238580644596368\n",
      "Iteration: 20800, Loss: 0.006534172687679529, Accuracy: 0.9223883409867994\n",
      "Iteration: 20864, Loss: 0.003013339126482606, Accuracy: 0.9212278356717434\n",
      "Iteration: 20928, Loss: 0.05732688680291176, Accuracy: 0.9257111430051737\n",
      "Iteration: 20992, Loss: 0.0015253998572006822, Accuracy: 0.9376015369780362\n",
      "Iteration: 21056, Loss: 0.029619505628943443, Accuracy: 0.9419426204403862\n",
      "Iteration: 21120, Loss: 0.030691487714648247, Accuracy: 0.9345864960923791\n",
      "Iteration: 21184, Loss: 0.20672611892223358, Accuracy: 0.935482331289677\n",
      "Iteration: 21248, Loss: 0.0035430395510047674, Accuracy: 0.9305909199028974\n",
      "Iteration: 21312, Loss: 0.0024540419690310955, Accuracy: 0.9405712099396624\n",
      "Iteration: 21376, Loss: 0.0005541739519685507, Accuracy: 0.937239134014817\n",
      "Iteration: 21440, Loss: 0.00393336545675993, Accuracy: 0.9435204347828403\n",
      "Iteration: 21504, Loss: 0.0017551869386807084, Accuracy: 0.9399434330698568\n",
      "Iteration: 21568, Loss: 0.0038181906566023827, Accuracy: 0.9428688178886659\n",
      "Iteration: 21632, Loss: 0.01978328451514244, Accuracy: 0.9403936705784872\n",
      "Iteration: 21696, Loss: 0.0010328862117603421, Accuracy: 0.9460380197997438\n",
      "Iteration: 21760, Loss: 0.030619582161307335, Accuracy: 0.9365642312186537\n",
      "Iteration: 21824, Loss: 0.02009676583111286, Accuracy: 0.9506742931844201\n",
      "Iteration: 21888, Loss: 0.0023919332306832075, Accuracy: 0.9511561283725314\n",
      "Iteration: 21952, Loss: 0.001276051509194076, Accuracy: 0.944732006493723\n",
      "Iteration: 22016, Loss: 0.0014485731953755021, Accuracy: 0.9434596079954645\n",
      "Iteration: 22080, Loss: 0.0019406969659030437, Accuracy: 0.941029818233801\n",
      "Iteration: 22144, Loss: 0.0016621096292510629, Accuracy: 0.9537029170169262\n",
      "Iteration: 22208, Loss: 0.014918099157512188, Accuracy: 0.956344120160793\n",
      "Iteration: 22272, Loss: 0.003523411927744746, Accuracy: 0.9532199999521254\n",
      "Iteration: 22336, Loss: 0.002138572046533227, Accuracy: 0.9395157595863566\n",
      "Iteration: 22400, Loss: 0.0005011071334592998, Accuracy: 0.954912240311387\n",
      "Iteration: 22464, Loss: 0.0010212402557954192, Accuracy: 0.9581364690966439\n",
      "Iteration: 22528, Loss: 0.0014335241867229342, Accuracy: 0.9585507102601696\n",
      "Iteration: 22592, Loss: 0.00033309447462670505, Accuracy: 0.9569698864361271\n",
      "Iteration: 22656, Loss: 0.000150505657074973, Accuracy: 0.9606075605697697\n",
      "Iteration: 22720, Loss: 0.021931856870651245, Accuracy: 0.9534006945905276\n",
      "Iteration: 22784, Loss: 0.0011155629763379693, Accuracy: 0.9544907904055435\n",
      "Iteration: 22848, Loss: 0.17996104061603546, Accuracy: 0.9557789498212514\n",
      "Iteration: 22912, Loss: 0.00037984084337949753, Accuracy: 0.9530816729238722\n",
      "Iteration: 22976, Loss: 0.0026815154124051332, Accuracy: 0.9533594680397073\n",
      "Iteration: 23040, Loss: 0.014116883277893066, Accuracy: 0.9658600598777412\n",
      "Iteration: 23104, Loss: 0.0011384948156774044, Accuracy: 0.9481257451407146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 23168, Loss: 0.006996267009526491, Accuracy: 0.9652146223961608\n",
      "Iteration: 23232, Loss: 0.003316342830657959, Accuracy: 0.9681079740257701\n",
      "Iteration: 23296, Loss: 0.0008441410027444363, Accuracy: 0.968096758631873\n",
      "Iteration: 23360, Loss: 0.00011613842798396945, Accuracy: 0.970986659580376\n",
      "Saved fullModel_dr[3]_replicate4.model\n",
      "Saved W_dr[3]_replicate4.p\n",
      "3 0.9895833333333334 [0.984375, 0.984375, 1.0]\n",
      "Saved w_dr[3]_replicate4.p\n",
      "Replicate 4 completed\n",
      "Time elapsed: 390.515625 seconds\n",
      "Training for delay range [4]...\n",
      "Iteration: 64, Loss: 0.27687808871269226, Accuracy: 0.4992848979309201\n",
      "Iteration: 128, Loss: 0.2523653209209442, Accuracy: 0.5010594483464956\n",
      "Iteration: 192, Loss: 0.2268849015235901, Accuracy: 0.5030880733393133\n",
      "Iteration: 256, Loss: 0.18788237869739532, Accuracy: 0.5161345601081848\n",
      "Iteration: 320, Loss: 0.1685243844985962, Accuracy: 0.5689237341284752\n",
      "Iteration: 384, Loss: 0.2546916604042053, Accuracy: 0.6007602708414197\n",
      "Iteration: 448, Loss: 0.13222499191761017, Accuracy: 0.6170975994318724\n",
      "Iteration: 512, Loss: 0.1694120317697525, Accuracy: 0.6273559657856822\n",
      "Iteration: 576, Loss: 0.1697152704000473, Accuracy: 0.6338218450546265\n",
      "Iteration: 640, Loss: 0.1723584532737732, Accuracy: 0.6395517657510936\n",
      "Iteration: 704, Loss: 0.2217731475830078, Accuracy: 0.6448674811981618\n",
      "Iteration: 768, Loss: 0.17706072330474854, Accuracy: 0.6474692719057202\n",
      "Iteration: 832, Loss: 0.10500731319189072, Accuracy: 0.6512166243046522\n",
      "Iteration: 896, Loss: 0.2281312346458435, Accuracy: 0.6544453226961195\n",
      "Iteration: 960, Loss: 0.180482879281044, Accuracy: 0.6547171506099403\n",
      "Iteration: 1024, Loss: 0.1215805783867836, Accuracy: 0.6577095310203731\n",
      "Iteration: 1088, Loss: 0.10883858054876328, Accuracy: 0.6610543858259916\n",
      "Iteration: 1152, Loss: 0.12087235599756241, Accuracy: 0.6627012556418777\n",
      "Iteration: 1216, Loss: 0.13073624670505524, Accuracy: 0.66704177018255\n",
      "Iteration: 1280, Loss: 0.2218383401632309, Accuracy: 0.6674144896678627\n",
      "Iteration: 1344, Loss: 0.14571307599544525, Accuracy: 0.6672213282436132\n",
      "Iteration: 1408, Loss: 0.14947456121444702, Accuracy: 0.6699099089019\n",
      "Iteration: 1472, Loss: 0.1480673849582672, Accuracy: 0.6779457344673574\n",
      "Iteration: 1536, Loss: 0.18865124881267548, Accuracy: 0.6725566773675382\n",
      "Iteration: 1600, Loss: 0.15192417800426483, Accuracy: 0.6746240085922182\n",
      "Iteration: 1664, Loss: 0.20419947803020477, Accuracy: 0.6770217912271619\n",
      "Iteration: 1728, Loss: 0.1191178634762764, Accuracy: 0.6795067256316543\n",
      "Iteration: 1792, Loss: 0.16289615631103516, Accuracy: 0.6743681663647294\n",
      "Iteration: 1856, Loss: 0.1149209514260292, Accuracy: 0.684640440158546\n",
      "Iteration: 1920, Loss: 0.09483299404382706, Accuracy: 0.6876529394648969\n",
      "Iteration: 1984, Loss: 0.13614638149738312, Accuracy: 0.6834524553269148\n",
      "Iteration: 2048, Loss: 0.15108007192611694, Accuracy: 0.6906806332990527\n",
      "Iteration: 2112, Loss: 0.08815037459135056, Accuracy: 0.6965983607806265\n",
      "Iteration: 2176, Loss: 0.13112898170948029, Accuracy: 0.6938806846737862\n",
      "Iteration: 2240, Loss: 0.1638026237487793, Accuracy: 0.698207167442888\n",
      "Iteration: 2304, Loss: 0.09429658204317093, Accuracy: 0.6961909267120063\n",
      "Iteration: 2368, Loss: 0.08416426181793213, Accuracy: 0.694091911893338\n",
      "Iteration: 2432, Loss: 0.16799795627593994, Accuracy: 0.7014470957219601\n",
      "Iteration: 2496, Loss: 0.11945194751024246, Accuracy: 0.6993254376575351\n",
      "Iteration: 2560, Loss: 0.09163638949394226, Accuracy: 0.7048734575510025\n",
      "Iteration: 2624, Loss: 0.09012500196695328, Accuracy: 0.7013815143145621\n",
      "Iteration: 2688, Loss: 0.1061844751238823, Accuracy: 0.7061816353816539\n",
      "Iteration: 2752, Loss: 0.24123398959636688, Accuracy: 0.706904238788411\n",
      "Iteration: 2816, Loss: 0.1059311255812645, Accuracy: 0.7058689552359283\n",
      "Iteration: 2880, Loss: 0.1032455638051033, Accuracy: 0.7084979531355202\n",
      "Iteration: 2944, Loss: 0.10374770313501358, Accuracy: 0.7130966116674244\n",
      "Iteration: 3008, Loss: 0.10481584817171097, Accuracy: 0.713954433100298\n",
      "Iteration: 3072, Loss: 0.09394946694374084, Accuracy: 0.7143814431037754\n",
      "Iteration: 3136, Loss: 0.148141548037529, Accuracy: 0.7207206678576767\n",
      "Iteration: 3200, Loss: 0.13659612834453583, Accuracy: 0.7180450297892094\n",
      "Iteration: 3264, Loss: 0.11701833456754684, Accuracy: 0.7156816800124943\n",
      "Iteration: 3328, Loss: 0.10387587547302246, Accuracy: 0.7198744860943407\n",
      "Iteration: 3392, Loss: 0.14296649396419525, Accuracy: 0.7198618811089545\n",
      "Iteration: 3456, Loss: 0.1483590453863144, Accuracy: 0.7346417198423296\n",
      "Iteration: 3520, Loss: 0.09731552004814148, Accuracy: 0.7335599535144866\n",
      "Iteration: 3584, Loss: 0.11983876675367355, Accuracy: 0.730660701636225\n",
      "Iteration: 3648, Loss: 0.5329381227493286, Accuracy: 0.7298606093972921\n",
      "Iteration: 3712, Loss: 0.114317387342453, Accuracy: 0.7308103814721107\n",
      "Iteration: 3776, Loss: 0.09514588117599487, Accuracy: 0.7383312548045069\n",
      "Iteration: 3840, Loss: 0.2985855042934418, Accuracy: 0.7332839369773865\n",
      "Iteration: 3904, Loss: 0.09783750772476196, Accuracy: 0.7283722071442753\n",
      "Iteration: 3968, Loss: 0.08940177410840988, Accuracy: 0.738378175534308\n",
      "Iteration: 4032, Loss: 0.09642422199249268, Accuracy: 0.7419863312970847\n",
      "Iteration: 4096, Loss: 0.1061224713921547, Accuracy: 0.7477695925626904\n",
      "Iteration: 4160, Loss: 0.09517552703619003, Accuracy: 0.7490494949743152\n",
      "Iteration: 4224, Loss: 0.10423070937395096, Accuracy: 0.7342306082136929\n",
      "Iteration: 4288, Loss: 0.08753164857625961, Accuracy: 0.744948803447187\n",
      "Iteration: 4352, Loss: 0.09691622108221054, Accuracy: 0.7491945954971015\n",
      "Iteration: 4416, Loss: 0.09566789120435715, Accuracy: 0.7503305254504085\n",
      "Iteration: 4480, Loss: 0.09391257911920547, Accuracy: 0.7450425052084029\n",
      "Iteration: 4544, Loss: 0.08642524480819702, Accuracy: 0.7499549917411059\n",
      "Iteration: 4608, Loss: 0.08907993882894516, Accuracy: 0.7485012351535261\n",
      "Iteration: 4672, Loss: 0.08825469017028809, Accuracy: 0.7406135066412389\n",
      "Iteration: 4736, Loss: 0.10323720425367355, Accuracy: 0.752618670463562\n",
      "Iteration: 4800, Loss: 0.10209430009126663, Accuracy: 0.7502875986974686\n",
      "Iteration: 4864, Loss: 0.26141753792762756, Accuracy: 0.7618184436578304\n",
      "Iteration: 4928, Loss: 0.1091628149151802, Accuracy: 0.7471664922777563\n",
      "Iteration: 4992, Loss: 0.10324370861053467, Accuracy: 0.744346370222047\n",
      "Iteration: 5056, Loss: 0.1088467612862587, Accuracy: 0.7490933386143297\n",
      "Iteration: 5120, Loss: 0.09276595711708069, Accuracy: 0.7304814287927002\n",
      "Iteration: 5184, Loss: 0.09185773134231567, Accuracy: 0.7595894967671484\n",
      "Iteration: 5248, Loss: 0.09676872938871384, Accuracy: 0.7641224770341069\n",
      "Iteration: 5312, Loss: 0.18188168108463287, Accuracy: 0.7632257542572916\n",
      "Iteration: 5376, Loss: 0.09827274829149246, Accuracy: 0.7697529557626694\n",
      "Iteration: 5440, Loss: 0.08909661322832108, Accuracy: 0.7650773110799491\n",
      "Iteration: 5504, Loss: 0.09320368617773056, Accuracy: 0.7591404388658702\n",
      "Iteration: 5568, Loss: 0.09133077412843704, Accuracy: 0.7547931554727256\n",
      "Iteration: 5632, Loss: 0.08993779867887497, Accuracy: 0.7670709281228483\n",
      "Iteration: 5696, Loss: 0.09580081701278687, Accuracy: 0.758995161158964\n",
      "Iteration: 5760, Loss: 0.08807522803544998, Accuracy: 0.7719686171039939\n",
      "Iteration: 5824, Loss: 0.08730826526880264, Accuracy: 0.7691927077248693\n",
      "Iteration: 5888, Loss: 0.09043050557374954, Accuracy: 0.7658649533987045\n",
      "Iteration: 5952, Loss: 0.09949424117803574, Accuracy: 0.7671669716946781\n",
      "Iteration: 6016, Loss: 0.09070459753274918, Accuracy: 0.7727379514835775\n",
      "Iteration: 6080, Loss: 0.08925623446702957, Accuracy: 0.7665180657058954\n",
      "Iteration: 6144, Loss: 0.09197802096605301, Accuracy: 0.7746837835293263\n",
      "Iteration: 6208, Loss: 0.0832521989941597, Accuracy: 0.7790749601554126\n",
      "Iteration: 6272, Loss: 0.08652514219284058, Accuracy: 0.7824240485206246\n",
      "Iteration: 6336, Loss: 0.09578952193260193, Accuracy: 0.7728908890858293\n",
      "Iteration: 6400, Loss: 0.08782406896352768, Accuracy: 0.7712051530834287\n",
      "Iteration: 6464, Loss: 0.08766230940818787, Accuracy: 0.7671372010372579\n",
      "Iteration: 6528, Loss: 0.08981559425592422, Accuracy: 0.7589704284910113\n",
      "Iteration: 6592, Loss: 0.08765408396720886, Accuracy: 0.7664307288359851\n",
      "Iteration: 6656, Loss: 0.09485583752393723, Accuracy: 0.78119817818515\n",
      "Iteration: 6720, Loss: 0.08685281127691269, Accuracy: 0.7794393114745617\n",
      "Iteration: 6784, Loss: 0.08762692660093307, Accuracy: 0.7649784723762423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 6848, Loss: 0.3119116425514221, Accuracy: 0.7770044384524226\n",
      "Iteration: 6912, Loss: 0.0915284976363182, Accuracy: 0.7763414343353361\n",
      "Iteration: 6976, Loss: 0.08978543430566788, Accuracy: 0.7637363779358566\n",
      "Iteration: 7040, Loss: 0.09392520040273666, Accuracy: 0.7725142673589289\n",
      "Iteration: 7104, Loss: 0.09441652148962021, Accuracy: 0.7641135815065354\n",
      "Iteration: 7168, Loss: 0.6149324774742126, Accuracy: 0.763279051752761\n",
      "Iteration: 7232, Loss: 0.09024086594581604, Accuracy: 0.759587555192411\n",
      "Iteration: 7296, Loss: 0.1074095070362091, Accuracy: 0.7771565520670265\n",
      "Iteration: 7360, Loss: 0.09449697285890579, Accuracy: 0.7783301647286862\n",
      "Iteration: 7424, Loss: 0.08432134240865707, Accuracy: 0.781574937980622\n",
      "Iteration: 7488, Loss: 0.08320895582437515, Accuracy: 0.787523017032072\n",
      "Iteration: 7552, Loss: 0.09154849499464035, Accuracy: 0.7699725262355059\n",
      "Iteration: 7616, Loss: 0.08501523733139038, Accuracy: 0.7871709521859884\n",
      "Iteration: 7680, Loss: 0.08534883707761765, Accuracy: 0.7820415140595287\n",
      "Iteration: 7744, Loss: 0.0948542132973671, Accuracy: 0.7835331612732261\n",
      "Iteration: 7808, Loss: 0.08642029017210007, Accuracy: 0.7847823824267834\n",
      "Iteration: 7872, Loss: 0.0881023108959198, Accuracy: 0.7777840087655932\n",
      "Iteration: 7936, Loss: 0.08743805438280106, Accuracy: 0.7874518523458391\n",
      "Iteration: 8000, Loss: 0.09106049686670303, Accuracy: 0.778589422814548\n",
      "Iteration: 8064, Loss: 0.08731850981712341, Accuracy: 0.7958007147535682\n",
      "Iteration: 8128, Loss: 0.08626729995012283, Accuracy: 0.7914270360488445\n",
      "Iteration: 8192, Loss: 0.0852704718708992, Accuracy: 0.7883936937432736\n",
      "Iteration: 8256, Loss: 0.08594325929880142, Accuracy: 0.7853282403666526\n",
      "Iteration: 8320, Loss: 0.08721699565649033, Accuracy: 0.7839657219592482\n",
      "Iteration: 8384, Loss: 0.08304847031831741, Accuracy: 0.7852951020468026\n",
      "Iteration: 8448, Loss: 0.09020266681909561, Accuracy: 0.7964817686006427\n",
      "Iteration: 8512, Loss: 0.08581990003585815, Accuracy: 0.7959560411982238\n",
      "Iteration: 8576, Loss: 0.0872858390212059, Accuracy: 0.7908725945744663\n",
      "Iteration: 8640, Loss: 0.0864158496260643, Accuracy: 0.7924546066205949\n",
      "Iteration: 8704, Loss: 0.09096670150756836, Accuracy: 0.788909227354452\n",
      "Iteration: 8768, Loss: 0.08302652090787888, Accuracy: 0.7820247635245323\n",
      "Iteration: 8832, Loss: 0.09023501724004745, Accuracy: 0.7907222050707787\n",
      "Iteration: 8896, Loss: 0.09033682942390442, Accuracy: 0.7805782300420105\n",
      "Iteration: 8960, Loss: 0.08675483614206314, Accuracy: 0.7805176533292979\n",
      "Iteration: 9024, Loss: 0.0899026021361351, Accuracy: 0.774303681217134\n",
      "Iteration: 9088, Loss: 0.08523043990135193, Accuracy: 0.7865595284383744\n",
      "Iteration: 9152, Loss: 0.08502934128046036, Accuracy: 0.798575138906017\n",
      "Iteration: 9216, Loss: 0.0854349434375763, Accuracy: 0.7906555992085487\n",
      "Iteration: 9280, Loss: 0.08370461314916611, Accuracy: 0.8007561229169369\n",
      "Iteration: 9344, Loss: 0.08761759847402573, Accuracy: 0.7915269788354635\n",
      "Iteration: 9408, Loss: 0.09008123725652695, Accuracy: 0.7915120350662619\n",
      "Iteration: 9472, Loss: 0.09044720977544785, Accuracy: 0.8012701380066574\n",
      "Iteration: 9536, Loss: 0.08907001465559006, Accuracy: 0.7991749448701739\n",
      "Iteration: 9600, Loss: 0.08387618511915207, Accuracy: 0.8036543682683259\n",
      "Iteration: 9664, Loss: 0.0832647904753685, Accuracy: 0.7832826704252511\n",
      "Iteration: 9728, Loss: 0.08725672960281372, Accuracy: 0.7689294246956706\n",
      "Iteration: 9792, Loss: 0.37618517875671387, Accuracy: 0.7797095822170377\n",
      "Iteration: 9856, Loss: 0.0901690199971199, Accuracy: 0.7914242246188223\n",
      "Iteration: 9920, Loss: 0.08721902221441269, Accuracy: 0.7986038539092988\n",
      "Iteration: 9984, Loss: 0.08410830050706863, Accuracy: 0.8000214034691453\n",
      "Iteration: 10048, Loss: 0.08704828470945358, Accuracy: 0.7973673499654979\n",
      "Iteration: 10112, Loss: 0.08541017025709152, Accuracy: 0.7947312584146857\n",
      "Iteration: 10176, Loss: 0.09033975005149841, Accuracy: 0.7953980893362314\n",
      "Iteration: 10240, Loss: 0.37571004033088684, Accuracy: 0.7888618039432913\n",
      "Iteration: 10304, Loss: 0.08592308312654495, Accuracy: 0.7962763116229326\n",
      "Iteration: 10368, Loss: 0.08378058671951294, Accuracy: 0.7961951862089336\n",
      "Iteration: 10432, Loss: 0.09053386002779007, Accuracy: 0.7972925086505711\n",
      "Iteration: 10496, Loss: 0.08477160334587097, Accuracy: 0.797064006794244\n",
      "Iteration: 10560, Loss: 0.08416468650102615, Accuracy: 0.8002958458382636\n",
      "Iteration: 10624, Loss: 0.08600211888551712, Accuracy: 0.79983866866678\n",
      "Iteration: 10688, Loss: 0.08977159112691879, Accuracy: 0.8012411023955792\n",
      "Iteration: 10752, Loss: 0.09132631868124008, Accuracy: 0.7977165572810918\n",
      "Iteration: 10816, Loss: 0.08646305650472641, Accuracy: 0.8015339053235948\n",
      "Iteration: 10880, Loss: 0.08287572115659714, Accuracy: 0.8023555814288557\n",
      "Iteration: 10944, Loss: 0.08203714340925217, Accuracy: 0.7838361200410873\n",
      "Iteration: 11008, Loss: 0.10489954799413681, Accuracy: 0.7952975910156965\n",
      "Iteration: 11072, Loss: 0.08977055549621582, Accuracy: 0.7933480434585363\n",
      "Iteration: 11136, Loss: 0.08934623748064041, Accuracy: 0.8044071348849684\n",
      "Iteration: 11200, Loss: 0.08560839295387268, Accuracy: 0.8033373551443219\n",
      "Iteration: 11264, Loss: 0.08261258155107498, Accuracy: 0.8041387961711735\n",
      "Iteration: 11328, Loss: 0.08215564489364624, Accuracy: 0.8007165403105319\n",
      "Iteration: 11392, Loss: 0.08594206720590591, Accuracy: 0.7830703190993518\n",
      "Iteration: 11456, Loss: 0.08867889642715454, Accuracy: 0.7911448574159294\n",
      "Iteration: 11520, Loss: 0.08193158358335495, Accuracy: 0.8032730214763433\n",
      "Iteration: 11584, Loss: 0.08435537666082382, Accuracy: 0.8041582042351365\n",
      "Iteration: 11648, Loss: 0.08399849385023117, Accuracy: 0.8093744239304215\n",
      "Iteration: 11712, Loss: 0.08302665501832962, Accuracy: 0.8049615835770965\n",
      "Iteration: 11776, Loss: 0.08457682281732559, Accuracy: 0.7903659872245044\n",
      "Iteration: 11840, Loss: 0.08397039026021957, Accuracy: 0.8089500553905964\n",
      "Iteration: 11904, Loss: 0.08428629487752914, Accuracy: 0.803265918744728\n",
      "Iteration: 11968, Loss: 0.08612558990716934, Accuracy: 0.8080592334736139\n",
      "Iteration: 12032, Loss: 0.2525879442691803, Accuracy: 0.7920203742105514\n",
      "Iteration: 12096, Loss: 0.08418909460306168, Accuracy: 0.7960666171275079\n",
      "Iteration: 12160, Loss: 0.08499759435653687, Accuracy: 0.7796694303397089\n",
      "Iteration: 12224, Loss: 0.08543065190315247, Accuracy: 0.7934919481631368\n",
      "Iteration: 12288, Loss: 0.08531609922647476, Accuracy: 0.8015173054300249\n",
      "Iteration: 12352, Loss: 0.08473845571279526, Accuracy: 0.8072648847009987\n",
      "Iteration: 12416, Loss: 0.08670982718467712, Accuracy: 0.8068214766681194\n",
      "Iteration: 12480, Loss: 0.08365684747695923, Accuracy: 0.8021840613801032\n",
      "Iteration: 12544, Loss: 0.08303965628147125, Accuracy: 0.8071492151357234\n",
      "Iteration: 12608, Loss: 0.08439567685127258, Accuracy: 0.7944359607063234\n",
      "Iteration: 12672, Loss: 0.08433737605810165, Accuracy: 0.8009647231083363\n",
      "Iteration: 12736, Loss: 0.08414021134376526, Accuracy: 0.7965523744933307\n",
      "Iteration: 12800, Loss: 0.08239011466503143, Accuracy: 0.8075019384268671\n",
      "Iteration: 12864, Loss: 0.08199352771043777, Accuracy: 0.8120646534953266\n",
      "Iteration: 12928, Loss: 0.0899837538599968, Accuracy: 0.8062074750196189\n",
      "Iteration: 12992, Loss: 0.08971158415079117, Accuracy: 0.8101892692502588\n",
      "Iteration: 13056, Loss: 0.08667030930519104, Accuracy: 0.8121713032014668\n",
      "Iteration: 13120, Loss: 0.08799544721841812, Accuracy: 0.8085004389286041\n",
      "Iteration: 13184, Loss: 0.08350944519042969, Accuracy: 0.7995036689098924\n",
      "Iteration: 13248, Loss: 0.08699022978544235, Accuracy: 0.809699634090066\n",
      "Iteration: 13312, Loss: 0.3789290487766266, Accuracy: 0.7991902858484536\n",
      "Iteration: 13376, Loss: 0.08891978859901428, Accuracy: 0.8050232706591487\n",
      "Iteration: 13440, Loss: 0.08251181989908218, Accuracy: 0.8064835020340979\n",
      "Iteration: 13504, Loss: 0.08166872709989548, Accuracy: 0.8074097484350204\n",
      "Iteration: 13568, Loss: 0.0877215787768364, Accuracy: 0.7955829678103328\n",
      "Iteration: 13632, Loss: 0.08948513120412827, Accuracy: 0.8129036480095237\n",
      "Iteration: 13696, Loss: 0.08842295408248901, Accuracy: 0.8085181077476591\n",
      "Iteration: 13760, Loss: 0.08742525428533554, Accuracy: 0.8025665851309896\n",
      "Iteration: 13824, Loss: 0.37158939242362976, Accuracy: 0.8040070186834782\n",
      "Iteration: 13888, Loss: 0.08445638418197632, Accuracy: 0.7997033402789384\n",
      "Iteration: 13952, Loss: 0.08454292267560959, Accuracy: 0.8084084189031273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 14016, Loss: 0.08652603626251221, Accuracy: 0.813141964841634\n",
      "Iteration: 14080, Loss: 0.08654898405075073, Accuracy: 0.8083287230692804\n",
      "Iteration: 14144, Loss: 0.0869135856628418, Accuracy: 0.813349632313475\n",
      "Iteration: 14208, Loss: 0.0873647928237915, Accuracy: 0.7970633930526674\n",
      "Iteration: 14272, Loss: 0.08655329793691635, Accuracy: 0.7767787107732147\n",
      "Iteration: 14336, Loss: 0.0817466452717781, Accuracy: 0.7713218186981976\n",
      "Iteration: 14400, Loss: 0.09700711816549301, Accuracy: 0.7980434759519994\n",
      "Iteration: 14464, Loss: 0.08347874134778976, Accuracy: 0.8001664825715125\n",
      "Iteration: 14528, Loss: 0.07976043969392776, Accuracy: 0.8064875828567892\n",
      "Iteration: 14592, Loss: 0.08278743922710419, Accuracy: 0.8095985553227365\n",
      "Iteration: 14656, Loss: 0.08344776183366776, Accuracy: 0.7989797545596957\n",
      "Iteration: 14720, Loss: 0.09229496121406555, Accuracy: 0.8018277189694345\n",
      "Iteration: 14784, Loss: 0.08476226776838303, Accuracy: 0.7878368410747498\n",
      "Iteration: 14848, Loss: 0.3764912188053131, Accuracy: 0.7768627407494932\n",
      "Iteration: 14912, Loss: 0.08855915069580078, Accuracy: 0.7727157149929553\n",
      "Iteration: 14976, Loss: 0.08804280310869217, Accuracy: 0.8113156370818615\n",
      "Iteration: 15040, Loss: 0.08684226870536804, Accuracy: 0.8048663272056729\n",
      "Iteration: 15104, Loss: 0.08175208419561386, Accuracy: 0.8057098707649857\n",
      "Iteration: 15168, Loss: 0.08500418066978455, Accuracy: 0.8134624008089304\n",
      "Iteration: 15232, Loss: 0.0858394131064415, Accuracy: 0.8079934257548302\n",
      "Iteration: 15296, Loss: 0.08125405013561249, Accuracy: 0.8093912596814334\n",
      "Iteration: 15360, Loss: 0.08677051216363907, Accuracy: 0.8092766478657722\n",
      "Iteration: 15424, Loss: 0.08356403559446335, Accuracy: 0.8092196392826736\n",
      "Iteration: 15488, Loss: 0.08396416157484055, Accuracy: 0.8108125303406268\n",
      "Iteration: 15552, Loss: 0.0848187506198883, Accuracy: 0.809365632943809\n",
      "Iteration: 15616, Loss: 0.08430192619562149, Accuracy: 0.8002893510274589\n",
      "Iteration: 15680, Loss: 0.08691441267728806, Accuracy: 0.8147982428781688\n",
      "Iteration: 15744, Loss: 0.08459562063217163, Accuracy: 0.8107626785058528\n",
      "Iteration: 15808, Loss: 0.08324406296014786, Accuracy: 0.8046766885090619\n",
      "Iteration: 15872, Loss: 0.08596546202898026, Accuracy: 0.798167411936447\n",
      "Iteration: 15936, Loss: 0.08415156602859497, Accuracy: 0.801633189432323\n",
      "Iteration: 16000, Loss: 0.0832250565290451, Accuracy: 0.8044491363689303\n",
      "Iteration: 16064, Loss: 0.0861709713935852, Accuracy: 0.8090109054464847\n",
      "Iteration: 16128, Loss: 0.08819243311882019, Accuracy: 0.7999510150402784\n",
      "Iteration: 16192, Loss: 0.08486777544021606, Accuracy: 0.806142580229789\n",
      "Iteration: 16256, Loss: 0.08539300411939621, Accuracy: 0.8149943493772298\n",
      "Iteration: 16320, Loss: 0.08672276139259338, Accuracy: 0.7960589246358722\n",
      "Iteration: 16384, Loss: 0.08764348179101944, Accuracy: 0.8146249318961054\n",
      "Iteration: 16448, Loss: 0.08326268941164017, Accuracy: 0.811260644113645\n",
      "Iteration: 16512, Loss: 0.08275657147169113, Accuracy: 0.8065895133186132\n",
      "Iteration: 16576, Loss: 0.0862768366932869, Accuracy: 0.8112034818623215\n",
      "Iteration: 16640, Loss: 0.08471912890672684, Accuracy: 0.8121501032728702\n",
      "Iteration: 16704, Loss: 0.08328114449977875, Accuracy: 0.8159894156269729\n",
      "Iteration: 16768, Loss: 0.08418919891119003, Accuracy: 0.793389456346631\n",
      "Iteration: 16832, Loss: 0.08350548148155212, Accuracy: 0.8098634367343038\n",
      "Iteration: 16896, Loss: 0.08633068948984146, Accuracy: 0.8156980888452381\n",
      "Iteration: 16960, Loss: 0.08376436680555344, Accuracy: 0.8139861912932247\n",
      "Iteration: 17024, Loss: 0.0848006010055542, Accuracy: 0.8059844472445548\n",
      "Iteration: 17088, Loss: 0.08418482542037964, Accuracy: 0.8170296519529074\n",
      "Iteration: 17152, Loss: 0.0857754573225975, Accuracy: 0.8029458865057677\n",
      "Iteration: 17216, Loss: 0.346544474363327, Accuracy: 0.8024255505297333\n",
      "Iteration: 17280, Loss: 0.08676338195800781, Accuracy: 0.8063056648243219\n",
      "Iteration: 17344, Loss: 0.08533372730016708, Accuracy: 0.8122040703892708\n",
      "Iteration: 17408, Loss: 0.08611048012971878, Accuracy: 0.8126872873399407\n",
      "Iteration: 17472, Loss: 0.08626779168844223, Accuracy: 0.8040737623814493\n",
      "Iteration: 17536, Loss: 0.08419405668973923, Accuracy: 0.8048717093188316\n",
      "Iteration: 17600, Loss: 0.08317631483078003, Accuracy: 0.7976023857481778\n",
      "Iteration: 17664, Loss: 0.08533064275979996, Accuracy: 0.8109738412313163\n",
      "Iteration: 17728, Loss: 0.08591437339782715, Accuracy: 0.8103514506947249\n",
      "Iteration: 17792, Loss: 0.08228921890258789, Accuracy: 0.8172779374290258\n",
      "Iteration: 17856, Loss: 0.08785293251276016, Accuracy: 0.8113554425071925\n",
      "Iteration: 17920, Loss: 0.08290994167327881, Accuracy: 0.8148101957049221\n",
      "Iteration: 17984, Loss: 0.09965024143457413, Accuracy: 0.7797460742294788\n",
      "Iteration: 18048, Loss: 0.08530783653259277, Accuracy: 0.797320333076641\n",
      "Iteration: 18112, Loss: 0.08440183848142624, Accuracy: 0.8079747408628464\n",
      "Iteration: 18176, Loss: 0.08494728803634644, Accuracy: 0.8164373789913952\n",
      "Iteration: 18240, Loss: 0.08451367169618607, Accuracy: 0.8166432590223849\n",
      "Iteration: 18304, Loss: 0.07884784787893295, Accuracy: 0.8101892205886543\n",
      "Iteration: 18368, Loss: 0.08553632348775864, Accuracy: 0.8123534799087793\n",
      "Iteration: 18432, Loss: 0.08467737585306168, Accuracy: 0.8048278342466801\n",
      "Iteration: 18496, Loss: 0.08487965911626816, Accuracy: 0.7611028177198023\n",
      "Iteration: 18560, Loss: 0.08293839544057846, Accuracy: 0.8126084350515157\n",
      "Iteration: 18624, Loss: 0.08716578036546707, Accuracy: 0.8128089446108788\n",
      "Iteration: 18688, Loss: 0.08032197505235672, Accuracy: 0.8059949232265353\n",
      "Iteration: 18752, Loss: 0.0855976864695549, Accuracy: 0.816285734763369\n",
      "Iteration: 18816, Loss: 0.08336911350488663, Accuracy: 0.8089664578437805\n",
      "Iteration: 18880, Loss: 0.08409198373556137, Accuracy: 0.8180255193728954\n",
      "Iteration: 18944, Loss: 0.08659851551055908, Accuracy: 0.8099440864752978\n",
      "Iteration: 19008, Loss: 0.08386392146348953, Accuracy: 0.81699806638062\n",
      "Iteration: 19072, Loss: 0.08282452076673508, Accuracy: 0.8120971613097936\n",
      "Iteration: 19136, Loss: 0.08391617983579636, Accuracy: 0.8136177745182067\n",
      "Iteration: 19200, Loss: 0.08524215966463089, Accuracy: 0.8164405045099556\n",
      "Iteration: 19264, Loss: 0.0831306055188179, Accuracy: 0.7990313591435552\n",
      "Iteration: 19328, Loss: 0.08526241034269333, Accuracy: 0.7961361042689532\n",
      "Iteration: 19392, Loss: 0.08510419726371765, Accuracy: 0.8180165332742035\n",
      "Iteration: 19456, Loss: 0.11656695604324341, Accuracy: 0.8003570358268917\n",
      "Iteration: 19520, Loss: 0.08718448877334595, Accuracy: 0.7971566093619913\n",
      "Iteration: 19584, Loss: 0.08365445584058762, Accuracy: 0.790332016069442\n",
      "Iteration: 19648, Loss: 0.08480977267026901, Accuracy: 0.8086504868697375\n",
      "Iteration: 19712, Loss: 0.08139117062091827, Accuracy: 0.8182682960759848\n",
      "Iteration: 19776, Loss: 0.3799320161342621, Accuracy: 0.8096533676143736\n",
      "Iteration: 19840, Loss: 0.08444405347108841, Accuracy: 0.8134907465428114\n",
      "Iteration: 19904, Loss: 0.08715017884969711, Accuracy: 0.8133457815274596\n",
      "Iteration: 19968, Loss: 0.087226003408432, Accuracy: 0.8176058570388705\n",
      "Iteration: 20032, Loss: 0.08570953458547592, Accuracy: 0.8188924125861377\n",
      "Iteration: 20096, Loss: 0.08259479701519012, Accuracy: 0.818996615242213\n",
      "Iteration: 20160, Loss: 0.0835345908999443, Accuracy: 0.8137690944131464\n",
      "Iteration: 20224, Loss: 0.0876542255282402, Accuracy: 0.8186896007973701\n",
      "Iteration: 20288, Loss: 0.3852628767490387, Accuracy: 0.8123654664959759\n",
      "Iteration: 20352, Loss: 0.0867031142115593, Accuracy: 0.8026876980438828\n",
      "Iteration: 20416, Loss: 0.08391817659139633, Accuracy: 0.8142368732951581\n",
      "Iteration: 20480, Loss: 0.08830393105745316, Accuracy: 0.8077767954673618\n",
      "Iteration: 20544, Loss: 0.08833428472280502, Accuracy: 0.7992350615095347\n",
      "Iteration: 20608, Loss: 0.08380034565925598, Accuracy: 0.8187036952003837\n",
      "Iteration: 20672, Loss: 0.08473410457372665, Accuracy: 0.8136598016135395\n",
      "Iteration: 20736, Loss: 0.08552489429712296, Accuracy: 0.8192296703346074\n",
      "Iteration: 20800, Loss: 0.08705088496208191, Accuracy: 0.8092051951680332\n",
      "Iteration: 20864, Loss: 0.08502393960952759, Accuracy: 0.8148465612903237\n",
      "Iteration: 20928, Loss: 0.08378072828054428, Accuracy: 0.8164846925064921\n",
      "Iteration: 20992, Loss: 0.08552508801221848, Accuracy: 0.804723335430026\n",
      "Iteration: 21056, Loss: 0.08505245298147202, Accuracy: 0.8197160670533776\n",
      "Iteration: 21120, Loss: 0.0852930024266243, Accuracy: 0.8064812514930964\n",
      "Iteration: 21184, Loss: 0.08280375599861145, Accuracy: 0.8080269077327102\n",
      "Iteration: 21248, Loss: 0.08333203941583633, Accuracy: 0.8168484268244356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 21312, Loss: 0.08453858643770218, Accuracy: 0.8149812403135002\n",
      "Iteration: 21376, Loss: 0.07921158522367477, Accuracy: 0.8198174482677132\n",
      "Iteration: 21440, Loss: 0.08545460551977158, Accuracy: 0.8094317768700421\n",
      "Iteration: 21504, Loss: 0.0839688703417778, Accuracy: 0.8185608135536313\n",
      "Iteration: 21568, Loss: 0.08244264870882034, Accuracy: 0.8166691772639751\n",
      "Iteration: 21632, Loss: 0.08193714916706085, Accuracy: 0.8196950985584408\n",
      "Iteration: 21696, Loss: 0.08423519134521484, Accuracy: 0.81460678903386\n",
      "Iteration: 21760, Loss: 0.08355250209569931, Accuracy: 0.8144593946635723\n",
      "Iteration: 21824, Loss: 0.08496487885713577, Accuracy: 0.8066638128366321\n",
      "Iteration: 21888, Loss: 0.0853644609451294, Accuracy: 0.8103990275412798\n",
      "Iteration: 21952, Loss: 0.08568889647722244, Accuracy: 0.8048798979725689\n",
      "Iteration: 22016, Loss: 0.08674204349517822, Accuracy: 0.8092492590658367\n",
      "Iteration: 22080, Loss: 0.08508813381195068, Accuracy: 0.8110090729314834\n",
      "Iteration: 22144, Loss: 0.0829821452498436, Accuracy: 0.8157754992134869\n",
      "Iteration: 22208, Loss: 0.08122269809246063, Accuracy: 0.8159882393665612\n",
      "Iteration: 22272, Loss: 0.08482661843299866, Accuracy: 0.786690327571705\n",
      "Iteration: 22336, Loss: 0.08861509710550308, Accuracy: 0.8179992036893964\n",
      "Iteration: 22400, Loss: 0.08194760233163834, Accuracy: 0.8044002742972225\n",
      "Iteration: 22464, Loss: 0.08919001370668411, Accuracy: 0.8207461833953857\n",
      "Iteration: 22528, Loss: 0.0826045423746109, Accuracy: 0.8153439713642001\n",
      "Iteration: 22592, Loss: 0.08427778631448746, Accuracy: 0.8200160856358707\n",
      "Iteration: 22656, Loss: 0.08490336686372757, Accuracy: 0.819966779788956\n",
      "Iteration: 22720, Loss: 0.08393245935440063, Accuracy: 0.8209966975264251\n",
      "Iteration: 22784, Loss: 0.08554735034704208, Accuracy: 0.8148811892606318\n",
      "Iteration: 22848, Loss: 0.08584702759981155, Accuracy: 0.8156924906652421\n",
      "Iteration: 22912, Loss: 0.08522725105285645, Accuracy: 0.8034933162853122\n",
      "Iteration: 22976, Loss: 0.08333560824394226, Accuracy: 0.80179109191522\n",
      "Iteration: 23040, Loss: 0.08346909284591675, Accuracy: 0.8039834399241954\n",
      "Iteration: 23104, Loss: 0.08438890427350998, Accuracy: 0.8155450976919383\n",
      "Iteration: 23168, Loss: 0.08507341146469116, Accuracy: 0.8107704853173345\n",
      "Iteration: 23232, Loss: 0.08261515200138092, Accuracy: 0.8203187063336372\n",
      "Iteration: 23296, Loss: 0.08400795608758926, Accuracy: 0.8199360442813486\n",
      "Iteration: 23360, Loss: 0.08445143699645996, Accuracy: 0.8161483858712018\n",
      "Iteration: 23424, Loss: 0.08443766087293625, Accuracy: 0.8210638139862567\n",
      "Iteration: 23488, Loss: 0.08520972728729248, Accuracy: 0.810693641891703\n",
      "Iteration: 23552, Loss: 0.0850767269730568, Accuracy: 0.816155122127384\n",
      "Iteration: 23616, Loss: 0.08395607024431229, Accuracy: 0.8208176176995039\n",
      "Iteration: 23680, Loss: 0.08376848697662354, Accuracy: 0.8209625950548798\n",
      "Iteration: 23744, Loss: 0.08425436168909073, Accuracy: 0.8211340620182455\n",
      "Iteration: 23808, Loss: 0.08499083667993546, Accuracy: 0.8208027221262455\n",
      "Iteration: 23872, Loss: 0.08301972597837448, Accuracy: 0.8105973263736814\n",
      "Iteration: 23936, Loss: 0.08540713042020798, Accuracy: 0.820910029578954\n",
      "Iteration: 24000, Loss: 0.08338870853185654, Accuracy: 0.8210161267779768\n",
      "Iteration: 24064, Loss: 0.08519673347473145, Accuracy: 0.8160319349262863\n",
      "Iteration: 24128, Loss: 0.08548293262720108, Accuracy: 0.8217790925409645\n",
      "Iteration: 24192, Loss: 0.08371181041002274, Accuracy: 0.8205565949901938\n",
      "Iteration: 24256, Loss: 0.08654764294624329, Accuracy: 0.8064348783809692\n",
      "Iteration: 24320, Loss: 0.08595773577690125, Accuracy: 0.8197339249309152\n",
      "Iteration: 24384, Loss: 0.08394228667020798, Accuracy: 0.8106568539515138\n",
      "Iteration: 24448, Loss: 0.08503829687833786, Accuracy: 0.8204059563577175\n",
      "Iteration: 24512, Loss: 0.08540315181016922, Accuracy: 0.8067172814626247\n",
      "Iteration: 24576, Loss: 0.08418545871973038, Accuracy: 0.8221278383862227\n",
      "Iteration: 24640, Loss: 0.08494842797517776, Accuracy: 0.8205977552570403\n",
      "Iteration: 24704, Loss: 0.08400550484657288, Accuracy: 0.816406495636329\n",
      "Iteration: 24768, Loss: 0.08450799435377121, Accuracy: 0.8165852671954781\n",
      "Iteration: 24832, Loss: 0.08436685055494308, Accuracy: 0.8216868105810136\n",
      "Iteration: 24896, Loss: 0.08434947580099106, Accuracy: 0.8172979827504605\n",
      "Iteration: 24960, Loss: 0.08734605461359024, Accuracy: 0.8219144437462091\n",
      "Iteration: 25024, Loss: 0.4002966582775116, Accuracy: 0.8069703504443169\n",
      "Iteration: 25088, Loss: 0.08552363514900208, Accuracy: 0.8169158776290715\n",
      "Iteration: 25152, Loss: 0.08322738111019135, Accuracy: 0.8223426286131144\n",
      "Iteration: 25216, Loss: 0.08434808254241943, Accuracy: 0.8173432003241032\n",
      "Iteration: 25280, Loss: 0.08402947336435318, Accuracy: 0.8171703461557627\n",
      "Iteration: 25344, Loss: 0.08420789241790771, Accuracy: 0.8224421262275428\n",
      "Iteration: 25408, Loss: 0.087258480489254, Accuracy: 0.817521657794714\n",
      "Iteration: 25472, Loss: 0.08514127880334854, Accuracy: 0.8194474091287702\n",
      "Iteration: 25536, Loss: 0.0856766477227211, Accuracy: 0.8168507311493158\n",
      "Iteration: 25600, Loss: 0.08569785952568054, Accuracy: 0.8213531165383756\n",
      "Iteration: 25664, Loss: 0.08243230730295181, Accuracy: 0.8219798454083502\n",
      "Iteration: 25728, Loss: 0.08188267797231674, Accuracy: 0.8180951133836061\n",
      "Iteration: 25792, Loss: 0.38758227229118347, Accuracy: 0.7986358047928661\n",
      "Iteration: 25856, Loss: 0.08168093115091324, Accuracy: 0.77779968874529\n",
      "Iteration: 25920, Loss: 0.08738207817077637, Accuracy: 0.8031117038335651\n",
      "Iteration: 25984, Loss: 0.08033496141433716, Accuracy: 0.7873366249259561\n",
      "Iteration: 26048, Loss: 0.0848962739109993, Accuracy: 0.8100009830668569\n",
      "Iteration: 26112, Loss: 0.0891503393650055, Accuracy: 0.8080056228209287\n",
      "Iteration: 26176, Loss: 0.08586191385984421, Accuracy: 0.8089179757516831\n",
      "Iteration: 26240, Loss: 0.08240579068660736, Accuracy: 0.816871474031359\n",
      "Iteration: 26304, Loss: 0.08651737123727798, Accuracy: 0.8207512667868286\n",
      "Iteration: 26368, Loss: 0.08524695783853531, Accuracy: 0.80152532691136\n",
      "Iteration: 26432, Loss: 0.08130805939435959, Accuracy: 0.8215565814170986\n",
      "Iteration: 26496, Loss: 0.08144187182188034, Accuracy: 0.8196483314968646\n",
      "Iteration: 26560, Loss: 0.08572039753198624, Accuracy: 0.818438304355368\n",
      "Iteration: 26624, Loss: 0.08532282710075378, Accuracy: 0.8001999068073928\n",
      "Iteration: 26688, Loss: 0.0849832221865654, Accuracy: 0.8208614306058735\n",
      "Iteration: 26752, Loss: 0.085004061460495, Accuracy: 0.8032086009625345\n",
      "Iteration: 26816, Loss: 0.08254895359277725, Accuracy: 0.8073612209409475\n",
      "Iteration: 26880, Loss: 0.08451509475708008, Accuracy: 0.8073028004728258\n",
      "Iteration: 26944, Loss: 0.08340299129486084, Accuracy: 0.8230850461404771\n",
      "Iteration: 27008, Loss: 0.08258960396051407, Accuracy: 0.8133533648215234\n",
      "Iteration: 27072, Loss: 0.08222543448209763, Accuracy: 0.8180765721481293\n",
      "Iteration: 27136, Loss: 0.08290958404541016, Accuracy: 0.8180182292126119\n",
      "Iteration: 27200, Loss: 0.08415693789720535, Accuracy: 0.8187758831772953\n",
      "Iteration: 27264, Loss: 0.09161394089460373, Accuracy: 0.8172972262836993\n",
      "Iteration: 27328, Loss: 0.08296915143728256, Accuracy: 0.822800847934559\n",
      "Iteration: 27392, Loss: 0.0853331908583641, Accuracy: 0.8229866486508399\n",
      "Iteration: 27456, Loss: 0.08366745710372925, Accuracy: 0.8185362489894032\n",
      "Iteration: 27520, Loss: 0.08512317389249802, Accuracy: 0.8217620372306556\n",
      "Iteration: 27584, Loss: 0.08590852469205856, Accuracy: 0.817916018422693\n",
      "Iteration: 27648, Loss: 0.08568405359983444, Accuracy: 0.8056165056768805\n",
      "Iteration: 27712, Loss: 0.082967109978199, Accuracy: 0.8108909619040787\n",
      "Iteration: 27776, Loss: 0.08300087600946426, Accuracy: 0.8231543225701898\n",
      "Iteration: 27840, Loss: 0.08334638923406601, Accuracy: 0.8185621893499047\n",
      "Iteration: 27904, Loss: 0.09357858449220657, Accuracy: 0.8176595196127892\n",
      "Iteration: 27968, Loss: 0.0826093927025795, Accuracy: 0.8233943658415228\n",
      "Iteration: 28032, Loss: 0.08535704761743546, Accuracy: 0.8233533203601837\n",
      "Iteration: 28096, Loss: 0.08324966579675674, Accuracy: 0.8229382177814841\n",
      "Iteration: 28160, Loss: 0.08523651957511902, Accuracy: 0.8182978541590273\n",
      "Iteration: 28224, Loss: 0.08522805571556091, Accuracy: 0.8235854706726968\n",
      "Iteration: 28288, Loss: 0.08487686514854431, Accuracy: 0.8212547171860933\n",
      "Iteration: 28352, Loss: 0.08443213254213333, Accuracy: 0.8239728494081646\n",
      "Iteration: 28416, Loss: 0.08609119057655334, Accuracy: 0.8236555666662753\n",
      "Iteration: 28480, Loss: 0.08358973264694214, Accuracy: 0.8233849459793419\n",
      "Iteration: 28544, Loss: 0.08438137918710709, Accuracy: 0.8185120683629066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 28608, Loss: 0.08565518260002136, Accuracy: 0.8220769499894232\n",
      "Iteration: 28672, Loss: 0.08453961461782455, Accuracy: 0.8187087893020362\n",
      "Iteration: 28736, Loss: 0.09867560863494873, Accuracy: 0.7999676659237593\n",
      "Iteration: 28800, Loss: 0.0872965157032013, Accuracy: 0.8239813076797873\n",
      "Iteration: 28864, Loss: 0.08408740162849426, Accuracy: 0.8163850076962262\n",
      "Iteration: 28928, Loss: 0.08521628379821777, Accuracy: 0.817590662278235\n",
      "Iteration: 28992, Loss: 0.0856533944606781, Accuracy: 0.8224882162176073\n",
      "Iteration: 29056, Loss: 0.08236465603113174, Accuracy: 0.8241280182264745\n",
      "Iteration: 29120, Loss: 0.08584213256835938, Accuracy: 0.8242672637570649\n",
      "Iteration: 29184, Loss: 0.08377032727003098, Accuracy: 0.8240825005341321\n",
      "Iteration: 29248, Loss: 0.08616688847541809, Accuracy: 0.8240872302558273\n",
      "Iteration: 29312, Loss: 0.0849975049495697, Accuracy: 0.8239903410430998\n",
      "Iteration: 29376, Loss: 0.08305750042200089, Accuracy: 0.8234051594045013\n",
      "Iteration: 29440, Loss: 0.08365292102098465, Accuracy: 0.822914301417768\n",
      "Iteration: 29504, Loss: 0.0848873183131218, Accuracy: 0.824002651264891\n",
      "Iteration: 29568, Loss: 0.0841209813952446, Accuracy: 0.8195722131058574\n",
      "Iteration: 29632, Loss: 0.0855141282081604, Accuracy: 0.8245631994213909\n",
      "Iteration: 29696, Loss: 0.0829833373427391, Accuracy: 0.8245017654262483\n",
      "Iteration: 29760, Loss: 0.08354441076517105, Accuracy: 0.8192074128892273\n",
      "Iteration: 29824, Loss: 0.08435720205307007, Accuracy: 0.822501132497564\n",
      "Iteration: 29888, Loss: 0.08469320088624954, Accuracy: 0.8152862899005413\n",
      "Iteration: 29952, Loss: 0.08457040041685104, Accuracy: 0.8084458699449897\n",
      "Iteration: 30016, Loss: 0.08313573151826859, Accuracy: 0.819820033153519\n",
      "Iteration: 30080, Loss: 0.08404883742332458, Accuracy: 0.819705433677882\n",
      "Iteration: 30144, Loss: 0.08364229649305344, Accuracy: 0.8242981799412519\n",
      "Iteration: 30208, Loss: 0.0839611068367958, Accuracy: 0.8197066893335432\n",
      "Iteration: 30272, Loss: 0.08459633588790894, Accuracy: 0.8246104111894965\n",
      "Iteration: 30336, Loss: 0.08443617075681686, Accuracy: 0.821878379676491\n",
      "Iteration: 30400, Loss: 0.08213455229997635, Accuracy: 0.8118919604457915\n",
      "Iteration: 30464, Loss: 0.08198908716440201, Accuracy: 0.8086465634405613\n",
      "Iteration: 30528, Loss: 0.08482155948877335, Accuracy: 0.8091031161602587\n",
      "Iteration: 30592, Loss: 0.08205749839544296, Accuracy: 0.8237042131368071\n",
      "Iteration: 30656, Loss: 0.08227301388978958, Accuracy: 0.8180248904973269\n",
      "Iteration: 30720, Loss: 0.08408058434724808, Accuracy: 0.813323758309707\n",
      "Iteration: 30784, Loss: 0.08263809233903885, Accuracy: 0.8248757536057383\n",
      "Iteration: 30848, Loss: 0.08192800730466843, Accuracy: 0.7996654445305467\n",
      "Iteration: 30912, Loss: 0.0867154523730278, Accuracy: 0.8168657319620252\n",
      "Iteration: 30976, Loss: 0.08577672392129898, Accuracy: 0.820031699957326\n",
      "Iteration: 31040, Loss: 0.08248931914567947, Accuracy: 0.8243756636511534\n",
      "Iteration: 31104, Loss: 0.08350136131048203, Accuracy: 0.8236654542852193\n",
      "Iteration: 31168, Loss: 0.08413686603307724, Accuracy: 0.8241588422097266\n",
      "Iteration: 31232, Loss: 0.08645686507225037, Accuracy: 0.8247351851314306\n",
      "Iteration: 31296, Loss: 0.0827070027589798, Accuracy: 0.8192129211965948\n",
      "Iteration: 31360, Loss: 0.08487647771835327, Accuracy: 0.8243229170329869\n",
      "Iteration: 31424, Loss: 0.08368176221847534, Accuracy: 0.8238187646493316\n",
      "Iteration: 31488, Loss: 0.08482726663351059, Accuracy: 0.8235645454842597\n",
      "Iteration: 31552, Loss: 0.0853986069560051, Accuracy: 0.8240585024468601\n",
      "Iteration: 31616, Loss: 0.08386503905057907, Accuracy: 0.8248924266081303\n",
      "Iteration: 31680, Loss: 0.08689864724874496, Accuracy: 0.8149582042824477\n",
      "Iteration: 31744, Loss: 0.08298172056674957, Accuracy: 0.8248908054083586\n",
      "Iteration: 31808, Loss: 0.08391144126653671, Accuracy: 0.819472978124395\n",
      "Iteration: 31872, Loss: 0.08512404561042786, Accuracy: 0.8249486412387341\n",
      "Iteration: 31936, Loss: 0.08583883196115494, Accuracy: 0.8241005586460233\n",
      "Iteration: 32000, Loss: 0.08608388155698776, Accuracy: 0.8198056935798377\n",
      "Iteration: 32064, Loss: 0.08486300706863403, Accuracy: 0.8248646347783506\n",
      "Iteration: 32128, Loss: 0.08397384732961655, Accuracy: 0.8142251279205084\n",
      "Iteration: 32192, Loss: 0.08370271325111389, Accuracy: 0.8248465803917497\n",
      "Iteration: 32256, Loss: 0.08479637652635574, Accuracy: 0.8252990648616105\n",
      "Iteration: 32320, Loss: 0.08486133068799973, Accuracy: 0.8252832188736647\n",
      "Iteration: 32384, Loss: 0.08335114270448685, Accuracy: 0.8249080919194967\n",
      "Iteration: 32448, Loss: 0.08309219032526016, Accuracy: 0.8246397036127746\n",
      "Iteration: 32512, Loss: 0.08441410213708878, Accuracy: 0.8179103441070765\n",
      "Iteration: 32576, Loss: 0.08439350128173828, Accuracy: 0.8134975684806705\n",
      "Iteration: 32640, Loss: 0.08308231085538864, Accuracy: 0.8150980309583247\n",
      "Iteration: 32704, Loss: 0.08628535270690918, Accuracy: 0.7619001336861402\n",
      "Iteration: 32768, Loss: 0.08394662290811539, Accuracy: 0.8088339837267995\n",
      "Iteration: 32832, Loss: 0.08178588002920151, Accuracy: 0.8077670747879893\n",
      "Iteration: 32896, Loss: 0.08694877475500107, Accuracy: 0.8081988114863634\n",
      "Iteration: 32960, Loss: 0.08716998249292374, Accuracy: 0.8230484104715288\n",
      "Iteration: 33024, Loss: 0.08445785194635391, Accuracy: 0.8224773104302585\n",
      "Iteration: 33088, Loss: 0.08636397868394852, Accuracy: 0.8241423754952848\n",
      "Iteration: 33152, Loss: 0.08474007248878479, Accuracy: 0.8138116335030645\n",
      "Iteration: 33216, Loss: 0.08184779435396194, Accuracy: 0.8249121580738574\n",
      "Iteration: 33280, Loss: 0.08378452062606812, Accuracy: 0.8142826147377491\n",
      "Iteration: 33344, Loss: 0.08224166184663773, Accuracy: 0.8038116276729852\n",
      "Iteration: 33408, Loss: 0.0854547917842865, Accuracy: 0.8141093729063869\n",
      "Iteration: 33472, Loss: 0.08435803651809692, Accuracy: 0.8250067527405918\n",
      "Iteration: 33536, Loss: 0.08660533279180527, Accuracy: 0.8196832796093076\n",
      "Iteration: 33600, Loss: 0.0802246630191803, Accuracy: 0.808424468152225\n",
      "Iteration: 33664, Loss: 0.08417478203773499, Accuracy: 0.8232128813397139\n",
      "Iteration: 33728, Loss: 0.08315016329288483, Accuracy: 0.8245272650383413\n",
      "Iteration: 33792, Loss: 0.08520371466875076, Accuracy: 0.824460641015321\n",
      "Iteration: 33856, Loss: 0.08432925492525101, Accuracy: 0.8203023683745414\n",
      "Iteration: 33920, Loss: 0.08353374153375626, Accuracy: 0.8151222399901599\n",
      "Iteration: 33984, Loss: 0.39767488837242126, Accuracy: 0.8140363928396255\n",
      "Iteration: 34048, Loss: 0.08507435768842697, Accuracy: 0.8144992615561932\n",
      "Iteration: 34112, Loss: 0.08574049919843674, Accuracy: 0.8220698195509613\n",
      "Iteration: 34176, Loss: 0.0849650502204895, Accuracy: 0.8245321353897452\n",
      "Iteration: 34240, Loss: 0.0852435901761055, Accuracy: 0.8247693895827979\n",
      "Iteration: 34304, Loss: 0.08623255044221878, Accuracy: 0.8252522484399378\n",
      "Iteration: 34368, Loss: 0.08117116242647171, Accuracy: 0.8201826277654618\n",
      "Iteration: 34432, Loss: 0.08376087993383408, Accuracy: 0.8035732212010771\n",
      "Iteration: 34496, Loss: 0.08224374055862427, Accuracy: 0.8253296681214124\n",
      "Iteration: 34560, Loss: 0.08471360802650452, Accuracy: 0.8239415721036494\n",
      "Iteration: 34624, Loss: 0.0846288725733757, Accuracy: 0.8075162880122662\n",
      "Iteration: 34688, Loss: 0.08511897176504135, Accuracy: 0.8201249432750046\n",
      "Iteration: 34752, Loss: 0.08342785388231277, Accuracy: 0.8067236414644867\n",
      "Iteration: 34816, Loss: 0.0848965048789978, Accuracy: 0.8030202279333025\n",
      "Iteration: 34880, Loss: 0.08415301889181137, Accuracy: 0.8204630522523075\n",
      "Iteration: 34944, Loss: 0.08595413714647293, Accuracy: 0.8243584870360792\n",
      "Iteration: 35008, Loss: 0.08376596122980118, Accuracy: 0.8128519987221807\n",
      "Iteration: 35072, Loss: 0.08377447724342346, Accuracy: 0.8247546418569982\n",
      "Iteration: 35136, Loss: 0.08165783435106277, Accuracy: 0.8187289771158248\n",
      "Iteration: 35200, Loss: 0.08081553131341934, Accuracy: 0.8244109482038766\n",
      "Iteration: 35264, Loss: 0.0864018127322197, Accuracy: 0.8239882306661457\n",
      "Iteration: 35328, Loss: 0.08184590935707092, Accuracy: 0.8153144919779152\n",
      "Iteration: 35392, Loss: 0.08396527171134949, Accuracy: 0.814433358842507\n",
      "Iteration: 35456, Loss: 0.08355338126420975, Accuracy: 0.8239342973101884\n",
      "Iteration: 35520, Loss: 0.08669150620698929, Accuracy: 0.8219184917397797\n",
      "Iteration: 35584, Loss: 0.08712049573659897, Accuracy: 0.823154820362106\n",
      "Iteration: 35648, Loss: 0.08365336805582047, Accuracy: 0.8202641909010708\n",
      "Iteration: 35712, Loss: 0.08248525857925415, Accuracy: 0.8153990339487791\n",
      "Iteration: 35776, Loss: 0.08785317093133926, Accuracy: 0.8252515227068216\n",
      "Iteration: 35840, Loss: 0.08208513259887695, Accuracy: 0.8208294927608222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 35904, Loss: 0.08244416862726212, Accuracy: 0.8104661977849901\n",
      "Iteration: 35968, Loss: 0.39933833479881287, Accuracy: 0.8142789069097489\n",
      "Iteration: 36032, Loss: 0.08799224346876144, Accuracy: 0.8246031526941806\n",
      "Iteration: 36096, Loss: 0.08374863862991333, Accuracy: 0.8203108897432685\n",
      "Iteration: 36160, Loss: 0.08531844615936279, Accuracy: 0.8255074846092612\n",
      "Iteration: 36224, Loss: 0.08595026284456253, Accuracy: 0.8248527394607663\n",
      "Iteration: 36288, Loss: 0.08421516418457031, Accuracy: 0.8243884476833045\n",
      "Iteration: 36352, Loss: 0.08303514122962952, Accuracy: 0.8243597326800227\n",
      "Iteration: 36416, Loss: 0.08480122685432434, Accuracy: 0.8149973726831377\n",
      "Iteration: 36480, Loss: 0.08315133303403854, Accuracy: 0.8198932325467467\n",
      "Iteration: 36544, Loss: 0.08623572438955307, Accuracy: 0.8203156902454793\n",
      "Iteration: 36608, Loss: 0.08450987935066223, Accuracy: 0.8246464610565454\n",
      "Iteration: 36672, Loss: 0.08654352277517319, Accuracy: 0.8250505591277033\n",
      "Iteration: 36736, Loss: 0.086479552090168, Accuracy: 0.8205306236632168\n",
      "Iteration: 36800, Loss: 0.0856371745467186, Accuracy: 0.8151370689738542\n",
      "Iteration: 36864, Loss: 0.08334089070558548, Accuracy: 0.8155390799511224\n",
      "Iteration: 36928, Loss: 0.08505594730377197, Accuracy: 0.8257597594056278\n",
      "Iteration: 36992, Loss: 0.08229371160268784, Accuracy: 0.8249242824967951\n",
      "Iteration: 37056, Loss: 0.08518116921186447, Accuracy: 0.825998670887202\n",
      "Iteration: 37120, Loss: 0.08264191448688507, Accuracy: 0.8256372665055096\n",
      "Iteration: 37184, Loss: 0.0864008367061615, Accuracy: 0.819338338682428\n",
      "Iteration: 37248, Loss: 0.08520349115133286, Accuracy: 0.819708994589746\n",
      "Iteration: 37312, Loss: 0.08571682125329971, Accuracy: 0.825036917347461\n",
      "Iteration: 37376, Loss: 0.08402669429779053, Accuracy: 0.8258410587441176\n",
      "Iteration: 37440, Loss: 0.08473452180624008, Accuracy: 0.8204799420200288\n",
      "Iteration: 37504, Loss: 0.08352958410978317, Accuracy: 0.8051732548046857\n",
      "Iteration: 37568, Loss: 0.08338762074708939, Accuracy: 0.8205268392339349\n",
      "Iteration: 37632, Loss: 0.0840839222073555, Accuracy: 0.8257783974986523\n",
      "Iteration: 37696, Loss: 0.08474428206682205, Accuracy: 0.8255799559410661\n",
      "Iteration: 37760, Loss: 0.08336164802312851, Accuracy: 0.8209430335555226\n",
      "Iteration: 37824, Loss: 0.08468300104141235, Accuracy: 0.8053611379582435\n",
      "Iteration: 37888, Loss: 0.08514080196619034, Accuracy: 0.8045265602413565\n",
      "Iteration: 37952, Loss: 0.086654432117939, Accuracy: 0.8223507723305374\n",
      "Iteration: 38016, Loss: 0.08681109547615051, Accuracy: 0.8104132353328168\n",
      "Iteration: 38080, Loss: 0.08429189771413803, Accuracy: 0.8192618370521814\n",
      "Iteration: 38144, Loss: 0.08405094593763351, Accuracy: 0.8171420120634139\n",
      "Iteration: 38208, Loss: 0.08219294995069504, Accuracy: 0.8234921591356397\n",
      "Iteration: 38272, Loss: 0.08786529302597046, Accuracy: 0.8247341914102435\n",
      "Iteration: 38336, Loss: 0.08302327245473862, Accuracy: 0.8261182529386133\n",
      "Iteration: 38400, Loss: 0.08896949142217636, Accuracy: 0.8171367994509637\n",
      "Iteration: 38464, Loss: 0.08212711662054062, Accuracy: 0.8190302986185998\n",
      "Iteration: 38528, Loss: 0.08359258621931076, Accuracy: 0.8156669677700847\n",
      "Iteration: 38592, Loss: 0.08213337510824203, Accuracy: 0.8123251171782613\n",
      "Iteration: 38656, Loss: 0.08490852266550064, Accuracy: 0.8058286604937166\n",
      "Iteration: 38720, Loss: 0.08393711596727371, Accuracy: 0.8123491920996457\n",
      "Iteration: 38784, Loss: 0.08197561651468277, Accuracy: 0.8177234893664718\n",
      "Iteration: 38848, Loss: 0.08428129553794861, Accuracy: 0.8205929424148053\n",
      "Iteration: 38912, Loss: 0.0855942890048027, Accuracy: 0.8202071113046259\n",
      "Iteration: 38976, Loss: 0.08693352341651917, Accuracy: 0.82499726023525\n",
      "Iteration: 39040, Loss: 0.08517815917730331, Accuracy: 0.8204168521333486\n",
      "Iteration: 39104, Loss: 0.08221568167209625, Accuracy: 0.8205180731602013\n",
      "Iteration: 39168, Loss: 0.08415437489748001, Accuracy: 0.8237745522055775\n",
      "Iteration: 39232, Loss: 0.08531118184328079, Accuracy: 0.8153605405241251\n",
      "Iteration: 39296, Loss: 0.08365485072135925, Accuracy: 0.8251623299438506\n",
      "Iteration: 39360, Loss: 0.08400601148605347, Accuracy: 0.8207842137198895\n",
      "Iteration: 39424, Loss: 0.08283126354217529, Accuracy: 0.826005254406482\n",
      "Iteration: 39488, Loss: 0.08389479666948318, Accuracy: 0.8200503278058022\n",
      "Iteration: 39552, Loss: 0.08119809627532959, Accuracy: 0.8256014662329108\n",
      "Iteration: 39616, Loss: 0.08338064700365067, Accuracy: 0.8158071988727897\n",
      "Iteration: 39680, Loss: 0.0820545181632042, Accuracy: 0.8247698382474482\n",
      "Iteration: 39744, Loss: 0.08600877970457077, Accuracy: 0.8212211409118026\n",
      "Iteration: 39808, Loss: 0.086312435567379, Accuracy: 0.8252578508108854\n",
      "Iteration: 39872, Loss: 0.0835103914141655, Accuracy: 0.8200880384538323\n",
      "Iteration: 39936, Loss: 0.08470496535301208, Accuracy: 0.8216546387411654\n",
      "Iteration: 40000, Loss: 0.08535421639680862, Accuracy: 0.8253517486155033\n",
      "Iteration: 40064, Loss: 0.0832141861319542, Accuracy: 0.8214376792311668\n",
      "Iteration: 40128, Loss: 0.08550634980201721, Accuracy: 0.8252869695425034\n",
      "Iteration: 40192, Loss: 0.08249824494123459, Accuracy: 0.8257856818381697\n",
      "Iteration: 40256, Loss: 0.0847126767039299, Accuracy: 0.8261253570672125\n",
      "Iteration: 40320, Loss: 0.08428961038589478, Accuracy: 0.8253306967671961\n",
      "Iteration: 40384, Loss: 0.08597143739461899, Accuracy: 0.8161210992839187\n",
      "Iteration: 40448, Loss: 0.08417878299951553, Accuracy: 0.8259951306972653\n",
      "Iteration: 40512, Loss: 0.08508016914129257, Accuracy: 0.8203325837384909\n",
      "Iteration: 40576, Loss: 0.08440905809402466, Accuracy: 0.8257284632418305\n",
      "Iteration: 40640, Loss: 0.08462513238191605, Accuracy: 0.8144887066446245\n",
      "Iteration: 40704, Loss: 0.08315864950418472, Accuracy: 0.8208142975345254\n",
      "Iteration: 40768, Loss: 0.08404604345560074, Accuracy: 0.8205914362333715\n",
      "Iteration: 40832, Loss: 0.08452537655830383, Accuracy: 0.820529482094571\n",
      "Iteration: 40896, Loss: 0.0811871811747551, Accuracy: 0.8205769108608365\n",
      "Iteration: 40960, Loss: 0.08345627784729004, Accuracy: 0.8118824721314013\n",
      "Iteration: 41024, Loss: 0.08398763090372086, Accuracy: 0.8204946075566113\n",
      "Iteration: 41088, Loss: 0.08067140728235245, Accuracy: 0.79982585972175\n",
      "Iteration: 41152, Loss: 0.08722862601280212, Accuracy: 0.7821990645024925\n",
      "Iteration: 41216, Loss: 0.7304005026817322, Accuracy: 0.7960219520609826\n",
      "Iteration: 41280, Loss: 0.08738409727811813, Accuracy: 0.8171148921828717\n",
      "Iteration: 41344, Loss: 0.0855032429099083, Accuracy: 0.8052046720404178\n",
      "Iteration: 41408, Loss: 0.08591365814208984, Accuracy: 0.8199606770649552\n",
      "Iteration: 41472, Loss: 0.08513623476028442, Accuracy: 0.8111291341483593\n",
      "Iteration: 41536, Loss: 0.07929634302854538, Accuracy: 0.8061325300950557\n",
      "Iteration: 41600, Loss: 0.08455125242471695, Accuracy: 0.8239462363999337\n",
      "Iteration: 41664, Loss: 0.08695921301841736, Accuracy: 0.7921286569908261\n",
      "Iteration: 41728, Loss: 0.08193664997816086, Accuracy: 0.8143883279990405\n",
      "Iteration: 41792, Loss: 0.08464769273996353, Accuracy: 0.8153740544803441\n",
      "Iteration: 41856, Loss: 0.07464258372783661, Accuracy: 0.8210977760609239\n",
      "Iteration: 41920, Loss: 0.08543816953897476, Accuracy: 0.8123563658446074\n",
      "Iteration: 41984, Loss: 0.08234501630067825, Accuracy: 0.8110034072306007\n",
      "Iteration: 42048, Loss: 0.08246263116598129, Accuracy: 0.8252393130678684\n",
      "Iteration: 42112, Loss: 0.0855323076248169, Accuracy: 0.811359500978142\n",
      "Iteration: 42176, Loss: 0.08035696297883987, Accuracy: 0.8183674863539636\n",
      "Iteration: 42240, Loss: 0.0842580497264862, Accuracy: 0.8154406007379293\n",
      "Iteration: 42304, Loss: 0.09286906570196152, Accuracy: 0.8252270247321576\n",
      "Iteration: 42368, Loss: 0.08687435835599899, Accuracy: 0.82013109466061\n",
      "Iteration: 42432, Loss: 0.08294381946325302, Accuracy: 0.8174408916383982\n",
      "Iteration: 42496, Loss: 0.07845428586006165, Accuracy: 0.8167254307772964\n",
      "Iteration: 42560, Loss: 0.07605519145727158, Accuracy: 0.8238902287557721\n",
      "Iteration: 42624, Loss: 0.0813164934515953, Accuracy: 0.8055307127069682\n",
      "Iteration: 42688, Loss: 0.07701931148767471, Accuracy: 0.8107302938587964\n",
      "Iteration: 42752, Loss: 0.07689598947763443, Accuracy: 0.8237898473162204\n",
      "Iteration: 42816, Loss: 0.0849788561463356, Accuracy: 0.8256570999510586\n",
      "Iteration: 42880, Loss: 0.0818890705704689, Accuracy: 0.8175185127183795\n",
      "Iteration: 42944, Loss: 0.0831703469157219, Accuracy: 0.8232409185729921\n",
      "Iteration: 43008, Loss: 0.08174199610948563, Accuracy: 0.8246982609853148\n",
      "Iteration: 43072, Loss: 0.0817127451300621, Accuracy: 0.8049928438849747\n",
      "Iteration: 43136, Loss: 0.0907500609755516, Accuracy: 0.8235808371100575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 43200, Loss: 0.07723361998796463, Accuracy: 0.8106078875716776\n",
      "Iteration: 43264, Loss: 0.0837165042757988, Accuracy: 0.8195162939373404\n",
      "Iteration: 43328, Loss: 0.08036809414625168, Accuracy: 0.8194781141355634\n",
      "Iteration: 43392, Loss: 0.08228295296430588, Accuracy: 0.8245167455170304\n",
      "Iteration: 43456, Loss: 0.08839798718690872, Accuracy: 0.8246610788628459\n",
      "Iteration: 43520, Loss: 0.08933987468481064, Accuracy: 0.8088269659783691\n",
      "Iteration: 43584, Loss: 0.08308648318052292, Accuracy: 0.804573642089963\n",
      "Iteration: 43648, Loss: 0.0858563780784607, Accuracy: 0.8147653471678495\n",
      "Iteration: 43712, Loss: 0.08479738235473633, Accuracy: 0.82348080445081\n",
      "Iteration: 43776, Loss: 0.08500746637582779, Accuracy: 0.8173917948734015\n",
      "Iteration: 43840, Loss: 0.07907204329967499, Accuracy: 0.8239107627887279\n",
      "Iteration: 43904, Loss: 0.08538394421339035, Accuracy: 0.8183949168305844\n",
      "Iteration: 43968, Loss: 0.08388179540634155, Accuracy: 0.8147540737409145\n",
      "Iteration: 44032, Loss: 0.0880565345287323, Accuracy: 0.8207630417309701\n",
      "Iteration: 44096, Loss: 0.08355215936899185, Accuracy: 0.8254411714151502\n",
      "Iteration: 44160, Loss: 0.08014576882123947, Accuracy: 0.8202352924272418\n",
      "Iteration: 44224, Loss: 0.08725177496671677, Accuracy: 0.7956264889799058\n",
      "Iteration: 44288, Loss: 0.08215919882059097, Accuracy: 0.8094527658540756\n",
      "Iteration: 44352, Loss: 0.08506359905004501, Accuracy: 0.8198414668440819\n",
      "Iteration: 44416, Loss: 0.08365803956985474, Accuracy: 0.8154983860440552\n",
      "Iteration: 44480, Loss: 0.08230435103178024, Accuracy: 0.8249191241338849\n",
      "Iteration: 44544, Loss: 0.08473385125398636, Accuracy: 0.8245968241244555\n",
      "Iteration: 44608, Loss: 0.08141576498746872, Accuracy: 0.8189275378827006\n",
      "Iteration: 44672, Loss: 0.08162253350019455, Accuracy: 0.8246288313530385\n",
      "Iteration: 44736, Loss: 0.08492983132600784, Accuracy: 0.8249064963310957\n",
      "Iteration: 44800, Loss: 0.08729378134012222, Accuracy: 0.8244456259999424\n",
      "Iteration: 44864, Loss: 0.08132894337177277, Accuracy: 0.8251978356856853\n",
      "Iteration: 44928, Loss: 0.08548983186483383, Accuracy: 0.8252834377344698\n",
      "Iteration: 44992, Loss: 0.08670546859502792, Accuracy: 0.8247873997315764\n",
      "Iteration: 45056, Loss: 0.08422628045082092, Accuracy: 0.8252274619881064\n",
      "Iteration: 45120, Loss: 0.08351912349462509, Accuracy: 0.8251165635883808\n",
      "Iteration: 45184, Loss: 0.08622446656227112, Accuracy: 0.8248493019491434\n",
      "Iteration: 45248, Loss: 0.08691275119781494, Accuracy: 0.8209773206617683\n",
      "Iteration: 45312, Loss: 0.0868411734700203, Accuracy: 0.8202413278631866\n",
      "Iteration: 45376, Loss: 0.08593335002660751, Accuracy: 0.8208665789570659\n",
      "Iteration: 45440, Loss: 0.08632171899080276, Accuracy: 0.8255708303768188\n",
      "Iteration: 45504, Loss: 0.08312481641769409, Accuracy: 0.8254147560801357\n",
      "Iteration: 45568, Loss: 0.08409330993890762, Accuracy: 0.815818936098367\n",
      "Iteration: 45632, Loss: 0.08560869842767715, Accuracy: 0.8209235789254308\n",
      "Iteration: 45696, Loss: 0.08523745089769363, Accuracy: 0.8258551436010748\n",
      "Iteration: 45760, Loss: 0.08416175097227097, Accuracy: 0.8254316134843975\n",
      "Iteration: 45824, Loss: 0.0829625204205513, Accuracy: 0.8253254231531173\n",
      "Iteration: 45888, Loss: 0.08228164911270142, Accuracy: 0.8243893452454358\n",
      "Iteration: 45952, Loss: 0.08564109355211258, Accuracy: 0.822267034323886\n",
      "Iteration: 46016, Loss: 0.08642906695604324, Accuracy: 0.8043309322092682\n",
      "Iteration: 46080, Loss: 0.08558207005262375, Accuracy: 0.8103813214693218\n",
      "Iteration: 46144, Loss: 0.083493672311306, Accuracy: 0.8160229527857155\n",
      "Iteration: 46208, Loss: 0.08320041000843048, Accuracy: 0.8257393063977361\n",
      "Iteration: 46272, Loss: 0.08635324984788895, Accuracy: 0.8257614674512297\n",
      "Iteration: 46336, Loss: 0.08205140382051468, Accuracy: 0.8132445206865668\n",
      "Iteration: 46400, Loss: 0.08383753150701523, Accuracy: 0.8245923470240086\n",
      "Iteration: 46464, Loss: 0.08656752109527588, Accuracy: 0.8237516463268548\n",
      "Iteration: 46528, Loss: 0.08147448301315308, Accuracy: 0.8117193838115782\n",
      "Iteration: 46592, Loss: 0.08171994239091873, Accuracy: 0.8257908020168543\n",
      "Iteration: 46656, Loss: 0.08384024351835251, Accuracy: 0.8201281754299998\n",
      "Iteration: 46720, Loss: 0.08434557914733887, Accuracy: 0.8242592888418585\n",
      "Iteration: 46784, Loss: 0.08238648623228073, Accuracy: 0.8161578692961484\n",
      "Iteration: 46848, Loss: 0.08480692654848099, Accuracy: 0.8216010783798993\n",
      "Iteration: 46912, Loss: 0.08226578682661057, Accuracy: 0.8120086241979152\n",
      "Iteration: 46976, Loss: 0.08439606428146362, Accuracy: 0.8214356971438974\n",
      "Iteration: 47040, Loss: 0.08531397581100464, Accuracy: 0.8175569179002196\n",
      "Iteration: 47104, Loss: 0.08607853204011917, Accuracy: 0.8168799197301269\n",
      "Iteration: 47168, Loss: 0.08497479557991028, Accuracy: 0.8160164766013622\n",
      "Iteration: 47232, Loss: 0.08625298738479614, Accuracy: 0.8230439769104123\n",
      "Iteration: 47296, Loss: 0.08375056833028793, Accuracy: 0.81443973002024\n",
      "Iteration: 47360, Loss: 0.0869276225566864, Accuracy: 0.8258077055215836\n",
      "Iteration: 47424, Loss: 0.08426160365343094, Accuracy: 0.8166338764131069\n",
      "Iteration: 47488, Loss: 0.08295834064483643, Accuracy: 0.8212910417933017\n",
      "Iteration: 47552, Loss: 0.08531550318002701, Accuracy: 0.8208357649855316\n",
      "Iteration: 47616, Loss: 0.08409842848777771, Accuracy: 0.818609283072874\n",
      "Iteration: 47680, Loss: 0.08558407425880432, Accuracy: 0.8244818323291838\n",
      "Iteration: 47744, Loss: 0.08188361674547195, Accuracy: 0.8215587609447539\n",
      "Iteration: 47808, Loss: 0.08252211660146713, Accuracy: 0.8254591920413077\n",
      "Iteration: 47872, Loss: 0.08431213349103928, Accuracy: 0.8256154633127153\n",
      "Iteration: 47936, Loss: 0.08382882922887802, Accuracy: 0.8189224521629512\n",
      "Iteration: 48000, Loss: 0.0855676457285881, Accuracy: 0.825804044958204\n",
      "Iteration: 48064, Loss: 0.08373145014047623, Accuracy: 0.8257724661380053\n",
      "Iteration: 48128, Loss: 0.08350232988595963, Accuracy: 0.8247917224653065\n",
      "Iteration: 48192, Loss: 0.08642398566007614, Accuracy: 0.8264737222343683\n",
      "Iteration: 48256, Loss: 0.08492166548967361, Accuracy: 0.8262142688035965\n",
      "Iteration: 48320, Loss: 0.08625241369009018, Accuracy: 0.82626743032597\n",
      "Iteration: 48384, Loss: 0.0834924578666687, Accuracy: 0.824101890437305\n",
      "Iteration: 48448, Loss: 0.0865856483578682, Accuracy: 0.8205818277783692\n",
      "Iteration: 48512, Loss: 0.4016526937484741, Accuracy: 0.8150089415721595\n",
      "Iteration: 48576, Loss: 0.08733474463224411, Accuracy: 0.8179379478096962\n",
      "Iteration: 48640, Loss: 0.08402211219072342, Accuracy: 0.8257162102963775\n",
      "Iteration: 48704, Loss: 0.08557889610528946, Accuracy: 0.8201999408192933\n",
      "Iteration: 48768, Loss: 0.08454238623380661, Accuracy: 0.8270420334301889\n",
      "Iteration: 48832, Loss: 0.0822753980755806, Accuracy: 0.8266857115086168\n",
      "Iteration: 48896, Loss: 0.08398833870887756, Accuracy: 0.8240745959337801\n",
      "Iteration: 48960, Loss: 0.08666986972093582, Accuracy: 0.8265864599961787\n",
      "Iteration: 49024, Loss: 0.08153996616601944, Accuracy: 0.8165392708033323\n",
      "Iteration: 49088, Loss: 0.084914930164814, Accuracy: 0.8213805954437703\n",
      "Iteration: 49152, Loss: 0.08295177668333054, Accuracy: 0.8259001122787595\n",
      "Iteration: 49216, Loss: 0.08127085119485855, Accuracy: 0.8213200343307108\n",
      "Iteration: 49280, Loss: 0.08510106801986694, Accuracy: 0.8249404733069241\n",
      "Iteration: 49344, Loss: 0.396932452917099, Accuracy: 0.8207913695368916\n",
      "Iteration: 49408, Loss: 0.08352411538362503, Accuracy: 0.8266151587013155\n",
      "Iteration: 49472, Loss: 0.08657342195510864, Accuracy: 0.8217554003931582\n",
      "Iteration: 49536, Loss: 0.08354493230581284, Accuracy: 0.8265654279384762\n",
      "Iteration: 49600, Loss: 0.08413077145814896, Accuracy: 0.8265212490223348\n",
      "Iteration: 49664, Loss: 0.08428621292114258, Accuracy: 0.8270860814955086\n",
      "Iteration: 49728, Loss: 0.08250748366117477, Accuracy: 0.826583516318351\n",
      "Iteration: 49792, Loss: 0.08530529588460922, Accuracy: 0.8215647023171186\n",
      "Iteration: 49856, Loss: 0.08446692675352097, Accuracy: 0.8147347448393703\n",
      "Iteration: 49920, Loss: 0.08256584405899048, Accuracy: 0.8072710405103862\n",
      "Iteration: 49984, Loss: 0.08322414010763168, Accuracy: 0.8246357629541308\n",
      "Iteration: 50048, Loss: 0.081990085542202, Accuracy: 0.8216143124736845\n",
      "Iteration: 50112, Loss: 0.08312264829874039, Accuracy: 0.8163877443876117\n",
      "Iteration: 50176, Loss: 0.08498888462781906, Accuracy: 0.825945105869323\n",
      "Iteration: 50240, Loss: 0.08570846170186996, Accuracy: 0.8217594565358013\n",
      "Iteration: 50304, Loss: 0.08370495587587357, Accuracy: 0.8266713775228709\n",
      "Iteration: 50368, Loss: 0.08460647612810135, Accuracy: 0.8265459758695215\n",
      "Iteration: 50432, Loss: 0.08523398637771606, Accuracy: 0.8264904182869941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 50496, Loss: 0.08500096201896667, Accuracy: 0.8217628872953355\n",
      "Iteration: 50560, Loss: 0.08548274636268616, Accuracy: 0.8262178909499198\n",
      "Iteration: 50624, Loss: 0.0847041979432106, Accuracy: 0.826518103480339\n",
      "Iteration: 50688, Loss: 0.08668029308319092, Accuracy: 0.8262067979667336\n",
      "Iteration: 50752, Loss: 0.08205399662256241, Accuracy: 0.8264657501131296\n",
      "Iteration: 50816, Loss: 0.08383234590291977, Accuracy: 0.8076785693410784\n",
      "Iteration: 50880, Loss: 0.08217085152864456, Accuracy: 0.8267762856557965\n",
      "Iteration: 50944, Loss: 0.08545605093240738, Accuracy: 0.8238956839777529\n",
      "Iteration: 51008, Loss: 0.08317556232213974, Accuracy: 0.8203645837493241\n",
      "Iteration: 51072, Loss: 0.085149846971035, Accuracy: 0.8002549812663347\n",
      "Iteration: 51136, Loss: 0.08417487144470215, Accuracy: 0.7909754060674459\n",
      "Iteration: 51200, Loss: 0.08542602509260178, Accuracy: 0.8167630222160369\n",
      "Iteration: 51264, Loss: 0.08451592922210693, Accuracy: 0.8101680828258395\n",
      "Iteration: 51328, Loss: 0.08378398418426514, Accuracy: 0.8247815284412354\n",
      "Iteration: 51392, Loss: 0.08293655514717102, Accuracy: 0.8204591027460992\n",
      "Iteration: 51456, Loss: 0.08207102119922638, Accuracy: 0.8257276478689164\n",
      "Iteration: 51520, Loss: 0.08105108886957169, Accuracy: 0.8196099838241935\n",
      "Iteration: 51584, Loss: 0.08395164459943771, Accuracy: 0.8210789358709008\n",
      "Iteration: 51648, Loss: 0.08639431744813919, Accuracy: 0.8260304399300367\n",
      "Iteration: 51712, Loss: 0.08384395390748978, Accuracy: 0.8262866253498942\n",
      "Iteration: 51776, Loss: 0.08214683085680008, Accuracy: 0.8156125799287111\n",
      "Iteration: 51840, Loss: 0.0842476561665535, Accuracy: 0.826052213087678\n",
      "Iteration: 51904, Loss: 0.0844913125038147, Accuracy: 0.8264051154255867\n",
      "Iteration: 51968, Loss: 0.08606163412332535, Accuracy: 0.7973355865105987\n",
      "Iteration: 52032, Loss: 0.08502952009439468, Accuracy: 0.8032341869547963\n",
      "Iteration: 52096, Loss: 0.08338161557912827, Accuracy: 0.825917151523754\n",
      "Iteration: 52160, Loss: 0.08422762155532837, Accuracy: 0.8161716831382364\n",
      "Iteration: 52224, Loss: 0.08248182386159897, Accuracy: 0.8260041906032711\n",
      "Iteration: 52288, Loss: 0.08437642455101013, Accuracy: 0.8211440136656165\n",
      "Iteration: 52352, Loss: 0.08515552431344986, Accuracy: 0.8164222661871463\n",
      "Iteration: 52416, Loss: 0.08376380056142807, Accuracy: 0.8132610656321049\n",
      "Iteration: 52480, Loss: 0.08665116876363754, Accuracy: 0.8265246383380145\n",
      "Iteration: 52544, Loss: 0.0834256112575531, Accuracy: 0.8200316475704312\n",
      "Iteration: 52608, Loss: 0.08288780599832535, Accuracy: 0.8264413843862712\n",
      "Iteration: 52672, Loss: 0.08180543035268784, Accuracy: 0.8164118072018027\n",
      "Iteration: 52736, Loss: 0.08362394571304321, Accuracy: 0.8265183495823294\n",
      "Iteration: 52800, Loss: 0.08319910615682602, Accuracy: 0.8118147607892752\n",
      "Iteration: 52864, Loss: 0.08599091321229935, Accuracy: 0.8203293278347701\n",
      "Iteration: 52928, Loss: 0.08321667462587357, Accuracy: 0.8161044276785105\n",
      "Iteration: 52992, Loss: 0.0835166797041893, Accuracy: 0.8115141044836491\n",
      "Iteration: 53056, Loss: 0.08434492349624634, Accuracy: 0.8259945036843419\n",
      "Iteration: 53120, Loss: 0.0834333673119545, Accuracy: 0.8258174993097782\n",
      "Iteration: 53184, Loss: 0.08544391393661499, Accuracy: 0.826721882680431\n",
      "Iteration: 53248, Loss: 0.08627114444971085, Accuracy: 0.8167600804008543\n",
      "Iteration: 53312, Loss: 0.08487769216299057, Accuracy: 0.8260887733194977\n",
      "Iteration: 53376, Loss: 0.08530786633491516, Accuracy: 0.8269708529114723\n",
      "Iteration: 53440, Loss: 0.08034856617450714, Accuracy: 0.8213619005400687\n",
      "Iteration: 53504, Loss: 0.08346215635538101, Accuracy: 0.8252226219046861\n",
      "Iteration: 53568, Loss: 0.08391141891479492, Accuracy: 0.8259280603379011\n",
      "Iteration: 53632, Loss: 0.08266294747591019, Accuracy: 0.8262392284814268\n",
      "Iteration: 53696, Loss: 0.08419188112020493, Accuracy: 0.8255168681498617\n",
      "Iteration: 53760, Loss: 0.08417787402868271, Accuracy: 0.8261532394681126\n",
      "Iteration: 53824, Loss: 0.08337447792291641, Accuracy: 0.8009639331139624\n",
      "Iteration: 53888, Loss: 0.08241710811853409, Accuracy: 0.8264163893181831\n",
      "Iteration: 53952, Loss: 0.08590856939554214, Accuracy: 0.8252506621647626\n",
      "Iteration: 54016, Loss: 0.08478468656539917, Accuracy: 0.823870140593499\n",
      "Iteration: 54080, Loss: 0.08485504239797592, Accuracy: 0.8267910147551447\n",
      "Iteration: 54144, Loss: 0.08391531556844711, Accuracy: 0.8269783798605204\n",
      "Iteration: 54208, Loss: 0.0837063416838646, Accuracy: 0.8250581144820899\n",
      "Iteration: 54272, Loss: 0.08559597283601761, Accuracy: 0.8184545044787228\n",
      "Iteration: 54336, Loss: 0.08508428186178207, Accuracy: 0.8223581621423364\n",
      "Iteration: 54400, Loss: 0.0859154760837555, Accuracy: 0.822219401365146\n",
      "Iteration: 54464, Loss: 0.08380934596061707, Accuracy: 0.8205777977127582\n",
      "Iteration: 54528, Loss: 0.0832313522696495, Accuracy: 0.8168637179769576\n",
      "Iteration: 54592, Loss: 0.08464508503675461, Accuracy: 0.8083889731206\n",
      "Iteration: 54656, Loss: 0.08538779616355896, Accuracy: 0.8222970410715789\n",
      "Iteration: 54720, Loss: 0.08065476268529892, Accuracy: 0.8217740543186665\n",
      "Iteration: 54784, Loss: 0.08458268642425537, Accuracy: 0.8174532549455762\n",
      "Iteration: 54848, Loss: 0.08299960196018219, Accuracy: 0.8260807592887431\n",
      "Iteration: 54912, Loss: 0.08541736006736755, Accuracy: 0.8210855480283499\n",
      "Iteration: 54976, Loss: 0.0827643945813179, Accuracy: 0.8181791494134814\n",
      "Iteration: 55040, Loss: 0.08338365703821182, Accuracy: 0.8170537997502834\n",
      "Iteration: 55104, Loss: 0.08495524525642395, Accuracy: 0.821948713157326\n",
      "Iteration: 55168, Loss: 0.08302347362041473, Accuracy: 0.8267402115743607\n",
      "Iteration: 55232, Loss: 0.08514963835477829, Accuracy: 0.8177026165649295\n",
      "Iteration: 55296, Loss: 0.08260268718004227, Accuracy: 0.8139573875814676\n",
      "Iteration: 55360, Loss: 0.08668167144060135, Accuracy: 0.8242083564400673\n",
      "Iteration: 55424, Loss: 0.0863666757941246, Accuracy: 0.8087773779407144\n",
      "Iteration: 55488, Loss: 0.08598622679710388, Accuracy: 0.8193408837541938\n",
      "Iteration: 55552, Loss: 0.0835985466837883, Accuracy: 0.8146735921036452\n",
      "Iteration: 55616, Loss: 0.0838908851146698, Accuracy: 0.8201638923492283\n",
      "Iteration: 55680, Loss: 0.08112285286188126, Accuracy: 0.8225243433844298\n",
      "Iteration: 55744, Loss: 0.08322436362504959, Accuracy: 0.8208549781702459\n",
      "Iteration: 55808, Loss: 0.08408418297767639, Accuracy: 0.8264184149447829\n",
      "Iteration: 55872, Loss: 0.0854090228676796, Accuracy: 0.8242356921546161\n",
      "Iteration: 55936, Loss: 0.06960784643888474, Accuracy: 0.8204842582345009\n",
      "Iteration: 56000, Loss: 0.08290818333625793, Accuracy: 0.8197740199975669\n",
      "Iteration: 56064, Loss: 0.08321353793144226, Accuracy: 0.8241049614734948\n",
      "Iteration: 56128, Loss: 0.08505108207464218, Accuracy: 0.8260913577396423\n",
      "Iteration: 56192, Loss: 0.08639142662286758, Accuracy: 0.8106505593750626\n",
      "Iteration: 56256, Loss: 0.0840163603425026, Accuracy: 0.8259653663262725\n",
      "Iteration: 56320, Loss: 0.08305781334638596, Accuracy: 0.825111118145287\n",
      "Iteration: 56384, Loss: 0.0827786847949028, Accuracy: 0.8163121382240206\n",
      "Iteration: 56448, Loss: 0.0823611244559288, Accuracy: 0.8229455105029047\n",
      "Iteration: 56512, Loss: 0.08383151888847351, Accuracy: 0.8168653671164066\n",
      "Iteration: 56576, Loss: 0.0824669599533081, Accuracy: 0.8105134272482246\n",
      "Iteration: 56640, Loss: 0.08421185612678528, Accuracy: 0.8268807134591043\n",
      "Iteration: 56704, Loss: 0.0852426066994667, Accuracy: 0.8267615877557546\n",
      "Iteration: 56768, Loss: 0.08233223110437393, Accuracy: 0.8056627751793712\n",
      "Iteration: 56832, Loss: 0.08518605679273605, Accuracy: 0.8112921805586666\n",
      "Iteration: 56896, Loss: 0.08632352203130722, Accuracy: 0.8270590303000063\n",
      "Iteration: 56960, Loss: 0.08605211228132248, Accuracy: 0.820941295241937\n",
      "Iteration: 57024, Loss: 0.08289290964603424, Accuracy: 0.8267403801437467\n",
      "Iteration: 57088, Loss: 0.0820375457406044, Accuracy: 0.8166863028891385\n",
      "Iteration: 57152, Loss: 0.08233055472373962, Accuracy: 0.8169374822173268\n",
      "Iteration: 57216, Loss: 0.08234133571386337, Accuracy: 0.8023832691833377\n",
      "Iteration: 57280, Loss: 0.08420819044113159, Accuracy: 0.82150525925681\n",
      "Iteration: 57344, Loss: 0.08470157533884048, Accuracy: 0.8117628288455307\n",
      "Iteration: 57408, Loss: 0.08424923568964005, Accuracy: 0.8120460296049714\n",
      "Iteration: 57472, Loss: 0.084781713783741, Accuracy: 0.8221949944272637\n",
      "Iteration: 57536, Loss: 0.08693265169858932, Accuracy: 0.8264205004088581\n",
      "Iteration: 57600, Loss: 0.0860757902264595, Accuracy: 0.8156110495328903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 57664, Loss: 0.08486612886190414, Accuracy: 0.8264383014757186\n",
      "Iteration: 57728, Loss: 0.08465039730072021, Accuracy: 0.8260779166594148\n",
      "Iteration: 57792, Loss: 0.08595812320709229, Accuracy: 0.8270523715764284\n",
      "Iteration: 57856, Loss: 0.0852687656879425, Accuracy: 0.8219336594920605\n",
      "Iteration: 57920, Loss: 0.08339619636535645, Accuracy: 0.8269191652070731\n",
      "Iteration: 57984, Loss: 0.08540945500135422, Accuracy: 0.8270620414987206\n",
      "Iteration: 58048, Loss: 0.08539101481437683, Accuracy: 0.8272133322898299\n",
      "Iteration: 58112, Loss: 0.08502022176980972, Accuracy: 0.8223939321469516\n",
      "Iteration: 58176, Loss: 0.08474879711866379, Accuracy: 0.8269772287458181\n",
      "Iteration: 58240, Loss: 0.08125869184732437, Accuracy: 0.8271197373978794\n",
      "Iteration: 58304, Loss: 0.08396107703447342, Accuracy: 0.82708322070539\n",
      "Iteration: 58368, Loss: 0.08318593353033066, Accuracy: 0.8270685623865575\n",
      "Iteration: 58432, Loss: 0.0850929319858551, Accuracy: 0.8269968794193119\n",
      "Iteration: 58496, Loss: 0.0870385691523552, Accuracy: 0.8269155586604029\n",
      "Iteration: 58560, Loss: 0.08591673523187637, Accuracy: 0.8219417282380164\n",
      "Iteration: 58624, Loss: 0.08200295269489288, Accuracy: 0.8274645721539855\n",
      "Iteration: 58688, Loss: 0.08415644615888596, Accuracy: 0.8172879305202514\n",
      "Iteration: 58752, Loss: 0.08324034512042999, Accuracy: 0.8274175687693059\n",
      "Iteration: 58816, Loss: 0.08364325016736984, Accuracy: 0.8075529432389885\n",
      "Iteration: 58880, Loss: 0.08404934406280518, Accuracy: 0.7963571236468852\n",
      "Iteration: 58944, Loss: 0.3958515226840973, Accuracy: 0.8008070508949459\n",
      "Iteration: 59008, Loss: 0.08364224433898926, Accuracy: 0.8128069378435612\n",
      "Iteration: 59072, Loss: 0.08379468321800232, Accuracy: 0.8062272346578538\n",
      "Iteration: 59136, Loss: 0.08593925088644028, Accuracy: 0.8167667114175856\n",
      "Iteration: 59200, Loss: 0.08769697695970535, Accuracy: 0.8252734071575105\n",
      "Iteration: 59264, Loss: 0.08494213223457336, Accuracy: 0.8255225738976151\n",
      "Iteration: 59328, Loss: 0.08525042980909348, Accuracy: 0.8256407552398741\n",
      "Iteration: 59392, Loss: 0.08607108145952225, Accuracy: 0.8210353304166347\n",
      "Iteration: 59456, Loss: 0.08547166734933853, Accuracy: 0.8246727085206658\n",
      "Iteration: 59520, Loss: 0.08458035439252853, Accuracy: 0.8261529409792274\n",
      "Iteration: 59584, Loss: 0.08395092934370041, Accuracy: 0.8161937058903277\n",
      "Iteration: 59648, Loss: 0.0827765241265297, Accuracy: 0.7950545190833509\n",
      "Iteration: 59712, Loss: 0.08409629017114639, Accuracy: 0.8251221862155944\n",
      "Iteration: 59776, Loss: 0.08352013677358627, Accuracy: 0.8188962358981371\n",
      "Iteration: 59840, Loss: 0.0845809057354927, Accuracy: 0.8207193738780916\n",
      "Iteration: 59904, Loss: 0.08167079836130142, Accuracy: 0.8209844883531332\n",
      "Iteration: 59968, Loss: 0.08366075158119202, Accuracy: 0.8211442593019456\n",
      "Iteration: 60032, Loss: 0.08583951741456985, Accuracy: 0.8124199595768005\n",
      "Iteration: 60096, Loss: 0.08493242412805557, Accuracy: 0.8262231149710715\n",
      "Iteration: 60160, Loss: 0.08387390524148941, Accuracy: 0.8219368532299995\n",
      "Iteration: 60224, Loss: 0.08528453856706619, Accuracy: 0.8263167690020055\n",
      "Iteration: 60288, Loss: 0.08157147467136383, Accuracy: 0.8265108549967408\n",
      "Iteration: 60352, Loss: 0.08498536795377731, Accuracy: 0.8260748812463135\n",
      "Iteration: 60416, Loss: 0.08543935418128967, Accuracy: 0.8262242167256773\n",
      "Iteration: 60480, Loss: 0.08275983482599258, Accuracy: 0.8208344222512096\n",
      "Iteration: 60544, Loss: 0.08382698893547058, Accuracy: 0.8261427187826484\n",
      "Iteration: 60608, Loss: 0.08085282891988754, Accuracy: 0.8262617292348295\n",
      "Iteration: 60672, Loss: 0.08395620435476303, Accuracy: 0.8264983075205237\n",
      "Iteration: 60736, Loss: 0.08486369997262955, Accuracy: 0.8183111818507314\n",
      "Iteration: 60800, Loss: 0.08498283475637436, Accuracy: 0.8224459437187761\n",
      "Iteration: 60864, Loss: 0.0847831442952156, Accuracy: 0.8270432576537132\n",
      "Iteration: 60928, Loss: 0.08466542512178421, Accuracy: 0.8218011888675392\n",
      "Iteration: 60992, Loss: 0.08277981728315353, Accuracy: 0.826962131774053\n",
      "Iteration: 61056, Loss: 0.08487255126237869, Accuracy: 0.822070685448125\n",
      "Iteration: 61120, Loss: 0.08203263580799103, Accuracy: 0.8006774876266718\n",
      "Iteration: 61184, Loss: 0.08833470940589905, Accuracy: 0.8080315869301558\n",
      "Iteration: 61248, Loss: 0.08654662221670151, Accuracy: 0.8160159497056156\n",
      "Iteration: 61312, Loss: 0.08400727063417435, Accuracy: 0.802816643146798\n",
      "Iteration: 61376, Loss: 0.08608745783567429, Accuracy: 0.8267502877861261\n",
      "Iteration: 61440, Loss: 0.08339276909828186, Accuracy: 0.8270452928263694\n",
      "Iteration: 61504, Loss: 0.08595642447471619, Accuracy: 0.8220116891898215\n",
      "Iteration: 61568, Loss: 0.0857834443449974, Accuracy: 0.8268809816800058\n",
      "Iteration: 61632, Loss: 0.08382457494735718, Accuracy: 0.8272779756225646\n",
      "Iteration: 61696, Loss: 0.08573654294013977, Accuracy: 0.816864717984572\n",
      "Iteration: 61760, Loss: 0.08565572649240494, Accuracy: 0.8220092861447483\n",
      "Iteration: 61824, Loss: 0.08362745493650436, Accuracy: 0.8271044809371233\n",
      "Iteration: 61888, Loss: 0.08485651761293411, Accuracy: 0.8270321630407125\n",
      "Iteration: 61952, Loss: 0.0846988782286644, Accuracy: 0.8267899199854583\n",
      "Iteration: 62016, Loss: 0.08402717113494873, Accuracy: 0.8266702874097973\n",
      "Iteration: 62080, Loss: 0.08462651818990707, Accuracy: 0.8274041078984737\n",
      "Iteration: 62144, Loss: 0.08367439359426498, Accuracy: 0.8221038638148457\n",
      "Iteration: 62208, Loss: 0.08634907752275467, Accuracy: 0.8272105846554041\n",
      "Iteration: 62272, Loss: 0.08511942625045776, Accuracy: 0.8271694493014365\n",
      "Iteration: 62336, Loss: 0.08439724892377853, Accuracy: 0.8272667787969112\n",
      "Iteration: 62400, Loss: 0.08365682512521744, Accuracy: 0.8272129688411951\n",
      "Iteration: 62464, Loss: 0.08415490388870239, Accuracy: 0.8224738114513457\n",
      "Iteration: 62528, Loss: 0.08357253670692444, Accuracy: 0.82738565816544\n",
      "Iteration: 62592, Loss: 0.08433505892753601, Accuracy: 0.8269968295935541\n",
      "Iteration: 62656, Loss: 0.08357074856758118, Accuracy: 0.8225657059811056\n",
      "Iteration: 62720, Loss: 0.08701974898576736, Accuracy: 0.8263770611956716\n",
      "Iteration: 62784, Loss: 0.40623727440834045, Accuracy: 0.8130875385832042\n",
      "Iteration: 62848, Loss: 0.08169623464345932, Accuracy: 0.8170800742227584\n",
      "Iteration: 62912, Loss: 0.0836571678519249, Accuracy: 0.8274091789498925\n",
      "Iteration: 62976, Loss: 0.08312628418207169, Accuracy: 0.8268695687875152\n",
      "Iteration: 63040, Loss: 0.08481073379516602, Accuracy: 0.8224965010304004\n",
      "Iteration: 63104, Loss: 0.08400747925043106, Accuracy: 0.8269588693510741\n",
      "Iteration: 63168, Loss: 0.08439109474420547, Accuracy: 0.8272369266487658\n",
      "Iteration: 63232, Loss: 0.08555767685174942, Accuracy: 0.8268825884442776\n",
      "Iteration: 63296, Loss: 0.08363595604896545, Accuracy: 0.8276473027653992\n",
      "Iteration: 63360, Loss: 0.08324014395475388, Accuracy: 0.8265859361272305\n",
      "Iteration: 63424, Loss: 0.08559185266494751, Accuracy: 0.8273504462558776\n",
      "Iteration: 63488, Loss: 0.08151897042989731, Accuracy: 0.8274316869210452\n",
      "Iteration: 63552, Loss: 0.08580582588911057, Accuracy: 0.8265625420026481\n",
      "Iteration: 63616, Loss: 0.08561991900205612, Accuracy: 0.8275779669638723\n",
      "Iteration: 63680, Loss: 0.08308859169483185, Accuracy: 0.8227187437005341\n",
      "Iteration: 63744, Loss: 0.08413813263177872, Accuracy: 0.822491001104936\n",
      "Iteration: 63808, Loss: 0.08308511227369308, Accuracy: 0.8278463622555137\n",
      "Iteration: 63872, Loss: 0.08266562223434448, Accuracy: 0.8274536391254514\n",
      "Iteration: 63936, Loss: 0.08380595594644547, Accuracy: 0.8275250217411667\n",
      "Iteration: 64000, Loss: 0.08343231678009033, Accuracy: 0.817497709300369\n",
      "Iteration: 64064, Loss: 0.0848899856209755, Accuracy: 0.807456134352833\n",
      "Iteration: 64128, Loss: 0.08615138381719589, Accuracy: 0.8091840918641537\n",
      "Iteration: 64192, Loss: 0.08345263451337814, Accuracy: 0.8270536141935736\n",
      "Iteration: 64256, Loss: 0.0843416079878807, Accuracy: 0.8270832763519138\n",
      "Iteration: 64320, Loss: 0.08397512882947922, Accuracy: 0.8170859673991799\n",
      "Iteration: 64384, Loss: 0.0864531397819519, Accuracy: 0.8162940323818475\n",
      "Iteration: 64448, Loss: 0.0830092802643776, Accuracy: 0.818166945129633\n",
      "Iteration: 64512, Loss: 0.08325232565402985, Accuracy: 0.8213638034649193\n",
      "Iteration: 64576, Loss: 0.08455280214548111, Accuracy: 0.8114221873693168\n",
      "Iteration: 64640, Loss: 0.08013637363910675, Accuracy: 0.8267769587691873\n",
      "Iteration: 64704, Loss: 0.08534824103116989, Accuracy: 0.8213779348880053\n",
      "Iteration: 64768, Loss: 0.08769103139638901, Accuracy: 0.826938821002841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 64832, Loss: 0.08348700404167175, Accuracy: 0.8214154504239559\n",
      "Iteration: 64896, Loss: 0.08322523534297943, Accuracy: 0.8268657773733139\n",
      "Iteration: 64960, Loss: 0.08382847905158997, Accuracy: 0.8270127812866122\n",
      "Iteration: 65024, Loss: 0.08234984427690506, Accuracy: 0.8267758586443961\n",
      "Iteration: 65088, Loss: 0.08498235791921616, Accuracy: 0.8214784082956612\n",
      "Iteration: 65152, Loss: 0.08304751664400101, Accuracy: 0.819244799669832\n",
      "Iteration: 65216, Loss: 0.08450881391763687, Accuracy: 0.8114615110680461\n",
      "Iteration: 65280, Loss: 0.08244911581277847, Accuracy: 0.8059016508050263\n",
      "Iteration: 65344, Loss: 0.08364226669073105, Accuracy: 0.817838377552107\n",
      "Iteration: 65408, Loss: 0.0821477547287941, Accuracy: 0.8230571176391095\n",
      "Iteration: 65472, Loss: 0.08373361080884933, Accuracy: 0.8213204944040626\n",
      "Iteration: 65536, Loss: 0.08340397477149963, Accuracy: 0.8271992385853082\n",
      "Iteration: 65600, Loss: 0.08382076770067215, Accuracy: 0.8273340540472418\n",
      "Iteration: 65664, Loss: 0.08322998136281967, Accuracy: 0.8262424962595105\n",
      "Iteration: 65728, Loss: 0.08610356599092484, Accuracy: 0.8265375234186649\n",
      "Iteration: 65792, Loss: 0.08283164352178574, Accuracy: 0.8225411002058536\n",
      "Iteration: 65856, Loss: 0.08531844615936279, Accuracy: 0.825287040323019\n",
      "Iteration: 65920, Loss: 0.08771710842847824, Accuracy: 0.8268913393840194\n",
      "Iteration: 65984, Loss: 0.08308438211679459, Accuracy: 0.8269234104081988\n",
      "Iteration: 66048, Loss: 0.08353566378355026, Accuracy: 0.8273270507343113\n",
      "Iteration: 66112, Loss: 0.08375697582960129, Accuracy: 0.8270179729443043\n",
      "Iteration: 66176, Loss: 0.08233342319726944, Accuracy: 0.8273462760262191\n",
      "Iteration: 66240, Loss: 0.08286291360855103, Accuracy: 0.8270799133460969\n",
      "Iteration: 66304, Loss: 0.08270878344774246, Accuracy: 0.8273042689543217\n",
      "Iteration: 66368, Loss: 0.0843801200389862, Accuracy: 0.8271623009350151\n",
      "Iteration: 66432, Loss: 0.083271823823452, Accuracy: 0.8277337865438312\n",
      "Iteration: 66496, Loss: 0.08273906260728836, Accuracy: 0.8272473348770291\n",
      "Iteration: 66560, Loss: 0.08174455910921097, Accuracy: 0.8273276283871382\n",
      "Iteration: 66624, Loss: 0.08317123353481293, Accuracy: 0.8224602451082319\n",
      "Iteration: 66688, Loss: 0.08257322758436203, Accuracy: 0.822236226638779\n",
      "Iteration: 66752, Loss: 0.08380237221717834, Accuracy: 0.8272237135097384\n",
      "Iteration: 66816, Loss: 0.08088267594575882, Accuracy: 0.8222686571534723\n",
      "Iteration: 66880, Loss: 0.08638942241668701, Accuracy: 0.8275971917901188\n",
      "Iteration: 66944, Loss: 0.08573618531227112, Accuracy: 0.8278806216549128\n",
      "Iteration: 67008, Loss: 0.08468687534332275, Accuracy: 0.8225633285474032\n",
      "Iteration: 67072, Loss: 0.08590316027402878, Accuracy: 0.8275767017621547\n",
      "Iteration: 67136, Loss: 0.08182184398174286, Accuracy: 0.8227932986337692\n",
      "Iteration: 67200, Loss: 0.08580991625785828, Accuracy: 0.8175544270779938\n",
      "Iteration: 67264, Loss: 0.08188021928071976, Accuracy: 0.827458237297833\n",
      "Iteration: 67328, Loss: 0.08600763231515884, Accuracy: 0.8279192512854934\n",
      "Iteration: 67392, Loss: 0.08233848214149475, Accuracy: 0.8229950449895114\n",
      "Iteration: 67456, Loss: 0.08531855791807175, Accuracy: 0.8276981650851667\n",
      "Iteration: 67520, Loss: 0.08367215842008591, Accuracy: 0.8279518864583224\n",
      "Iteration: 67584, Loss: 0.08295957744121552, Accuracy: 0.8276686202734709\n",
      "Iteration: 67648, Loss: 0.08343669027090073, Accuracy: 0.8226533457636833\n",
      "Iteration: 67712, Loss: 0.08327264338731766, Accuracy: 0.827469001756981\n",
      "Iteration: 67776, Loss: 0.08410070091485977, Accuracy: 0.8273057132028043\n",
      "Iteration: 67840, Loss: 0.08322829753160477, Accuracy: 0.8278190863784403\n",
      "Iteration: 67904, Loss: 0.08537322282791138, Accuracy: 0.822637120494619\n",
      "Iteration: 67968, Loss: 0.08345335721969604, Accuracy: 0.8281406082678586\n",
      "Iteration: 68032, Loss: 0.086815245449543, Accuracy: 0.8172743029426783\n",
      "Iteration: 68096, Loss: 0.08419061452150345, Accuracy: 0.8225704852957278\n",
      "Iteration: 68160, Loss: 0.08319336920976639, Accuracy: 0.8231814298778772\n",
      "Iteration: 68224, Loss: 0.08432039618492126, Accuracy: 0.7972595300525427\n",
      "Iteration: 68288, Loss: 0.08428916335105896, Accuracy: 0.8096250498201698\n",
      "Iteration: 68352, Loss: 0.08533560484647751, Accuracy: 0.8250792790204287\n",
      "Iteration: 68416, Loss: 0.083969347178936, Accuracy: 0.811672632349655\n",
      "Iteration: 68480, Loss: 0.08576340228319168, Accuracy: 0.8274991582147777\n",
      "Iteration: 68544, Loss: 0.08368317037820816, Accuracy: 0.8225304351653904\n",
      "Iteration: 68608, Loss: 0.08576366305351257, Accuracy: 0.8229524332564324\n",
      "Iteration: 68672, Loss: 0.08235501497983932, Accuracy: 0.8281679828651249\n",
      "Iteration: 68736, Loss: 0.08184843510389328, Accuracy: 0.8272155115846545\n",
      "Iteration: 68800, Loss: 0.08592929691076279, Accuracy: 0.8223226652480662\n",
      "Iteration: 68864, Loss: 0.08630097657442093, Accuracy: 0.821873371489346\n",
      "Iteration: 68928, Loss: 0.0837320014834404, Accuracy: 0.8226606089156121\n",
      "Iteration: 68992, Loss: 0.08498090505599976, Accuracy: 0.8127707443200052\n",
      "Iteration: 69056, Loss: 0.08478782325983047, Accuracy: 0.8231657401192933\n",
      "Iteration: 69120, Loss: 0.08588343858718872, Accuracy: 0.8215394229628146\n",
      "Iteration: 69184, Loss: 0.0847800076007843, Accuracy: 0.8233530507422984\n",
      "Iteration: 69248, Loss: 0.407813161611557, Accuracy: 0.8141477066092193\n",
      "Iteration: 69312, Loss: 0.08285783976316452, Accuracy: 0.8179498370736837\n",
      "Iteration: 69376, Loss: 0.08425527065992355, Accuracy: 0.8277855811174959\n",
      "Iteration: 69440, Loss: 0.08493685722351074, Accuracy: 0.8181478471960872\n",
      "Iteration: 69504, Loss: 0.083213672041893, Accuracy: 0.8231664746999741\n",
      "Iteration: 69568, Loss: 0.08558899164199829, Accuracy: 0.8282941954676062\n",
      "Iteration: 69632, Loss: 0.08463925123214722, Accuracy: 0.8231632008682936\n",
      "Iteration: 69696, Loss: 0.08224212378263474, Accuracy: 0.8283165981993079\n",
      "Iteration: 69760, Loss: 0.0838458314538002, Accuracy: 0.828133805654943\n",
      "Iteration: 69824, Loss: 0.08330437541007996, Accuracy: 0.8236321448348463\n",
      "Iteration: 69888, Loss: 0.08289632946252823, Accuracy: 0.8172521244268864\n",
      "Iteration: 69952, Loss: 0.08347771316766739, Accuracy: 0.8241916750557721\n",
      "Iteration: 70016, Loss: 0.08489512652158737, Accuracy: 0.8275043058674783\n",
      "Iteration: 70080, Loss: 0.08322460949420929, Accuracy: 0.8281437242403626\n",
      "Iteration: 70144, Loss: 0.08168454468250275, Accuracy: 0.8269278523512185\n",
      "Iteration: 70208, Loss: 0.08510741591453552, Accuracy: 0.8177638207562268\n",
      "Iteration: 70272, Loss: 0.08428749442100525, Accuracy: 0.8183437418192625\n",
      "Iteration: 70336, Loss: 0.08078303188085556, Accuracy: 0.8236417574808002\n",
      "Iteration: 70400, Loss: 0.08325614035129547, Accuracy: 0.8195475076790899\n",
      "Iteration: 70464, Loss: 0.08595722913742065, Accuracy: 0.8228288826067001\n",
      "Iteration: 70528, Loss: 0.08220580220222473, Accuracy: 0.8280264164786786\n",
      "Iteration: 70592, Loss: 0.08443994075059891, Accuracy: 0.8199367886409163\n",
      "Iteration: 70656, Loss: 0.0823078379034996, Accuracy: 0.8055806055199355\n",
      "Iteration: 70720, Loss: 0.08221936225891113, Accuracy: 0.8273256674874574\n",
      "Iteration: 70784, Loss: 0.08527051657438278, Accuracy: 0.827612312277779\n",
      "Iteration: 70848, Loss: 0.08495486527681351, Accuracy: 0.8246701892931014\n",
      "Iteration: 70912, Loss: 0.08381935954093933, Accuracy: 0.8179641859605908\n",
      "Iteration: 70976, Loss: 0.08734876662492752, Accuracy: 0.8274864216800779\n",
      "Iteration: 71040, Loss: 0.0859900712966919, Accuracy: 0.8278808279428631\n",
      "Iteration: 71104, Loss: 0.08479971438646317, Accuracy: 0.827923308359459\n",
      "Iteration: 71168, Loss: 0.08247531205415726, Accuracy: 0.8242613985203207\n",
      "Iteration: 71232, Loss: 0.08348384499549866, Accuracy: 0.8206908700522035\n",
      "Iteration: 71296, Loss: 0.08559250086545944, Accuracy: 0.8199052065610886\n",
      "Iteration: 71360, Loss: 0.08538860082626343, Accuracy: 0.8275901505257934\n",
      "Iteration: 71424, Loss: 0.08349939435720444, Accuracy: 0.8274196619167924\n",
      "Iteration: 71488, Loss: 0.08180782198905945, Accuracy: 0.8277060522232205\n",
      "Iteration: 71552, Loss: 0.08497106283903122, Accuracy: 0.8278630340937525\n",
      "Iteration: 71616, Loss: 0.08422639220952988, Accuracy: 0.8277082901913673\n",
      "Iteration: 71680, Loss: 0.08497246354818344, Accuracy: 0.8265697166789323\n",
      "Iteration: 71744, Loss: 0.083567313849926, Accuracy: 0.8277667881920934\n",
      "Iteration: 71808, Loss: 0.08470524102449417, Accuracy: 0.8281572759151459\n",
      "Iteration: 71872, Loss: 0.08496812731027603, Accuracy: 0.828136419178918\n",
      "Iteration: 71936, Loss: 0.08474066108465195, Accuracy: 0.8281314137857407\n",
      "Iteration: 72000, Loss: 0.08266080170869827, Accuracy: 0.8279608271550387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 72064, Loss: 0.08393245935440063, Accuracy: 0.8278839713893831\n",
      "Iteration: 72128, Loss: 0.08464864641427994, Accuracy: 0.8281934203114361\n",
      "Iteration: 72192, Loss: 0.08454077690839767, Accuracy: 0.8229703730903566\n",
      "Iteration: 72256, Loss: 0.08550164103507996, Accuracy: 0.8280610018409789\n",
      "Iteration: 72320, Loss: 0.08359985798597336, Accuracy: 0.8276332532986999\n",
      "Iteration: 72384, Loss: 0.0840466246008873, Accuracy: 0.82774543389678\n",
      "Iteration: 72448, Loss: 0.0842566192150116, Accuracy: 0.8276965846307576\n",
      "Iteration: 72512, Loss: 0.08479652553796768, Accuracy: 0.8277683116029948\n",
      "Iteration: 72576, Loss: 0.08311671763658524, Accuracy: 0.823201764607802\n",
      "Iteration: 72640, Loss: 0.0821838304400444, Accuracy: 0.8281970808748156\n",
      "Iteration: 72704, Loss: 0.0837165042757988, Accuracy: 0.8283189407084137\n",
      "Iteration: 72768, Loss: 0.40814653038978577, Accuracy: 0.807411769637838\n",
      "Iteration: 72832, Loss: 0.08321983367204666, Accuracy: 0.8024075208231807\n",
      "Iteration: 72896, Loss: 0.08139299601316452, Accuracy: 0.8260530077386647\n",
      "Iteration: 72960, Loss: 0.08766556531190872, Accuracy: 0.817630076315254\n",
      "Iteration: 73024, Loss: 0.08794406056404114, Accuracy: 0.826840816764161\n",
      "Iteration: 73088, Loss: 0.08282021433115005, Accuracy: 0.8271807434502989\n",
      "Iteration: 73152, Loss: 0.08505546301603317, Accuracy: 0.8221936917398125\n",
      "Iteration: 73216, Loss: 0.08799604326486588, Accuracy: 0.8267524114344269\n",
      "Iteration: 73280, Loss: 0.08167453855276108, Accuracy: 0.8267325323540717\n",
      "Iteration: 73344, Loss: 0.08145485073328018, Accuracy: 0.8255313101690263\n",
      "Iteration: 73408, Loss: 0.07980857044458389, Accuracy: 0.8263581891078502\n",
      "Iteration: 73472, Loss: 0.08527789264917374, Accuracy: 0.8272382239811122\n",
      "Iteration: 73536, Loss: 0.08384519070386887, Accuracy: 0.8273268977645785\n",
      "Iteration: 73600, Loss: 0.08138976246118546, Accuracy: 0.8222033812198788\n",
      "Iteration: 73664, Loss: 0.08302385360002518, Accuracy: 0.8239436401054263\n",
      "Iteration: 73728, Loss: 0.08338499069213867, Accuracy: 0.821355463238433\n",
      "Iteration: 73792, Loss: 0.08545558899641037, Accuracy: 0.821669997414574\n",
      "Iteration: 73856, Loss: 0.08295579999685287, Accuracy: 0.8114182245917618\n",
      "Iteration: 73920, Loss: 0.08183528482913971, Accuracy: 0.8085602847859263\n",
      "Iteration: 73984, Loss: 0.08414290100336075, Accuracy: 0.8220851551741362\n",
      "Iteration: 74048, Loss: 0.08351271599531174, Accuracy: 0.8273679113481194\n",
      "Iteration: 74112, Loss: 0.08760756999254227, Accuracy: 0.821057929424569\n",
      "Iteration: 74176, Loss: 0.0847502052783966, Accuracy: 0.8227977526839823\n",
      "Iteration: 74240, Loss: 0.08568048477172852, Accuracy: 0.8278413203079253\n",
      "Iteration: 74304, Loss: 0.08285189419984818, Accuracy: 0.8228668388910592\n",
      "Iteration: 74368, Loss: 0.08363974839448929, Accuracy: 0.8223745885770768\n",
      "Iteration: 74432, Loss: 0.08727573603391647, Accuracy: 0.8029239487368613\n",
      "Iteration: 74496, Loss: 0.08506765961647034, Accuracy: 0.8212478265631944\n",
      "Iteration: 74560, Loss: 0.08214734494686127, Accuracy: 0.8275578084867448\n",
      "Iteration: 74624, Loss: 0.08469614386558533, Accuracy: 0.8274833068717271\n",
      "Iteration: 74688, Loss: 0.08394733816385269, Accuracy: 0.8270495375618339\n",
      "Iteration: 74752, Loss: 0.08235467225313187, Accuracy: 0.822824779432267\n",
      "Iteration: 74816, Loss: 0.08519795536994934, Accuracy: 0.8270395998843014\n",
      "Iteration: 74880, Loss: 0.08576347678899765, Accuracy: 0.8273005373775959\n",
      "Iteration: 74944, Loss: 0.08231764286756516, Accuracy: 0.8263412357773632\n",
      "Iteration: 75008, Loss: 0.08297642320394516, Accuracy: 0.8186220361385494\n",
      "Iteration: 75072, Loss: 0.08482745289802551, Accuracy: 0.828108458314091\n",
      "Iteration: 75136, Loss: 0.08258319646120071, Accuracy: 0.827699116198346\n",
      "Iteration: 75200, Loss: 0.08357444405555725, Accuracy: 0.822560663567856\n",
      "Iteration: 75264, Loss: 0.08453527092933655, Accuracy: 0.8278044830076396\n",
      "Iteration: 75328, Loss: 0.0860929861664772, Accuracy: 0.8278447783086449\n",
      "Iteration: 75392, Loss: 0.08365306258201599, Accuracy: 0.8270038873888552\n",
      "Iteration: 75456, Loss: 0.08189306408166885, Accuracy: 0.8278471557423472\n",
      "Iteration: 75520, Loss: 0.08437567204236984, Accuracy: 0.827885435661301\n",
      "Iteration: 75584, Loss: 0.08587919920682907, Accuracy: 0.8229095793794841\n",
      "Iteration: 75648, Loss: 0.08629458397626877, Accuracy: 0.8276946423575282\n",
      "Iteration: 75712, Loss: 0.08445438742637634, Accuracy: 0.8267038143239915\n",
      "Iteration: 75776, Loss: 0.08434141427278519, Accuracy: 0.8231787090189755\n",
      "Iteration: 75840, Loss: 0.0858960673213005, Accuracy: 0.8275788079481572\n",
      "Iteration: 75904, Loss: 0.08342526108026505, Accuracy: 0.8276459374465048\n",
      "Iteration: 75968, Loss: 0.0860290452837944, Accuracy: 0.827643393073231\n",
      "Iteration: 76032, Loss: 0.08432436734437943, Accuracy: 0.8174668282736093\n",
      "Iteration: 76096, Loss: 0.08375167846679688, Accuracy: 0.8159228761214763\n",
      "Iteration: 76160, Loss: 0.08463530987501144, Accuracy: 0.7945175380446017\n",
      "Iteration: 76224, Loss: 0.08519726991653442, Accuracy: 0.8226438739802688\n",
      "Iteration: 76288, Loss: 0.08693647384643555, Accuracy: 0.8172901736106724\n",
      "Iteration: 76352, Loss: 0.08496122807264328, Accuracy: 0.822847860166803\n",
      "Iteration: 76416, Loss: 0.0833342894911766, Accuracy: 0.8254360808059573\n",
      "Iteration: 76480, Loss: 0.08093466609716415, Accuracy: 0.8275653312448412\n",
      "Iteration: 76544, Loss: 0.08526620268821716, Accuracy: 0.8224100053776056\n",
      "Iteration: 76608, Loss: 0.08286020159721375, Accuracy: 0.827702771872282\n",
      "Iteration: 76672, Loss: 0.0832882896065712, Accuracy: 0.825563108548522\n",
      "Iteration: 76736, Loss: 0.08603889495134354, Accuracy: 0.8227223835419863\n",
      "Iteration: 76800, Loss: 0.08315639942884445, Accuracy: 0.8272820976562798\n",
      "Iteration: 76864, Loss: 0.08284948021173477, Accuracy: 0.8278597090393305\n",
      "Iteration: 76928, Loss: 0.08383122086524963, Accuracy: 0.8274986315518618\n",
      "Iteration: 76992, Loss: 0.08458858728408813, Accuracy: 0.8224005189258605\n",
      "Iteration: 77056, Loss: 0.08385583013296127, Accuracy: 0.8277887622825801\n",
      "Iteration: 77120, Loss: 0.08263344317674637, Accuracy: 0.8275908387731761\n",
      "Iteration: 77184, Loss: 0.08460190147161484, Accuracy: 0.8280745474621654\n",
      "Iteration: 77248, Loss: 0.08430848270654678, Accuracy: 0.8277503210119903\n",
      "Iteration: 77312, Loss: 0.0840018019080162, Accuracy: 0.8279685876332223\n",
      "Iteration: 77376, Loss: 0.08308582007884979, Accuracy: 0.8276245184242725\n",
      "Iteration: 77440, Loss: 0.08302246779203415, Accuracy: 0.8279770480003208\n",
      "Iteration: 77504, Loss: 0.08645076304674149, Accuracy: 0.82803740282543\n",
      "Iteration: 77568, Loss: 0.08349758386611938, Accuracy: 0.8281832488719374\n",
      "Iteration: 77632, Loss: 0.0837927758693695, Accuracy: 0.8282788000069559\n",
      "Iteration: 77696, Loss: 0.08351694792509079, Accuracy: 0.8282813911791891\n",
      "Iteration: 77760, Loss: 0.08331524580717087, Accuracy: 0.8232488119974732\n",
      "Iteration: 77824, Loss: 0.08444663882255554, Accuracy: 0.8214747132733464\n",
      "Iteration: 77888, Loss: 0.08119982481002808, Accuracy: 0.8217354018706828\n",
      "Iteration: 77952, Loss: 0.08278382569551468, Accuracy: 0.828151835128665\n",
      "Iteration: 78016, Loss: 0.08353256434202194, Accuracy: 0.8269664386752993\n",
      "Iteration: 78080, Loss: 0.08436423540115356, Accuracy: 0.8282470745034516\n",
      "Iteration: 78144, Loss: 0.08388268202543259, Accuracy: 0.8230688518378884\n",
      "Iteration: 78208, Loss: 0.0814051702618599, Accuracy: 0.825210245558992\n",
      "Iteration: 78272, Loss: 0.08153336495161057, Accuracy: 0.8273905457463115\n",
      "Iteration: 78336, Loss: 0.08427708595991135, Accuracy: 0.8230700427666306\n",
      "Iteration: 78400, Loss: 0.0849376916885376, Accuracy: 0.8281033535022289\n",
      "Iteration: 78464, Loss: 0.08399873226881027, Accuracy: 0.8177953094709665\n",
      "Iteration: 78528, Loss: 0.08509155362844467, Accuracy: 0.8231936215888709\n",
      "Iteration: 78592, Loss: 0.08305167406797409, Accuracy: 0.8285065423697233\n",
      "Iteration: 78656, Loss: 0.08271556347608566, Accuracy: 0.828390313545242\n",
      "Iteration: 78720, Loss: 0.08237535506486893, Accuracy: 0.82672198722139\n",
      "Iteration: 78784, Loss: 0.08685547113418579, Accuracy: 0.8278884764295071\n",
      "Iteration: 78848, Loss: 0.08545675873756409, Accuracy: 0.8282657559029758\n",
      "Iteration: 78912, Loss: 0.08298381417989731, Accuracy: 0.828326906543225\n",
      "Iteration: 78976, Loss: 0.08429703861474991, Accuracy: 0.8283260483294725\n",
      "Iteration: 79040, Loss: 0.08124027401208878, Accuracy: 0.8281255483161658\n",
      "Iteration: 79104, Loss: 0.08288297057151794, Accuracy: 0.8282482749782503\n",
      "Iteration: 79168, Loss: 0.08370202779769897, Accuracy: 0.8284750515595078\n",
      "Iteration: 79232, Loss: 0.08569050580263138, Accuracy: 0.8280031702015549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 79296, Loss: 0.08434733003377914, Accuracy: 0.8284808155149221\n",
      "Iteration: 79360, Loss: 0.0825469121336937, Accuracy: 0.8283449725713581\n",
      "Iteration: 79424, Loss: 0.0839301124215126, Accuracy: 0.8280489896424115\n",
      "Iteration: 79488, Loss: 0.08774752169847488, Accuracy: 0.8261854737065732\n",
      "Iteration: 79552, Loss: 0.08507323265075684, Accuracy: 0.8076165800448507\n",
      "Iteration: 79616, Loss: 0.08421147614717484, Accuracy: 0.8202412314713001\n",
      "Iteration: 79680, Loss: 0.08243418484926224, Accuracy: 0.828222447540611\n",
      "Iteration: 79744, Loss: 0.08507441729307175, Accuracy: 0.822793654864654\n",
      "Iteration: 79808, Loss: 0.08412468433380127, Accuracy: 0.8262969306670129\n",
      "Iteration: 79872, Loss: 0.08533211797475815, Accuracy: 0.8278325663413852\n",
      "Iteration: 79936, Loss: 0.30843326449394226, Accuracy: 0.8114768823143095\n",
      "Iteration: 80000, Loss: 0.08240815997123718, Accuracy: 0.8270422604400665\n",
      "Iteration: 80064, Loss: 0.08577298372983932, Accuracy: 0.8216062248684466\n",
      "Iteration: 80128, Loss: 0.08437628298997879, Accuracy: 0.8279613838531077\n",
      "Iteration: 80192, Loss: 0.0841386541724205, Accuracy: 0.8277591429650784\n",
      "Iteration: 80256, Loss: 0.08382800966501236, Accuracy: 0.827916469424963\n",
      "Iteration: 80320, Loss: 0.0881606861948967, Accuracy: 0.8227321212179959\n",
      "Iteration: 80384, Loss: 0.0841730460524559, Accuracy: 0.8190298890694976\n",
      "Iteration: 80448, Loss: 0.08412111550569534, Accuracy: 0.8281732050236315\n",
      "Iteration: 80512, Loss: 0.0841023400425911, Accuracy: 0.8285514453891665\n",
      "Iteration: 80576, Loss: 0.08343114703893661, Accuracy: 0.8231151225045323\n",
      "Iteration: 80640, Loss: 0.08524966984987259, Accuracy: 0.8266827403567731\n",
      "Iteration: 80704, Loss: 0.08512306213378906, Accuracy: 0.8233146285638213\n",
      "Iteration: 80768, Loss: 0.08403273671865463, Accuracy: 0.8180169882252812\n",
      "Iteration: 80832, Loss: 0.08364788442850113, Accuracy: 0.8182638089638203\n",
      "Iteration: 80896, Loss: 0.08375871181488037, Accuracy: 0.8230249625630677\n",
      "Iteration: 80960, Loss: 0.08538534492254257, Accuracy: 0.8279954015742987\n",
      "Iteration: 81024, Loss: 0.08674141019582748, Accuracy: 0.8278071859385818\n",
      "Iteration: 81088, Loss: 0.08569872379302979, Accuracy: 0.8177055257838219\n",
      "Iteration: 81152, Loss: 0.0854850709438324, Accuracy: 0.8216939149424434\n",
      "Iteration: 81216, Loss: 0.08745292574167252, Accuracy: 0.8229539757594466\n",
      "Iteration: 81280, Loss: 0.08298587054014206, Accuracy: 0.8278587951790541\n",
      "Iteration: 81344, Loss: 0.08216723054647446, Accuracy: 0.8281806884333491\n",
      "Iteration: 81408, Loss: 0.08571063727140427, Accuracy: 0.8270089926663786\n",
      "Iteration: 81472, Loss: 0.08424747735261917, Accuracy: 0.8281353721395135\n",
      "Iteration: 81536, Loss: 0.08244388550519943, Accuracy: 0.8278236265759915\n",
      "Iteration: 81600, Loss: 0.08377233892679214, Accuracy: 0.8266523787751794\n",
      "Iteration: 81664, Loss: 0.08630413562059402, Accuracy: 0.828215079382062\n",
      "Iteration: 81728, Loss: 0.08487840741872787, Accuracy: 0.8229613392613828\n",
      "Iteration: 81792, Loss: 0.0821903869509697, Accuracy: 0.8285454155411571\n",
      "Iteration: 81856, Loss: 0.08356215804815292, Accuracy: 0.8281036450061947\n",
      "Iteration: 81920, Loss: 0.08543425053358078, Accuracy: 0.8285015299916267\n",
      "Iteration: 81984, Loss: 0.08331357687711716, Accuracy: 0.8229911583475769\n",
      "Iteration: 82048, Loss: 0.08238750696182251, Accuracy: 0.8206759940367192\n",
      "Iteration: 82112, Loss: 0.0849764421582222, Accuracy: 0.8281207357067615\n",
      "Iteration: 82176, Loss: 0.08326149731874466, Accuracy: 0.8285076143220067\n",
      "Iteration: 82240, Loss: 0.0829404667019844, Accuracy: 0.8284760448150337\n",
      "Iteration: 82304, Loss: 0.08259952813386917, Accuracy: 0.8282938415650278\n",
      "Iteration: 82368, Loss: 0.08562275767326355, Accuracy: 0.8284242316149175\n",
      "Iteration: 82432, Loss: 0.08159039169549942, Accuracy: 0.8284588160458952\n",
      "Iteration: 82496, Loss: 0.08320070058107376, Accuracy: 0.8284127796068788\n",
      "Iteration: 82560, Loss: 0.08586303144693375, Accuracy: 0.819828869542107\n",
      "Iteration: 82624, Loss: 0.08163844794034958, Accuracy: 0.8221812893170863\n",
      "Iteration: 82688, Loss: 0.08342375606298447, Accuracy: 0.8130144274327904\n",
      "Iteration: 82752, Loss: 0.3243567645549774, Accuracy: 0.8223853588569909\n",
      "Iteration: 82816, Loss: 0.08406925201416016, Accuracy: 0.828441524412483\n",
      "Iteration: 82880, Loss: 0.08390593528747559, Accuracy: 0.8281969686504453\n",
      "Iteration: 82944, Loss: 0.08491140604019165, Accuracy: 0.8279637126252055\n",
      "Iteration: 83008, Loss: 0.08298517018556595, Accuracy: 0.828284535324201\n",
      "Iteration: 83072, Loss: 0.08621010184288025, Accuracy: 0.8283149015624076\n",
      "Iteration: 83136, Loss: 0.08406027406454086, Accuracy: 0.8284614128060639\n",
      "Iteration: 83200, Loss: 0.08316884934902191, Accuracy: 0.8285044354852289\n",
      "Iteration: 83264, Loss: 0.0827879086136818, Accuracy: 0.8283453593030572\n",
      "Iteration: 83328, Loss: 0.08460422605276108, Accuracy: 0.8233797752764076\n",
      "Iteration: 83392, Loss: 0.08426421880722046, Accuracy: 0.8257117951288819\n",
      "Iteration: 83456, Loss: 0.08735895156860352, Accuracy: 0.8180565170478076\n",
      "Iteration: 83520, Loss: 0.08379565924406052, Accuracy: 0.8280099658295512\n",
      "Iteration: 83584, Loss: 0.08507048338651657, Accuracy: 0.8284173449501395\n",
      "Iteration: 83648, Loss: 0.08198641985654831, Accuracy: 0.8233955649193376\n",
      "Iteration: 83712, Loss: 0.08360258489847183, Accuracy: 0.8237237334251404\n",
      "Iteration: 83776, Loss: 0.0848115012049675, Accuracy: 0.8282804219052196\n",
      "Iteration: 83840, Loss: 0.08526284247636795, Accuracy: 0.8283927359152585\n",
      "Iteration: 83904, Loss: 0.08415936678647995, Accuracy: 0.8279401266481727\n",
      "Iteration: 83968, Loss: 0.08131299167871475, Accuracy: 0.8149664469528943\n",
      "Iteration: 84032, Loss: 0.08479872345924377, Accuracy: 0.8113901994656771\n",
      "Iteration: 84096, Loss: 0.08320415765047073, Accuracy: 0.8231852911412716\n",
      "Iteration: 84160, Loss: 0.0840328261256218, Accuracy: 0.8283996179234236\n",
      "Iteration: 84224, Loss: 0.08501874655485153, Accuracy: 0.8284023082815111\n",
      "Iteration: 84288, Loss: 0.08553027361631393, Accuracy: 0.8264093392062932\n",
      "Iteration: 84352, Loss: 0.08512233942747116, Accuracy: 0.8277278470341116\n",
      "Iteration: 84416, Loss: 0.08380141109228134, Accuracy: 0.8279711315408349\n",
      "Iteration: 84480, Loss: 0.08478911966085434, Accuracy: 0.8283257163129747\n",
      "Iteration: 84544, Loss: 0.08603867143392563, Accuracy: 0.8282515604514629\n",
      "Iteration: 84608, Loss: 0.08376612514257431, Accuracy: 0.8288495009765029\n",
      "Iteration: 84672, Loss: 0.08571331948041916, Accuracy: 0.827820671023801\n",
      "Iteration: 84736, Loss: 0.08172204345464706, Accuracy: 0.821712042670697\n",
      "Iteration: 84800, Loss: 0.08521115779876709, Accuracy: 0.8281253585591912\n",
      "Iteration: 84864, Loss: 0.08352755755186081, Accuracy: 0.8249199341516942\n",
      "Iteration: 84928, Loss: 0.08260872215032578, Accuracy: 0.8250318337231874\n",
      "Iteration: 84992, Loss: 0.08272503316402435, Accuracy: 0.8151547135785222\n",
      "Iteration: 85056, Loss: 0.0818980485200882, Accuracy: 0.8268417553044856\n",
      "Iteration: 85120, Loss: 0.08229104429483414, Accuracy: 0.8284177558962256\n",
      "Iteration: 85184, Loss: 0.08385498076677322, Accuracy: 0.8285938820336014\n",
      "Iteration: 85248, Loss: 0.0864667296409607, Accuracy: 0.8276225582230836\n",
      "Iteration: 85312, Loss: 0.08394551277160645, Accuracy: 0.8273603380657732\n",
      "Iteration: 85376, Loss: 0.08409412950277328, Accuracy: 0.8285827280487865\n",
      "Iteration: 85440, Loss: 0.08456640690565109, Accuracy: 0.8275775467045605\n",
      "Iteration: 85504, Loss: 0.08394453674554825, Accuracy: 0.8282307917252183\n",
      "Iteration: 85568, Loss: 0.08552806824445724, Accuracy: 0.8279907645191997\n",
      "Iteration: 85632, Loss: 0.08389660716056824, Accuracy: 0.8286720728501678\n",
      "Iteration: 85696, Loss: 0.08517136424779892, Accuracy: 0.8285758781712502\n",
      "Iteration: 85760, Loss: 0.08647909760475159, Accuracy: 0.8252264789771289\n",
      "Iteration: 85824, Loss: 0.0834587812423706, Accuracy: 0.8099883403629065\n",
      "Iteration: 85888, Loss: 0.08271091431379318, Accuracy: 0.822251392994076\n",
      "Iteration: 85952, Loss: 0.08223501592874527, Accuracy: 0.8202495195437223\n",
      "Iteration: 86016, Loss: 0.08461644500494003, Accuracy: 0.822563637746498\n",
      "Iteration: 86080, Loss: 0.08437636494636536, Accuracy: 0.825306013925001\n",
      "Iteration: 86144, Loss: 0.08576589822769165, Accuracy: 0.8285136909689754\n",
      "Iteration: 86208, Loss: 0.08400347083806992, Accuracy: 0.8240245084743947\n",
      "Iteration: 86272, Loss: 0.082151398062706, Accuracy: 0.8231238536536694\n",
      "Iteration: 86336, Loss: 0.08591228723526001, Accuracy: 0.8233712024521083\n",
      "Iteration: 86400, Loss: 0.08691135793924332, Accuracy: 0.8278523127082735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 86464, Loss: 0.0836038812994957, Accuracy: 0.8268367596901953\n",
      "Iteration: 86528, Loss: 0.08470123261213303, Accuracy: 0.8281118320301175\n",
      "Iteration: 86592, Loss: 0.08537433296442032, Accuracy: 0.8179058248642832\n",
      "Iteration: 86656, Loss: 0.08581998199224472, Accuracy: 0.8229277860373259\n",
      "Iteration: 86720, Loss: 0.08366736769676208, Accuracy: 0.8217222823295742\n",
      "Iteration: 86784, Loss: 0.08142085373401642, Accuracy: 0.8177860958967358\n",
      "Iteration: 86848, Loss: 0.08643519878387451, Accuracy: 0.8282211781479418\n",
      "Iteration: 86912, Loss: 0.08594327419996262, Accuracy: 0.8278778686653823\n",
      "Iteration: 86976, Loss: 0.08510607481002808, Accuracy: 0.8221361478790641\n",
      "Iteration: 87040, Loss: 0.0813988447189331, Accuracy: 0.8163139685057104\n",
      "Iteration: 87104, Loss: 0.0784054771065712, Accuracy: 0.8239731632638723\n",
      "Iteration: 87168, Loss: 0.08439251035451889, Accuracy: 0.8092841154430062\n",
      "Iteration: 87232, Loss: 0.08685656636953354, Accuracy: 0.822512383107096\n",
      "Iteration: 87296, Loss: 0.08454164862632751, Accuracy: 0.8037088257260621\n",
      "Iteration: 87360, Loss: 0.0809369906783104, Accuracy: 0.8235517737921327\n",
      "Iteration: 87424, Loss: 0.08737482875585556, Accuracy: 0.8288041690830141\n",
      "Iteration: 87488, Loss: 0.08215627819299698, Accuracy: 0.8235034109093249\n",
      "Iteration: 87552, Loss: 0.0867190733551979, Accuracy: 0.824241298250854\n",
      "Iteration: 87616, Loss: 0.08177919685840607, Accuracy: 0.8218506560660899\n",
      "Iteration: 87680, Loss: 0.0798618420958519, Accuracy: 0.8282842729240656\n",
      "Iteration: 87744, Loss: 0.08269963413476944, Accuracy: 0.8242902853526175\n",
      "Iteration: 87808, Loss: 0.08615266531705856, Accuracy: 0.8260713934432715\n",
      "Iteration: 87872, Loss: 0.0821644738316536, Accuracy: 0.8279526496771723\n",
      "Iteration: 87936, Loss: 0.08338522166013718, Accuracy: 0.8238317531067878\n",
      "Iteration: 88000, Loss: 0.08501391857862473, Accuracy: 0.8283364076633006\n",
      "Iteration: 88064, Loss: 0.08337799459695816, Accuracy: 0.827651261119172\n",
      "Iteration: 88128, Loss: 0.0855422392487526, Accuracy: 0.8268471099436283\n",
      "Iteration: 88192, Loss: 0.07946637272834778, Accuracy: 0.8268292848952115\n",
      "Iteration: 88256, Loss: 0.08254741877317429, Accuracy: 0.8275626758113503\n",
      "Iteration: 88320, Loss: 0.08691376447677612, Accuracy: 0.818204335635528\n",
      "Iteration: 88384, Loss: 0.08506666868925095, Accuracy: 0.8262767216656357\n",
      "Iteration: 88448, Loss: 0.08202449977397919, Accuracy: 0.8281429198104888\n",
      "Iteration: 88512, Loss: 0.08181212842464447, Accuracy: 0.828475363785401\n",
      "Iteration: 88576, Loss: 0.08443331718444824, Accuracy: 0.8284990189131349\n",
      "Iteration: 88640, Loss: 0.08575439453125, Accuracy: 0.8272119485773146\n",
      "Iteration: 88704, Loss: 0.0596364289522171, Accuracy: 0.8283799069467932\n",
      "Iteration: 88768, Loss: 0.08254075795412064, Accuracy: 0.8208348259795457\n",
      "Iteration: 88832, Loss: 0.0888029932975769, Accuracy: 0.8177061614114791\n",
      "Iteration: 88896, Loss: 0.0785236582159996, Accuracy: 0.8269447544589639\n",
      "Iteration: 88960, Loss: 0.08131565153598785, Accuracy: 0.8125264986883849\n",
      "Iteration: 89024, Loss: 0.08515015244483948, Accuracy: 0.8234941933769733\n",
      "Iteration: 89088, Loss: 0.08541300892829895, Accuracy: 0.8179354073945433\n",
      "Iteration: 89152, Loss: 0.08242113888263702, Accuracy: 0.8230533371679485\n",
      "Iteration: 89216, Loss: 0.08791536837816238, Accuracy: 0.8282231376506388\n",
      "Iteration: 89280, Loss: 0.08828895539045334, Accuracy: 0.8273796453140676\n",
      "Iteration: 89344, Loss: 0.0868234857916832, Accuracy: 0.8080845968797803\n",
      "Iteration: 89408, Loss: 0.08784095197916031, Accuracy: 0.8238144519273192\n",
      "Iteration: 89472, Loss: 0.08464500308036804, Accuracy: 0.8245885279029608\n",
      "Iteration: 89536, Loss: 0.08685899525880814, Accuracy: 0.825031882384792\n",
      "Iteration: 89600, Loss: 0.08565062284469604, Accuracy: 0.8280025068670511\n",
      "Iteration: 89664, Loss: 0.08375778794288635, Accuracy: 0.8279654753860086\n",
      "Iteration: 89728, Loss: 0.08644279092550278, Accuracy: 0.8269949653185904\n",
      "Iteration: 89792, Loss: 0.08439528942108154, Accuracy: 0.8282237502280623\n",
      "Iteration: 89856, Loss: 0.08415666222572327, Accuracy: 0.8281660317443311\n",
      "Iteration: 89920, Loss: 0.08127515763044357, Accuracy: 0.8281901760492474\n",
      "Iteration: 89984, Loss: 0.08029866963624954, Accuracy: 0.8285854265559465\n",
      "Iteration: 90048, Loss: 0.08398395776748657, Accuracy: 0.8096679814625531\n",
      "Iteration: 90112, Loss: 0.0825127512216568, Accuracy: 0.8282783897593617\n",
      "Iteration: 90176, Loss: 0.08192528784275055, Accuracy: 0.8280158103443682\n",
      "Iteration: 90240, Loss: 0.08306210488080978, Accuracy: 0.8280863261315972\n",
      "Iteration: 90304, Loss: 0.08066414296627045, Accuracy: 0.8238124966155738\n",
      "Iteration: 90368, Loss: 0.08316245675086975, Accuracy: 0.8263182330410928\n",
      "Iteration: 90432, Loss: 0.08837146311998367, Accuracy: 0.8283571088686585\n",
      "Iteration: 90496, Loss: 0.08825820684432983, Accuracy: 0.8276759008876979\n",
      "Iteration: 90560, Loss: 0.08250807970762253, Accuracy: 0.8282760169822723\n",
      "Iteration: 90624, Loss: 0.08073340356349945, Accuracy: 0.8281212223228067\n",
      "Iteration: 90688, Loss: 0.08295614272356033, Accuracy: 0.8286539448890835\n",
      "Iteration: 90752, Loss: 0.07855770736932755, Accuracy: 0.8251405991613865\n",
      "Iteration: 90816, Loss: 0.08154001832008362, Accuracy: 0.8167845022398978\n",
      "Iteration: 90880, Loss: 0.09047376364469528, Accuracy: 0.827641150681302\n",
      "Iteration: 90944, Loss: 0.08934512734413147, Accuracy: 0.8278801352716982\n",
      "Iteration: 91008, Loss: 0.08743693679571152, Accuracy: 0.8263161182403564\n",
      "Iteration: 91072, Loss: 0.08172056823968887, Accuracy: 0.8231774258892983\n",
      "Iteration: 91136, Loss: 0.08032827824354172, Accuracy: 0.8283535407390445\n",
      "Iteration: 91200, Loss: 0.07996431738138199, Accuracy: 0.8279094055760652\n",
      "Iteration: 91264, Loss: 0.08495514839887619, Accuracy: 0.8238271723967046\n",
      "Iteration: 91328, Loss: 0.08242244273424149, Accuracy: 0.8188624724280089\n",
      "Iteration: 91392, Loss: 0.08696281164884567, Accuracy: 0.8234277449082583\n",
      "Iteration: 91456, Loss: 0.08146794885396957, Accuracy: 0.8216291761491448\n",
      "Iteration: 91520, Loss: 0.08410399407148361, Accuracy: 0.8275358623359352\n",
      "Iteration: 91584, Loss: 0.08768513053655624, Accuracy: 0.8219047721941024\n",
      "Iteration: 91648, Loss: 0.08312191814184189, Accuracy: 0.8225087958853692\n",
      "Iteration: 91712, Loss: 0.08578115701675415, Accuracy: 0.8282363847829401\n",
      "Iteration: 91776, Loss: 0.0865892767906189, Accuracy: 0.8282547870185226\n",
      "Iteration: 91840, Loss: 0.08161861449480057, Accuracy: 0.8275866482872516\n",
      "Iteration: 91904, Loss: 0.08586046099662781, Accuracy: 0.8283396358601749\n",
      "Iteration: 91968, Loss: 0.08653729408979416, Accuracy: 0.828287084819749\n",
      "Iteration: 92032, Loss: 0.08816366642713547, Accuracy: 0.8283461444079876\n",
      "Iteration: 92096, Loss: 0.07983928173780441, Accuracy: 0.8244693584274501\n",
      "Iteration: 92160, Loss: 0.07930441945791245, Accuracy: 0.8164599714800715\n",
      "Iteration: 92224, Loss: 0.08164755254983902, Accuracy: 0.8186634574085474\n",
      "Iteration: 92288, Loss: 0.08365149050951004, Accuracy: 0.823616921203211\n",
      "Iteration: 92352, Loss: 0.08599677681922913, Accuracy: 0.8286050776951015\n",
      "Iteration: 92416, Loss: 0.08256921917200089, Accuracy: 0.8286743047647178\n",
      "Iteration: 92480, Loss: 0.08254312723875046, Accuracy: 0.8289114229846746\n",
      "Iteration: 92544, Loss: 0.08292391151189804, Accuracy: 0.828414389397949\n",
      "Iteration: 92608, Loss: 0.08487334847450256, Accuracy: 0.8284457423724234\n",
      "Iteration: 92672, Loss: 0.08059150725603104, Accuracy: 0.8282723382581025\n",
      "Iteration: 92736, Loss: 0.08387602120637894, Accuracy: 0.8279030292760581\n",
      "Iteration: 92800, Loss: 0.08231694996356964, Accuracy: 0.8284822846762836\n",
      "Iteration: 92864, Loss: 0.08786649256944656, Accuracy: 0.8186045195907354\n",
      "Iteration: 92928, Loss: 0.08316875994205475, Accuracy: 0.8280831209849566\n",
      "Iteration: 92992, Loss: 0.08357849717140198, Accuracy: 0.8287374614737928\n",
      "Iteration: 93056, Loss: 0.0811891183257103, Accuracy: 0.8284302493557334\n",
      "Iteration: 93120, Loss: 0.0844484344124794, Accuracy: 0.8234451035968959\n",
      "Iteration: 93184, Loss: 0.0877392366528511, Accuracy: 0.8277249981183559\n",
      "Iteration: 93248, Loss: 0.08954911679029465, Accuracy: 0.828439905308187\n",
      "Iteration: 93312, Loss: 0.08207099139690399, Accuracy: 0.8288909755647182\n",
      "Iteration: 93376, Loss: 0.08712805062532425, Accuracy: 0.8234172055963427\n",
      "Iteration: 93440, Loss: 0.0875096395611763, Accuracy: 0.8243874486070126\n",
      "Iteration: 93504, Loss: 0.08620765060186386, Accuracy: 0.7988316372502595\n",
      "Iteration: 93568, Loss: 0.07793890684843063, Accuracy: 0.7928835398051888\n",
      "Iteration: 93632, Loss: 0.4090029299259186, Accuracy: 0.7970977153163403\n",
      "Iteration: 93696, Loss: 0.24229444563388824, Accuracy: 0.7418521095532924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 93760, Loss: 0.10275254398584366, Accuracy: 0.7427353898528963\n",
      "Iteration: 93824, Loss: 0.749157190322876, Accuracy: 0.7446504640392959\n",
      "Iteration: 93888, Loss: 0.06889856606721878, Accuracy: 0.7764206298161298\n",
      "Iteration: 93952, Loss: 0.1137615516781807, Accuracy: 0.745218220166862\n",
      "Iteration: 94016, Loss: 0.11371228843927383, Accuracy: 0.7593812830746174\n",
      "Iteration: 94080, Loss: 0.06464051455259323, Accuracy: 0.7613653370644897\n",
      "Iteration: 94144, Loss: 0.1851332187652588, Accuracy: 0.741894420934841\n",
      "Iteration: 94208, Loss: 0.12195631116628647, Accuracy: 0.7150053915102035\n",
      "Iteration: 94272, Loss: 0.15517278015613556, Accuracy: 0.7327505084685981\n",
      "Iteration: 94336, Loss: 0.058806080371141434, Accuracy: 0.7714476678520441\n",
      "Iteration: 94400, Loss: 0.12956975400447845, Accuracy: 0.772726588184014\n",
      "Iteration: 94464, Loss: 0.15674063563346863, Accuracy: 0.7433173726312816\n",
      "Iteration: 94528, Loss: 0.12303584069013596, Accuracy: 0.7105989913688973\n",
      "Iteration: 94592, Loss: 0.03625548630952835, Accuracy: 0.7557613810058683\n",
      "Iteration: 94656, Loss: 0.04260917007923126, Accuracy: 0.7252710469765589\n",
      "Iteration: 94720, Loss: 0.02869025617837906, Accuracy: 0.68931025324855\n",
      "Iteration: 94784, Loss: 0.04357718303799629, Accuracy: 0.7421470961999148\n",
      "Iteration: 94848, Loss: 0.03478238359093666, Accuracy: 0.7236127585638314\n",
      "Iteration: 94912, Loss: 0.14580373466014862, Accuracy: 0.6951890495838597\n",
      "Iteration: 94976, Loss: 0.03264071047306061, Accuracy: 0.7533144037006423\n",
      "Iteration: 95040, Loss: 0.3574940860271454, Accuracy: 0.7724871301325038\n",
      "Iteration: 95104, Loss: 0.01660982519388199, Accuracy: 0.7564904346363619\n",
      "Iteration: 95168, Loss: 0.7036195397377014, Accuracy: 0.7551448183367029\n",
      "Iteration: 95232, Loss: 0.03235814347863197, Accuracy: 0.7293534185737371\n",
      "Iteration: 95296, Loss: 0.10718610882759094, Accuracy: 0.7739763031713665\n",
      "Iteration: 95360, Loss: 0.15036733448505402, Accuracy: 0.7578017179621384\n",
      "Iteration: 95424, Loss: 0.45785650610923767, Accuracy: 0.7278892238391563\n",
      "Iteration: 95488, Loss: 0.07207990437746048, Accuracy: 0.751573673216626\n",
      "Iteration: 95552, Loss: 0.03872348368167877, Accuracy: 0.7582352705067024\n",
      "Iteration: 95616, Loss: 0.07217999547719955, Accuracy: 0.7609335866291076\n",
      "Iteration: 95680, Loss: 0.4857902526855469, Accuracy: 0.7338225414277986\n",
      "Iteration: 95744, Loss: 0.23263108730316162, Accuracy: 0.7363019528565928\n",
      "Iteration: 95808, Loss: 0.08516353368759155, Accuracy: 0.7708431695355102\n",
      "Iteration: 95872, Loss: 0.660362184047699, Accuracy: 0.7890767110511661\n",
      "Iteration: 95936, Loss: 0.14365433156490326, Accuracy: 0.777933461999055\n",
      "Iteration: 96000, Loss: 0.08534589409828186, Accuracy: 0.8088227445841767\n",
      "Iteration: 96064, Loss: 0.3725113868713379, Accuracy: 0.8048135365825146\n",
      "Iteration: 96128, Loss: 0.08974942564964294, Accuracy: 0.7672149515128694\n",
      "Iteration: 96192, Loss: 0.37084710597991943, Accuracy: 0.7910814281785861\n",
      "Iteration: 96256, Loss: 0.03014594316482544, Accuracy: 0.7901354882051237\n",
      "Iteration: 96320, Loss: 0.14597691595554352, Accuracy: 0.8030191298457794\n",
      "Iteration: 96384, Loss: 0.07577966898679733, Accuracy: 0.7860706768697128\n",
      "Iteration: 96448, Loss: 0.36875322461128235, Accuracy: 0.7803103820770048\n",
      "Iteration: 96512, Loss: 0.09649152308702469, Accuracy: 0.7928119240677916\n",
      "Iteration: 96576, Loss: 0.07723446935415268, Accuracy: 0.776331018016208\n",
      "Iteration: 96640, Loss: 0.09486193209886551, Accuracy: 0.7919141100719571\n",
      "Iteration: 96704, Loss: 0.02556353062391281, Accuracy: 0.8031181550468318\n",
      "Iteration: 96768, Loss: 0.07825770229101181, Accuracy: 0.7905614274204709\n",
      "Iteration: 96832, Loss: 0.4734592139720917, Accuracy: 0.7864646174712107\n",
      "Iteration: 96896, Loss: 0.09195166826248169, Accuracy: 0.8170557760749944\n",
      "Iteration: 96960, Loss: 0.3697763979434967, Accuracy: 0.8145395204192027\n",
      "Iteration: 97024, Loss: 0.006056126672774553, Accuracy: 0.8137649918207899\n",
      "Iteration: 97088, Loss: 0.05080796405673027, Accuracy: 0.8092387853539549\n",
      "Iteration: 97152, Loss: 0.14606216549873352, Accuracy: 0.8072935497038998\n",
      "Iteration: 97216, Loss: 0.1515076756477356, Accuracy: 0.8220371609786525\n",
      "Iteration: 97280, Loss: 0.2518497109413147, Accuracy: 0.818886406312231\n",
      "Iteration: 97344, Loss: 0.08990183472633362, Accuracy: 0.8119710505707189\n",
      "Iteration: 97408, Loss: 0.25350120663642883, Accuracy: 0.8233862720080651\n",
      "Iteration: 97472, Loss: 0.04425671324133873, Accuracy: 0.834925203176681\n",
      "Iteration: 97536, Loss: 0.16294905543327332, Accuracy: 0.8274472765042447\n",
      "Iteration: 97600, Loss: 0.033063944429159164, Accuracy: 0.8352033349801786\n",
      "Iteration: 97664, Loss: 0.006841381546109915, Accuracy: 0.8170016782241873\n",
      "Iteration: 97728, Loss: 0.07992659509181976, Accuracy: 0.8222253802814521\n",
      "Iteration: 97792, Loss: 0.09061721712350845, Accuracy: 0.8279289781930856\n",
      "Iteration: 97856, Loss: 0.037543684244155884, Accuracy: 0.8389213114278391\n",
      "Iteration: 97920, Loss: 0.04798661172389984, Accuracy: 0.839345526357647\n",
      "Iteration: 97984, Loss: 0.05812666937708855, Accuracy: 0.8406261901836842\n",
      "Iteration: 98048, Loss: 0.11167344450950623, Accuracy: 0.825689728022553\n",
      "Iteration: 98112, Loss: 0.09516245126724243, Accuracy: 0.838797599542886\n",
      "Iteration: 98176, Loss: 0.4176872968673706, Accuracy: 0.8399521870887838\n",
      "Iteration: 98240, Loss: 0.09548372775316238, Accuracy: 0.8503168124007061\n",
      "Iteration: 98304, Loss: 0.09410398453474045, Accuracy: 0.8516670920071192\n",
      "Iteration: 98368, Loss: 0.024484118446707726, Accuracy: 0.8327814332442358\n",
      "Iteration: 98432, Loss: 0.020671356469392776, Accuracy: 0.8464153861277737\n",
      "Iteration: 98496, Loss: 0.0955994501709938, Accuracy: 0.8481173726613633\n",
      "Iteration: 98560, Loss: 0.07009205967187881, Accuracy: 0.8382571429829113\n",
      "Iteration: 98624, Loss: 0.010522492229938507, Accuracy: 0.8455082210712135\n",
      "Iteration: 98688, Loss: 0.03608527034521103, Accuracy: 0.8401050503598526\n",
      "Iteration: 98752, Loss: 0.10848810523748398, Accuracy: 0.8470206157071516\n",
      "Iteration: 98816, Loss: 0.07107462733983994, Accuracy: 0.848802448483184\n",
      "Iteration: 98880, Loss: 0.05940093472599983, Accuracy: 0.8450008308282122\n",
      "Iteration: 98944, Loss: 0.011589542962610722, Accuracy: 0.8438535773893818\n",
      "Iteration: 99008, Loss: 0.011600560508668423, Accuracy: 0.8399526193970814\n",
      "Iteration: 99072, Loss: 0.03599327802658081, Accuracy: 0.8527072757715359\n",
      "Iteration: 99136, Loss: 0.013605575077235699, Accuracy: 0.8540979331592098\n",
      "Iteration: 99200, Loss: 0.013408225029706955, Accuracy: 0.8443577377474867\n",
      "Iteration: 99264, Loss: 0.28025496006011963, Accuracy: 0.8519378708442673\n",
      "Iteration: 99328, Loss: 0.053816527128219604, Accuracy: 0.8587297688936815\n",
      "Iteration: 99392, Loss: 0.07338932901620865, Accuracy: 0.8592004302190617\n",
      "Iteration: 99456, Loss: 0.057231608778238297, Accuracy: 0.8406870277831331\n",
      "Iteration: 99520, Loss: 0.02671383135020733, Accuracy: 0.8610361166647635\n",
      "Iteration: 99584, Loss: 0.031949955970048904, Accuracy: 0.8529629215481691\n",
      "Iteration: 99648, Loss: 0.020262734964489937, Accuracy: 0.8567130932933651\n",
      "Iteration: 99712, Loss: 0.03129525110125542, Accuracy: 0.8529981972533278\n",
      "Iteration: 99776, Loss: 0.11384356021881104, Accuracy: 0.860480604111217\n",
      "Iteration: 99840, Loss: 0.05389246344566345, Accuracy: 0.8485869879950769\n",
      "Iteration: 99904, Loss: 0.008357405662536621, Accuracy: 0.8531520338729024\n",
      "Iteration: 99968, Loss: 0.11136534810066223, Accuracy: 0.8636136577697471\n",
      "Iteration: 100032, Loss: 0.09675022959709167, Accuracy: 0.863042167853564\n",
      "Iteration: 100096, Loss: 0.028586119413375854, Accuracy: 0.8448758798185736\n",
      "Iteration: 100160, Loss: 0.013551000505685806, Accuracy: 0.859673663158901\n",
      "Iteration: 100224, Loss: 0.09074113517999649, Accuracy: 0.8500717211863957\n",
      "Iteration: 100288, Loss: 0.11497805267572403, Accuracy: 0.8517695206101052\n",
      "Iteration: 100352, Loss: 0.11699265241622925, Accuracy: 0.842931195104029\n",
      "Iteration: 100416, Loss: 0.021340379491448402, Accuracy: 0.8607318254653364\n",
      "Iteration: 100480, Loss: 0.08607260137796402, Accuracy: 0.8391917336848564\n",
      "Iteration: 100544, Loss: 0.12504346668720245, Accuracy: 0.8396150270127691\n",
      "Iteration: 100608, Loss: 0.02143433503806591, Accuracy: 0.8601567571749911\n",
      "Iteration: 100672, Loss: 0.027310175821185112, Accuracy: 0.8572292038588785\n",
      "Iteration: 100736, Loss: 0.007549639791250229, Accuracy: 0.8688127961358987\n",
      "Iteration: 100800, Loss: 0.01055858377367258, Accuracy: 0.8634759651031345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 100864, Loss: 0.08299318701028824, Accuracy: 0.8323988586198539\n",
      "Iteration: 100928, Loss: 0.007666449993848801, Accuracy: 0.8548458804143593\n",
      "Iteration: 100992, Loss: 0.05383637174963951, Accuracy: 0.8412495080847293\n",
      "Iteration: 101056, Loss: 0.052647385746240616, Accuracy: 0.8418022016994655\n",
      "Iteration: 101120, Loss: 0.00742552662268281, Accuracy: 0.8395496416487731\n",
      "Iteration: 101184, Loss: 0.08166592568159103, Accuracy: 0.8497543014236726\n",
      "Iteration: 101248, Loss: 0.11152652651071548, Accuracy: 0.8558655296219513\n",
      "Iteration: 101312, Loss: 0.05972066521644592, Accuracy: 0.8480596977169625\n",
      "Iteration: 101376, Loss: 0.08301906287670135, Accuracy: 0.8518186463043094\n",
      "Iteration: 101440, Loss: 0.1028657853603363, Accuracy: 0.8587909413035959\n",
      "Iteration: 101504, Loss: 0.027814364060759544, Accuracy: 0.8580099516548216\n",
      "Iteration: 101568, Loss: 0.08196898549795151, Accuracy: 0.859145853552036\n",
      "Iteration: 101632, Loss: 0.022761911153793335, Accuracy: 0.8544606564682908\n",
      "Iteration: 101696, Loss: 0.02362728863954544, Accuracy: 0.8436653926037252\n",
      "Iteration: 101760, Loss: 0.09843850135803223, Accuracy: 0.8625487360404804\n",
      "Iteration: 101824, Loss: 0.08647531270980835, Accuracy: 0.8590557504212484\n",
      "Iteration: 101888, Loss: 0.08358805626630783, Accuracy: 0.8653540226514451\n",
      "Iteration: 101952, Loss: 0.015697551891207695, Accuracy: 0.8509853118448518\n",
      "Iteration: 102016, Loss: 0.011726624332368374, Accuracy: 0.8562850465532392\n",
      "Iteration: 102080, Loss: 0.02677890658378601, Accuracy: 0.867467722739093\n",
      "Iteration: 102144, Loss: 0.027056707069277763, Accuracy: 0.8629862904781476\n",
      "Iteration: 102208, Loss: 0.08031649142503738, Accuracy: 0.855915485182777\n",
      "Iteration: 102272, Loss: 0.014179368503391743, Accuracy: 0.8573140338994563\n",
      "Iteration: 102336, Loss: 0.0780956968665123, Accuracy: 0.8605483590508811\n",
      "Iteration: 102400, Loss: 0.05951946601271629, Accuracy: 0.8417211617343128\n",
      "Iteration: 102464, Loss: 0.027052661404013634, Accuracy: 0.8357633196283132\n",
      "Iteration: 102528, Loss: 0.007825355045497417, Accuracy: 0.8470874396734871\n",
      "Iteration: 102592, Loss: 0.027968889102339745, Accuracy: 0.856571207579691\n",
      "Iteration: 102656, Loss: 0.008222213946282864, Accuracy: 0.845480137038976\n",
      "Iteration: 102720, Loss: 0.026553092524409294, Accuracy: 0.869138271373231\n",
      "Iteration: 102784, Loss: 0.007324631791561842, Accuracy: 0.862508674908895\n",
      "Iteration: 102848, Loss: 0.09277325868606567, Accuracy: 0.8518027828540653\n",
      "Iteration: 102912, Loss: 0.0919610857963562, Accuracy: 0.8516717085731216\n",
      "Iteration: 102976, Loss: 0.025186778977513313, Accuracy: 0.8695011421223171\n",
      "Iteration: 103040, Loss: 0.08485043048858643, Accuracy: 0.8479941874975339\n",
      "Iteration: 103104, Loss: 0.0176937784999609, Accuracy: 0.8671387120266445\n",
      "Iteration: 103168, Loss: 0.0070784613490104675, Accuracy: 0.8733978064265102\n",
      "Iteration: 103232, Loss: 0.10057304054498672, Accuracy: 0.8735153973684646\n",
      "Iteration: 103296, Loss: 0.08291516453027725, Accuracy: 0.8413367021712475\n",
      "Iteration: 103360, Loss: 0.01896127499639988, Accuracy: 0.8644483230891638\n",
      "Iteration: 103424, Loss: 0.009687804616987705, Accuracy: 0.8665033864090219\n",
      "Iteration: 103488, Loss: 0.08081994950771332, Accuracy: 0.8587582661421038\n",
      "Iteration: 103552, Loss: 0.0999034121632576, Accuracy: 0.8655939290765673\n",
      "Iteration: 103616, Loss: 0.008921363390982151, Accuracy: 0.8720623269327916\n",
      "Iteration: 103680, Loss: 0.00588221475481987, Accuracy: 0.8691156912245788\n",
      "Iteration: 103744, Loss: 0.062476545572280884, Accuracy: 0.8322044397355057\n",
      "Iteration: 103808, Loss: 0.058363303542137146, Accuracy: 0.8498961392324418\n",
      "Iteration: 103872, Loss: 0.08211631327867508, Accuracy: 0.8585246654693037\n",
      "Iteration: 103936, Loss: 0.12015350908041, Accuracy: 0.8631959505728446\n",
      "Iteration: 104000, Loss: 0.009955634362995625, Accuracy: 0.8675498347147368\n",
      "Iteration: 104064, Loss: 0.07118282467126846, Accuracy: 0.8675977642997168\n",
      "Iteration: 104128, Loss: 0.06117011979222298, Accuracy: 0.8694814821938053\n",
      "Iteration: 104192, Loss: 0.09418364614248276, Accuracy: 0.8802755479700863\n",
      "Iteration: 104256, Loss: 0.11547503620386124, Accuracy: 0.8565553753869608\n",
      "Iteration: 104320, Loss: 0.06370627135038376, Accuracy: 0.8750156819005497\n",
      "Iteration: 104384, Loss: 0.015487642027437687, Accuracy: 0.873682024772279\n",
      "Iteration: 104448, Loss: 0.006971797440201044, Accuracy: 0.8761658922885545\n",
      "Iteration: 104512, Loss: 0.10857071727514267, Accuracy: 0.8643989223637618\n",
      "Iteration: 104576, Loss: 0.060016706585884094, Accuracy: 0.8713729402516037\n",
      "Iteration: 104640, Loss: 0.11335033923387527, Accuracy: 0.8733306257636286\n",
      "Iteration: 104704, Loss: 0.008452014066278934, Accuracy: 0.8670087178470567\n",
      "Iteration: 104768, Loss: 0.08171995729207993, Accuracy: 0.8753181422362104\n",
      "Iteration: 104832, Loss: 0.06584339588880539, Accuracy: 0.8759196034516208\n",
      "Iteration: 104896, Loss: 0.09633510559797287, Accuracy: 0.8793410268845037\n",
      "Iteration: 104960, Loss: 0.06520851701498032, Accuracy: 0.8733459213399328\n",
      "Iteration: 105024, Loss: 0.004765856079757214, Accuracy: 0.8697719826595858\n",
      "Iteration: 105088, Loss: 0.08637955039739609, Accuracy: 0.8700851852772757\n",
      "Iteration: 105152, Loss: 0.08978691697120667, Accuracy: 0.8722362534608692\n",
      "Iteration: 105216, Loss: 0.014127521775662899, Accuracy: 0.8594014248810709\n",
      "Iteration: 105280, Loss: 0.00866425596177578, Accuracy: 0.8793821512372233\n",
      "Iteration: 105344, Loss: 0.02789631299674511, Accuracy: 0.879931534640491\n",
      "Iteration: 105408, Loss: 0.10601687431335449, Accuracy: 0.8761236791033298\n",
      "Iteration: 105472, Loss: 0.07723727822303772, Accuracy: 0.8721135985688306\n",
      "Iteration: 105536, Loss: 0.007385830860584974, Accuracy: 0.8803976039635018\n",
      "Iteration: 105600, Loss: 0.004131402354687452, Accuracy: 0.8718376757460646\n",
      "Iteration: 105664, Loss: 0.06870618462562561, Accuracy: 0.8774560417514294\n",
      "Iteration: 105728, Loss: 0.0036832585465162992, Accuracy: 0.8818316490505822\n",
      "Iteration: 105792, Loss: 0.06821038573980331, Accuracy: 0.8819328868994489\n",
      "Iteration: 105856, Loss: 0.012291911989450455, Accuracy: 0.8722408471512608\n",
      "Iteration: 105920, Loss: 0.009458123706281185, Accuracy: 0.8816902964026667\n",
      "Iteration: 105984, Loss: 0.0046778479591012, Accuracy: 0.8644342353218235\n",
      "Iteration: 106048, Loss: 0.06665433943271637, Accuracy: 0.8742085885023698\n",
      "Iteration: 106112, Loss: 0.003399980952963233, Accuracy: 0.880812517774757\n",
      "Iteration: 106176, Loss: 0.11181188374757767, Accuracy: 0.8799317062366754\n",
      "Iteration: 106240, Loss: 0.08781588077545166, Accuracy: 0.8742725021438673\n",
      "Iteration: 106304, Loss: 0.009081308729946613, Accuracy: 0.8757613713969477\n",
      "Iteration: 106368, Loss: 0.11819807440042496, Accuracy: 0.8821492787683383\n",
      "Iteration: 106432, Loss: 0.006252114195376635, Accuracy: 0.8823139633750543\n",
      "Iteration: 106496, Loss: 0.06004306674003601, Accuracy: 0.875178704794962\n",
      "Iteration: 106560, Loss: 0.06740503758192062, Accuracy: 0.8610637840465643\n",
      "Iteration: 106624, Loss: 0.011495906859636307, Accuracy: 0.8833574319723994\n",
      "Iteration: 106688, Loss: 0.0062660533003509045, Accuracy: 0.8736341139301658\n",
      "Iteration: 106752, Loss: 0.063987597823143, Accuracy: 0.8748243749141693\n",
      "Iteration: 106816, Loss: 0.011313720606267452, Accuracy: 0.8608447140431963\n",
      "Iteration: 106880, Loss: 0.007009234745055437, Accuracy: 0.8726137862540781\n",
      "Iteration: 106944, Loss: 0.07880564033985138, Accuracy: 0.8638437975896522\n",
      "Iteration: 107008, Loss: 0.07752200961112976, Accuracy: 0.8767233926919289\n",
      "Iteration: 107072, Loss: 0.0778413861989975, Accuracy: 0.8852459191111848\n",
      "Iteration: 107136, Loss: 0.08392897248268127, Accuracy: 0.8769783520838246\n",
      "Iteration: 107200, Loss: 0.007736606057733297, Accuracy: 0.8720516071189195\n",
      "Iteration: 107264, Loss: 0.010025483556091785, Accuracy: 0.8828655505203642\n",
      "Iteration: 107328, Loss: 0.004490941762924194, Accuracy: 0.8823303558165208\n",
      "Iteration: 107392, Loss: 0.12071820348501205, Accuracy: 0.8767037866637111\n",
      "Iteration: 107456, Loss: 0.08706561475992203, Accuracy: 0.8746725449454971\n",
      "Iteration: 107520, Loss: 0.09108636528253555, Accuracy: 0.8789687898242846\n",
      "Iteration: 107584, Loss: 0.09670933336019516, Accuracy: 0.8840391972917132\n",
      "Iteration: 107648, Loss: 0.00896125752478838, Accuracy: 0.8826026815222576\n",
      "Iteration: 107712, Loss: 0.009436337277293205, Accuracy: 0.8841214834828861\n",
      "Iteration: 107776, Loss: 0.0974268987774849, Accuracy: 0.8779091555043124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 107840, Loss: 0.06926388293504715, Accuracy: 0.8842423033784144\n",
      "Iteration: 107904, Loss: 0.002619408071041107, Accuracy: 0.8860274876351468\n",
      "Iteration: 107968, Loss: 0.09851580113172531, Accuracy: 0.8827994196326472\n",
      "Iteration: 108032, Loss: 0.002434756839647889, Accuracy: 0.8856313611904625\n",
      "Iteration: 108096, Loss: 0.007388339843600988, Accuracy: 0.8871820585336536\n",
      "Iteration: 108160, Loss: 0.009859590791165829, Accuracy: 0.8772438733431045\n",
      "Iteration: 108224, Loss: 0.006075622048228979, Accuracy: 0.8878408361924812\n",
      "Iteration: 108288, Loss: 0.008409067988395691, Accuracy: 0.8836749218171462\n",
      "Iteration: 108352, Loss: 0.08598900586366653, Accuracy: 0.888034990784945\n",
      "Iteration: 108416, Loss: 0.0029826012905687094, Accuracy: 0.8831105127756018\n",
      "Iteration: 108480, Loss: 0.0049439300782978535, Accuracy: 0.8850452936894726\n",
      "Iteration: 108544, Loss: 0.10699515789747238, Accuracy: 0.875186197925359\n",
      "Iteration: 108608, Loss: 0.10343267768621445, Accuracy: 0.8860087323992047\n",
      "Iteration: 108672, Loss: 0.08831342309713364, Accuracy: 0.8846269269706681\n",
      "Iteration: 108736, Loss: 0.10773556679487228, Accuracy: 0.8869437518296763\n",
      "Iteration: 108800, Loss: 0.07578428834676743, Accuracy: 0.8779534218483604\n",
      "Iteration: 108864, Loss: 0.06720170378684998, Accuracy: 0.8879553944861982\n",
      "Iteration: 108928, Loss: 0.0025108607951551676, Accuracy: 0.889650952158263\n",
      "Iteration: 108992, Loss: 0.09352315217256546, Accuracy: 0.8831772124976851\n",
      "Iteration: 109056, Loss: 0.0790708139538765, Accuracy: 0.8771618054015562\n",
      "Iteration: 109120, Loss: 0.007676936220377684, Accuracy: 0.8885015066189226\n",
      "Iteration: 109184, Loss: 0.012794307433068752, Accuracy: 0.8869293512252625\n",
      "Iteration: 109248, Loss: 0.005216540303081274, Accuracy: 0.8890915322990622\n",
      "Iteration: 109312, Loss: 0.1037202998995781, Accuracy: 0.8887463687860873\n",
      "Iteration: 109376, Loss: 0.07713322341442108, Accuracy: 0.8877069108420983\n",
      "Iteration: 109440, Loss: 0.002454126952216029, Accuracy: 0.8738264003477525\n",
      "Iteration: 109504, Loss: 0.05877174809575081, Accuracy: 0.8721045994025189\n",
      "Iteration: 109568, Loss: 0.08620996028184891, Accuracy: 0.880907928221859\n",
      "Iteration: 109632, Loss: 0.002705709310248494, Accuracy: 0.8858586322749034\n",
      "Iteration: 109696, Loss: 0.007834333926439285, Accuracy: 0.866037978528766\n",
      "Iteration: 109760, Loss: 0.002841128734871745, Accuracy: 0.8710626116662752\n",
      "Iteration: 109824, Loss: 0.07361512631177902, Accuracy: 0.8762388039031066\n",
      "Iteration: 109888, Loss: 0.09277164936065674, Accuracy: 0.8852775922860019\n",
      "Iteration: 109952, Loss: 0.0025003033224493265, Accuracy: 0.8919220281823073\n",
      "Iteration: 110016, Loss: 0.08227028697729111, Accuracy: 0.8881158258009236\n",
      "Iteration: 110080, Loss: 0.002308680210262537, Accuracy: 0.8882382632873487\n",
      "Iteration: 110144, Loss: 0.007592759560793638, Accuracy: 0.8844336500333156\n",
      "Iteration: 110208, Loss: 0.002158969873562455, Accuracy: 0.8879009411321022\n",
      "Iteration: 110272, Loss: 0.002226080745458603, Accuracy: 0.8749772757582832\n",
      "Iteration: 110336, Loss: 0.0986621305346489, Accuracy: 0.8765244083770085\n",
      "Iteration: 110400, Loss: 0.06233147904276848, Accuracy: 0.8860252019076142\n",
      "Iteration: 110464, Loss: 0.0900140032172203, Accuracy: 0.8893688105745241\n",
      "Iteration: 110528, Loss: 0.08903524279594421, Accuracy: 0.8711162066610996\n",
      "Iteration: 110592, Loss: 0.006284327711910009, Accuracy: 0.8797873821749818\n",
      "Iteration: 110656, Loss: 0.08994872123003006, Accuracy: 0.8813298913592007\n",
      "Iteration: 110720, Loss: 0.002451802371069789, Accuracy: 0.8851459342404269\n",
      "Iteration: 110784, Loss: 0.09406011551618576, Accuracy: 0.8884918222611304\n",
      "Iteration: 110848, Loss: 0.064876027405262, Accuracy: 0.8762662127264775\n",
      "Iteration: 110912, Loss: 0.0020873895846307278, Accuracy: 0.8649010942899622\n",
      "Iteration: 110976, Loss: 0.0766516849398613, Accuracy: 0.8854719310475048\n",
      "Iteration: 111040, Loss: 0.09857591986656189, Accuracy: 0.8855042650538962\n",
      "Iteration: 111104, Loss: 0.004658505320549011, Accuracy: 0.8808201200154144\n",
      "Iteration: 111168, Loss: 0.0920601412653923, Accuracy: 0.8841728096886072\n",
      "Iteration: 111232, Loss: 0.013486146926879883, Accuracy: 0.8831620448036119\n",
      "Iteration: 111296, Loss: 0.077189140021801, Accuracy: 0.8923995889781509\n",
      "Iteration: 111360, Loss: 0.09549859911203384, Accuracy: 0.8843490551225841\n",
      "Iteration: 111424, Loss: 0.10891186445951462, Accuracy: 0.8873521001951303\n",
      "Iteration: 111488, Loss: 0.005508359521627426, Accuracy: 0.8909775169740897\n",
      "Iteration: 111552, Loss: 0.001904731267131865, Accuracy: 0.881072413205402\n",
      "Iteration: 111616, Loss: 0.0030444134026765823, Accuracy: 0.8709189307119232\n",
      "Iteration: 111680, Loss: 0.005007447209209204, Accuracy: 0.8905533889774233\n",
      "Iteration: 111744, Loss: 0.08266030997037888, Accuracy: 0.8858716455870308\n",
      "Iteration: 111808, Loss: 0.09128779172897339, Accuracy: 0.8758451909234282\n",
      "Iteration: 111872, Loss: 0.00560363195836544, Accuracy: 0.8870876844739541\n",
      "Iteration: 111936, Loss: 0.002686557359993458, Accuracy: 0.8719975922722369\n",
      "Iteration: 112000, Loss: 0.09768979996442795, Accuracy: 0.8603782937861979\n",
      "Iteration: 112064, Loss: 0.10452646762132645, Accuracy: 0.871113634260837\n",
      "Iteration: 112128, Loss: 0.07331722974777222, Accuracy: 0.8861912477877922\n",
      "Iteration: 112192, Loss: 0.10435234755277634, Accuracy: 0.8883761865145061\n",
      "Iteration: 112256, Loss: 0.09877049177885056, Accuracy: 0.8854436599358451\n",
      "Iteration: 112320, Loss: 0.005631620530039072, Accuracy: 0.8864974315802101\n",
      "Iteration: 112384, Loss: 0.017688913270831108, Accuracy: 0.8914535138756037\n",
      "Iteration: 112448, Loss: 0.09785424917936325, Accuracy: 0.8862034765188582\n",
      "Iteration: 112512, Loss: 0.08718135952949524, Accuracy: 0.8889332156686578\n",
      "Iteration: 112576, Loss: 0.10112974792718887, Accuracy: 0.8817560486495495\n",
      "Iteration: 112640, Loss: 0.0018081233138218522, Accuracy: 0.889464436477283\n",
      "Iteration: 112704, Loss: 0.10835755616426468, Accuracy: 0.8832672533462755\n",
      "Iteration: 112768, Loss: 0.06942089647054672, Accuracy: 0.882560701778857\n",
      "Iteration: 112832, Loss: 0.08140096813440323, Accuracy: 0.8817654801241588\n",
      "Iteration: 112896, Loss: 0.0033231580164283514, Accuracy: 0.8823613908025436\n",
      "Iteration: 112960, Loss: 0.02696937881410122, Accuracy: 0.8835723551746923\n",
      "Iteration: 113024, Loss: 0.08338113874197006, Accuracy: 0.8933724068047013\n",
      "Iteration: 113088, Loss: 0.0016982256202027202, Accuracy: 0.8872376623330638\n",
      "Iteration: 113152, Loss: 0.004230763763189316, Accuracy: 0.8829993502877187\n",
      "Iteration: 113216, Loss: 0.07139522582292557, Accuracy: 0.8930445026489906\n",
      "Iteration: 113280, Loss: 0.0020579909905791283, Accuracy: 0.891967082337942\n",
      "Iteration: 113344, Loss: 0.09835664182901382, Accuracy: 0.8871650215005502\n",
      "Iteration: 113408, Loss: 0.06432729959487915, Accuracy: 0.8866660560306627\n",
      "Iteration: 113472, Loss: 0.1063443049788475, Accuracy: 0.8876831227971707\n",
      "Iteration: 113536, Loss: 0.0914541482925415, Accuracy: 0.8838480865233578\n",
      "Iteration: 113600, Loss: 0.06415782868862152, Accuracy: 0.8882626423728652\n",
      "Iteration: 113664, Loss: 0.08358023315668106, Accuracy: 0.8893613662803546\n",
      "Iteration: 113728, Loss: 0.08747238665819168, Accuracy: 0.8852864530927036\n",
      "Iteration: 113792, Loss: 0.0739787295460701, Accuracy: 0.8879949705442414\n",
      "Iteration: 113856, Loss: 0.09480682015419006, Accuracy: 0.8929543359845411\n",
      "Iteration: 113920, Loss: 0.002601984655484557, Accuracy: 0.8886075004702434\n",
      "Iteration: 113984, Loss: 0.0018217223696410656, Accuracy: 0.8935436732135713\n",
      "Iteration: 114048, Loss: 0.0018194393487647176, Accuracy: 0.8931577944604214\n",
      "Iteration: 114112, Loss: 0.08807412534952164, Accuracy: 0.8889225029270165\n",
      "Iteration: 114176, Loss: 0.09306082874536514, Accuracy: 0.8874136466765776\n",
      "Iteration: 114240, Loss: 0.07678092271089554, Accuracy: 0.8737519649148453\n",
      "Iteration: 114304, Loss: 0.00628424808382988, Accuracy: 0.8591955917363521\n",
      "Iteration: 114368, Loss: 0.00509765837341547, Accuracy: 0.8767840920481831\n",
      "Iteration: 114432, Loss: 0.0019811990205198526, Accuracy: 0.881314661091892\n",
      "Iteration: 114496, Loss: 0.07544145733118057, Accuracy: 0.8882151231518947\n",
      "Iteration: 114560, Loss: 0.0039389487355947495, Accuracy: 0.8851187605469022\n",
      "Iteration: 114624, Loss: 0.0014884773408994079, Accuracy: 0.8880782986525446\n",
      "Iteration: 114688, Loss: 0.08308962732553482, Accuracy: 0.8879723566351458\n",
      "Iteration: 114752, Loss: 0.062292780727148056, Accuracy: 0.894924341206206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 114816, Loss: 0.005259808152914047, Accuracy: 0.893036810826743\n",
      "Iteration: 114880, Loss: 0.005030701402574778, Accuracy: 0.8844606475322507\n",
      "Iteration: 114944, Loss: 0.00165477953851223, Accuracy: 0.8832663307839539\n",
      "Iteration: 115008, Loss: 0.0967046394944191, Accuracy: 0.8851804740552325\n",
      "Iteration: 115072, Loss: 0.0034001271706074476, Accuracy: 0.8906757400836796\n",
      "Iteration: 115136, Loss: 0.07921478897333145, Accuracy: 0.8853061168338172\n",
      "Iteration: 115200, Loss: 0.004872575867921114, Accuracy: 0.893839858181309\n",
      "Iteration: 115264, Loss: 0.004148814361542463, Accuracy: 0.894444844831014\n",
      "Iteration: 115328, Loss: 0.09014081209897995, Accuracy: 0.8924941510776989\n",
      "Iteration: 115392, Loss: 0.08359486609697342, Accuracy: 0.8822454662295058\n",
      "Iteration: 115456, Loss: 0.09243903309106827, Accuracy: 0.8919996751355939\n",
      "Iteration: 115520, Loss: 0.08603403717279434, Accuracy: 0.8935405691736378\n",
      "Iteration: 115584, Loss: 0.0846400260925293, Accuracy: 0.8878358585352544\n",
      "Iteration: 115648, Loss: 0.0018375478684902191, Accuracy: 0.8891417973209172\n",
      "Iteration: 115712, Loss: 0.0015261414228007197, Accuracy: 0.8912492022791412\n",
      "Iteration: 115776, Loss: 0.004636106546968222, Accuracy: 0.890156515117269\n",
      "Iteration: 115840, Loss: 0.09639871120452881, Accuracy: 0.889834188419627\n",
      "Iteration: 115904, Loss: 0.07577089220285416, Accuracy: 0.8949247093696613\n",
      "Iteration: 115968, Loss: 0.09328881651163101, Accuracy: 0.8874802184000146\n",
      "Iteration: 116032, Loss: 0.00421541603282094, Accuracy: 0.886832950724056\n",
      "Iteration: 116096, Loss: 0.004459061194211245, Accuracy: 0.8932598302781116\n",
      "Iteration: 116160, Loss: 0.10479327291250229, Accuracy: 0.8947348837100435\n",
      "Iteration: 116224, Loss: 0.0016602087998762727, Accuracy: 0.8958019362471532\n",
      "Iteration: 116288, Loss: 0.001735788187943399, Accuracy: 0.8888353162910789\n",
      "Iteration: 116352, Loss: 0.07108894735574722, Accuracy: 0.8849283132876735\n",
      "Iteration: 116416, Loss: 0.0017274897545576096, Accuracy: 0.894417867064476\n",
      "Iteration: 116480, Loss: 0.003593093017116189, Accuracy: 0.8943414006207604\n",
      "Iteration: 116544, Loss: 0.0014946026494726539, Accuracy: 0.8888308102905285\n",
      "Iteration: 116608, Loss: 0.004480673465877771, Accuracy: 0.8871623097511474\n",
      "Iteration: 116672, Loss: 0.0035818840842694044, Accuracy: 0.8889270800864324\n",
      "Iteration: 116736, Loss: 0.06234193965792656, Accuracy: 0.895041506853886\n",
      "Iteration: 116800, Loss: 0.07601942867040634, Accuracy: 0.8948744698427618\n",
      "Iteration: 116864, Loss: 0.0014062962727621198, Accuracy: 0.889701687527122\n",
      "Iteration: 116928, Loss: 0.08304798603057861, Accuracy: 0.8930621727195103\n",
      "Iteration: 116992, Loss: 0.001706787385046482, Accuracy: 0.8851033828686923\n",
      "Iteration: 117056, Loss: 0.0918554961681366, Accuracy: 0.8841443732380867\n",
      "Iteration: 117120, Loss: 0.08328842371702194, Accuracy: 0.8890873055788688\n",
      "Iteration: 117184, Loss: 0.004304249305278063, Accuracy: 0.8869877306860872\n",
      "Iteration: 117248, Loss: 0.0017286321381106973, Accuracy: 0.8749427851580549\n",
      "Iteration: 117312, Loss: 0.0770171657204628, Accuracy: 0.8916452977573499\n",
      "Iteration: 117376, Loss: 0.001358026172965765, Accuracy: 0.8944704147870652\n",
      "Iteration: 117440, Loss: 0.0035756388679146767, Accuracy: 0.8956952080479823\n",
      "Iteration: 117504, Loss: 0.08477286249399185, Accuracy: 0.8920154161169194\n",
      "Iteration: 117568, Loss: 0.061001066118478775, Accuracy: 0.8963549365871586\n",
      "Iteration: 117632, Loss: 0.09007465839385986, Accuracy: 0.8844911463384051\n",
      "Iteration: 117696, Loss: 0.08201012760400772, Accuracy: 0.892782219190849\n",
      "Iteration: 117760, Loss: 0.0058636777102947235, Accuracy: 0.8874496788484976\n",
      "Iteration: 117824, Loss: 0.08181653916835785, Accuracy: 0.8952431997749954\n",
      "Iteration: 117888, Loss: 0.002663759281858802, Accuracy: 0.8892484023235738\n",
      "Iteration: 117952, Loss: 0.10050374269485474, Accuracy: 0.897070016944781\n",
      "Iteration: 118016, Loss: 0.003718258813023567, Accuracy: 0.8840155388170388\n",
      "Iteration: 118080, Loss: 0.07718261331319809, Accuracy: 0.8940254344779532\n",
      "Iteration: 118144, Loss: 0.09262030571699142, Accuracy: 0.8881020362023264\n",
      "Iteration: 118208, Loss: 0.05471960827708244, Accuracy: 0.8877661514270585\n",
      "Iteration: 118272, Loss: 0.0014998409897089005, Accuracy: 0.8867689045728184\n",
      "Iteration: 118336, Loss: 0.06854523718357086, Accuracy: 0.8813968978647608\n",
      "Iteration: 118400, Loss: 0.0026233193930238485, Accuracy: 0.896548563381657\n",
      "Iteration: 118464, Loss: 0.0014522935962304473, Accuracy: 0.886728819925338\n",
      "Iteration: 118528, Loss: 0.0027772996108978987, Accuracy: 0.8949214443855453\n",
      "Iteration: 118592, Loss: 0.003473899560049176, Accuracy: 0.8955288840516005\n",
      "Iteration: 118656, Loss: 0.4285637140274048, Accuracy: 0.8837302559113596\n",
      "Iteration: 118720, Loss: 0.0015586260706186295, Accuracy: 0.893945365678519\n",
      "Iteration: 118784, Loss: 0.08887665718793869, Accuracy: 0.8817392577475403\n",
      "Iteration: 118848, Loss: 0.09388238191604614, Accuracy: 0.8976025898009539\n",
      "Iteration: 118912, Loss: 0.18862175941467285, Accuracy: 0.8870634816703387\n",
      "Iteration: 118976, Loss: 0.0027903644368052483, Accuracy: 0.8883193501969799\n",
      "Iteration: 119040, Loss: 0.0824892446398735, Accuracy: 0.8987163114943542\n",
      "Iteration: 119104, Loss: 0.060309961438179016, Accuracy: 0.8941293171083089\n",
      "Iteration: 119168, Loss: 0.09003272652626038, Accuracy: 0.8959241440461483\n",
      "Iteration: 119232, Loss: 0.12490943819284439, Accuracy: 0.8921987010107841\n",
      "Iteration: 119296, Loss: 0.0031951714772731066, Accuracy: 0.89103839037125\n",
      "Iteration: 119360, Loss: 0.003277986543253064, Accuracy: 0.8895053350715898\n",
      "Iteration: 119424, Loss: 0.07738179713487625, Accuracy: 0.8921762555255555\n",
      "Iteration: 119488, Loss: 0.00276465923525393, Accuracy: 0.889218753145542\n",
      "Iteration: 119552, Loss: 0.09066105633974075, Accuracy: 0.8910612928739283\n",
      "Iteration: 119616, Loss: 0.0027548058424144983, Accuracy: 0.8861154013720807\n",
      "Iteration: 119680, Loss: 0.0023061216343194246, Accuracy: 0.8888598640041891\n",
      "Iteration: 119744, Loss: 0.05950090289115906, Accuracy: 0.8885563483054284\n",
      "Iteration: 119808, Loss: 0.08160407096147537, Accuracy: 0.8914997060783207\n",
      "Iteration: 119872, Loss: 0.004550203215330839, Accuracy: 0.895415242499439\n",
      "Iteration: 119936, Loss: 0.08220406621694565, Accuracy: 0.8883187933824956\n",
      "Iteration: 120000, Loss: 0.09241796284914017, Accuracy: 0.8911162110161968\n",
      "Iteration: 120064, Loss: 0.0017669849330559373, Accuracy: 0.8843410621630028\n",
      "Iteration: 120128, Loss: 0.0027520302683115005, Accuracy: 0.8998734931810759\n",
      "Iteration: 120192, Loss: 0.07807452976703644, Accuracy: 0.8945426080317702\n",
      "Iteration: 120256, Loss: 0.09218022227287292, Accuracy: 0.8897542619379237\n",
      "Iteration: 120320, Loss: 0.05208997055888176, Accuracy: 0.8922075416485313\n",
      "Iteration: 120384, Loss: 0.0030317362397909164, Accuracy: 0.8926921159145422\n",
      "Iteration: 120448, Loss: 0.003170437179505825, Accuracy: 0.8932024261739571\n",
      "Iteration: 120512, Loss: 0.09161923080682755, Accuracy: 0.8942841952957679\n",
      "Iteration: 120576, Loss: 0.0018730188021436334, Accuracy: 0.894273513549706\n",
      "Iteration: 120640, Loss: 0.0024381461553275585, Accuracy: 0.8908392558223568\n",
      "Iteration: 120704, Loss: 0.0016625444404780865, Accuracy: 0.8889087641437072\n",
      "Iteration: 120768, Loss: 0.09219229966402054, Accuracy: 0.888082507008221\n",
      "Iteration: 120832, Loss: 0.04855700209736824, Accuracy: 0.8925877030997071\n",
      "Iteration: 120896, Loss: 0.07749829441308975, Accuracy: 0.8992732022306882\n",
      "Iteration: 120960, Loss: 0.0956125482916832, Accuracy: 0.897225706547033\n",
      "Iteration: 121024, Loss: 0.11114498972892761, Accuracy: 0.8970318196807057\n",
      "Iteration: 121088, Loss: 0.0012151538394391537, Accuracy: 0.9030883235973306\n",
      "Iteration: 121152, Loss: 0.08707378059625626, Accuracy: 0.8941631329653319\n",
      "Iteration: 121216, Loss: 0.0026090533938258886, Accuracy: 0.8996044046944007\n",
      "Iteration: 121280, Loss: 0.0016367820790037513, Accuracy: 0.8992628101841547\n",
      "Iteration: 121344, Loss: 0.002305367263033986, Accuracy: 0.8916429313831031\n",
      "Iteration: 121408, Loss: 0.002480152528733015, Accuracy: 0.9003214224649128\n",
      "Iteration: 121472, Loss: 0.0023229429498314857, Accuracy: 0.9039102590468246\n",
      "Iteration: 121536, Loss: 0.0008276232983916998, Accuracy: 0.9042031415156089\n",
      "Iteration: 121600, Loss: 0.08949068188667297, Accuracy: 0.9000868899165653\n",
      "Iteration: 121664, Loss: 0.0018360939575359225, Accuracy: 0.8978878482303116\n",
      "Iteration: 121728, Loss: 0.002551368670538068, Accuracy: 0.8874208607594483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 121792, Loss: 0.002518630353733897, Accuracy: 0.8996778043510858\n",
      "Iteration: 121856, Loss: 0.0025082463398575783, Accuracy: 0.9033596421650145\n",
      "Iteration: 121920, Loss: 0.07897604256868362, Accuracy: 0.9011142853123602\n",
      "Iteration: 121984, Loss: 0.0009044543257914484, Accuracy: 0.895548638451146\n",
      "Iteration: 122048, Loss: 0.0017227394273504615, Accuracy: 0.8985003181442153\n",
      "Iteration: 122112, Loss: 0.0016225603176280856, Accuracy: 0.8970732821326237\n",
      "Iteration: 122176, Loss: 0.0043671331368386745, Accuracy: 0.8789955670654308\n",
      "Iteration: 122240, Loss: 0.09782293438911438, Accuracy: 0.9088159693055786\n",
      "Iteration: 122304, Loss: 0.07802221924066544, Accuracy: 0.9048100061772857\n",
      "Iteration: 122368, Loss: 0.001029540435411036, Accuracy: 0.9035820961580612\n",
      "Iteration: 122432, Loss: 0.0019476526649668813, Accuracy: 0.9059237017645501\n",
      "Iteration: 122496, Loss: 0.006955070421099663, Accuracy: 0.9003330286650453\n",
      "Iteration: 122560, Loss: 0.0018053773092105985, Accuracy: 0.9074445743171964\n",
      "Iteration: 122624, Loss: 0.09932678937911987, Accuracy: 0.9020103488874156\n",
      "Iteration: 122688, Loss: 0.002324458444491029, Accuracy: 0.9045030398992822\n",
      "Iteration: 122752, Loss: 0.001356999739073217, Accuracy: 0.8973933813977055\n",
      "Iteration: 122816, Loss: 0.06966955214738846, Accuracy: 0.902994901582133\n",
      "Iteration: 122880, Loss: 0.000835549843031913, Accuracy: 0.8918413338251412\n",
      "Iteration: 122944, Loss: 0.11475727707147598, Accuracy: 0.9027342415356543\n",
      "Iteration: 123008, Loss: 0.0009442637674510479, Accuracy: 0.9085375177382957\n",
      "Iteration: 123072, Loss: 0.08557853102684021, Accuracy: 0.9070012613374274\n",
      "Iteration: 123136, Loss: 0.07355786114931107, Accuracy: 0.9088216059608385\n",
      "Iteration: 123200, Loss: 0.0022239431273192167, Accuracy: 0.8883783737255726\n",
      "Iteration: 123264, Loss: 0.0009048273786902428, Accuracy: 0.9061572427162901\n",
      "Iteration: 123328, Loss: 0.07337569445371628, Accuracy: 0.907689999206923\n",
      "Iteration: 123392, Loss: 0.001689770258963108, Accuracy: 0.9061249807127751\n",
      "Iteration: 123456, Loss: 0.0013940505450591445, Accuracy: 0.9078308902389836\n",
      "Iteration: 123520, Loss: 0.1139533594250679, Accuracy: 0.9051704292360228\n",
      "Iteration: 123584, Loss: 0.0033313557505607605, Accuracy: 0.9107739275495987\n",
      "Iteration: 123648, Loss: 0.0021565814968198538, Accuracy: 0.9002741223957855\n",
      "Iteration: 123712, Loss: 0.00208590948022902, Accuracy: 0.909648057713639\n",
      "Iteration: 123776, Loss: 0.0010449780384078622, Accuracy: 0.9065198658499867\n",
      "Iteration: 123840, Loss: 0.06306368857622147, Accuracy: 0.9033686169132125\n",
      "Iteration: 123904, Loss: 0.006687199231237173, Accuracy: 0.912122678157175\n",
      "Iteration: 123968, Loss: 0.0013796003768220544, Accuracy: 0.9069008819933515\n",
      "Iteration: 124032, Loss: 0.0009245364926755428, Accuracy: 0.90218081563944\n",
      "Iteration: 124096, Loss: 0.02989654242992401, Accuracy: 0.9130113579449244\n",
      "Iteration: 124160, Loss: 0.0011633242247626185, Accuracy: 0.8989192289300263\n",
      "Iteration: 124224, Loss: 0.0009402248542755842, Accuracy: 0.9037436171493027\n",
      "Iteration: 124288, Loss: 0.001530133537016809, Accuracy: 0.9153440183436032\n",
      "Iteration: 124352, Loss: 0.0009553226991556585, Accuracy: 0.9055123398720752\n",
      "Iteration: 124416, Loss: 0.001446960843168199, Accuracy: 0.9000571587821469\n",
      "Iteration: 124480, Loss: 0.001053083105944097, Accuracy: 0.9018933677289169\n",
      "Iteration: 124544, Loss: 0.08961047977209091, Accuracy: 0.8935553311603144\n",
      "Iteration: 124608, Loss: 0.02466139942407608, Accuracy: 0.897581901808735\n",
      "Iteration: 124672, Loss: 0.0839822068810463, Accuracy: 0.9051131538872141\n",
      "Iteration: 124736, Loss: 0.0012666005641222, Accuracy: 0.9089352817391045\n",
      "Iteration: 124800, Loss: 0.3311935365200043, Accuracy: 0.9082144444109872\n",
      "Iteration: 124864, Loss: 0.09600689262151718, Accuracy: 0.9104294037970249\n",
      "Iteration: 124928, Loss: 0.013397759757936, Accuracy: 0.9141777704353444\n",
      "Iteration: 124992, Loss: 0.0015879147686064243, Accuracy: 0.8999677872925531\n",
      "Iteration: 125056, Loss: 0.0016883857315406203, Accuracy: 0.9146996374765877\n",
      "Iteration: 125120, Loss: 0.0007912665023468435, Accuracy: 0.9189008452231064\n",
      "Iteration: 125184, Loss: 0.0013635557843372226, Accuracy: 0.9170275335782208\n",
      "Iteration: 125248, Loss: 0.0004906912799924612, Accuracy: 0.9142366058076732\n",
      "Iteration: 125312, Loss: 0.08280939608812332, Accuracy: 0.9071936662658118\n",
      "Iteration: 125376, Loss: 0.0023994306102395058, Accuracy: 0.9100080470961984\n",
      "Iteration: 125440, Loss: 0.07345513254404068, Accuracy: 0.9161307580943685\n",
      "Iteration: 125504, Loss: 0.0041435412131249905, Accuracy: 0.8992004516767338\n",
      "Iteration: 125568, Loss: 0.0013724244199693203, Accuracy: 0.9112398166325875\n",
      "Iteration: 125632, Loss: 0.06619716435670853, Accuracy: 0.9164240062818862\n",
      "Iteration: 125696, Loss: 0.0007900685886852443, Accuracy: 0.9168563525890931\n",
      "Iteration: 125760, Loss: 0.01607167348265648, Accuracy: 0.9191768108430551\n",
      "Iteration: 125824, Loss: 0.00798027217388153, Accuracy: 0.9144179671129677\n",
      "Iteration: 125888, Loss: 0.09263519197702408, Accuracy: 0.9150745449878741\n",
      "Iteration: 125952, Loss: 0.0009395251981914043, Accuracy: 0.9136032583628548\n",
      "Iteration: 126016, Loss: 0.00043651051237247884, Accuracy: 0.9194526565552223\n",
      "Iteration: 126080, Loss: 0.001817579846829176, Accuracy: 0.9107003270473797\n",
      "Iteration: 126144, Loss: 0.022367795929312706, Accuracy: 0.921131131486618\n",
      "Iteration: 126208, Loss: 0.03402673825621605, Accuracy: 0.9161107155523496\n",
      "Iteration: 126272, Loss: 0.002996098017320037, Accuracy: 0.9235673101211432\n",
      "Iteration: 126336, Loss: 0.0008505239966325462, Accuracy: 0.9212170028040418\n",
      "Iteration: 126400, Loss: 0.000830122793558985, Accuracy: 0.9254600547719747\n",
      "Iteration: 126464, Loss: 0.000593191129155457, Accuracy: 0.9132862743717851\n",
      "Iteration: 126528, Loss: 0.0005862997495569289, Accuracy: 0.9236179185681976\n",
      "Iteration: 126592, Loss: 0.000885289628058672, Accuracy: 0.9264567282662028\n",
      "Iteration: 126656, Loss: 0.001397914718836546, Accuracy: 0.9182506921351887\n",
      "Iteration: 126720, Loss: 0.0007748762145638466, Accuracy: 0.9185961596376728\n",
      "Iteration: 126784, Loss: 0.006184863392263651, Accuracy: 0.9260485103150131\n",
      "Iteration: 126848, Loss: 0.00039111447404138744, Accuracy: 0.9249354056664743\n",
      "Iteration: 126912, Loss: 0.0006170615670271218, Accuracy: 0.9109796835837187\n",
      "Iteration: 126976, Loss: 0.06364772468805313, Accuracy: 0.9221186836948618\n",
      "Iteration: 127040, Loss: 0.06028686463832855, Accuracy: 0.9172762642847374\n",
      "Iteration: 127104, Loss: 0.032320600003004074, Accuracy: 0.9231541019544238\n",
      "Iteration: 127168, Loss: 0.08757131546735764, Accuracy: 0.9254965686704963\n",
      "Iteration: 127232, Loss: 0.09337124228477478, Accuracy: 0.9288701204495737\n",
      "Iteration: 127296, Loss: 0.0012119935126975179, Accuracy: 0.9116542776173446\n",
      "Iteration: 127360, Loss: 0.03553425148129463, Accuracy: 0.9174887762928847\n",
      "Iteration: 127424, Loss: 0.011582928709685802, Accuracy: 0.9287843967176741\n",
      "Iteration: 127488, Loss: 0.001322978176176548, Accuracy: 0.9339307454647496\n",
      "Iteration: 127552, Loss: 0.025435904040932655, Accuracy: 0.9263729523518123\n",
      "Iteration: 127616, Loss: 0.037962306290864944, Accuracy: 0.9292014812672278\n",
      "Iteration: 127680, Loss: 0.10886652022600174, Accuracy: 0.9254816253087483\n",
      "Iteration: 127744, Loss: 0.0065328627824783325, Accuracy: 0.9223498891951749\n",
      "Iteration: 127808, Loss: 0.015290338546037674, Accuracy: 0.9159757722809445\n",
      "Iteration: 127872, Loss: 0.0006581767811439931, Accuracy: 0.915992028414621\n",
      "Iteration: 127936, Loss: 0.0643967017531395, Accuracy: 0.9210669121675892\n",
      "Iteration: 128000, Loss: 0.00033105493639595807, Accuracy: 0.9277815223467769\n",
      "Iteration: 128064, Loss: 0.012762746773660183, Accuracy: 0.9330963881075149\n",
      "Iteration: 128128, Loss: 0.00034158583730459213, Accuracy: 0.9300122823624406\n",
      "Iteration: 128192, Loss: 0.03725312650203705, Accuracy: 0.9323824453895213\n",
      "Iteration: 128256, Loss: 0.006282111629843712, Accuracy: 0.93589028705901\n",
      "Iteration: 128320, Loss: 0.06901076436042786, Accuracy: 0.9322864072601078\n",
      "Iteration: 128384, Loss: 0.009663927368819714, Accuracy: 0.9375725972349755\n",
      "Iteration: 128448, Loss: 0.0005909728934057057, Accuracy: 0.9327657711255597\n",
      "Iteration: 128512, Loss: 0.004316566977649927, Accuracy: 0.9296909552504076\n",
      "Iteration: 128576, Loss: 0.0008349643903784454, Accuracy: 0.9417140257282881\n",
      "Iteration: 128640, Loss: 0.0009109894162975252, Accuracy: 0.9164168847928522\n",
      "Iteration: 128704, Loss: 0.33563709259033203, Accuracy: 0.929791077367554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 128768, Loss: 0.0004535112821031362, Accuracy: 0.910207581546274\n",
      "Iteration: 128832, Loss: 0.03906042501330376, Accuracy: 0.9331800032232422\n",
      "Iteration: 128896, Loss: 0.0002612951793707907, Accuracy: 0.9417426578875165\n",
      "Iteration: 128960, Loss: 0.003096902510151267, Accuracy: 0.943366917752428\n",
      "Iteration: 129024, Loss: 0.00035085741546936333, Accuracy: 0.93537689637742\n",
      "Iteration: 129088, Loss: 0.035064589232206345, Accuracy: 0.9368773798414622\n",
      "Iteration: 129152, Loss: 0.015400850214064121, Accuracy: 0.9466855509235756\n",
      "Iteration: 129216, Loss: 0.052818577736616135, Accuracy: 0.9331216776408837\n",
      "Iteration: 129280, Loss: 0.00043433051905594766, Accuracy: 0.9326694617557223\n",
      "Iteration: 129344, Loss: 0.02281084656715393, Accuracy: 0.936316989507759\n",
      "Iteration: 129408, Loss: 0.022539647296071053, Accuracy: 0.947331429910264\n",
      "Iteration: 129472, Loss: 0.0005275714211165905, Accuracy: 0.9420923026118544\n",
      "Iteration: 129536, Loss: 0.0030461412388831377, Accuracy: 0.9339491844002623\n",
      "Iteration: 129600, Loss: 0.02776697464287281, Accuracy: 0.9395291973341955\n",
      "Iteration: 129664, Loss: 0.000427082646638155, Accuracy: 0.948648625635542\n",
      "Iteration: 129728, Loss: 0.1796562224626541, Accuracy: 0.9325752485601697\n",
      "Iteration: 129792, Loss: 0.02692536823451519, Accuracy: 0.9483936648466624\n",
      "Iteration: 129856, Loss: 0.0030194639693945646, Accuracy: 0.9376446598762413\n",
      "Iteration: 129920, Loss: 0.000326675915857777, Accuracy: 0.9454259891790571\n",
      "Iteration: 129984, Loss: 0.00875056628137827, Accuracy: 0.9258822223055176\n",
      "Iteration: 130048, Loss: 0.0012338599190115929, Accuracy: 0.9327825241271057\n",
      "Iteration: 130112, Loss: 0.2026847004890442, Accuracy: 0.920443191229424\n",
      "Iteration: 130176, Loss: 0.016757039353251457, Accuracy: 0.9263478298380505\n",
      "Iteration: 130240, Loss: 0.02357030101120472, Accuracy: 0.9131920806321432\n",
      "Iteration: 130304, Loss: 0.007067355792969465, Accuracy: 0.9378447266208241\n",
      "Iteration: 130368, Loss: 0.011269904673099518, Accuracy: 0.9380761309585068\n",
      "Iteration: 130432, Loss: 0.00026659443392418325, Accuracy: 0.9485827519383747\n",
      "Iteration: 130496, Loss: 0.002151493215933442, Accuracy: 0.9556679712841287\n",
      "Iteration: 130560, Loss: 0.0006204232340678573, Accuracy: 0.9458654683185159\n",
      "Iteration: 130624, Loss: 0.001676915562711656, Accuracy: 0.9411486314493231\n",
      "Iteration: 130688, Loss: 0.003089743433520198, Accuracy: 0.9463802020618459\n",
      "Iteration: 130752, Loss: 0.001573690795339644, Accuracy: 0.9381830869460828\n",
      "Iteration: 130816, Loss: 0.02654513716697693, Accuracy: 0.9475055055736448\n",
      "Iteration: 130880, Loss: 0.03716916963458061, Accuracy: 0.9492047693565837\n",
      "Iteration: 130944, Loss: 0.0019417502917349339, Accuracy: 0.9509934550223988\n",
      "Iteration: 131008, Loss: 0.0002445558493491262, Accuracy: 0.9474128786532674\n",
      "Iteration: 131072, Loss: 0.0024093338288366795, Accuracy: 0.9484197790152393\n",
      "Iteration: 131136, Loss: 0.3334035575389862, Accuracy: 0.9324261766741984\n",
      "Iteration: 131200, Loss: 0.0002655325224623084, Accuracy: 0.9541836708449409\n",
      "Iteration: 131264, Loss: 0.0004383837804198265, Accuracy: 0.9493389473718707\n",
      "Iteration: 131328, Loss: 0.06586746126413345, Accuracy: 0.9523928735143272\n",
      "Iteration: 131392, Loss: 0.001261592493392527, Accuracy: 0.9483667859676643\n",
      "Iteration: 131456, Loss: 0.010219770483672619, Accuracy: 0.940807521721581\n",
      "Iteration: 131520, Loss: 0.010344595648348331, Accuracy: 0.9577462688903324\n",
      "Iteration: 131584, Loss: 0.0002615656121633947, Accuracy: 0.9617039259464946\n",
      "Iteration: 131648, Loss: 0.003892217529937625, Accuracy: 0.9570553693847614\n",
      "Iteration: 131712, Loss: 0.005072110332548618, Accuracy: 0.9412274073984008\n",
      "Iteration: 131776, Loss: 0.0040872967801988125, Accuracy: 0.9550154466596723\n",
      "Iteration: 131840, Loss: 0.006486135069280863, Accuracy: 0.9537991413344571\n",
      "Iteration: 131904, Loss: 0.01549553032964468, Accuracy: 0.9615528304966574\n",
      "Iteration: 131968, Loss: 0.011140427552163601, Accuracy: 0.9573460862302454\n",
      "Iteration: 132032, Loss: 0.0001503895182395354, Accuracy: 0.9575305261314497\n",
      "Iteration: 132096, Loss: 0.0004049035196658224, Accuracy: 0.9586238994852465\n",
      "Iteration: 132160, Loss: 0.0056642796844244, Accuracy: 0.9539844321043347\n",
      "Iteration: 132224, Loss: 0.0049598198384046555, Accuracy: 0.953699301036977\n",
      "Iteration: 132288, Loss: 0.031266216188669205, Accuracy: 0.9604513435479021\n",
      "Iteration: 132352, Loss: 0.0009357454837299883, Accuracy: 0.9636022781378415\n",
      "Iteration: 132416, Loss: 0.002153151435777545, Accuracy: 0.9623790848709177\n",
      "Iteration: 132480, Loss: 0.00370283261872828, Accuracy: 0.9620110270770965\n",
      "Iteration: 132544, Loss: 0.0019286909373477101, Accuracy: 0.9561418597222655\n",
      "Iteration: 132608, Loss: 0.0018536858260631561, Accuracy: 0.9633626677605207\n",
      "Iteration: 132672, Loss: 3.7085163057781756e-05, Accuracy: 0.9560399097608752\n",
      "Iteration: 132736, Loss: 7.869170076446608e-05, Accuracy: 0.952965022472199\n",
      "Iteration: 132800, Loss: 0.008435570634901524, Accuracy: 0.9580519932387688\n",
      "Iteration: 132864, Loss: 0.00030134525150060654, Accuracy: 0.9580936318307067\n",
      "Iteration: 132928, Loss: 0.0021958129946142435, Accuracy: 0.9576525931552169\n",
      "Iteration: 132992, Loss: 0.002864333102479577, Accuracy: 0.9554484635955305\n",
      "Iteration: 133056, Loss: 0.0018220538040623069, Accuracy: 0.9652265792719845\n",
      "Iteration: 133120, Loss: 0.0867675170302391, Accuracy: 0.9504521836424829\n",
      "Iteration: 133184, Loss: 0.020910387858748436, Accuracy: 0.9494164462666959\n",
      "Iteration: 133248, Loss: 0.00454323086887598, Accuracy: 0.9637866098928498\n",
      "Iteration: 133312, Loss: 2.1775069399154745e-05, Accuracy: 0.958843735861592\n",
      "Iteration: 133376, Loss: 8.701271144673228e-05, Accuracy: 0.954274143823568\n",
      "Iteration: 133440, Loss: 0.0002301087515661493, Accuracy: 0.9579022106881894\n",
      "Iteration: 133504, Loss: 0.00046409270726144314, Accuracy: 0.9623426949474378\n",
      "Iteration: 133568, Loss: 6.455963739426807e-05, Accuracy: 0.9565455141855637\n",
      "Iteration: 133632, Loss: 0.0008175606490112841, Accuracy: 0.9589251655088447\n",
      "Iteration: 133696, Loss: 0.0012430889764800668, Accuracy: 0.9667288510172511\n",
      "Iteration: 133760, Loss: 0.0006509852246381342, Accuracy: 0.9684650445633451\n",
      "Iteration: 133824, Loss: 0.00028960584313608706, Accuracy: 0.9601765308470931\n",
      "Iteration: 133888, Loss: 0.0026823217049241066, Accuracy: 0.9518310910534638\n",
      "Iteration: 133952, Loss: 0.00021207670215517282, Accuracy: 0.9584617581713246\n",
      "Iteration: 134016, Loss: 1.8510034351493232e-05, Accuracy: 0.961003848047767\n",
      "Iteration: 134080, Loss: 0.006635868921875954, Accuracy: 0.9583866050616052\n",
      "Iteration: 134144, Loss: 0.0013052941067144275, Accuracy: 0.952847921733337\n",
      "Iteration: 134208, Loss: 0.0032032986637204885, Accuracy: 0.9625021201154595\n",
      "Iteration: 134272, Loss: 0.0005468755844049156, Accuracy: 0.9597197281582339\n",
      "Iteration: 134336, Loss: 0.00025277092936448753, Accuracy: 0.9584699985462066\n",
      "Iteration: 134400, Loss: 8.203852303267922e-06, Accuracy: 0.9419797618083976\n",
      "Iteration: 134464, Loss: 0.0004336716665420681, Accuracy: 0.9573608925875305\n",
      "Iteration: 134528, Loss: 0.00041417451575398445, Accuracy: 0.9677211988491763\n",
      "Iteration: 134592, Loss: 0.0023479450028389692, Accuracy: 0.9632691195074585\n",
      "Iteration: 134656, Loss: 0.00020598527044057846, Accuracy: 0.9677785500662139\n",
      "Iteration: 134720, Loss: 0.00015885650645941496, Accuracy: 0.9720151731708029\n",
      "Saved fullModel_dr[4]_replicate0.model\n",
      "Saved W_dr[4]_replicate0.p\n",
      "4 0.9947916666666666 [0.984375, 1.0, 1.0]\n",
      "Saved w_dr[4]_replicate0.p\n",
      "Replicate 0 completed\n",
      "Time elapsed: 560.453125 seconds\n",
      "Iteration: 64, Loss: 0.23042118549346924, Accuracy: 0.5000459053553641\n",
      "Iteration: 128, Loss: 0.22509567439556122, Accuracy: 0.49988377606496215\n",
      "Iteration: 192, Loss: 0.21753297746181488, Accuracy: 0.5013522454537451\n",
      "Iteration: 256, Loss: 0.17500238120555878, Accuracy: 0.5150933312252164\n",
      "Iteration: 320, Loss: 0.23251581192016602, Accuracy: 0.5741812903434038\n",
      "Iteration: 384, Loss: 0.18466247618198395, Accuracy: 0.6049246196635067\n",
      "Iteration: 448, Loss: 0.17530064284801483, Accuracy: 0.6194254057481885\n",
      "Iteration: 512, Loss: 0.18437032401561737, Accuracy: 0.6297818869352341\n",
      "Iteration: 576, Loss: 0.16069558262825012, Accuracy: 0.6348748845048249\n",
      "Iteration: 640, Loss: 0.1656188666820526, Accuracy: 0.6387872276827693\n",
      "Iteration: 704, Loss: 0.17793391644954681, Accuracy: 0.6416869512759149\n",
      "Iteration: 768, Loss: 0.16127750277519226, Accuracy: 0.6442828071303666\n",
      "Iteration: 832, Loss: 0.15659978985786438, Accuracy: 0.64562329929322\n",
      "Iteration: 896, Loss: 0.16429896652698517, Accuracy: 0.6479552048258483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 960, Loss: 0.18095742166042328, Accuracy: 0.648845577146858\n",
      "Iteration: 1024, Loss: 0.18009062111377716, Accuracy: 0.6497860248200595\n",
      "Iteration: 1088, Loss: 0.1616901010274887, Accuracy: 0.6505664740689099\n",
      "Iteration: 1152, Loss: 0.1645761877298355, Accuracy: 0.6516193016432226\n",
      "Iteration: 1216, Loss: 0.1755887269973755, Accuracy: 0.6523222578689456\n",
      "Iteration: 1280, Loss: 0.1750132441520691, Accuracy: 0.6529681729152799\n",
      "Iteration: 1344, Loss: 0.1586524397134781, Accuracy: 0.6531099872663617\n",
      "Iteration: 1408, Loss: 0.16471971571445465, Accuracy: 0.6548031349666417\n",
      "Iteration: 1472, Loss: 0.17298616468906403, Accuracy: 0.6547108474187553\n",
      "Iteration: 1536, Loss: 0.17475180327892303, Accuracy: 0.6554048210382462\n",
      "Iteration: 1600, Loss: 0.1743701845407486, Accuracy: 0.6556373527273536\n",
      "Iteration: 1664, Loss: 0.16486716270446777, Accuracy: 0.6558020962402225\n",
      "Iteration: 1728, Loss: 0.16196610033512115, Accuracy: 0.6568618770688772\n",
      "Iteration: 1792, Loss: 0.17256741225719452, Accuracy: 0.656905744690448\n",
      "Iteration: 1856, Loss: 0.1588587462902069, Accuracy: 0.6567219980061054\n",
      "Iteration: 1920, Loss: 0.1637357622385025, Accuracy: 0.657392228487879\n",
      "Iteration: 1984, Loss: 0.17153435945510864, Accuracy: 0.6576912109740078\n",
      "Iteration: 2048, Loss: 0.16989213228225708, Accuracy: 0.658272797241807\n",
      "Iteration: 2112, Loss: 0.1733335703611374, Accuracy: 0.6584282098338008\n",
      "Iteration: 2176, Loss: 0.16700546443462372, Accuracy: 0.6583913299255073\n",
      "Iteration: 2240, Loss: 0.1651948243379593, Accuracy: 0.6580367372371256\n",
      "Iteration: 2304, Loss: 0.16487962007522583, Accuracy: 0.6583672994747758\n",
      "Iteration: 2368, Loss: 0.1632583886384964, Accuracy: 0.6587332133203745\n",
      "Iteration: 2432, Loss: 0.17397929728031158, Accuracy: 0.6588465017266572\n",
      "Iteration: 2496, Loss: 0.17054694890975952, Accuracy: 0.6592984241433442\n",
      "Iteration: 2560, Loss: 0.16311821341514587, Accuracy: 0.6546138282865286\n",
      "Iteration: 2624, Loss: 0.17070181667804718, Accuracy: 0.6587355709634721\n",
      "Iteration: 2688, Loss: 0.1742660254240036, Accuracy: 0.6591609604656696\n",
      "Iteration: 2752, Loss: 0.16982562839984894, Accuracy: 0.6592761371284723\n",
      "Iteration: 2816, Loss: 0.16512563824653625, Accuracy: 0.6594165316782892\n",
      "Iteration: 2880, Loss: 0.16564399003982544, Accuracy: 0.6594774811528623\n",
      "Iteration: 2944, Loss: 0.16820605099201202, Accuracy: 0.6601782441139221\n",
      "Iteration: 3008, Loss: 0.1618679314851761, Accuracy: 0.660240969620645\n",
      "Iteration: 3072, Loss: 0.16201959550380707, Accuracy: 0.6604170054197311\n",
      "Iteration: 3136, Loss: 0.17134952545166016, Accuracy: 0.6603591437451541\n",
      "Iteration: 3200, Loss: 0.17276261746883392, Accuracy: 0.6605798630043864\n",
      "Iteration: 3264, Loss: 0.17439205944538116, Accuracy: 0.6604839391075075\n",
      "Iteration: 3328, Loss: 0.16903509199619293, Accuracy: 0.6613140972331166\n",
      "Iteration: 3392, Loss: 0.16566745936870575, Accuracy: 0.6610817578621209\n",
      "Iteration: 3456, Loss: 0.165207639336586, Accuracy: 0.660773266106844\n",
      "Iteration: 3520, Loss: 0.16945873200893402, Accuracy: 0.6616110992617905\n",
      "Iteration: 3584, Loss: 0.16654753684997559, Accuracy: 0.6613083365373313\n",
      "Iteration: 3648, Loss: 0.16962939500808716, Accuracy: 0.6612675092183053\n",
      "Iteration: 3712, Loss: 0.16568179428577423, Accuracy: 0.6612397790886462\n",
      "Iteration: 3776, Loss: 0.1688012033700943, Accuracy: 0.6613452103920281\n",
      "Iteration: 3840, Loss: 0.17038081586360931, Accuracy: 0.6615575104951859\n",
      "Iteration: 3904, Loss: 0.17122642695903778, Accuracy: 0.6531686601229012\n",
      "Iteration: 3968, Loss: 0.16898877918720245, Accuracy: 0.6597422300837934\n",
      "Iteration: 4032, Loss: 0.16497446596622467, Accuracy: 0.66067372309044\n",
      "Iteration: 4096, Loss: 0.16593001782894135, Accuracy: 0.6613212060183287\n",
      "Iteration: 4160, Loss: 0.1645851582288742, Accuracy: 0.6605666563846171\n",
      "Iteration: 4224, Loss: 0.16771136224269867, Accuracy: 0.6615601675584912\n",
      "Iteration: 4288, Loss: 0.172036811709404, Accuracy: 0.6617152765393257\n",
      "Iteration: 4352, Loss: 0.16795049607753754, Accuracy: 0.6622383454814553\n",
      "Iteration: 4416, Loss: 0.16608835756778717, Accuracy: 0.6618811916559935\n",
      "Iteration: 4480, Loss: 0.16723686456680298, Accuracy: 0.662390154786408\n",
      "Iteration: 4544, Loss: 0.16438671946525574, Accuracy: 0.6571346917189658\n",
      "Iteration: 4608, Loss: 0.1690257042646408, Accuracy: 0.6620619255118072\n",
      "Iteration: 4672, Loss: 0.16870196163654327, Accuracy: 0.6621662187390029\n",
      "Iteration: 4736, Loss: 0.16384391486644745, Accuracy: 0.662657224573195\n",
      "Iteration: 4800, Loss: 0.16946034133434296, Accuracy: 0.66262580268085\n",
      "Iteration: 4864, Loss: 0.16137585043907166, Accuracy: 0.662605207413435\n",
      "Iteration: 4928, Loss: 0.17267465591430664, Accuracy: 0.6626898893155158\n",
      "Iteration: 4992, Loss: 0.17097027599811554, Accuracy: 0.66305788513273\n",
      "Iteration: 5056, Loss: 0.16868603229522705, Accuracy: 0.662722023203969\n",
      "Iteration: 5120, Loss: 0.16881708800792694, Accuracy: 0.6631912747398019\n",
      "Iteration: 5184, Loss: 0.16723091900348663, Accuracy: 0.6628507170826197\n",
      "Iteration: 5248, Loss: 0.16789846122264862, Accuracy: 0.6630031131207943\n",
      "Iteration: 5312, Loss: 0.16739507019519806, Accuracy: 0.6631687749177217\n",
      "Iteration: 5376, Loss: 0.16964949667453766, Accuracy: 0.6633094577118754\n",
      "Iteration: 5440, Loss: 0.17056477069854736, Accuracy: 0.663345520850271\n",
      "Iteration: 5504, Loss: 0.16983287036418915, Accuracy: 0.6630443087778986\n",
      "Iteration: 5568, Loss: 0.16689737141132355, Accuracy: 0.6630037291906774\n",
      "Iteration: 5632, Loss: 0.16862249374389648, Accuracy: 0.6633163406513631\n",
      "Iteration: 5696, Loss: 0.16676945984363556, Accuracy: 0.6634199190884829\n",
      "Iteration: 5760, Loss: 0.16817156970500946, Accuracy: 0.6636655298061669\n",
      "Iteration: 5824, Loss: 0.16674929857254028, Accuracy: 0.6635250276885927\n",
      "Iteration: 5888, Loss: 0.1676473170518875, Accuracy: 0.6637018416076899\n",
      "Iteration: 5952, Loss: 0.16695882380008698, Accuracy: 0.6634199628606439\n",
      "Iteration: 6016, Loss: 0.17031686007976532, Accuracy: 0.6635434189811349\n",
      "Iteration: 6080, Loss: 0.16467271745204926, Accuracy: 0.6641032178886235\n",
      "Iteration: 6144, Loss: 0.16596530377864838, Accuracy: 0.6634346358478069\n",
      "Iteration: 6208, Loss: 0.16874586045742035, Accuracy: 0.6636676080524921\n",
      "Iteration: 6272, Loss: 0.16797174513339996, Accuracy: 0.663543107919395\n",
      "Iteration: 6336, Loss: 0.16997027397155762, Accuracy: 0.6638539247214794\n",
      "Iteration: 6400, Loss: 0.17116987705230713, Accuracy: 0.6637286599725485\n",
      "Iteration: 6464, Loss: 0.16993741691112518, Accuracy: 0.6637154072523117\n",
      "Iteration: 6528, Loss: 0.16778427362442017, Accuracy: 0.6639783773571253\n",
      "Iteration: 6592, Loss: 0.17151498794555664, Accuracy: 0.6639890680089593\n",
      "Iteration: 6656, Loss: 0.1709863692522049, Accuracy: 0.6642194916494191\n",
      "Iteration: 6720, Loss: 0.16813774406909943, Accuracy: 0.6640209052711725\n",
      "Iteration: 6784, Loss: 0.16792500019073486, Accuracy: 0.6641630218364298\n",
      "Iteration: 6848, Loss: 0.16521337628364563, Accuracy: 0.660616887267679\n",
      "Iteration: 6912, Loss: 0.16802167892456055, Accuracy: 0.664277701638639\n",
      "Iteration: 6976, Loss: 0.16521617770195007, Accuracy: 0.6648061643354595\n",
      "Iteration: 7040, Loss: 0.16496293246746063, Accuracy: 0.6644915081560612\n",
      "Iteration: 7104, Loss: 0.1715797334909439, Accuracy: 0.6645262679085135\n",
      "Iteration: 7168, Loss: 0.16934847831726074, Accuracy: 0.6648075822740793\n",
      "Iteration: 7232, Loss: 0.1670365333557129, Accuracy: 0.6646788902580738\n",
      "Iteration: 7296, Loss: 0.16831479966640472, Accuracy: 0.6645167586393654\n",
      "Iteration: 7360, Loss: 0.16700606048107147, Accuracy: 0.6647891192696989\n",
      "Iteration: 7424, Loss: 0.16332349181175232, Accuracy: 0.6645575882866979\n",
      "Iteration: 7488, Loss: 0.16295702755451202, Accuracy: 0.6645700838416815\n",
      "Iteration: 7552, Loss: 0.16960079967975616, Accuracy: 0.6646937439218163\n",
      "Iteration: 7616, Loss: 0.16529622673988342, Accuracy: 0.6627812385559082\n",
      "Iteration: 7680, Loss: 0.16728763282299042, Accuracy: 0.6598508963361382\n",
      "Iteration: 7744, Loss: 0.16318286955356598, Accuracy: 0.663543454837054\n",
      "Iteration: 7808, Loss: 0.1589847356081009, Accuracy: 0.6650071409530938\n",
      "Iteration: 7872, Loss: 0.1733742356300354, Accuracy: 0.6641514454968274\n",
      "Iteration: 7936, Loss: 0.1662548929452896, Accuracy: 0.6650708680972457\n",
      "Iteration: 8000, Loss: 0.1616387516260147, Accuracy: 0.663277531042695\n",
      "Iteration: 8064, Loss: 0.16570496559143066, Accuracy: 0.6658722464926541\n",
      "Iteration: 8128, Loss: 0.15342365205287933, Accuracy: 0.6670712428167462\n",
      "Iteration: 8192, Loss: 0.14485789835453033, Accuracy: 0.6670500310137868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 8256, Loss: 0.16512969136238098, Accuracy: 0.6693754438310862\n",
      "Iteration: 8320, Loss: 0.1605900079011917, Accuracy: 0.669617023319006\n",
      "Iteration: 8384, Loss: 0.120186448097229, Accuracy: 0.6670843847095966\n",
      "Iteration: 8448, Loss: 0.13048924505710602, Accuracy: 0.671521277166903\n",
      "Iteration: 8512, Loss: 0.1599688082933426, Accuracy: 0.6730616297572851\n",
      "Iteration: 8576, Loss: 0.1151786670088768, Accuracy: 0.6751946792937815\n",
      "Iteration: 8640, Loss: 0.11496780067682266, Accuracy: 0.68015265930444\n",
      "Iteration: 8704, Loss: 0.10278788954019547, Accuracy: 0.6812665343750268\n",
      "Iteration: 8768, Loss: 0.1572832316160202, Accuracy: 0.6899388339370489\n",
      "Iteration: 8832, Loss: 0.14585621654987335, Accuracy: 0.6903286827728152\n",
      "Iteration: 8896, Loss: 0.14612840116024017, Accuracy: 0.6927995271980762\n",
      "Iteration: 8960, Loss: 0.14288942515850067, Accuracy: 0.6980143412947655\n",
      "Iteration: 9024, Loss: 0.06718867272138596, Accuracy: 0.704825033666566\n",
      "Iteration: 9088, Loss: 0.18284006416797638, Accuracy: 0.7048718989826739\n",
      "Iteration: 9152, Loss: 0.15330730378627777, Accuracy: 0.7201155964285135\n",
      "Iteration: 9216, Loss: 0.1385270655155182, Accuracy: 0.7181966514326632\n",
      "Iteration: 9280, Loss: 0.08585628867149353, Accuracy: 0.7234304153826088\n",
      "Iteration: 9344, Loss: 0.06260951608419418, Accuracy: 0.7292706149164587\n",
      "Iteration: 9408, Loss: 0.12779469788074493, Accuracy: 0.7420091445092112\n",
      "Iteration: 9472, Loss: 0.062352586537599564, Accuracy: 0.7494332045316696\n",
      "Iteration: 9536, Loss: 0.12990790605545044, Accuracy: 0.7475727947894484\n",
      "Iteration: 9600, Loss: 0.1364498883485794, Accuracy: 0.7577383841853589\n",
      "Iteration: 9664, Loss: 0.048608601093292236, Accuracy: 0.7580301980488002\n",
      "Iteration: 9728, Loss: 0.13097985088825226, Accuracy: 0.7735479411203414\n",
      "Iteration: 9792, Loss: 0.12343982607126236, Accuracy: 0.764589928323403\n",
      "Iteration: 9856, Loss: 0.10890159755945206, Accuracy: 0.7769318607170135\n",
      "Iteration: 9920, Loss: 0.09347611665725708, Accuracy: 0.7742072625551373\n",
      "Iteration: 9984, Loss: 0.0702991634607315, Accuracy: 0.7792305829934776\n",
      "Iteration: 10048, Loss: 0.05305054783821106, Accuracy: 0.7698368998244405\n",
      "Iteration: 10112, Loss: 0.1421099156141281, Accuracy: 0.7751722170505673\n",
      "Iteration: 10176, Loss: 0.0566696859896183, Accuracy: 0.7893607751466334\n",
      "Iteration: 10240, Loss: 0.11781585961580276, Accuracy: 0.7851851612795144\n",
      "Iteration: 10304, Loss: 0.09936773777008057, Accuracy: 0.7895380002446473\n",
      "Iteration: 10368, Loss: 0.09552743285894394, Accuracy: 0.7799804294481874\n",
      "Iteration: 10432, Loss: 0.10295573621988297, Accuracy: 0.7873538138810545\n",
      "Iteration: 10496, Loss: 0.05766673386096954, Accuracy: 0.7828749208711088\n",
      "Iteration: 10560, Loss: 0.06721898168325424, Accuracy: 0.7884649257175624\n",
      "Iteration: 10624, Loss: 0.10769566148519516, Accuracy: 0.7971184360794723\n",
      "Iteration: 10688, Loss: 0.09507010132074356, Accuracy: 0.7901884410530329\n",
      "Iteration: 10752, Loss: 0.11039867252111435, Accuracy: 0.7979827576782554\n",
      "Iteration: 10816, Loss: 0.061210379004478455, Accuracy: 0.7894342648796737\n",
      "Iteration: 10880, Loss: 0.1128164753317833, Accuracy: 0.7966258265078068\n",
      "Iteration: 10944, Loss: 0.09358074516057968, Accuracy: 0.8022500057704747\n",
      "Iteration: 11008, Loss: 0.06121392920613289, Accuracy: 0.7999973630066961\n",
      "Iteration: 11072, Loss: 0.1009400263428688, Accuracy: 0.7955776136368513\n",
      "Iteration: 11136, Loss: 0.09704581648111343, Accuracy: 0.7992556379176676\n",
      "Iteration: 11200, Loss: 0.1146068349480629, Accuracy: 0.8057978341821581\n",
      "Iteration: 11264, Loss: 0.10019791126251221, Accuracy: 0.8059584987349808\n",
      "Iteration: 11328, Loss: 0.07220540195703506, Accuracy: 0.8061945845838636\n",
      "Iteration: 11392, Loss: 0.09221088886260986, Accuracy: 0.8089792281389236\n",
      "Iteration: 11456, Loss: 0.08001533895730972, Accuracy: 0.8080019252374768\n",
      "Iteration: 11520, Loss: 0.08263222128152847, Accuracy: 0.7996181503403932\n",
      "Iteration: 11584, Loss: 0.09271687269210815, Accuracy: 0.8088976724538952\n",
      "Iteration: 11648, Loss: 0.06180986762046814, Accuracy: 0.8007981639821082\n",
      "Iteration: 11712, Loss: 0.0987466350197792, Accuracy: 0.7986052187625319\n",
      "Iteration: 11776, Loss: 0.07404191046953201, Accuracy: 0.8107288146857172\n",
      "Iteration: 11840, Loss: 0.08732529729604721, Accuracy: 0.8030739342793822\n",
      "Iteration: 11904, Loss: 0.08622777462005615, Accuracy: 0.8096148807089776\n",
      "Iteration: 11968, Loss: 0.06811635941267014, Accuracy: 0.8083656635135412\n",
      "Iteration: 12032, Loss: 0.07705821841955185, Accuracy: 0.8099147393368185\n",
      "Iteration: 12096, Loss: 0.089701808989048, Accuracy: 0.8153434782288969\n",
      "Iteration: 12160, Loss: 0.09197789430618286, Accuracy: 0.8034504726529121\n",
      "Iteration: 12224, Loss: 0.09020379185676575, Accuracy: 0.7961674679536372\n",
      "Iteration: 12288, Loss: 0.1044730618596077, Accuracy: 0.8086635642684996\n",
      "Iteration: 12352, Loss: 0.06813967227935791, Accuracy: 0.8148989386390895\n",
      "Iteration: 12416, Loss: 0.07123409956693649, Accuracy: 0.8171307854354382\n",
      "Iteration: 12480, Loss: 0.11070812493562698, Accuracy: 0.8083117003552616\n",
      "Iteration: 12544, Loss: 0.10876741260290146, Accuracy: 0.8161168079823256\n",
      "Iteration: 12608, Loss: 0.09918280690908432, Accuracy: 0.8161601037718356\n",
      "Iteration: 12672, Loss: 0.06920456141233444, Accuracy: 0.8134442635346204\n",
      "Iteration: 12736, Loss: 0.10392101854085922, Accuracy: 0.813753052148968\n",
      "Iteration: 12800, Loss: 0.09911543130874634, Accuracy: 0.8044009143486619\n",
      "Iteration: 12864, Loss: 0.10083889961242676, Accuracy: 0.810084969503805\n",
      "Iteration: 12928, Loss: 0.20098258554935455, Accuracy: 0.8027801932767034\n",
      "Iteration: 12992, Loss: 0.09209436178207397, Accuracy: 0.8194614418316633\n",
      "Iteration: 13056, Loss: 0.08179563283920288, Accuracy: 0.8147668514866382\n",
      "Iteration: 13120, Loss: 0.08005929738283157, Accuracy: 0.8161857428494841\n",
      "Iteration: 13184, Loss: 0.11640322953462601, Accuracy: 0.8176317596808076\n",
      "Iteration: 13248, Loss: 0.0729566439986229, Accuracy: 0.8187974609900266\n",
      "Iteration: 13312, Loss: 0.07325810939073563, Accuracy: 0.8215662557631731\n",
      "Iteration: 13376, Loss: 0.08940892666578293, Accuracy: 0.8140726375859231\n",
      "Iteration: 13440, Loss: 0.07175292819738388, Accuracy: 0.8148079088423401\n",
      "Iteration: 13504, Loss: 0.08860338479280472, Accuracy: 0.8194057180080563\n",
      "Iteration: 13568, Loss: 0.08823773264884949, Accuracy: 0.8234399606008083\n",
      "Iteration: 13632, Loss: 0.09769795089960098, Accuracy: 0.8245176163036376\n",
      "Iteration: 13696, Loss: 0.07219503074884415, Accuracy: 0.8201206850353628\n",
      "Iteration: 13760, Loss: 0.06475746631622314, Accuracy: 0.8161171930842102\n",
      "Iteration: 13824, Loss: 0.05965994670987129, Accuracy: 0.8253136596176773\n",
      "Iteration: 13888, Loss: 0.08286844938993454, Accuracy: 0.8219579558353871\n",
      "Iteration: 13952, Loss: 0.0716848373413086, Accuracy: 0.821936764754355\n",
      "Iteration: 14016, Loss: 0.08434277772903442, Accuracy: 0.8148516025394201\n",
      "Iteration: 14080, Loss: 0.0708112120628357, Accuracy: 0.8125100068282336\n",
      "Iteration: 14144, Loss: 0.10175330191850662, Accuracy: 0.8221427742391825\n",
      "Iteration: 14208, Loss: 0.06521565467119217, Accuracy: 0.8214727381709963\n",
      "Iteration: 14272, Loss: 0.11306777596473694, Accuracy: 0.8212499532382935\n",
      "Iteration: 14336, Loss: 0.06320309638977051, Accuracy: 0.8019364944193512\n",
      "Iteration: 14400, Loss: 0.0959106907248497, Accuracy: 0.8240982268471271\n",
      "Iteration: 14464, Loss: 0.07655464857816696, Accuracy: 0.8234639486763626\n",
      "Iteration: 14528, Loss: 0.07210621982812881, Accuracy: 0.8164272317662835\n",
      "Iteration: 14592, Loss: 0.09212366491556168, Accuracy: 0.8257987098768353\n",
      "Iteration: 14656, Loss: 0.06817948073148727, Accuracy: 0.8267139985691756\n",
      "Iteration: 14720, Loss: 0.06416638940572739, Accuracy: 0.8214817685075104\n",
      "Iteration: 14784, Loss: 0.062104810029268265, Accuracy: 0.8265525444876403\n",
      "Iteration: 14848, Loss: 0.07129847258329391, Accuracy: 0.8238670809660107\n",
      "Iteration: 14912, Loss: 0.06052793934941292, Accuracy: 0.8253673915751278\n",
      "Iteration: 14976, Loss: 0.06802615523338318, Accuracy: 0.8273965681437403\n",
      "Iteration: 15040, Loss: 0.04490832984447479, Accuracy: 0.8272676663473248\n",
      "Iteration: 15104, Loss: 0.08618970960378647, Accuracy: 0.8316887903492898\n",
      "Iteration: 15168, Loss: 0.050403475761413574, Accuracy: 0.8198886795435101\n",
      "Iteration: 15232, Loss: 0.08132973313331604, Accuracy: 0.8297155578620732\n",
      "Iteration: 15296, Loss: 0.07027705758810043, Accuracy: 0.8301667380146682\n",
      "Iteration: 15360, Loss: 0.11947844177484512, Accuracy: 0.8326533802319318\n",
      "Iteration: 15424, Loss: 0.10679414123296738, Accuracy: 0.8271052804775536\n",
      "Iteration: 15488, Loss: 0.062369998544454575, Accuracy: 0.8233633413910866\n",
      "Iteration: 15552, Loss: 0.07687925547361374, Accuracy: 0.8268141020089388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 15616, Loss: 0.09320628643035889, Accuracy: 0.8327080954331905\n",
      "Iteration: 15680, Loss: 0.12758831679821014, Accuracy: 0.82782446523197\n",
      "Iteration: 15744, Loss: 0.11531376838684082, Accuracy: 0.8325654896907508\n",
      "Iteration: 15808, Loss: 0.05548246577382088, Accuracy: 0.8330068071372807\n",
      "Iteration: 15872, Loss: 0.03656351938843727, Accuracy: 0.8357775285840034\n",
      "Iteration: 15936, Loss: 0.059782952070236206, Accuracy: 0.8355265120044351\n",
      "Iteration: 16000, Loss: 0.058079302310943604, Accuracy: 0.829950810293667\n",
      "Iteration: 16064, Loss: 0.09357321262359619, Accuracy: 0.8312745140865445\n",
      "Iteration: 16128, Loss: 0.07202553749084473, Accuracy: 0.8256182824261487\n",
      "Iteration: 16192, Loss: 0.046109169721603394, Accuracy: 0.8282016400480643\n",
      "Iteration: 16256, Loss: 0.0558534599840641, Accuracy: 0.8335034104529768\n",
      "Iteration: 16320, Loss: 0.055589597672224045, Accuracy: 0.8391562241595238\n",
      "Iteration: 16384, Loss: 0.06953946501016617, Accuracy: 0.8366766276303679\n",
      "Iteration: 16448, Loss: 0.06226060166954994, Accuracy: 0.8427197788842022\n",
      "Iteration: 16512, Loss: 0.07177875190973282, Accuracy: 0.8444837359711528\n",
      "Iteration: 16576, Loss: 0.09990812093019485, Accuracy: 0.8407381048891693\n",
      "Iteration: 16640, Loss: 0.04467548429965973, Accuracy: 0.8377673667855561\n",
      "Iteration: 16704, Loss: 0.10458274930715561, Accuracy: 0.8389730376657099\n",
      "Iteration: 16768, Loss: 0.04275847598910332, Accuracy: 0.831176234758459\n",
      "Iteration: 16832, Loss: 0.03248592093586922, Accuracy: 0.8365537730278447\n",
      "Iteration: 16896, Loss: 0.056060731410980225, Accuracy: 0.8405175770167261\n",
      "Iteration: 16960, Loss: 0.03169945254921913, Accuracy: 0.840632839477621\n",
      "Iteration: 17024, Loss: 0.03674893453717232, Accuracy: 0.8469918899936602\n",
      "Iteration: 17088, Loss: 0.11846055835485458, Accuracy: 0.8431541802128777\n",
      "Iteration: 17152, Loss: 0.1014227494597435, Accuracy: 0.8467834137845784\n",
      "Iteration: 17216, Loss: 0.0450393445789814, Accuracy: 0.8398872036486864\n",
      "Iteration: 17280, Loss: 0.09665435552597046, Accuracy: 0.8435640255920589\n",
      "Iteration: 17344, Loss: 0.039412032812833786, Accuracy: 0.8361242113169283\n",
      "Iteration: 17408, Loss: 0.10132688283920288, Accuracy: 0.8296816219808534\n",
      "Iteration: 17472, Loss: 0.09180948883295059, Accuracy: 0.8476304402574897\n",
      "Iteration: 17536, Loss: 0.09320995956659317, Accuracy: 0.8410595590248704\n",
      "Iteration: 17600, Loss: 0.08171204477548599, Accuracy: 0.846786504262127\n",
      "Iteration: 17664, Loss: 0.06679737567901611, Accuracy: 0.8464709428371862\n",
      "Iteration: 17728, Loss: 0.06801753491163254, Accuracy: 0.8405283745378256\n",
      "Iteration: 17792, Loss: 0.15331988036632538, Accuracy: 0.8315501864999533\n",
      "Iteration: 17856, Loss: 0.02398522198200226, Accuracy: 0.8245751643553376\n",
      "Iteration: 17920, Loss: 0.1088218092918396, Accuracy: 0.8497058919165283\n",
      "Iteration: 17984, Loss: 0.04603269696235657, Accuracy: 0.8429115792969242\n",
      "Iteration: 18048, Loss: 0.023751050233840942, Accuracy: 0.8507002388359979\n",
      "Iteration: 18112, Loss: 0.023757224902510643, Accuracy: 0.8536215733038262\n",
      "Iteration: 18176, Loss: 0.044440582394599915, Accuracy: 0.8532952758250758\n",
      "Iteration: 18240, Loss: 0.04106824845075607, Accuracy: 0.8487835270352662\n",
      "Iteration: 18304, Loss: 0.0792173370718956, Accuracy: 0.8476942358538508\n",
      "Iteration: 18368, Loss: 0.046273041516542435, Accuracy: 0.8577829478308558\n",
      "Iteration: 18432, Loss: 0.06522519886493683, Accuracy: 0.8606694574700668\n",
      "Iteration: 18496, Loss: 0.08273787051439285, Accuracy: 0.8371749497018754\n",
      "Iteration: 18560, Loss: 0.05350427329540253, Accuracy: 0.8636325433617458\n",
      "Iteration: 18624, Loss: 0.05038406327366829, Accuracy: 0.8552404857473448\n",
      "Iteration: 18688, Loss: 0.056877464056015015, Accuracy: 0.8509623830905184\n",
      "Iteration: 18752, Loss: 0.038364458829164505, Accuracy: 0.8603132143616676\n",
      "Iteration: 18816, Loss: 0.01505154836922884, Accuracy: 0.8586105637950823\n",
      "Iteration: 18880, Loss: 0.04838947579264641, Accuracy: 0.8559705810621381\n",
      "Iteration: 18944, Loss: 0.032261814922094345, Accuracy: 0.8620514711365104\n",
      "Iteration: 19008, Loss: 0.021647363901138306, Accuracy: 0.8510644780471921\n",
      "Iteration: 19072, Loss: 0.030304482206702232, Accuracy: 0.844507624511607\n",
      "Iteration: 19136, Loss: 0.01645650714635849, Accuracy: 0.8609495871933177\n",
      "Iteration: 19200, Loss: 0.06257066875696182, Accuracy: 0.8480591385159642\n",
      "Iteration: 19264, Loss: 0.08268532902002335, Accuracy: 0.8646183974342421\n",
      "Iteration: 19328, Loss: 0.03127383068203926, Accuracy: 0.8623196417465806\n",
      "Iteration: 19392, Loss: 0.10277018696069717, Accuracy: 0.8549733215477318\n",
      "Iteration: 19456, Loss: 0.014153905212879181, Accuracy: 0.8674133197637275\n",
      "Iteration: 19520, Loss: 0.06729617714881897, Accuracy: 0.8671130208531395\n",
      "Iteration: 19584, Loss: 0.10527916997671127, Accuracy: 0.8645582707831636\n",
      "Iteration: 19648, Loss: 0.023589149117469788, Accuracy: 0.8704920700984076\n",
      "Iteration: 19712, Loss: 0.10038522630929947, Accuracy: 0.8630551405949518\n",
      "Iteration: 19776, Loss: 0.029360949993133545, Accuracy: 0.8730320479953662\n",
      "Iteration: 19840, Loss: 0.0298016220331192, Accuracy: 0.8693072183523327\n",
      "Iteration: 19904, Loss: 0.03327411785721779, Accuracy: 0.8655550022376701\n",
      "Iteration: 19968, Loss: 0.053364139050245285, Accuracy: 0.8596015514340252\n",
      "Iteration: 20032, Loss: 0.029527748003602028, Accuracy: 0.8632113158237189\n",
      "Iteration: 20096, Loss: 0.012282651849091053, Accuracy: 0.8658916422864422\n",
      "Iteration: 20160, Loss: 0.041928019374608994, Accuracy: 0.8559885700233281\n",
      "Iteration: 20224, Loss: 0.06329312175512314, Accuracy: 0.8706233876291662\n",
      "Iteration: 20288, Loss: 0.02873704768717289, Accuracy: 0.8510437714867294\n",
      "Iteration: 20352, Loss: 0.02836480177938938, Accuracy: 0.8656320063164458\n",
      "Iteration: 20416, Loss: 0.07348708808422089, Accuracy: 0.870922147994861\n",
      "Iteration: 20480, Loss: 0.02276797406375408, Accuracy: 0.8686637458158657\n",
      "Iteration: 20544, Loss: 0.011659790761768818, Accuracy: 0.8792880771216005\n",
      "Iteration: 20608, Loss: 0.019869845360517502, Accuracy: 0.8688832381740212\n",
      "Iteration: 20672, Loss: 0.09857986122369766, Accuracy: 0.8639942802255973\n",
      "Iteration: 20736, Loss: 0.06331390887498856, Accuracy: 0.8629078271915205\n",
      "Iteration: 20800, Loss: 0.056149810552597046, Accuracy: 0.8676579479360953\n",
      "Iteration: 20864, Loss: 0.014433067291975021, Accuracy: 0.8667139533208683\n",
      "Iteration: 20928, Loss: 0.048082590103149414, Accuracy: 0.8784949854016304\n",
      "Iteration: 20992, Loss: 0.022505195811390877, Accuracy: 0.8791707787895575\n",
      "Iteration: 21056, Loss: 0.021765822544693947, Accuracy: 0.8695325883454643\n",
      "Iteration: 21120, Loss: 0.007989971898496151, Accuracy: 0.8627800528192893\n",
      "Iteration: 21184, Loss: 0.01943538524210453, Accuracy: 0.8838860901305452\n",
      "Iteration: 21248, Loss: 0.03366418555378914, Accuracy: 0.8769377025892027\n",
      "Iteration: 21312, Loss: 0.03113284893333912, Accuracy: 0.8800147373694927\n",
      "Iteration: 21376, Loss: 0.08560899645090103, Accuracy: 0.8796444867621176\n",
      "Iteration: 21440, Loss: 0.006756506860256195, Accuracy: 0.8762923707836308\n",
      "Iteration: 21504, Loss: 0.02294888161122799, Accuracy: 0.8800589790334925\n",
      "Iteration: 21568, Loss: 0.11426317691802979, Accuracy: 0.877897152735386\n",
      "Iteration: 21632, Loss: 0.03840081766247749, Accuracy: 0.86558516981313\n",
      "Iteration: 21696, Loss: 0.01808759942650795, Accuracy: 0.8791706144693308\n",
      "Iteration: 21760, Loss: 0.01174047589302063, Accuracy: 0.890240486478433\n",
      "Iteration: 21824, Loss: 0.007475011050701141, Accuracy: 0.8899476654478349\n",
      "Iteration: 21888, Loss: 0.02716459333896637, Accuracy: 0.8936373194446787\n",
      "Iteration: 21952, Loss: 0.09727919101715088, Accuracy: 0.8913606472196989\n",
      "Iteration: 22016, Loss: 0.04362334683537483, Accuracy: 0.88933561288286\n",
      "Iteration: 22080, Loss: 0.08079001307487488, Accuracy: 0.8746295135933906\n",
      "Iteration: 22144, Loss: 0.05340023338794708, Accuracy: 0.8853160231956281\n",
      "Iteration: 22208, Loss: 0.044039491564035416, Accuracy: 0.8832781874225475\n",
      "Iteration: 22272, Loss: 0.03202170506119728, Accuracy: 0.8845646894187666\n",
      "Iteration: 22336, Loss: 0.00637740409001708, Accuracy: 0.8854400949203409\n",
      "Iteration: 22400, Loss: 0.018901770934462547, Accuracy: 0.89541118737543\n",
      "Iteration: 22464, Loss: 0.015487712807953358, Accuracy: 0.8958973904955201\n",
      "Iteration: 22528, Loss: 0.005516398698091507, Accuracy: 0.8903388390899636\n",
      "Iteration: 22592, Loss: 0.03268902376294136, Accuracy: 0.8902833998436108\n",
      "Iteration: 22656, Loss: 0.005401726812124252, Accuracy: 0.8921476306859404\n",
      "Iteration: 22720, Loss: 0.06627678871154785, Accuracy: 0.8927093169768341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 22784, Loss: 0.008788956329226494, Accuracy: 0.883235132379923\n",
      "Iteration: 22848, Loss: 0.04114535078406334, Accuracy: 0.8952701151720248\n",
      "Iteration: 22912, Loss: 0.0671960636973381, Accuracy: 0.8869372871122323\n",
      "Iteration: 22976, Loss: 0.023678293451666832, Accuracy: 0.879491702769883\n",
      "Iteration: 23040, Loss: 0.04466228559613228, Accuracy: 0.8941040311474353\n",
      "Iteration: 23104, Loss: 0.05670971795916557, Accuracy: 0.8946921457536519\n",
      "Iteration: 23168, Loss: 0.034312617033720016, Accuracy: 0.8967202345957048\n",
      "Iteration: 23232, Loss: 0.031250324100255966, Accuracy: 0.879090312984772\n",
      "Iteration: 23296, Loss: 0.06264781206846237, Accuracy: 0.9028836182551458\n",
      "Iteration: 23360, Loss: 0.024107592180371284, Accuracy: 0.8964695539325476\n",
      "Iteration: 23424, Loss: 0.014794106595218182, Accuracy: 0.9147566764149815\n",
      "Iteration: 23488, Loss: 0.004070532042533159, Accuracy: 0.8954726979718544\n",
      "Iteration: 23552, Loss: 0.012449443340301514, Accuracy: 0.9016246676328592\n",
      "Iteration: 23616, Loss: 0.016702264547348022, Accuracy: 0.8927018932881765\n",
      "Iteration: 23680, Loss: 0.0967315211892128, Accuracy: 0.8927122337045148\n",
      "Iteration: 23744, Loss: 0.014227175153791904, Accuracy: 0.9100455323932692\n",
      "Iteration: 23808, Loss: 0.0251753106713295, Accuracy: 0.9092516559176147\n",
      "Iteration: 23872, Loss: 0.005701020359992981, Accuracy: 0.8995644049136899\n",
      "Iteration: 23936, Loss: 0.004037349950522184, Accuracy: 0.9021811689599417\n",
      "Iteration: 24000, Loss: 0.015645338222384453, Accuracy: 0.9089603640022688\n",
      "Iteration: 24064, Loss: 0.012321953661739826, Accuracy: 0.9012974051875062\n",
      "Iteration: 24128, Loss: 0.053281206637620926, Accuracy: 0.9095045355497859\n",
      "Iteration: 24192, Loss: 0.0028401128947734833, Accuracy: 0.9047849329654127\n",
      "Iteration: 24256, Loss: 0.018190741539001465, Accuracy: 0.9058435840997845\n",
      "Iteration: 24320, Loss: 0.0027355358470231295, Accuracy: 0.9095522571587935\n",
      "Iteration: 24384, Loss: 0.02299860119819641, Accuracy: 0.9134815444122069\n",
      "Iteration: 24448, Loss: 0.017845533788204193, Accuracy: 0.8955866814940237\n",
      "Iteration: 24512, Loss: 0.0120031563565135, Accuracy: 0.9116145910229534\n",
      "Iteration: 24576, Loss: 0.002790323691442609, Accuracy: 0.9091868798714131\n",
      "Iteration: 24640, Loss: 0.02867349050939083, Accuracy: 0.9158298336551525\n",
      "Iteration: 24704, Loss: 0.00780646363273263, Accuracy: 0.9107965208240785\n",
      "Iteration: 24768, Loss: 0.07841500639915466, Accuracy: 0.8931399813154712\n",
      "Iteration: 24832, Loss: 0.045148417353630066, Accuracy: 0.9043668226804584\n",
      "Iteration: 24896, Loss: 0.012765067629516125, Accuracy: 0.9161455083522014\n",
      "Iteration: 24960, Loss: 0.006678932812064886, Accuracy: 0.9147839586366899\n",
      "Iteration: 25024, Loss: 0.006046396214514971, Accuracy: 0.9144425104605034\n",
      "Iteration: 25088, Loss: 0.009611982852220535, Accuracy: 0.9089788424316794\n",
      "Iteration: 25152, Loss: 0.0026188052725046873, Accuracy: 0.9142954331473447\n",
      "Iteration: 25216, Loss: 0.0021492999512702227, Accuracy: 0.9236898577364627\n",
      "Iteration: 25280, Loss: 0.039921391755342484, Accuracy: 0.9248586930625606\n",
      "Iteration: 25344, Loss: 0.0018984200432896614, Accuracy: 0.9141706599621102\n",
      "Iteration: 25408, Loss: 0.012286558747291565, Accuracy: 0.9164544368977658\n",
      "Iteration: 25472, Loss: 0.012064403854310513, Accuracy: 0.9275053436576854\n",
      "Iteration: 25536, Loss: 0.10599682480096817, Accuracy: 0.9186928725684993\n",
      "Iteration: 25600, Loss: 0.0023381251376122236, Accuracy: 0.9176118459145073\n",
      "Iteration: 25664, Loss: 0.002208080142736435, Accuracy: 0.9279063633293845\n",
      "Iteration: 25728, Loss: 0.0018040044233202934, Accuracy: 0.913155922666192\n",
      "Iteration: 25792, Loss: 0.026913518086075783, Accuracy: 0.9225716659566388\n",
      "Iteration: 25856, Loss: 0.16783659160137177, Accuracy: 0.9149236453231424\n",
      "Iteration: 25920, Loss: 0.009016212075948715, Accuracy: 0.9061034272017423\n",
      "Iteration: 25984, Loss: 0.039961863309144974, Accuracy: 0.9160064509196673\n",
      "Iteration: 26048, Loss: 0.01192706823348999, Accuracy: 0.9217654978274368\n",
      "Iteration: 26112, Loss: 0.0030699344351887703, Accuracy: 0.9195592750911601\n",
      "Iteration: 26176, Loss: 0.026494896039366722, Accuracy: 0.9373244706366677\n",
      "Iteration: 26240, Loss: 0.12554530799388885, Accuracy: 0.9293215915095061\n",
      "Iteration: 26304, Loss: 0.009454965591430664, Accuracy: 0.9166922043950763\n",
      "Iteration: 26368, Loss: 0.010946360416710377, Accuracy: 0.9238059011986479\n",
      "Iteration: 26432, Loss: 0.0019034092547371984, Accuracy: 0.9287039692280814\n",
      "Iteration: 26496, Loss: 0.0016043055802583694, Accuracy: 0.9335767843876965\n",
      "Iteration: 26560, Loss: 0.008580637164413929, Accuracy: 0.9082509415748063\n",
      "Iteration: 26624, Loss: 0.009444431401789188, Accuracy: 0.9204640575044323\n",
      "Iteration: 26688, Loss: 0.009593538008630276, Accuracy: 0.9298364139685873\n",
      "Iteration: 26752, Loss: 0.0015720281517133117, Accuracy: 0.9284796734282281\n",
      "Iteration: 26816, Loss: 0.008208781480789185, Accuracy: 0.9362900919804815\n",
      "Iteration: 26880, Loss: 0.00420484459027648, Accuracy: 0.936413999996148\n",
      "Iteration: 26944, Loss: 0.0017458131769672036, Accuracy: 0.9283601727802306\n",
      "Iteration: 27008, Loss: 0.030978068709373474, Accuracy: 0.9302660801040474\n",
      "Iteration: 27072, Loss: 0.003918410744518042, Accuracy: 0.9389470476307906\n",
      "Iteration: 27136, Loss: 0.008448467589914799, Accuracy: 0.9397389894584194\n",
      "Iteration: 27200, Loss: 0.1132848858833313, Accuracy: 0.9233612475218251\n",
      "Iteration: 27264, Loss: 0.009826327674090862, Accuracy: 0.9389530117623508\n",
      "Iteration: 27328, Loss: 0.011324062943458557, Accuracy: 0.9367644627054688\n",
      "Iteration: 27392, Loss: 0.010661501437425613, Accuracy: 0.9328920575790107\n",
      "Iteration: 27456, Loss: 0.011185671202838421, Accuracy: 0.9389833268942311\n",
      "Iteration: 27520, Loss: 0.014051730744540691, Accuracy: 0.9351809492800385\n",
      "Iteration: 27584, Loss: 0.0016349563375115395, Accuracy: 0.9401531492476352\n",
      "Iteration: 27648, Loss: 0.001621068804524839, Accuracy: 0.9379989592707716\n",
      "Iteration: 27712, Loss: 0.00321371597237885, Accuracy: 0.939086382772075\n",
      "Iteration: 27776, Loss: 0.0066413902677595615, Accuracy: 0.9482314457709435\n",
      "Iteration: 27840, Loss: 0.008479267358779907, Accuracy: 0.942788714542985\n",
      "Iteration: 27904, Loss: 0.008531351573765278, Accuracy: 0.9438990638591349\n",
      "Iteration: 27968, Loss: 0.0031644583214074373, Accuracy: 0.9373787295189686\n",
      "Iteration: 28032, Loss: 0.008019691333174706, Accuracy: 0.9312760483589955\n",
      "Iteration: 28096, Loss: 0.011896493844687939, Accuracy: 0.9324912457959726\n",
      "Iteration: 28160, Loss: 0.005749220494180918, Accuracy: 0.9495810156222433\n",
      "Iteration: 28224, Loss: 0.004457331728190184, Accuracy: 0.9420957179681864\n",
      "Iteration: 28288, Loss: 0.0032319892197847366, Accuracy: 0.9270363029791042\n",
      "Iteration: 28352, Loss: 0.046025652438402176, Accuracy: 0.914605019701412\n",
      "Iteration: 28416, Loss: 0.0025954267475754023, Accuracy: 0.9475255737779662\n",
      "Iteration: 28480, Loss: 0.10803528875112534, Accuracy: 0.9457450865593273\n",
      "Iteration: 28544, Loss: 0.004309359472244978, Accuracy: 0.946055942971725\n",
      "Iteration: 28608, Loss: 0.002600600942969322, Accuracy: 0.9477741854498163\n",
      "Iteration: 28672, Loss: 0.009153362363576889, Accuracy: 0.9501745188899804\n",
      "Iteration: 28736, Loss: 0.011021683923900127, Accuracy: 0.9386355902825017\n",
      "Iteration: 28800, Loss: 0.02902984619140625, Accuracy: 0.9247173948970158\n",
      "Iteration: 28864, Loss: 0.001222116407006979, Accuracy: 0.9496472990431357\n",
      "Iteration: 28928, Loss: 0.0006837888504378498, Accuracy: 0.9487999539414886\n",
      "Iteration: 28992, Loss: 0.0073054078966379166, Accuracy: 0.9351959279738367\n",
      "Iteration: 29056, Loss: 0.009833169169723988, Accuracy: 0.9513113386637997\n",
      "Iteration: 29120, Loss: 0.006593453232198954, Accuracy: 0.9479313628107775\n",
      "Iteration: 29184, Loss: 0.0017144543817266822, Accuracy: 0.9565647375420667\n",
      "Iteration: 29248, Loss: 0.013602078892290592, Accuracy: 0.9428810515382793\n",
      "Iteration: 29312, Loss: 0.006265981588512659, Accuracy: 0.9506827726727352\n",
      "Iteration: 29376, Loss: 0.004278989974409342, Accuracy: 0.9491699505888391\n",
      "Iteration: 29440, Loss: 0.0053018927574157715, Accuracy: 0.9519007557537407\n",
      "Iteration: 29504, Loss: 0.006103312596678734, Accuracy: 0.9440885233052541\n",
      "Iteration: 29568, Loss: 0.0008143547456711531, Accuracy: 0.9559511396801099\n",
      "Iteration: 29632, Loss: 0.005700856447219849, Accuracy: 0.9485778728267178\n",
      "Iteration: 29696, Loss: 0.0008802414522506297, Accuracy: 0.9605241346289404\n",
      "Iteration: 29760, Loss: 0.004294493701308966, Accuracy: 0.9497553142718971\n",
      "Iteration: 29824, Loss: 0.006492117419838905, Accuracy: 0.9448177958547603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 29888, Loss: 0.0008424101979471743, Accuracy: 0.9609764733177144\n",
      "Iteration: 29952, Loss: 0.0031135433819144964, Accuracy: 0.9609321988828015\n",
      "Iteration: 30016, Loss: 0.0011286326916888356, Accuracy: 0.9481397377385292\n",
      "Iteration: 30080, Loss: 0.005145563278347254, Accuracy: 0.9526606649160385\n",
      "Iteration: 30144, Loss: 0.008202998898923397, Accuracy: 0.9460309093410615\n",
      "Iteration: 30208, Loss: 0.005671035032719374, Accuracy: 0.9479718236543704\n",
      "Iteration: 30272, Loss: 0.0047304644249379635, Accuracy: 0.9512816302885767\n",
      "Iteration: 30336, Loss: 0.0010886102681979537, Accuracy: 0.9570922147249803\n",
      "Iteration: 30400, Loss: 0.000895491277333349, Accuracy: 0.9614697570214048\n",
      "Iteration: 30464, Loss: 0.0008876154315657914, Accuracy: 0.9540719848591834\n",
      "Iteration: 30528, Loss: 0.002916930941864848, Accuracy: 0.9574837326945271\n",
      "Iteration: 30592, Loss: 0.001241986290551722, Accuracy: 0.9555269852280617\n",
      "Iteration: 30656, Loss: 0.0008235776913352311, Accuracy: 0.9531172051210888\n",
      "Iteration: 30720, Loss: 0.0181542057543993, Accuracy: 0.9565280406386591\n",
      "Iteration: 30784, Loss: 0.0025040919426828623, Accuracy: 0.9518320491188206\n",
      "Iteration: 30848, Loss: 0.0038596622180193663, Accuracy: 0.9612862608628348\n",
      "Iteration: 30912, Loss: 0.003943112213164568, Accuracy: 0.9546375400677789\n",
      "Iteration: 30976, Loss: 0.0006955710123293102, Accuracy: 0.9643135669466574\n",
      "Iteration: 31040, Loss: 0.0006850836798548698, Accuracy: 0.9600909795262851\n",
      "Iteration: 31104, Loss: 0.0067552742548286915, Accuracy: 0.9441241799504496\n",
      "Iteration: 31168, Loss: 0.0006494370172731578, Accuracy: 0.9615911446744576\n",
      "Iteration: 31232, Loss: 0.0018223345978185534, Accuracy: 0.9578344329784159\n",
      "Iteration: 31296, Loss: 0.003298616735264659, Accuracy: 0.9488389076141175\n",
      "Iteration: 31360, Loss: 0.0038700930308550596, Accuracy: 0.9592459675041027\n",
      "Iteration: 31424, Loss: 0.0023542989511042833, Accuracy: 0.9667274510720745\n",
      "Iteration: 31488, Loss: 0.0005356140318326652, Accuracy: 0.9605702224216657\n",
      "Iteration: 31552, Loss: 0.000770072394516319, Accuracy: 0.9595968243083917\n",
      "Iteration: 31616, Loss: 0.002447353443130851, Accuracy: 0.9588174484670162\n",
      "Iteration: 31680, Loss: 0.002840091474354267, Accuracy: 0.960139816015726\n",
      "Iteration: 31744, Loss: 0.008192837238311768, Accuracy: 0.9617164341616444\n",
      "Iteration: 31808, Loss: 0.00572374789044261, Accuracy: 0.9657091726257931\n",
      "Iteration: 31872, Loss: 0.0012844192096963525, Accuracy: 0.956992132938467\n",
      "Iteration: 31936, Loss: 0.0007607354200445116, Accuracy: 0.9692395435704384\n",
      "Iteration: 32000, Loss: 0.0006189534324221313, Accuracy: 0.9684217502945103\n",
      "Iteration: 32064, Loss: 0.0016267277533188462, Accuracy: 0.9616539302805904\n",
      "Iteration: 32128, Loss: 0.000677742063999176, Accuracy: 0.9722300604043994\n",
      "Saved fullModel_dr[4]_replicate1.model\n",
      "Saved W_dr[4]_replicate1.p\n",
      "4 0.9947916666666666 [1.0, 1.0, 0.984375]\n",
      "Saved w_dr[4]_replicate1.p\n",
      "Replicate 1 completed\n",
      "Time elapsed: 600.71875 seconds\n",
      "Iteration: 64, Loss: 0.24336040019989014, Accuracy: 0.5030727968551219\n",
      "Iteration: 128, Loss: 0.17481954395771027, Accuracy: 0.5352500220760703\n",
      "Iteration: 192, Loss: 0.18602865934371948, Accuracy: 0.5753675857558846\n",
      "Iteration: 256, Loss: 0.19720982015132904, Accuracy: 0.6009155977517366\n",
      "Iteration: 320, Loss: 0.16714031994342804, Accuracy: 0.6153909284621477\n",
      "Iteration: 384, Loss: 0.17789910733699799, Accuracy: 0.6254566768184304\n",
      "Iteration: 448, Loss: 0.17258302867412567, Accuracy: 0.632326696999371\n",
      "Iteration: 512, Loss: 0.16013003885746002, Accuracy: 0.6360852895304561\n",
      "Iteration: 576, Loss: 0.18392567336559296, Accuracy: 0.6397805092856288\n",
      "Iteration: 640, Loss: 0.1650582104921341, Accuracy: 0.6431080945767462\n",
      "Iteration: 704, Loss: 0.154842808842659, Accuracy: 0.6447190814651549\n",
      "Iteration: 768, Loss: 0.15514324605464935, Accuracy: 0.646411748137325\n",
      "Iteration: 832, Loss: 0.17507685720920563, Accuracy: 0.6480154921300709\n",
      "Iteration: 896, Loss: 0.16644175350666046, Accuracy: 0.6489744745194912\n",
      "Iteration: 960, Loss: 0.16596081852912903, Accuracy: 0.6502677244134247\n",
      "Iteration: 1024, Loss: 0.15885715186595917, Accuracy: 0.6518219807185233\n",
      "Iteration: 1088, Loss: 0.17197169363498688, Accuracy: 0.6524188141338527\n",
      "Iteration: 1152, Loss: 0.16950751841068268, Accuracy: 0.6531480243429542\n",
      "Iteration: 1216, Loss: 0.17821244895458221, Accuracy: 0.6535499850288033\n",
      "Iteration: 1280, Loss: 0.1777539849281311, Accuracy: 0.654365002643317\n",
      "Iteration: 1344, Loss: 0.16066263616085052, Accuracy: 0.6549814534373581\n",
      "Iteration: 1408, Loss: 0.17333024740219116, Accuracy: 0.6552992998622358\n",
      "Iteration: 1472, Loss: 0.1712065488100052, Accuracy: 0.655774743296206\n",
      "Iteration: 1536, Loss: 0.1764279007911682, Accuracy: 0.6563311228528619\n",
      "Iteration: 1600, Loss: 0.17955756187438965, Accuracy: 0.6566291460767388\n",
      "Iteration: 1664, Loss: 0.16795533895492554, Accuracy: 0.6572770597413182\n",
      "Iteration: 1728, Loss: 0.17495512962341309, Accuracy: 0.6575633883476257\n",
      "Iteration: 1792, Loss: 0.1663637012243271, Accuracy: 0.6579278665594757\n",
      "Iteration: 1856, Loss: 0.16797436773777008, Accuracy: 0.6579997022636235\n",
      "Iteration: 1920, Loss: 0.16973626613616943, Accuracy: 0.6584774302318692\n",
      "Iteration: 1984, Loss: 0.16451559960842133, Accuracy: 0.6587648312561214\n",
      "Iteration: 2048, Loss: 0.17157262563705444, Accuracy: 0.6584992627613246\n",
      "Iteration: 2112, Loss: 0.16441667079925537, Accuracy: 0.6590763493441045\n",
      "Iteration: 2176, Loss: 0.16643637418746948, Accuracy: 0.6590115218423307\n",
      "Iteration: 2240, Loss: 0.16331642866134644, Accuracy: 0.6595774707384408\n",
      "Iteration: 2304, Loss: 0.1668245792388916, Accuracy: 0.6297584665007889\n",
      "Iteration: 2368, Loss: 0.15641896426677704, Accuracy: 0.6589808873832226\n",
      "Iteration: 2432, Loss: 0.1726399064064026, Accuracy: 0.6589024816639721\n",
      "Iteration: 2496, Loss: 0.17571358382701874, Accuracy: 0.659617779776454\n",
      "Iteration: 2560, Loss: 0.16959290206432343, Accuracy: 0.6595258065499365\n",
      "Iteration: 2624, Loss: 0.1624147742986679, Accuracy: 0.6599392257630825\n",
      "Iteration: 2688, Loss: 0.1678735762834549, Accuracy: 0.6545659112744033\n",
      "Iteration: 2752, Loss: 0.1629050225019455, Accuracy: 0.6596157355234027\n",
      "Iteration: 2816, Loss: 0.1657983809709549, Accuracy: 0.6599993440322578\n",
      "Iteration: 2880, Loss: 0.1672910898923874, Accuracy: 0.6602023537270725\n",
      "Iteration: 2944, Loss: 0.17141182720661163, Accuracy: 0.6607537404634058\n",
      "Iteration: 3008, Loss: 0.17003946006298065, Accuracy: 0.66078861663118\n",
      "Iteration: 3072, Loss: 0.1672501564025879, Accuracy: 0.6608490995131433\n",
      "Iteration: 3136, Loss: 0.1682632714509964, Accuracy: 0.6611620127223432\n",
      "Iteration: 3200, Loss: 0.16715097427368164, Accuracy: 0.6557188695296645\n",
      "Iteration: 3264, Loss: 0.17035716772079468, Accuracy: 0.6610172735527158\n",
      "Iteration: 3328, Loss: 0.16510041058063507, Accuracy: 0.661164762917906\n",
      "Iteration: 3392, Loss: 0.16904699802398682, Accuracy: 0.656191065441817\n",
      "Iteration: 3456, Loss: 0.17253124713897705, Accuracy: 0.6611513504758477\n",
      "Iteration: 3520, Loss: 0.1724272221326828, Accuracy: 0.6613688440993428\n",
      "Iteration: 3584, Loss: 0.16341762244701385, Accuracy: 0.6565415621735156\n",
      "Iteration: 3648, Loss: 0.16525231301784515, Accuracy: 0.660840452183038\n",
      "Iteration: 3712, Loss: 0.1708143800497055, Accuracy: 0.6611519432626665\n",
      "Iteration: 3776, Loss: 0.17184536159038544, Accuracy: 0.6616905722767115\n",
      "Iteration: 3840, Loss: 0.16850785911083221, Accuracy: 0.6619111252948642\n",
      "Iteration: 3904, Loss: 0.16688261926174164, Accuracy: 0.6616231808438897\n",
      "Iteration: 3968, Loss: 0.16960681974887848, Accuracy: 0.6621249285526574\n",
      "Iteration: 4032, Loss: 0.1698262244462967, Accuracy: 0.6618326692841947\n",
      "Iteration: 4096, Loss: 0.1710328608751297, Accuracy: 0.6569881681352854\n",
      "Iteration: 4160, Loss: 0.1659983992576599, Accuracy: 0.6615348313935101\n",
      "Iteration: 4224, Loss: 0.169771209359169, Accuracy: 0.661902560852468\n",
      "Iteration: 4288, Loss: 0.166878342628479, Accuracy: 0.662058720830828\n",
      "Iteration: 4352, Loss: 0.17275989055633545, Accuracy: 0.6623479295521975\n",
      "Iteration: 4416, Loss: 0.1681712120771408, Accuracy: 0.6621346436440945\n",
      "Iteration: 4480, Loss: 0.17157840728759766, Accuracy: 0.6623827232979238\n",
      "Iteration: 4544, Loss: 0.17067070305347443, Accuracy: 0.6622527441941202\n",
      "Iteration: 4608, Loss: 0.16326284408569336, Accuracy: 0.6538904258050025\n",
      "Iteration: 4672, Loss: 0.17382729053497314, Accuracy: 0.6570422220975161\n",
      "Iteration: 4736, Loss: 0.16875743865966797, Accuracy: 0.6624786774627864\n",
      "Iteration: 4800, Loss: 0.16509029269218445, Accuracy: 0.6613540532998741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4864, Loss: 0.1720232516527176, Accuracy: 0.6623327932320535\n",
      "Iteration: 4928, Loss: 0.16636909544467926, Accuracy: 0.662808258086443\n",
      "Iteration: 4992, Loss: 0.16730642318725586, Accuracy: 0.6624743570573628\n",
      "Iteration: 5056, Loss: 0.16586750745773315, Accuracy: 0.6629248978570104\n",
      "Iteration: 5120, Loss: 0.1713799238204956, Accuracy: 0.662704044021666\n",
      "Iteration: 5184, Loss: 0.16659608483314514, Accuracy: 0.6632339721545577\n",
      "Iteration: 5248, Loss: 0.16534243524074554, Accuracy: 0.6629664315842092\n",
      "Iteration: 5312, Loss: 0.1695890873670578, Accuracy: 0.6627716673538089\n",
      "Iteration: 5376, Loss: 0.16795885562896729, Accuracy: 0.6631997511722147\n",
      "Iteration: 5440, Loss: 0.16579101979732513, Accuracy: 0.6627541962079704\n",
      "Iteration: 5504, Loss: 0.1667490452528, Accuracy: 0.6632211375981569\n",
      "Iteration: 5568, Loss: 0.16605769097805023, Accuracy: 0.6629486763849854\n",
      "Iteration: 5632, Loss: 0.16975603997707367, Accuracy: 0.6629990874789655\n",
      "Iteration: 5696, Loss: 0.16444970667362213, Accuracy: 0.6636105244979262\n",
      "Iteration: 5760, Loss: 0.1643928438425064, Accuracy: 0.6635739509947598\n",
      "Iteration: 5824, Loss: 0.1719166487455368, Accuracy: 0.6633542170748115\n",
      "Iteration: 5888, Loss: 0.16852881014347076, Accuracy: 0.6635182383470237\n",
      "Iteration: 5952, Loss: 0.1666133552789688, Accuracy: 0.6636486793868244\n",
      "Iteration: 6016, Loss: 0.16656969487667084, Accuracy: 0.6635939390398562\n",
      "Iteration: 6080, Loss: 0.16810816526412964, Accuracy: 0.6635897462256253\n",
      "Iteration: 6144, Loss: 0.16548427939414978, Accuracy: 0.6636852649971843\n",
      "Iteration: 6208, Loss: 0.16991297900676727, Accuracy: 0.6638637036085129\n",
      "Iteration: 6272, Loss: 0.16727392375469208, Accuracy: 0.6641470724716783\n",
      "Iteration: 6336, Loss: 0.16862176358699799, Accuracy: 0.6635872484184802\n",
      "Iteration: 6400, Loss: 0.16733871400356293, Accuracy: 0.6641175784170628\n",
      "Iteration: 6464, Loss: 0.16839079558849335, Accuracy: 0.6637769746594131\n",
      "Iteration: 6528, Loss: 0.16658076643943787, Accuracy: 0.6635740860365331\n",
      "Iteration: 6592, Loss: 0.17079992592334747, Accuracy: 0.6634991690516472\n",
      "Iteration: 6656, Loss: 0.16588318347930908, Accuracy: 0.6637190696783364\n",
      "Iteration: 6720, Loss: 0.16743315756320953, Accuracy: 0.6639206134714186\n",
      "Iteration: 6784, Loss: 0.16862539947032928, Accuracy: 0.6642545149661601\n",
      "Iteration: 6848, Loss: 0.16650518774986267, Accuracy: 0.6643455908633769\n",
      "Iteration: 6912, Loss: 0.16659612953662872, Accuracy: 0.6641826201230288\n",
      "Iteration: 6976, Loss: 0.16763193905353546, Accuracy: 0.6641709418036044\n",
      "Iteration: 7040, Loss: 0.16730089485645294, Accuracy: 0.6641754521988332\n",
      "Iteration: 7104, Loss: 0.1711147576570511, Accuracy: 0.6644009370356798\n",
      "Iteration: 7168, Loss: 0.16993506252765656, Accuracy: 0.6642896072007716\n",
      "Iteration: 7232, Loss: 0.1683272123336792, Accuracy: 0.6643073367886245\n",
      "Iteration: 7296, Loss: 0.16939188539981842, Accuracy: 0.6640963102690876\n",
      "Iteration: 7360, Loss: 0.16834326088428497, Accuracy: 0.6639633793383837\n",
      "Iteration: 7424, Loss: 0.16905897855758667, Accuracy: 0.664238712284714\n",
      "Iteration: 7488, Loss: 0.1679915189743042, Accuracy: 0.6643366096541286\n",
      "Iteration: 7552, Loss: 0.17117373645305634, Accuracy: 0.6644577640108764\n",
      "Iteration: 7616, Loss: 0.16640222072601318, Accuracy: 0.6642587310634553\n",
      "Iteration: 7680, Loss: 0.1687089204788208, Accuracy: 0.6645732671022415\n",
      "Iteration: 7744, Loss: 0.16918396949768066, Accuracy: 0.664553543087095\n",
      "Iteration: 7808, Loss: 0.17005133628845215, Accuracy: 0.6646453300490975\n",
      "Iteration: 7872, Loss: 0.1708008050918579, Accuracy: 0.6642722194083035\n",
      "Iteration: 7936, Loss: 0.16694407165050507, Accuracy: 0.6644459855742753\n",
      "Iteration: 8000, Loss: 0.16584940254688263, Accuracy: 0.6647541355341673\n",
      "Iteration: 8064, Loss: 0.17227448523044586, Accuracy: 0.6640662252902985\n",
      "Iteration: 8128, Loss: 0.1685764044523239, Accuracy: 0.6644935719668865\n",
      "Iteration: 8192, Loss: 0.16675043106079102, Accuracy: 0.6647882126271725\n",
      "Iteration: 8256, Loss: 0.16969013214111328, Accuracy: 0.664294611196965\n",
      "Iteration: 8320, Loss: 0.16605187952518463, Accuracy: 0.6648722849786282\n",
      "Iteration: 8384, Loss: 0.16885733604431152, Accuracy: 0.6646883832290769\n",
      "Iteration: 8448, Loss: 0.16797085106372833, Accuracy: 0.6646765759214759\n",
      "Iteration: 8512, Loss: 0.16481119394302368, Accuracy: 0.6650312808342278\n",
      "Iteration: 8576, Loss: 0.17138798534870148, Accuracy: 0.6647850228473544\n",
      "Iteration: 8640, Loss: 0.16808605194091797, Accuracy: 0.6648890348151326\n",
      "Iteration: 8704, Loss: 0.17093002796173096, Accuracy: 0.6648642490617931\n",
      "Iteration: 8768, Loss: 0.1653827279806137, Accuracy: 0.6651396527886391\n",
      "Iteration: 8832, Loss: 0.1660182625055313, Accuracy: 0.6644243481568992\n",
      "Iteration: 8896, Loss: 0.1703030914068222, Accuracy: 0.6646853345446289\n",
      "Iteration: 8960, Loss: 0.16975414752960205, Accuracy: 0.6651707934215665\n",
      "Iteration: 9024, Loss: 0.16910763084888458, Accuracy: 0.6645574918948114\n",
      "Iteration: 9088, Loss: 0.16919301450252533, Accuracy: 0.6649791062809527\n",
      "Iteration: 9152, Loss: 0.1673501580953598, Accuracy: 0.664737737737596\n",
      "Iteration: 9216, Loss: 0.1674436777830124, Accuracy: 0.665136681869626\n",
      "Iteration: 9280, Loss: 0.16661055386066437, Accuracy: 0.6649044137448072\n",
      "Iteration: 9344, Loss: 0.16755855083465576, Accuracy: 0.6649581617675722\n",
      "Iteration: 9408, Loss: 0.16848976910114288, Accuracy: 0.6652404363267124\n",
      "Iteration: 9472, Loss: 0.16792042553424835, Accuracy: 0.6652768081985414\n",
      "Iteration: 9536, Loss: 0.16814343631267548, Accuracy: 0.6653065658174455\n",
      "Iteration: 9600, Loss: 0.16982334852218628, Accuracy: 0.6644153483211994\n",
      "Iteration: 9664, Loss: 0.16459640860557556, Accuracy: 0.6651189066469669\n",
      "Iteration: 9728, Loss: 0.16726362705230713, Accuracy: 0.6647745915688574\n",
      "Iteration: 9792, Loss: 0.16753946244716644, Accuracy: 0.6652712551876903\n",
      "Iteration: 9856, Loss: 0.1691911816596985, Accuracy: 0.6652708728797734\n",
      "Iteration: 9920, Loss: 0.1654076725244522, Accuracy: 0.664978735614568\n",
      "Iteration: 9984, Loss: 0.16928631067276, Accuracy: 0.6653975541703403\n",
      "Iteration: 10048, Loss: 0.17007684707641602, Accuracy: 0.6650934191420674\n",
      "Iteration: 10112, Loss: 0.16800762712955475, Accuracy: 0.6654515727423131\n",
      "Iteration: 10176, Loss: 0.1686488389968872, Accuracy: 0.6652783006429672\n",
      "Iteration: 10240, Loss: 0.16733312606811523, Accuracy: 0.6655770218931139\n",
      "Iteration: 10304, Loss: 0.17025883495807648, Accuracy: 0.6653526108711958\n",
      "Iteration: 10368, Loss: 0.16798563301563263, Accuracy: 0.6653988598845899\n",
      "Iteration: 10432, Loss: 0.1681932657957077, Accuracy: 0.6651747426949441\n",
      "Iteration: 10496, Loss: 0.16931939125061035, Accuracy: 0.6652836911380291\n",
      "Iteration: 10560, Loss: 0.16776812076568604, Accuracy: 0.6655439822934568\n",
      "Iteration: 10624, Loss: 0.16822589933872223, Accuracy: 0.6651657498441637\n",
      "Iteration: 10688, Loss: 0.1680249124765396, Accuracy: 0.6654381812550128\n",
      "Iteration: 10752, Loss: 0.17033623158931732, Accuracy: 0.6653119619004428\n",
      "Iteration: 10816, Loss: 0.16473372280597687, Accuracy: 0.6650145845487714\n",
      "Iteration: 10880, Loss: 0.1663580983877182, Accuracy: 0.6652328823693097\n",
      "Iteration: 10944, Loss: 0.16843414306640625, Accuracy: 0.6654431945644319\n",
      "Iteration: 11008, Loss: 0.1662750393152237, Accuracy: 0.6656101667322218\n",
      "Iteration: 11072, Loss: 0.17087878286838531, Accuracy: 0.6652982938103378\n",
      "Iteration: 11136, Loss: 0.16626840829849243, Accuracy: 0.6654856372624636\n",
      "Iteration: 11200, Loss: 0.16810376942157745, Accuracy: 0.665301080327481\n",
      "Iteration: 11264, Loss: 0.16984403133392334, Accuracy: 0.6653712834231555\n",
      "Iteration: 11328, Loss: 0.17067162692546844, Accuracy: 0.6652561528608203\n",
      "Iteration: 11392, Loss: 0.16867797076702118, Accuracy: 0.6651158696040511\n",
      "Iteration: 11456, Loss: 0.17096881568431854, Accuracy: 0.6655711000785232\n",
      "Iteration: 11520, Loss: 0.1681756228208542, Accuracy: 0.6654189298860729\n",
      "Iteration: 11584, Loss: 0.166977658867836, Accuracy: 0.6654035183601081\n",
      "Iteration: 11648, Loss: 0.1684437394142151, Accuracy: 0.6655575833283365\n",
      "Iteration: 11712, Loss: 0.1710866242647171, Accuracy: 0.6653664759360254\n",
      "Iteration: 11776, Loss: 0.1669963002204895, Accuracy: 0.6657955860719085\n",
      "Iteration: 11840, Loss: 0.1640581488609314, Accuracy: 0.6655507506802678\n",
      "Iteration: 11904, Loss: 0.16547542810440063, Accuracy: 0.6656264532357454\n",
      "Iteration: 11968, Loss: 0.16929708421230316, Accuracy: 0.6654927683994174\n",
      "Iteration: 12032, Loss: 0.17006556689739227, Accuracy: 0.6656239167787135\n",
      "Iteration: 12096, Loss: 0.1668691784143448, Accuracy: 0.6658175634220243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 12160, Loss: 0.1683918684720993, Accuracy: 0.6657206485979259\n",
      "Iteration: 12224, Loss: 0.16520287096500397, Accuracy: 0.6654001479037106\n",
      "Iteration: 12288, Loss: 0.1705039143562317, Accuracy: 0.6654911837540567\n",
      "Iteration: 12352, Loss: 0.16784606873989105, Accuracy: 0.6655495329760015\n",
      "Iteration: 12416, Loss: 0.16612578928470612, Accuracy: 0.6656453791074455\n",
      "Iteration: 12480, Loss: 0.1721106767654419, Accuracy: 0.6655486761592329\n",
      "Iteration: 12544, Loss: 0.16743725538253784, Accuracy: 0.6655033933930099\n",
      "Iteration: 12608, Loss: 0.1648539900779724, Accuracy: 0.6656041932292283\n",
      "Iteration: 12672, Loss: 0.16724854707717896, Accuracy: 0.6658316906541586\n",
      "Iteration: 12736, Loss: 0.1662912219762802, Accuracy: 0.6657227813266218\n",
      "Iteration: 12800, Loss: 0.1679900884628296, Accuracy: 0.6657575569115579\n",
      "Iteration: 12864, Loss: 0.16729843616485596, Accuracy: 0.6654714378528297\n",
      "Iteration: 12928, Loss: 0.16884709894657135, Accuracy: 0.6656863614916801\n",
      "Iteration: 12992, Loss: 0.16527549922466278, Accuracy: 0.6658255709335208\n",
      "Iteration: 13056, Loss: 0.16825352609157562, Accuracy: 0.6657813140191138\n",
      "Iteration: 13120, Loss: 0.16634945571422577, Accuracy: 0.665743067394942\n",
      "Iteration: 13184, Loss: 0.16673590242862701, Accuracy: 0.6658482821658254\n",
      "Iteration: 13248, Loss: 0.1707133799791336, Accuracy: 0.6656662500463426\n",
      "Iteration: 13312, Loss: 0.16851584613323212, Accuracy: 0.6657289625145495\n",
      "Iteration: 13376, Loss: 0.16858673095703125, Accuracy: 0.6656714272685349\n",
      "Iteration: 13440, Loss: 0.16791273653507233, Accuracy: 0.6655657957307994\n",
      "Iteration: 13504, Loss: 0.16996555030345917, Accuracy: 0.6658116215839982\n",
      "Iteration: 13568, Loss: 0.16912488639354706, Accuracy: 0.6655867858789861\n",
      "Iteration: 13632, Loss: 0.17222577333450317, Accuracy: 0.665657626464963\n",
      "Iteration: 13696, Loss: 0.16540871560573578, Accuracy: 0.6656935303471982\n",
      "Iteration: 13760, Loss: 0.1698545664548874, Accuracy: 0.6660297717899084\n",
      "Iteration: 13824, Loss: 0.16298271715641022, Accuracy: 0.6654875939711928\n",
      "Iteration: 13888, Loss: 0.16810967028141022, Accuracy: 0.6658431901596487\n",
      "Iteration: 13952, Loss: 0.1677461862564087, Accuracy: 0.6657282835803926\n",
      "Iteration: 14016, Loss: 0.1690112203359604, Accuracy: 0.6658287062309682\n",
      "Iteration: 14080, Loss: 0.1663631647825241, Accuracy: 0.6658866195939481\n",
      "Iteration: 14144, Loss: 0.16828973591327667, Accuracy: 0.6658333805389702\n",
      "Iteration: 14208, Loss: 0.17006485164165497, Accuracy: 0.6657898928970098\n",
      "Iteration: 14272, Loss: 0.16954916715621948, Accuracy: 0.6657693474553525\n",
      "Iteration: 14336, Loss: 0.167319193482399, Accuracy: 0.665712621062994\n",
      "Iteration: 14400, Loss: 0.1688786894083023, Accuracy: 0.6657335911877453\n",
      "Iteration: 14464, Loss: 0.1681329607963562, Accuracy: 0.6658926294185221\n",
      "Iteration: 14528, Loss: 0.1676824539899826, Accuracy: 0.6654584011994302\n",
      "Iteration: 14592, Loss: 0.1694643646478653, Accuracy: 0.6658722418360412\n",
      "Iteration: 14656, Loss: 0.16915588080883026, Accuracy: 0.6658989703282714\n",
      "Iteration: 14720, Loss: 0.16741716861724854, Accuracy: 0.6658370736986399\n",
      "Iteration: 14784, Loss: 0.16900283098220825, Accuracy: 0.6657690042629838\n",
      "Iteration: 14848, Loss: 0.16858188807964325, Accuracy: 0.665768978651613\n",
      "Iteration: 14912, Loss: 0.16671496629714966, Accuracy: 0.6658454844728112\n",
      "Iteration: 14976, Loss: 0.1669863909482956, Accuracy: 0.6657800646498799\n",
      "Iteration: 15040, Loss: 0.1687459945678711, Accuracy: 0.6659580115228891\n",
      "Iteration: 15104, Loss: 0.16652260720729828, Accuracy: 0.6658995049074292\n",
      "Iteration: 15168, Loss: 0.1688959002494812, Accuracy: 0.6658232701011002\n",
      "Iteration: 15232, Loss: 0.1688639372587204, Accuracy: 0.6654190034605563\n",
      "Iteration: 15296, Loss: 0.16819219291210175, Accuracy: 0.6661780918948352\n",
      "Iteration: 15360, Loss: 0.16813619434833527, Accuracy: 0.6656157649122179\n",
      "Iteration: 15424, Loss: 0.16765767335891724, Accuracy: 0.6658078730106354\n",
      "Iteration: 15488, Loss: 0.17074088752269745, Accuracy: 0.6638926989398897\n",
      "Iteration: 15552, Loss: 0.1700703352689743, Accuracy: 0.6657149000093341\n",
      "Iteration: 15616, Loss: 0.16616284847259521, Accuracy: 0.6658436139114201\n",
      "Iteration: 15680, Loss: 0.1666760891675949, Accuracy: 0.6659590508788824\n",
      "Iteration: 15744, Loss: 0.1659916490316391, Accuracy: 0.6660011159256101\n",
      "Iteration: 15808, Loss: 0.16737373173236847, Accuracy: 0.6659762728959322\n",
      "Iteration: 15872, Loss: 0.16489137709140778, Accuracy: 0.6658839457668364\n",
      "Iteration: 15936, Loss: 0.16721856594085693, Accuracy: 0.6659540818072855\n",
      "Iteration: 16000, Loss: 0.16643042862415314, Accuracy: 0.6658183643594384\n",
      "Iteration: 16064, Loss: 0.16716904938220978, Accuracy: 0.6657990585081279\n",
      "Iteration: 16128, Loss: 0.16825200617313385, Accuracy: 0.6656733169220388\n",
      "Iteration: 16192, Loss: 0.167647123336792, Accuracy: 0.665608826559037\n",
      "Iteration: 16256, Loss: 0.16794586181640625, Accuracy: 0.6659080651588738\n",
      "Iteration: 16320, Loss: 0.16754186153411865, Accuracy: 0.665497116278857\n",
      "Iteration: 16384, Loss: 0.1648714542388916, Accuracy: 0.6658454509451985\n",
      "Iteration: 16448, Loss: 0.16857540607452393, Accuracy: 0.6659339545294642\n",
      "Iteration: 16512, Loss: 0.17065507173538208, Accuracy: 0.6655897232703865\n",
      "Iteration: 16576, Loss: 0.16663531959056854, Accuracy: 0.6660505444742739\n",
      "Iteration: 16640, Loss: 0.16479597985744476, Accuracy: 0.6658248431049287\n",
      "Iteration: 16704, Loss: 0.16781018674373627, Accuracy: 0.6654789783060551\n",
      "Iteration: 16768, Loss: 0.17058968544006348, Accuracy: 0.6657382436096668\n",
      "Iteration: 16832, Loss: 0.16764290630817413, Accuracy: 0.6659530242905021\n",
      "Iteration: 16896, Loss: 0.17071950435638428, Accuracy: 0.6605776138603687\n",
      "Iteration: 16960, Loss: 0.16947853565216064, Accuracy: 0.665227297693491\n",
      "Iteration: 17024, Loss: 0.16970963776111603, Accuracy: 0.6658182619139552\n",
      "Iteration: 17088, Loss: 0.1674349457025528, Accuracy: 0.6657301671802998\n",
      "Iteration: 17152, Loss: 0.16916079819202423, Accuracy: 0.6656094356440008\n",
      "Iteration: 17216, Loss: 0.16818095743656158, Accuracy: 0.6655302816070616\n",
      "Iteration: 17280, Loss: 0.16486412286758423, Accuracy: 0.6657308940775692\n",
      "Iteration: 17344, Loss: 0.1667688935995102, Accuracy: 0.6656643450260162\n",
      "Iteration: 17408, Loss: 0.16683350503444672, Accuracy: 0.6656340155750513\n",
      "Iteration: 17472, Loss: 0.16822080314159393, Accuracy: 0.6653685769997537\n",
      "Iteration: 17536, Loss: 0.16315655410289764, Accuracy: 0.6650261017493904\n",
      "Iteration: 17600, Loss: 0.16927115619182587, Accuracy: 0.6649816483259201\n",
      "Iteration: 17664, Loss: 0.16467130184173584, Accuracy: 0.6601033108308911\n",
      "Iteration: 17728, Loss: 0.16501356661319733, Accuracy: 0.6643058676272631\n",
      "Iteration: 17792, Loss: 0.16477426886558533, Accuracy: 0.6655547562986612\n",
      "Iteration: 17856, Loss: 0.1710868924856186, Accuracy: 0.6656667906790972\n",
      "Iteration: 17920, Loss: 0.16611960530281067, Accuracy: 0.6652695671655238\n",
      "Iteration: 17984, Loss: 0.1628764420747757, Accuracy: 0.6653830432333052\n",
      "Iteration: 18048, Loss: 0.16474910080432892, Accuracy: 0.6655909167602658\n",
      "Iteration: 18112, Loss: 0.16847853362560272, Accuracy: 0.6657084077596664\n",
      "Iteration: 18176, Loss: 0.16513200104236603, Accuracy: 0.6650346927344799\n",
      "Iteration: 18240, Loss: 0.16336925327777863, Accuracy: 0.6656065136194229\n",
      "Iteration: 18304, Loss: 0.1699700951576233, Accuracy: 0.6653955015353858\n",
      "Iteration: 18368, Loss: 0.17178064584732056, Accuracy: 0.6656516077928245\n",
      "Iteration: 18432, Loss: 0.16511447727680206, Accuracy: 0.6653247070498765\n",
      "Iteration: 18496, Loss: 0.16424335539340973, Accuracy: 0.6653299410827458\n",
      "Iteration: 18560, Loss: 0.16378465294837952, Accuracy: 0.6648452724330127\n",
      "Iteration: 18624, Loss: 0.17040127515792847, Accuracy: 0.6649395227432251\n",
      "Iteration: 18688, Loss: 0.1675700545310974, Accuracy: 0.6649790275841951\n",
      "Iteration: 18752, Loss: 0.16993190348148346, Accuracy: 0.6651972406543791\n",
      "Iteration: 18816, Loss: 0.1644318848848343, Accuracy: 0.6643638731911778\n",
      "Iteration: 18880, Loss: 0.16818790137767792, Accuracy: 0.6641013887710869\n",
      "Iteration: 18944, Loss: 0.16488154232501984, Accuracy: 0.6660853764042258\n",
      "Iteration: 19008, Loss: 0.16650669276714325, Accuracy: 0.6657746792770922\n",
      "Iteration: 19072, Loss: 0.1630491465330124, Accuracy: 0.6657346212305129\n",
      "Iteration: 19136, Loss: 0.16791363060474396, Accuracy: 0.6656259023584425\n",
      "Iteration: 19200, Loss: 0.1677061915397644, Accuracy: 0.6652115103788674\n",
      "Iteration: 19264, Loss: 0.16849815845489502, Accuracy: 0.6657299045473337\n",
      "Iteration: 19328, Loss: 0.1679699569940567, Accuracy: 0.6658139051869512\n",
      "Iteration: 19392, Loss: 0.1675250083208084, Accuracy: 0.6654167338274419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 19456, Loss: 0.16748206317424774, Accuracy: 0.6650693467818201\n",
      "Iteration: 19520, Loss: 0.1693257838487625, Accuracy: 0.6654818742536008\n",
      "Iteration: 19584, Loss: 0.1668885201215744, Accuracy: 0.6637204545550048\n",
      "Iteration: 19648, Loss: 0.16893000900745392, Accuracy: 0.6653739712201059\n",
      "Iteration: 19712, Loss: 0.16294611990451813, Accuracy: 0.6613149936310947\n",
      "Iteration: 19776, Loss: 0.17568618059158325, Accuracy: 0.6627534199506044\n",
      "Iteration: 19840, Loss: 0.17204642295837402, Accuracy: 0.6659524887800217\n",
      "Iteration: 19904, Loss: 0.16880345344543457, Accuracy: 0.6658281818963587\n",
      "Iteration: 19968, Loss: 0.16481806337833405, Accuracy: 0.6658739917911589\n",
      "Iteration: 20032, Loss: 0.16404251754283905, Accuracy: 0.6661972375586629\n",
      "Iteration: 20096, Loss: 0.16480572521686554, Accuracy: 0.6660099932923913\n",
      "Iteration: 20160, Loss: 0.16616815328598022, Accuracy: 0.6658294121734798\n",
      "Iteration: 20224, Loss: 0.168687105178833, Accuracy: 0.6662080860696733\n",
      "Iteration: 20288, Loss: 0.1650756150484085, Accuracy: 0.6660332730971277\n",
      "Iteration: 20352, Loss: 0.16675712168216705, Accuracy: 0.6652830289676785\n",
      "Iteration: 20416, Loss: 0.16375169157981873, Accuracy: 0.665977441240102\n",
      "Iteration: 20480, Loss: 0.16965071856975555, Accuracy: 0.6662818547338247\n",
      "Iteration: 20544, Loss: 0.16449519991874695, Accuracy: 0.6655842596665025\n",
      "Iteration: 20608, Loss: 0.1659509837627411, Accuracy: 0.6653770455159247\n",
      "Iteration: 20672, Loss: 0.1606261283159256, Accuracy: 0.6657804725691676\n",
      "Iteration: 20736, Loss: 0.16539449989795685, Accuracy: 0.6657166597433388\n",
      "Iteration: 20800, Loss: 0.16275106370449066, Accuracy: 0.6626254059374332\n",
      "Iteration: 20864, Loss: 0.16404511034488678, Accuracy: 0.6607215008698404\n",
      "Iteration: 20928, Loss: 0.16908353567123413, Accuracy: 0.666461085435003\n",
      "Iteration: 20992, Loss: 0.16830508410930634, Accuracy: 0.6661752285435796\n",
      "Iteration: 21056, Loss: 0.1667463183403015, Accuracy: 0.6652093371376395\n",
      "Iteration: 21120, Loss: 0.16630087792873383, Accuracy: 0.6660753395408392\n",
      "Iteration: 21184, Loss: 0.16448970139026642, Accuracy: 0.6644569300115108\n",
      "Iteration: 21248, Loss: 0.1669190526008606, Accuracy: 0.6657935064285994\n",
      "Iteration: 21312, Loss: 0.1638721078634262, Accuracy: 0.666534848511219\n",
      "Iteration: 21376, Loss: 0.17643344402313232, Accuracy: 0.6659117150120437\n",
      "Iteration: 21440, Loss: 0.17034505307674408, Accuracy: 0.6659633559174836\n",
      "Iteration: 21504, Loss: 0.16891469061374664, Accuracy: 0.6660473244264722\n",
      "Iteration: 21568, Loss: 0.16082081198692322, Accuracy: 0.6653373660519719\n",
      "Iteration: 21632, Loss: 0.17429248988628387, Accuracy: 0.6655344949103892\n",
      "Iteration: 21696, Loss: 0.15977108478546143, Accuracy: 0.6653785537928343\n",
      "Iteration: 21760, Loss: 0.16141508519649506, Accuracy: 0.6670851898379624\n",
      "Iteration: 21824, Loss: 0.16678954660892487, Accuracy: 0.6664191992022097\n",
      "Iteration: 21888, Loss: 0.16055873036384583, Accuracy: 0.6679536569863558\n",
      "Iteration: 21952, Loss: 0.1639711707830429, Accuracy: 0.665971152484417\n",
      "Iteration: 22016, Loss: 0.1468958854675293, Accuracy: 0.6668748389929533\n",
      "Iteration: 22080, Loss: 0.14596742391586304, Accuracy: 0.6683312845416367\n",
      "Iteration: 22144, Loss: 0.13578300178050995, Accuracy: 0.6629031407646835\n",
      "Iteration: 22208, Loss: 0.16529589891433716, Accuracy: 0.6660274737514555\n",
      "Iteration: 22272, Loss: 0.13182403147220612, Accuracy: 0.6723045385442674\n",
      "Iteration: 22336, Loss: 0.1540275514125824, Accuracy: 0.6733533958904445\n",
      "Iteration: 22400, Loss: 0.18807442486286163, Accuracy: 0.6761383460834622\n",
      "Iteration: 22464, Loss: 0.12816652655601501, Accuracy: 0.6756320046260953\n",
      "Iteration: 22528, Loss: 0.12099689245223999, Accuracy: 0.6789696253836155\n",
      "Iteration: 22592, Loss: 0.12152602523565292, Accuracy: 0.686705213971436\n",
      "Iteration: 22656, Loss: 0.14127075672149658, Accuracy: 0.689780539367348\n",
      "Iteration: 22720, Loss: 0.11443088203668594, Accuracy: 0.6946621448732913\n",
      "Iteration: 22784, Loss: 0.09781249612569809, Accuracy: 0.6964972221758217\n",
      "Iteration: 22848, Loss: 0.09389277547597885, Accuracy: 0.7060260800644755\n",
      "Iteration: 22912, Loss: 0.07344216853380203, Accuracy: 0.7137390952557325\n",
      "Iteration: 22976, Loss: 0.15545009076595306, Accuracy: 0.7151725052390248\n",
      "Iteration: 23040, Loss: 0.10331565141677856, Accuracy: 0.726816818350926\n",
      "Iteration: 23104, Loss: 0.1519661396741867, Accuracy: 0.7270257486961782\n",
      "Iteration: 23168, Loss: 0.13394677639007568, Accuracy: 0.7315370952710509\n",
      "Iteration: 23232, Loss: 0.12463787198066711, Accuracy: 0.7462547684554011\n",
      "Iteration: 23296, Loss: 0.11143968254327774, Accuracy: 0.7538699076976627\n",
      "Iteration: 23360, Loss: 0.08418116718530655, Accuracy: 0.7656888978090137\n",
      "Iteration: 23424, Loss: 0.08192230015993118, Accuracy: 0.7654979622457176\n",
      "Iteration: 23488, Loss: 0.09061148762702942, Accuracy: 0.7760621034540236\n",
      "Iteration: 23552, Loss: 0.05851144716143608, Accuracy: 0.7822463454212993\n",
      "Iteration: 23616, Loss: 0.08805782347917557, Accuracy: 0.7812439976260066\n",
      "Iteration: 23680, Loss: 0.09090135246515274, Accuracy: 0.780187654774636\n",
      "Iteration: 23744, Loss: 0.10852330923080444, Accuracy: 0.7832238413393497\n",
      "Iteration: 23808, Loss: 0.11148367077112198, Accuracy: 0.7937793065793812\n",
      "Iteration: 23872, Loss: 0.07844366878271103, Accuracy: 0.7942797162104398\n",
      "Iteration: 23936, Loss: 0.08230683207511902, Accuracy: 0.7943019703961909\n",
      "Iteration: 24000, Loss: 0.06647564470767975, Accuracy: 0.7976597063243389\n",
      "Iteration: 24064, Loss: 0.25959834456443787, Accuracy: 0.7965886546298862\n",
      "Iteration: 24128, Loss: 0.08374833315610886, Accuracy: 0.789381257025525\n",
      "Iteration: 24192, Loss: 0.09433454275131226, Accuracy: 0.799978124210611\n",
      "Iteration: 24256, Loss: 0.11002703756093979, Accuracy: 0.7997149187140167\n",
      "Iteration: 24320, Loss: 0.07108171284198761, Accuracy: 0.8029205945786089\n",
      "Iteration: 24384, Loss: 0.06552192568778992, Accuracy: 0.8026118685957044\n",
      "Iteration: 24448, Loss: 0.10796413570642471, Accuracy: 0.8051949487999082\n",
      "Iteration: 24512, Loss: 0.11672761291265488, Accuracy: 0.8047031869646162\n",
      "Iteration: 24576, Loss: 0.08349141478538513, Accuracy: 0.8058422713074833\n",
      "Iteration: 24640, Loss: 0.1069217249751091, Accuracy: 0.8008998818695545\n",
      "Iteration: 24704, Loss: 0.07368668168783188, Accuracy: 0.7945869900286198\n",
      "Iteration: 24768, Loss: 0.07392551749944687, Accuracy: 0.8021979737095535\n",
      "Iteration: 24832, Loss: 0.10806199908256531, Accuracy: 0.8066093227826059\n",
      "Iteration: 24896, Loss: 0.07929500192403793, Accuracy: 0.8088384496513754\n",
      "Iteration: 24960, Loss: 0.10870953649282455, Accuracy: 0.802966485498473\n",
      "Iteration: 25024, Loss: 0.09202232956886292, Accuracy: 0.8075058169197291\n",
      "Iteration: 25088, Loss: 0.0682438313961029, Accuracy: 0.813838749891147\n",
      "Iteration: 25152, Loss: 0.05819558724761009, Accuracy: 0.8139857386704534\n",
      "Iteration: 25216, Loss: 0.06104990839958191, Accuracy: 0.8134442588780075\n",
      "Iteration: 25280, Loss: 0.06718600541353226, Accuracy: 0.8157088491134346\n",
      "Iteration: 25344, Loss: 0.06317908316850662, Accuracy: 0.8153705503791571\n",
      "Iteration: 25408, Loss: 0.06110738590359688, Accuracy: 0.8139805579558015\n",
      "Iteration: 25472, Loss: 0.052469756454229355, Accuracy: 0.8168358313851058\n",
      "Iteration: 25536, Loss: 0.06654036045074463, Accuracy: 0.8188105237204581\n",
      "Iteration: 25600, Loss: 0.07380340248346329, Accuracy: 0.8182515120133758\n",
      "Iteration: 25664, Loss: 0.10642043501138687, Accuracy: 0.8195511631201953\n",
      "Iteration: 25728, Loss: 0.11259239166975021, Accuracy: 0.8229288603179157\n",
      "Iteration: 25792, Loss: 0.045158207416534424, Accuracy: 0.8174911960959435\n",
      "Iteration: 25856, Loss: 0.09434273838996887, Accuracy: 0.8095863156486303\n",
      "Iteration: 25920, Loss: 0.06782221049070358, Accuracy: 0.8097570897080004\n",
      "Iteration: 25984, Loss: 0.05341055989265442, Accuracy: 0.8210352594032884\n",
      "Iteration: 26048, Loss: 0.11162694543600082, Accuracy: 0.8270994708873332\n",
      "Iteration: 26112, Loss: 0.06039350852370262, Accuracy: 0.827915872912854\n",
      "Iteration: 26176, Loss: 0.04227161407470703, Accuracy: 0.8295863880775869\n",
      "Iteration: 26240, Loss: 0.03334612771868706, Accuracy: 0.8277986478060484\n",
      "Iteration: 26304, Loss: 0.03187131509184837, Accuracy: 0.8326512260828167\n",
      "Iteration: 26368, Loss: 0.03570105507969856, Accuracy: 0.8339610928669572\n",
      "Iteration: 26432, Loss: 0.10596755892038345, Accuracy: 0.8366991762304679\n",
      "Iteration: 26496, Loss: 0.04479733482003212, Accuracy: 0.8334466015221551\n",
      "Iteration: 26560, Loss: 0.11498180776834488, Accuracy: 0.8403576518176123\n",
      "Iteration: 26624, Loss: 0.07665906101465225, Accuracy: 0.8351519561838359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 26688, Loss: 0.07109769433736801, Accuracy: 0.8384511561598629\n",
      "Iteration: 26752, Loss: 0.04036940634250641, Accuracy: 0.8410823369631544\n",
      "Iteration: 26816, Loss: 0.027574539184570312, Accuracy: 0.842685547657311\n",
      "Iteration: 26880, Loss: 0.05790486931800842, Accuracy: 0.8415781940566376\n",
      "Iteration: 26944, Loss: 0.07232027500867844, Accuracy: 0.8305293974699453\n",
      "Iteration: 27008, Loss: 0.05979889631271362, Accuracy: 0.8331726780161262\n",
      "Iteration: 27072, Loss: 0.11857717484235764, Accuracy: 0.8378266800427809\n",
      "Iteration: 27136, Loss: 0.11028202623128891, Accuracy: 0.8341376257594675\n",
      "Iteration: 27200, Loss: 0.036055222153663635, Accuracy: 0.8432688387110829\n",
      "Iteration: 27264, Loss: 0.11291428655385971, Accuracy: 0.8463704336900264\n",
      "Iteration: 27328, Loss: 0.08539838343858719, Accuracy: 0.8482368619879708\n",
      "Iteration: 27392, Loss: 0.028330067172646523, Accuracy: 0.8428619977785274\n",
      "Iteration: 27456, Loss: 0.019034368917346, Accuracy: 0.8468359716935083\n",
      "Iteration: 27520, Loss: 0.08809377998113632, Accuracy: 0.8498239928158\n",
      "Iteration: 27584, Loss: 0.051861464977264404, Accuracy: 0.8549562530824915\n",
      "Iteration: 27648, Loss: 0.025508606806397438, Accuracy: 0.8522965436568484\n",
      "Iteration: 27712, Loss: 0.020494887605309486, Accuracy: 0.8544591790996492\n",
      "Iteration: 27776, Loss: 0.05013222619891167, Accuracy: 0.8493562628282234\n",
      "Iteration: 27840, Loss: 0.08432769030332565, Accuracy: 0.837529183132574\n",
      "Iteration: 27904, Loss: 0.05682876706123352, Accuracy: 0.8517548707313836\n",
      "Iteration: 27968, Loss: 0.018534524366259575, Accuracy: 0.8594829408684745\n",
      "Iteration: 28032, Loss: 0.027530020102858543, Accuracy: 0.8503985257120803\n",
      "Iteration: 28096, Loss: 0.06619784981012344, Accuracy: 0.8530208175070584\n",
      "Iteration: 28160, Loss: 0.09868202358484268, Accuracy: 0.8598271486116573\n",
      "Iteration: 28224, Loss: 0.08453746885061264, Accuracy: 0.8654767929110676\n",
      "Iteration: 28288, Loss: 0.015822483226656914, Accuracy: 0.8648793438915163\n",
      "Iteration: 28352, Loss: 0.011207631789147854, Accuracy: 0.8547993534011766\n",
      "Iteration: 28416, Loss: 0.06971477717161179, Accuracy: 0.8546864892123267\n",
      "Iteration: 28480, Loss: 0.056054744869470596, Accuracy: 0.8636494981474243\n",
      "Iteration: 28544, Loss: 0.07576475292444229, Accuracy: 0.8542356163961813\n",
      "Iteration: 28608, Loss: 0.09714043140411377, Accuracy: 0.8550164108746685\n",
      "Iteration: 28672, Loss: 0.05584678053855896, Accuracy: 0.8604340623714961\n",
      "Iteration: 28736, Loss: 0.010299347341060638, Accuracy: 0.8612952955882065\n",
      "Iteration: 28800, Loss: 0.04326535761356354, Accuracy: 0.8629442296805792\n",
      "Iteration: 28864, Loss: 0.02159039117395878, Accuracy: 0.8709017532528378\n",
      "Iteration: 28928, Loss: 0.009600854478776455, Accuracy: 0.8736589204636402\n",
      "Iteration: 28992, Loss: 0.003877391340211034, Accuracy: 0.8491387311369181\n",
      "Iteration: 29056, Loss: 0.09407820552587509, Accuracy: 0.8597703864215873\n",
      "Iteration: 29120, Loss: 0.03442121669650078, Accuracy: 0.8753738238010556\n",
      "Iteration: 29184, Loss: 0.008203435689210892, Accuracy: 0.8755925211589783\n",
      "Iteration: 29248, Loss: 0.03985903412103653, Accuracy: 0.8726861758041196\n",
      "Iteration: 29312, Loss: 0.07507890462875366, Accuracy: 0.8766523988451809\n",
      "Iteration: 29376, Loss: 0.09139873832464218, Accuracy: 0.8701609768904746\n",
      "Iteration: 29440, Loss: 0.06459187716245651, Accuracy: 0.8751402533380315\n",
      "Iteration: 29504, Loss: 0.012372970581054688, Accuracy: 0.8709448892623186\n",
      "Iteration: 29568, Loss: 0.004713631700724363, Accuracy: 0.8756849949713796\n",
      "Iteration: 29632, Loss: 0.08034174889326096, Accuracy: 0.869708722922951\n",
      "Iteration: 29696, Loss: 0.050192613154649734, Accuracy: 0.8760975252371281\n",
      "Iteration: 29760, Loss: 0.06258950382471085, Accuracy: 0.8659144441480748\n",
      "Iteration: 29824, Loss: 0.0940650925040245, Accuracy: 0.8659760931041092\n",
      "Iteration: 29888, Loss: 0.042660992592573166, Accuracy: 0.8819326344528235\n",
      "Iteration: 29952, Loss: 0.11806843429803848, Accuracy: 0.8782509978045709\n",
      "Iteration: 30016, Loss: 0.009301788173615932, Accuracy: 0.8798183241160586\n",
      "Iteration: 30080, Loss: 0.023297393694519997, Accuracy: 0.8826428228057921\n",
      "Iteration: 30144, Loss: 0.0031705338042229414, Accuracy: 0.8781629052828066\n",
      "Iteration: 30208, Loss: 0.04425473511219025, Accuracy: 0.8865564684965648\n",
      "Iteration: 30272, Loss: 0.003951479215174913, Accuracy: 0.8853858872316778\n",
      "Iteration: 30336, Loss: 0.009233139455318451, Accuracy: 0.8922962144715711\n",
      "Iteration: 30400, Loss: 0.07322480529546738, Accuracy: 0.8664847609470598\n",
      "Iteration: 30464, Loss: 0.002416731556877494, Accuracy: 0.8885396959958598\n",
      "Iteration: 30528, Loss: 0.037557926028966904, Accuracy: 0.8908365826064255\n",
      "Iteration: 30592, Loss: 0.09987295418977737, Accuracy: 0.8876530779816676\n",
      "Iteration: 30656, Loss: 0.0033488564658910036, Accuracy: 0.89272980359965\n",
      "Iteration: 30720, Loss: 0.00564391165971756, Accuracy: 0.8834840768249705\n",
      "Iteration: 30784, Loss: 0.010572221130132675, Accuracy: 0.8998816865496337\n",
      "Iteration: 30848, Loss: 0.003037964226678014, Accuracy: 0.8956771835801192\n",
      "Iteration: 30912, Loss: 0.003210450289770961, Accuracy: 0.8979259698244277\n",
      "Iteration: 30976, Loss: 0.006174298003315926, Accuracy: 0.89176527413656\n",
      "Iteration: 31040, Loss: 0.05107487365603447, Accuracy: 0.9088509250141215\n",
      "Iteration: 31104, Loss: 0.0770128145813942, Accuracy: 0.8948506040906068\n",
      "Iteration: 31168, Loss: 0.038288503885269165, Accuracy: 0.883106907713227\n",
      "Iteration: 31232, Loss: 0.005407331511378288, Accuracy: 0.9047760954999831\n",
      "Iteration: 31296, Loss: 0.007839398458600044, Accuracy: 0.9013794035126921\n",
      "Iteration: 31360, Loss: 0.051880255341529846, Accuracy: 0.9010494353133254\n",
      "Iteration: 31424, Loss: 0.028004953637719154, Accuracy: 0.8955760026583448\n",
      "Iteration: 31488, Loss: 0.09648006409406662, Accuracy: 0.9082415542798117\n",
      "Iteration: 31552, Loss: 0.07712775468826294, Accuracy: 0.9035306093282998\n",
      "Iteration: 31616, Loss: 0.01455262303352356, Accuracy: 0.91170570711256\n",
      "Iteration: 31680, Loss: 0.0038650762289762497, Accuracy: 0.9105198192410171\n",
      "Iteration: 31744, Loss: 0.31971991062164307, Accuracy: 0.9049422278476413\n",
      "Iteration: 31808, Loss: 0.12214589864015579, Accuracy: 0.8939883827115409\n",
      "Iteration: 31872, Loss: 0.0025692975614219904, Accuracy: 0.9065387363079935\n",
      "Iteration: 31936, Loss: 0.011808388866484165, Accuracy: 0.916890595399309\n",
      "Iteration: 32000, Loss: 0.002937869867309928, Accuracy: 0.9093516857828945\n",
      "Iteration: 32064, Loss: 0.01893552578985691, Accuracy: 0.9183549223234877\n",
      "Iteration: 32128, Loss: 0.0018666634568944573, Accuracy: 0.91186410485534\n",
      "Iteration: 32192, Loss: 0.0077789463102817535, Accuracy: 0.9202754184661899\n",
      "Iteration: 32256, Loss: 0.03661778196692467, Accuracy: 0.8999971124285366\n",
      "Iteration: 32320, Loss: 0.0016763560706749558, Accuracy: 0.9134489848511294\n",
      "Iteration: 32384, Loss: 0.002451767912134528, Accuracy: 0.9244170769234188\n",
      "Iteration: 32448, Loss: 0.018736904487013817, Accuracy: 0.9187103103031404\n",
      "Iteration: 32512, Loss: 0.000821919646114111, Accuracy: 0.8998509347438812\n",
      "Iteration: 32576, Loss: 0.016643503680825233, Accuracy: 0.9178356884804089\n",
      "Iteration: 32640, Loss: 0.03345799446105957, Accuracy: 0.9286441770673264\n",
      "Iteration: 32704, Loss: 0.28394630551338196, Accuracy: 0.9124692846526159\n",
      "Iteration: 32768, Loss: 0.03416355326771736, Accuracy: 0.9093711004534271\n",
      "Iteration: 32832, Loss: 0.02726486511528492, Accuracy: 0.9290998255455634\n",
      "Iteration: 32896, Loss: 0.008137653581798077, Accuracy: 0.9240654719906161\n",
      "Iteration: 32960, Loss: 0.007814419455826283, Accuracy: 0.8995884684409248\n",
      "Iteration: 33024, Loss: 0.00038244796451181173, Accuracy: 0.9279743492952548\n",
      "Iteration: 33088, Loss: 0.0031736053060740232, Accuracy: 0.9325386803975562\n",
      "Iteration: 33152, Loss: 0.026762275025248528, Accuracy: 0.9356922725710319\n",
      "Iteration: 33216, Loss: 0.007509076502174139, Accuracy: 0.9206545156921493\n",
      "Iteration: 33280, Loss: 0.008783027529716492, Accuracy: 0.9136634761234745\n",
      "Iteration: 33344, Loss: 0.007990998215973377, Accuracy: 0.9264662006607978\n",
      "Iteration: 33408, Loss: 0.0006872537196613848, Accuracy: 0.9234839689306682\n",
      "Iteration: 33472, Loss: 0.012053675949573517, Accuracy: 0.9259446122014197\n",
      "Iteration: 33536, Loss: 0.000682290003169328, Accuracy: 0.9355258606519783\n",
      "Iteration: 33600, Loss: 0.0011573085794225335, Accuracy: 0.9256598395149922\n",
      "Iteration: 33664, Loss: 0.030686557292938232, Accuracy: 0.9230173959222157\n",
      "Iteration: 33728, Loss: 0.010777033865451813, Accuracy: 0.9263278671423905\n",
      "Iteration: 33792, Loss: 0.00038361441693268716, Accuracy: 0.9447027713467833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 33856, Loss: 0.11698206514120102, Accuracy: 0.9333442667266354\n",
      "Iteration: 33920, Loss: 0.008069610223174095, Accuracy: 0.9348875090654474\n",
      "Iteration: 33984, Loss: 0.00121596350800246, Accuracy: 0.9248762730130693\n",
      "Iteration: 34048, Loss: 0.0750126764178276, Accuracy: 0.9338570270338096\n",
      "Iteration: 34112, Loss: 0.002774312859401107, Accuracy: 0.930201701587066\n",
      "Iteration: 34176, Loss: 0.004195612855255604, Accuracy: 0.9456548238522373\n",
      "Iteration: 34240, Loss: 0.0005198274157010019, Accuracy: 0.9453704736515647\n",
      "Iteration: 34304, Loss: 0.0018257852643728256, Accuracy: 0.9444955308863427\n",
      "Iteration: 34368, Loss: 0.00039166430360637605, Accuracy: 0.9316320091893431\n",
      "Iteration: 34432, Loss: 0.21717143058776855, Accuracy: 0.9271898207516642\n",
      "Iteration: 34496, Loss: 0.0008595794788561761, Accuracy: 0.9212909156049136\n",
      "Iteration: 34560, Loss: 0.024852076545357704, Accuracy: 0.9426612916577142\n",
      "Iteration: 34624, Loss: 0.0006057642167434096, Accuracy: 0.9518752918738755\n",
      "Iteration: 34688, Loss: 0.005904409568756819, Accuracy: 0.9359632601845078\n",
      "Iteration: 34752, Loss: 0.00518712168559432, Accuracy: 0.9379901783540845\n",
      "Iteration: 34816, Loss: 0.0021104742772877216, Accuracy: 0.9358564911381109\n",
      "Iteration: 34880, Loss: 0.00833513867110014, Accuracy: 0.9349020199588267\n",
      "Iteration: 34944, Loss: 0.00490731792524457, Accuracy: 0.9395855994443991\n",
      "Iteration: 35008, Loss: 0.00030795877682976425, Accuracy: 0.9418543719584704\n",
      "Iteration: 35072, Loss: 0.005441363900899887, Accuracy: 0.9490796793324989\n",
      "Iteration: 35136, Loss: 0.001457297126762569, Accuracy: 0.9528162162532681\n",
      "Iteration: 35200, Loss: 0.03019925393164158, Accuracy: 0.945103536672832\n",
      "Iteration: 35264, Loss: 0.004418542142957449, Accuracy: 0.9527928696843446\n",
      "Iteration: 35328, Loss: 0.0025858294684439898, Accuracy: 0.9389347206160892\n",
      "Iteration: 35392, Loss: 0.0006994353025220335, Accuracy: 0.9458229250158183\n",
      "Iteration: 35456, Loss: 6.25040556769818e-05, Accuracy: 0.941088072853745\n",
      "Iteration: 35520, Loss: 0.0013912646099925041, Accuracy: 0.9471936914051184\n",
      "Iteration: 35584, Loss: 0.0003467670176178217, Accuracy: 0.9529267521575093\n",
      "Iteration: 35648, Loss: 0.0313650481402874, Accuracy: 0.9549767462085583\n",
      "Iteration: 35712, Loss: 0.004079632926732302, Accuracy: 0.9514586078585126\n",
      "Iteration: 35776, Loss: 0.0040224348194897175, Accuracy: 0.9418512238626136\n",
      "Iteration: 35840, Loss: 0.0027539615985006094, Accuracy: 0.9531103765184525\n",
      "Iteration: 35904, Loss: 0.011819727718830109, Accuracy: 0.9501217924116645\n",
      "Iteration: 35968, Loss: 0.004638708662241697, Accuracy: 0.9397106271862867\n",
      "Iteration: 36032, Loss: 0.0022718801628798246, Accuracy: 0.9534285342087969\n",
      "Iteration: 36096, Loss: 0.0008290133555419743, Accuracy: 0.9541915795125533\n",
      "Iteration: 36160, Loss: 0.001650285325013101, Accuracy: 0.9514470801441348\n",
      "Iteration: 36224, Loss: 0.0010009082034230232, Accuracy: 0.9489297281688778\n",
      "Iteration: 36288, Loss: 0.00028013219707645476, Accuracy: 0.9479047181303031\n",
      "Iteration: 36352, Loss: 0.003162638284265995, Accuracy: 0.9589419954500045\n",
      "Iteration: 36416, Loss: 0.0003811820934060961, Accuracy: 0.9602746884411317\n",
      "Iteration: 36480, Loss: 0.0024267544504255056, Accuracy: 0.9542326478476753\n",
      "Iteration: 36544, Loss: 0.019006328657269478, Accuracy: 0.9552123608955299\n",
      "Iteration: 36608, Loss: 0.0011546023888513446, Accuracy: 0.9598438517277827\n",
      "Iteration: 36672, Loss: 0.0015156801091507077, Accuracy: 0.9388458586399793\n",
      "Iteration: 36736, Loss: 0.0010265059536322951, Accuracy: 0.9602884345076745\n",
      "Iteration: 36800, Loss: 0.0001837351592257619, Accuracy: 0.9435982138529653\n",
      "Iteration: 36864, Loss: 0.0003188620903529227, Accuracy: 0.963933196675498\n",
      "Iteration: 36928, Loss: 0.0001911001600092277, Accuracy: 0.9651013068360044\n",
      "Iteration: 36992, Loss: 7.549530710093677e-05, Accuracy: 0.9488331901447964\n",
      "Iteration: 37056, Loss: 0.00021320096857380122, Accuracy: 0.9590068251782213\n",
      "Iteration: 37120, Loss: 0.15578441321849823, Accuracy: 0.9637244250334334\n",
      "Iteration: 37184, Loss: 0.007387166377156973, Accuracy: 0.9685927863392862\n",
      "Iteration: 37248, Loss: 0.00028949620900675654, Accuracy: 0.9641241272329353\n",
      "Iteration: 37312, Loss: 0.0008167543564923108, Accuracy: 0.968611587988562\n",
      "Iteration: 37376, Loss: 0.036132488399744034, Accuracy: 0.9627747671547695\n",
      "Iteration: 37440, Loss: 0.0002413250767858699, Accuracy: 0.962910255540919\n",
      "Iteration: 37504, Loss: 0.0018287046113982797, Accuracy: 0.955784432386281\n",
      "Iteration: 37568, Loss: 0.00024793794727884233, Accuracy: 0.9687429611149128\n",
      "Iteration: 37632, Loss: 0.0029848923441022635, Accuracy: 0.9605479273814126\n",
      "Iteration: 37696, Loss: 0.0016035201260820031, Accuracy: 0.969094479958585\n",
      "Iteration: 37760, Loss: 0.00024517555721104145, Accuracy: 0.9627338759382837\n",
      "Iteration: 37824, Loss: 0.00034886409412138164, Accuracy: 0.9440923081565415\n",
      "Iteration: 37888, Loss: 0.002471515443176031, Accuracy: 0.9667399363024742\n",
      "Iteration: 37952, Loss: 0.002496415050700307, Accuracy: 0.966160796888289\n",
      "Iteration: 38016, Loss: 0.0008794043096713722, Accuracy: 0.97127219709364\n",
      "Saved fullModel_dr[4]_replicate2.model\n",
      "Saved W_dr[4]_replicate2.p\n",
      "4 0.9739583333333334 [1.0, 0.96875, 0.953125]\n",
      "Saved w_dr[4]_replicate2.p\n",
      "Replicate 2 completed\n",
      "Time elapsed: 645.328125 seconds\n",
      "Iteration: 64, Loss: 0.2540842592716217, Accuracy: 0.49943137541413307\n",
      "Iteration: 128, Loss: 0.2579488754272461, Accuracy: 0.5051861880347133\n",
      "Iteration: 192, Loss: 0.18154112994670868, Accuracy: 0.556239852681756\n",
      "Iteration: 256, Loss: 0.15019693970680237, Accuracy: 0.5972996037453413\n",
      "Iteration: 320, Loss: 0.1503387838602066, Accuracy: 0.6153289033100009\n",
      "Iteration: 384, Loss: 0.16164584457874298, Accuracy: 0.6262511000968516\n",
      "Iteration: 448, Loss: 0.18764394521713257, Accuracy: 0.6337307463400066\n",
      "Iteration: 512, Loss: 0.18100197613239288, Accuracy: 0.6380772283300757\n",
      "Iteration: 576, Loss: 0.18148082494735718, Accuracy: 0.6412293631583452\n",
      "Iteration: 640, Loss: 0.17760394513607025, Accuracy: 0.6444264561869204\n",
      "Iteration: 704, Loss: 0.17219823598861694, Accuracy: 0.6460617128759623\n",
      "Iteration: 768, Loss: 0.16792704164981842, Accuracy: 0.6476140627637506\n",
      "Iteration: 832, Loss: 0.16164155304431915, Accuracy: 0.6495888731442392\n",
      "Iteration: 896, Loss: 0.16276729106903076, Accuracy: 0.6502678268589079\n",
      "Iteration: 960, Loss: 0.15922866761684418, Accuracy: 0.651280983351171\n",
      "Iteration: 1024, Loss: 0.15726697444915771, Accuracy: 0.6526817488484085\n",
      "Iteration: 1088, Loss: 0.16047072410583496, Accuracy: 0.6533915535546839\n",
      "Iteration: 1152, Loss: 0.18131054937839508, Accuracy: 0.6540007451549172\n",
      "Iteration: 1216, Loss: 0.16521048545837402, Accuracy: 0.6547588361427188\n",
      "Iteration: 1280, Loss: 0.17757463455200195, Accuracy: 0.6547160791233182\n",
      "Iteration: 1344, Loss: 0.17177414894104004, Accuracy: 0.6553722936660051\n",
      "Iteration: 1408, Loss: 0.1580238938331604, Accuracy: 0.6513616819866002\n",
      "Iteration: 1472, Loss: 0.17757125198841095, Accuracy: 0.652556259650737\n",
      "Iteration: 1536, Loss: 0.16015206277370453, Accuracy: 0.6560059976764023\n",
      "Iteration: 1600, Loss: 0.17987103760242462, Accuracy: 0.6563625545240939\n",
      "Iteration: 1664, Loss: 0.1797419935464859, Accuracy: 0.6567537956871092\n",
      "Iteration: 1728, Loss: 0.16656526923179626, Accuracy: 0.657032507006079\n",
      "Iteration: 1792, Loss: 0.1585523933172226, Accuracy: 0.6576204993762076\n",
      "Iteration: 1856, Loss: 0.16727302968502045, Accuracy: 0.6580717572942376\n",
      "Iteration: 1920, Loss: 0.16383959352970123, Accuracy: 0.6582126612775028\n",
      "Iteration: 1984, Loss: 0.1610681116580963, Accuracy: 0.658413122408092\n",
      "Iteration: 2048, Loss: 0.17477498948574066, Accuracy: 0.6584338983520865\n",
      "Iteration: 2112, Loss: 0.16267530620098114, Accuracy: 0.6588698830455542\n",
      "Iteration: 2176, Loss: 0.16358451545238495, Accuracy: 0.6590299899689853\n",
      "Iteration: 2240, Loss: 0.16832752525806427, Accuracy: 0.6590864616446197\n",
      "Iteration: 2304, Loss: 0.16029900312423706, Accuracy: 0.6595515669323504\n",
      "Iteration: 2368, Loss: 0.16322220861911774, Accuracy: 0.6596288061700761\n",
      "Iteration: 2432, Loss: 0.1720609813928604, Accuracy: 0.6596124367788434\n",
      "Iteration: 2496, Loss: 0.1693403571844101, Accuracy: 0.6600497774779797\n",
      "Iteration: 2560, Loss: 0.1710985153913498, Accuracy: 0.6600607559084892\n",
      "Iteration: 2624, Loss: 0.16547523438930511, Accuracy: 0.6603127154521644\n",
      "Iteration: 2688, Loss: 0.1731317639350891, Accuracy: 0.6604779111221433\n",
      "Iteration: 2752, Loss: 0.1722785234451294, Accuracy: 0.6607624273747206\n",
      "Iteration: 2816, Loss: 0.17254328727722168, Accuracy: 0.6607471909373999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2880, Loss: 0.1749512404203415, Accuracy: 0.6611232347786427\n",
      "Iteration: 2944, Loss: 0.17531520128250122, Accuracy: 0.6610968611203134\n",
      "Iteration: 3008, Loss: 0.16384382545948029, Accuracy: 0.6610824558883905\n",
      "Iteration: 3072, Loss: 0.16996419429779053, Accuracy: 0.6613657004199922\n",
      "Iteration: 3136, Loss: 0.16812175512313843, Accuracy: 0.661611630115658\n",
      "Iteration: 3200, Loss: 0.16242729127407074, Accuracy: 0.6615962111391127\n",
      "Iteration: 3264, Loss: 0.17395098507404327, Accuracy: 0.6612967639230192\n",
      "Iteration: 3328, Loss: 0.17496168613433838, Accuracy: 0.6615888443775475\n",
      "Iteration: 3392, Loss: 0.16314755380153656, Accuracy: 0.6619694693945348\n",
      "Iteration: 3456, Loss: 0.16217929124832153, Accuracy: 0.6617074264213443\n",
      "Iteration: 3520, Loss: 0.16366593539714813, Accuracy: 0.6621295739896595\n",
      "Iteration: 3584, Loss: 0.16791117191314697, Accuracy: 0.6621231702156365\n",
      "Iteration: 3648, Loss: 0.16847796738147736, Accuracy: 0.6623947517946362\n",
      "Iteration: 3712, Loss: 0.16950498521327972, Accuracy: 0.662478354293853\n",
      "Iteration: 3776, Loss: 0.1677878499031067, Accuracy: 0.6621840507723391\n",
      "Iteration: 3840, Loss: 0.16858547925949097, Accuracy: 0.6626874762587249\n",
      "Iteration: 3904, Loss: 0.1655937284231186, Accuracy: 0.6622602250427008\n",
      "Iteration: 3968, Loss: 0.16777239739894867, Accuracy: 0.6626819237135351\n",
      "Iteration: 4032, Loss: 0.16696785390377045, Accuracy: 0.6626675613224506\n",
      "Iteration: 4096, Loss: 0.1675809621810913, Accuracy: 0.6628680108115077\n",
      "Iteration: 4160, Loss: 0.16310273110866547, Accuracy: 0.6628229203633964\n",
      "Iteration: 4224, Loss: 0.16935515403747559, Accuracy: 0.662885557860136\n",
      "Iteration: 4288, Loss: 0.16939860582351685, Accuracy: 0.6630114675499499\n",
      "Iteration: 4352, Loss: 0.16693644225597382, Accuracy: 0.6624460187740624\n",
      "Iteration: 4416, Loss: 0.16749416291713715, Accuracy: 0.6630552331916988\n",
      "Iteration: 4480, Loss: 0.16848063468933105, Accuracy: 0.6630075103603303\n",
      "Iteration: 4544, Loss: 0.17049020528793335, Accuracy: 0.6634005629457533\n",
      "Iteration: 4608, Loss: 0.1673167198896408, Accuracy: 0.6628298768773675\n",
      "Iteration: 4672, Loss: 0.16932572424411774, Accuracy: 0.6632936242967844\n",
      "Iteration: 4736, Loss: 0.1654372364282608, Accuracy: 0.6632756441831589\n",
      "Iteration: 4800, Loss: 0.16822092235088348, Accuracy: 0.6636453201062977\n",
      "Iteration: 4864, Loss: 0.1678953766822815, Accuracy: 0.6634780317544937\n",
      "Iteration: 4928, Loss: 0.16686664521694183, Accuracy: 0.6631260006688535\n",
      "Iteration: 4992, Loss: 0.16924692690372467, Accuracy: 0.6633390220813453\n",
      "Iteration: 5056, Loss: 0.16816562414169312, Accuracy: 0.663670604582876\n",
      "Iteration: 5120, Loss: 0.16847185790538788, Accuracy: 0.6636344734579325\n",
      "Iteration: 5184, Loss: 0.16617059707641602, Accuracy: 0.6639441973529756\n",
      "Iteration: 5248, Loss: 0.16841278970241547, Accuracy: 0.6634338744916022\n",
      "Iteration: 5312, Loss: 0.17095112800598145, Accuracy: 0.6635314170271158\n",
      "Iteration: 5376, Loss: 0.16930605471134186, Accuracy: 0.6636758972890675\n",
      "Iteration: 5440, Loss: 0.1684519648551941, Accuracy: 0.6638896688818932\n",
      "Iteration: 5504, Loss: 0.16789793968200684, Accuracy: 0.6639373078942299\n",
      "Iteration: 5568, Loss: 0.16806519031524658, Accuracy: 0.6639402401633561\n",
      "Iteration: 5632, Loss: 0.16926468908786774, Accuracy: 0.6637965156696737\n",
      "Iteration: 5696, Loss: 0.1682308167219162, Accuracy: 0.6640392998233438\n",
      "Iteration: 5760, Loss: 0.16690750420093536, Accuracy: 0.6640490936115384\n",
      "Iteration: 5824, Loss: 0.16926328837871552, Accuracy: 0.664131716825068\n",
      "Iteration: 5888, Loss: 0.16905765235424042, Accuracy: 0.6642840974964201\n",
      "Iteration: 5952, Loss: 0.16952936351299286, Accuracy: 0.6641657091677189\n",
      "Iteration: 6016, Loss: 0.16746897995471954, Accuracy: 0.6644297488965094\n",
      "Iteration: 6080, Loss: 0.16910898685455322, Accuracy: 0.6642885152250528\n",
      "Iteration: 6144, Loss: 0.17111624777317047, Accuracy: 0.6641416936181486\n",
      "Iteration: 6208, Loss: 0.16498586535453796, Accuracy: 0.6644691242836416\n",
      "Iteration: 6272, Loss: 0.16595672070980072, Accuracy: 0.6643867050297558\n",
      "Iteration: 6336, Loss: 0.1684849113225937, Accuracy: 0.6642833556979895\n",
      "Iteration: 6400, Loss: 0.17010104656219482, Accuracy: 0.6645309715531766\n",
      "Iteration: 6464, Loss: 0.16483044624328613, Accuracy: 0.6643279497511685\n",
      "Iteration: 6528, Loss: 0.16868317127227783, Accuracy: 0.6643301644362509\n",
      "Iteration: 6592, Loss: 0.16849152743816376, Accuracy: 0.6645907601341605\n",
      "Iteration: 6656, Loss: 0.16994936764240265, Accuracy: 0.6644188542850316\n",
      "Iteration: 6720, Loss: 0.16582952439785004, Accuracy: 0.6646854486316442\n",
      "Iteration: 6784, Loss: 0.17177458107471466, Accuracy: 0.6646051350980997\n",
      "Iteration: 6848, Loss: 0.17013388872146606, Accuracy: 0.6641135010868311\n",
      "Iteration: 6912, Loss: 0.16902750730514526, Accuracy: 0.6641365331597626\n",
      "Iteration: 6976, Loss: 0.1665041297674179, Accuracy: 0.6645730119198561\n",
      "Iteration: 7040, Loss: 0.16846920549869537, Accuracy: 0.6645148992538452\n",
      "Iteration: 7104, Loss: 0.17032282054424286, Accuracy: 0.6646935031749308\n",
      "Iteration: 7168, Loss: 0.16678591072559357, Accuracy: 0.6648910762742162\n",
      "Iteration: 7232, Loss: 0.165757954120636, Accuracy: 0.6645145062357187\n",
      "Iteration: 7296, Loss: 0.16650694608688354, Accuracy: 0.6644119210541248\n",
      "Iteration: 7360, Loss: 0.168196901679039, Accuracy: 0.6647633207030594\n",
      "Iteration: 7424, Loss: 0.16742976009845734, Accuracy: 0.6647206414490938\n",
      "Iteration: 7488, Loss: 0.1690436750650406, Accuracy: 0.6644975431263447\n",
      "Iteration: 7552, Loss: 0.16993588209152222, Accuracy: 0.664743494708091\n",
      "Iteration: 7616, Loss: 0.16746437549591064, Accuracy: 0.6649896209128201\n",
      "Iteration: 7680, Loss: 0.16826684772968292, Accuracy: 0.6648782747797668\n",
      "Iteration: 7744, Loss: 0.16587373614311218, Accuracy: 0.6646905872039497\n",
      "Iteration: 7808, Loss: 0.16826163232326508, Accuracy: 0.6645207619294524\n",
      "Iteration: 7872, Loss: 0.16926521062850952, Accuracy: 0.6647140700370073\n",
      "Iteration: 7936, Loss: 0.16699528694152832, Accuracy: 0.6649557477794588\n",
      "Iteration: 8000, Loss: 0.16550959646701813, Accuracy: 0.6649867491796613\n",
      "Iteration: 8064, Loss: 0.16444535553455353, Accuracy: 0.6650697072036564\n",
      "Iteration: 8128, Loss: 0.16734258830547333, Accuracy: 0.6650778139010072\n",
      "Iteration: 8192, Loss: 0.17022569477558136, Accuracy: 0.6651624925434589\n",
      "Iteration: 8256, Loss: 0.1690802127122879, Accuracy: 0.6650686101056635\n",
      "Iteration: 8320, Loss: 0.16754208505153656, Accuracy: 0.6652523349039257\n",
      "Iteration: 8384, Loss: 0.1678674966096878, Accuracy: 0.6648419974371791\n",
      "Iteration: 8448, Loss: 0.17091600596904755, Accuracy: 0.6652002246119082\n",
      "Iteration: 8512, Loss: 0.167990580201149, Accuracy: 0.6643438604660332\n",
      "Iteration: 8576, Loss: 0.16677112877368927, Accuracy: 0.6647465019486845\n",
      "Iteration: 8640, Loss: 0.16633158922195435, Accuracy: 0.6650154236704111\n",
      "Iteration: 8704, Loss: 0.1661226600408554, Accuracy: 0.6648095375858247\n",
      "Iteration: 8768, Loss: 0.1670295000076294, Accuracy: 0.6649589510634542\n",
      "Iteration: 8832, Loss: 0.1670098453760147, Accuracy: 0.66523741139099\n",
      "Iteration: 8896, Loss: 0.16874535381793976, Accuracy: 0.664968438912183\n",
      "Iteration: 8960, Loss: 0.16789080202579498, Accuracy: 0.6650813771411777\n",
      "Iteration: 9024, Loss: 0.16759325563907623, Accuracy: 0.6652417066507041\n",
      "Iteration: 9088, Loss: 0.1692158579826355, Accuracy: 0.6648757485672832\n",
      "Iteration: 9152, Loss: 0.1676672250032425, Accuracy: 0.6651897761039436\n",
      "Iteration: 9216, Loss: 0.16730432212352753, Accuracy: 0.6651339423842728\n",
      "Iteration: 9280, Loss: 0.16679178178310394, Accuracy: 0.6647788644768298\n",
      "Iteration: 9344, Loss: 0.16759885847568512, Accuracy: 0.6649928893893957\n",
      "Iteration: 9408, Loss: 0.16876256465911865, Accuracy: 0.6649393788538873\n",
      "Iteration: 9472, Loss: 0.16675125062465668, Accuracy: 0.6652564010582864\n",
      "Iteration: 9536, Loss: 0.166800856590271, Accuracy: 0.6652139769867063\n",
      "Iteration: 9600, Loss: 0.16729946434497833, Accuracy: 0.6653876132331789\n",
      "Iteration: 9664, Loss: 0.16658028960227966, Accuracy: 0.6655441490001976\n",
      "Iteration: 9728, Loss: 0.1656857281923294, Accuracy: 0.665015562903136\n",
      "Iteration: 9792, Loss: 0.16658352315425873, Accuracy: 0.6653685537166893\n",
      "Iteration: 9856, Loss: 0.16731305420398712, Accuracy: 0.6654354617930949\n",
      "Iteration: 9920, Loss: 0.1663263887166977, Accuracy: 0.6653017564676702\n",
      "Iteration: 9984, Loss: 0.16613607108592987, Accuracy: 0.6652203067205846\n",
      "Iteration: 10048, Loss: 0.1683468073606491, Accuracy: 0.6654094797559083\n",
      "Iteration: 10112, Loss: 0.16847340762615204, Accuracy: 0.6651301318779588\n",
      "Iteration: 10176, Loss: 0.16710783541202545, Accuracy: 0.665510140825063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10240, Loss: 0.1685623973608017, Accuracy: 0.6652802829630673\n",
      "Iteration: 10304, Loss: 0.16804639995098114, Accuracy: 0.6653433865867555\n",
      "Iteration: 10368, Loss: 0.16845150291919708, Accuracy: 0.6655241004191339\n",
      "Iteration: 10432, Loss: 0.16883091628551483, Accuracy: 0.665335793979466\n",
      "Iteration: 10496, Loss: 0.16803376376628876, Accuracy: 0.6649686601012945\n",
      "Iteration: 10560, Loss: 0.17046630382537842, Accuracy: 0.6653407718986273\n",
      "Iteration: 10624, Loss: 0.16772590577602386, Accuracy: 0.6653681420721114\n",
      "Iteration: 10688, Loss: 0.16636137664318085, Accuracy: 0.6655983072705567\n",
      "Iteration: 10752, Loss: 0.16710269451141357, Accuracy: 0.6655308734625578\n",
      "Iteration: 10816, Loss: 0.16862134635448456, Accuracy: 0.6653750520199537\n",
      "Iteration: 10880, Loss: 0.166524738073349, Accuracy: 0.6654356196522713\n",
      "Iteration: 10944, Loss: 0.16733473539352417, Accuracy: 0.6656452990137041\n",
      "Iteration: 11008, Loss: 0.1674947738647461, Accuracy: 0.6653639185242355\n",
      "Iteration: 11072, Loss: 0.1674799919128418, Accuracy: 0.6654169978573918\n",
      "Iteration: 11136, Loss: 0.16521309316158295, Accuracy: 0.6653593014925718\n",
      "Iteration: 11200, Loss: 0.1674795299768448, Accuracy: 0.6653673658147454\n",
      "Iteration: 11264, Loss: 0.1688091903924942, Accuracy: 0.6654952568933368\n",
      "Iteration: 11328, Loss: 0.1686682254076004, Accuracy: 0.6654534977860749\n",
      "Iteration: 11392, Loss: 0.16780422627925873, Accuracy: 0.6654491676017642\n",
      "Iteration: 11456, Loss: 0.16802138090133667, Accuracy: 0.6655097575858235\n",
      "Iteration: 11520, Loss: 0.1655399054288864, Accuracy: 0.665311899036169\n",
      "Iteration: 11584, Loss: 0.16518239676952362, Accuracy: 0.6655676267109811\n",
      "Iteration: 11648, Loss: 0.16714002192020416, Accuracy: 0.6656430577859282\n",
      "Iteration: 11712, Loss: 0.16715002059936523, Accuracy: 0.6655591786839068\n",
      "Iteration: 11776, Loss: 0.16913287341594696, Accuracy: 0.6656193076632917\n",
      "Iteration: 11840, Loss: 0.16864843666553497, Accuracy: 0.6655616946518421\n",
      "Iteration: 11904, Loss: 0.1650797575712204, Accuracy: 0.6604027431458235\n",
      "Iteration: 11968, Loss: 0.17243917286396027, Accuracy: 0.6651394572108984\n",
      "Iteration: 12032, Loss: 0.16781578958034515, Accuracy: 0.665325038600713\n",
      "Iteration: 12096, Loss: 0.16995613276958466, Accuracy: 0.6649741437286139\n",
      "Iteration: 12160, Loss: 0.16676586866378784, Accuracy: 0.6596775748766959\n",
      "Iteration: 12224, Loss: 0.17161953449249268, Accuracy: 0.6656132182106376\n",
      "Iteration: 12288, Loss: 0.1655532568693161, Accuracy: 0.6650684210471809\n",
      "Iteration: 12352, Loss: 0.16963668167591095, Accuracy: 0.6654773778282106\n",
      "Iteration: 12416, Loss: 0.16857706010341644, Accuracy: 0.6655519958585501\n",
      "Iteration: 12480, Loss: 0.16704435646533966, Accuracy: 0.6652500573545694\n",
      "Iteration: 12544, Loss: 0.1688140481710434, Accuracy: 0.665464153047651\n",
      "Iteration: 12608, Loss: 0.1674542874097824, Accuracy: 0.6655947314575315\n",
      "Iteration: 12672, Loss: 0.16948819160461426, Accuracy: 0.6653860565274954\n",
      "Iteration: 12736, Loss: 0.1682376116514206, Accuracy: 0.6655577588826418\n",
      "Iteration: 12800, Loss: 0.1692187786102295, Accuracy: 0.6650366391986609\n",
      "Iteration: 12864, Loss: 0.1692860722541809, Accuracy: 0.6649555489420891\n",
      "Iteration: 12928, Loss: 0.16859333217144012, Accuracy: 0.6650898857042193\n",
      "Iteration: 12992, Loss: 0.1685798168182373, Accuracy: 0.6652356092818081\n",
      "Iteration: 13056, Loss: 0.16812670230865479, Accuracy: 0.6650724192149937\n",
      "Iteration: 13120, Loss: 0.16759467124938965, Accuracy: 0.665333982091397\n",
      "Iteration: 13184, Loss: 0.17122173309326172, Accuracy: 0.6650021150708199\n",
      "Iteration: 13248, Loss: 0.16714982688426971, Accuracy: 0.664844686165452\n",
      "Iteration: 13312, Loss: 0.16800034046173096, Accuracy: 0.6651048441417515\n",
      "Iteration: 13376, Loss: 0.168948233127594, Accuracy: 0.6648636478930712\n",
      "Iteration: 13440, Loss: 0.17010287940502167, Accuracy: 0.6649457826279104\n",
      "Iteration: 13504, Loss: 0.1618746668100357, Accuracy: 0.6644856417551637\n",
      "Iteration: 13568, Loss: 0.16917943954467773, Accuracy: 0.6640239944681525\n",
      "Iteration: 13632, Loss: 0.16969357430934906, Accuracy: 0.664097139146179\n",
      "Iteration: 13696, Loss: 0.17258071899414062, Accuracy: 0.6656859805807471\n",
      "Iteration: 13760, Loss: 0.16734124720096588, Accuracy: 0.6652599759399891\n",
      "Iteration: 13824, Loss: 0.17253418266773224, Accuracy: 0.6653108661994338\n",
      "Iteration: 13888, Loss: 0.17180031538009644, Accuracy: 0.6644646199420094\n",
      "Iteration: 13952, Loss: 0.16251565515995026, Accuracy: 0.6655101245269179\n",
      "Iteration: 14016, Loss: 0.17124897241592407, Accuracy: 0.6649039136245847\n",
      "Iteration: 14080, Loss: 0.16485415399074554, Accuracy: 0.6641266802325845\n",
      "Iteration: 14144, Loss: 0.17005802690982819, Accuracy: 0.6647991826757789\n",
      "Iteration: 14208, Loss: 0.1669003814458847, Accuracy: 0.6640381943434477\n",
      "Iteration: 14272, Loss: 0.164009228348732, Accuracy: 0.664648016449064\n",
      "Iteration: 14336, Loss: 0.1697613000869751, Accuracy: 0.6657761815004051\n",
      "Iteration: 14400, Loss: 0.16368605196475983, Accuracy: 0.6659082812257111\n",
      "Iteration: 14464, Loss: 0.16503416001796722, Accuracy: 0.6661373665556312\n",
      "Iteration: 14528, Loss: 0.16999752819538116, Accuracy: 0.6656679604202509\n",
      "Iteration: 14592, Loss: 0.16775886714458466, Accuracy: 0.6658672317862511\n",
      "Iteration: 14656, Loss: 0.16908307373523712, Accuracy: 0.6657469440251589\n",
      "Iteration: 14720, Loss: 0.16666078567504883, Accuracy: 0.6656655906699598\n",
      "Iteration: 14784, Loss: 0.16632713377475739, Accuracy: 0.6644899845123291\n",
      "Iteration: 14848, Loss: 0.1744658499956131, Accuracy: 0.6623571556992829\n",
      "Iteration: 14912, Loss: 0.16444051265716553, Accuracy: 0.6656119721010327\n",
      "Iteration: 14976, Loss: 0.172105610370636, Accuracy: 0.6655130940489471\n",
      "Iteration: 15040, Loss: 0.17275571823120117, Accuracy: 0.6659414232708514\n",
      "Iteration: 15104, Loss: 0.16846032440662384, Accuracy: 0.6656581992283463\n",
      "Iteration: 15168, Loss: 0.16876959800720215, Accuracy: 0.6658186074346304\n",
      "Iteration: 15232, Loss: 0.16649824380874634, Accuracy: 0.6659232396632433\n",
      "Iteration: 15296, Loss: 0.16572926938533783, Accuracy: 0.6656601666472852\n",
      "Iteration: 15360, Loss: 0.1684994250535965, Accuracy: 0.6661217170767486\n",
      "Iteration: 15424, Loss: 0.16594193875789642, Accuracy: 0.6659510531462729\n",
      "Iteration: 15488, Loss: 0.1676035374403, Accuracy: 0.6658437331207097\n",
      "Iteration: 15552, Loss: 0.16940490901470184, Accuracy: 0.6660087746568024\n",
      "Iteration: 15616, Loss: 0.16943399608135223, Accuracy: 0.6643963251262903\n",
      "Iteration: 15680, Loss: 0.16389264166355133, Accuracy: 0.6661937311291695\n",
      "Iteration: 15744, Loss: 0.1691688895225525, Accuracy: 0.6661074892617762\n",
      "Iteration: 15808, Loss: 0.16773885488510132, Accuracy: 0.6659230445511639\n",
      "Iteration: 15872, Loss: 0.1675945520401001, Accuracy: 0.6658667353913188\n",
      "Iteration: 15936, Loss: 0.16550235450267792, Accuracy: 0.665955722797662\n",
      "Iteration: 16000, Loss: 0.16596342623233795, Accuracy: 0.6660520029254258\n",
      "Iteration: 16064, Loss: 0.1699581891298294, Accuracy: 0.6659338711760938\n",
      "Iteration: 16128, Loss: 0.16487456858158112, Accuracy: 0.6647310755215585\n",
      "Iteration: 16192, Loss: 0.17198066413402557, Accuracy: 0.6643413421697915\n",
      "Iteration: 16256, Loss: 0.16808967292308807, Accuracy: 0.6655251951888204\n",
      "Iteration: 16320, Loss: 0.16446124017238617, Accuracy: 0.6637135092169046\n",
      "Iteration: 16384, Loss: 0.1621679812669754, Accuracy: 0.6639746990986168\n",
      "Iteration: 16448, Loss: 0.1593770682811737, Accuracy: 0.6654701177030802\n",
      "Iteration: 16512, Loss: 0.1725212186574936, Accuracy: 0.6632496323436499\n",
      "Iteration: 16576, Loss: 0.15405674278736115, Accuracy: 0.6652221009135246\n",
      "Iteration: 16640, Loss: 0.1637154370546341, Accuracy: 0.662872395478189\n",
      "Iteration: 16704, Loss: 0.17065955698490143, Accuracy: 0.6676136925816536\n",
      "Iteration: 16768, Loss: 0.15723147988319397, Accuracy: 0.6662089615128934\n",
      "Iteration: 16832, Loss: 0.15100394189357758, Accuracy: 0.6662075687199831\n",
      "Iteration: 16896, Loss: 0.15583598613739014, Accuracy: 0.6644861646927893\n",
      "Iteration: 16960, Loss: 0.16788458824157715, Accuracy: 0.6639178697951138\n",
      "Iteration: 17024, Loss: 0.16576068103313446, Accuracy: 0.66721949307248\n",
      "Iteration: 17088, Loss: 0.13726688921451569, Accuracy: 0.6691405498422682\n",
      "Iteration: 17152, Loss: 0.16060711443424225, Accuracy: 0.6704564779065549\n",
      "Iteration: 17216, Loss: 0.159542977809906, Accuracy: 0.6669536107219756\n",
      "Iteration: 17280, Loss: 0.18040060997009277, Accuracy: 0.6709094396792352\n",
      "Iteration: 17344, Loss: 0.16429133713245392, Accuracy: 0.6725597255863249\n",
      "Iteration: 17408, Loss: 0.11726653575897217, Accuracy: 0.675918513443321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 17472, Loss: 0.15785741806030273, Accuracy: 0.676497220993042\n",
      "Iteration: 17536, Loss: 0.13938531279563904, Accuracy: 0.6741755302064121\n",
      "Iteration: 17600, Loss: 0.16595011949539185, Accuracy: 0.6760866940021515\n",
      "Iteration: 17664, Loss: 0.13594259321689606, Accuracy: 0.6758429505862296\n",
      "Iteration: 17728, Loss: 0.1258263736963272, Accuracy: 0.6858004163950682\n",
      "Iteration: 17792, Loss: 0.14197324216365814, Accuracy: 0.6825101603753865\n",
      "Iteration: 17856, Loss: 0.09804036468267441, Accuracy: 0.6899378136731684\n",
      "Iteration: 17920, Loss: 0.1272260993719101, Accuracy: 0.6888227784074843\n",
      "Iteration: 17984, Loss: 0.1852279156446457, Accuracy: 0.69617650215514\n",
      "Iteration: 18048, Loss: 0.125019833445549, Accuracy: 0.6927590935956687\n",
      "Iteration: 18112, Loss: 0.1453675776720047, Accuracy: 0.6985076435375959\n",
      "Iteration: 18176, Loss: 0.18317805230617523, Accuracy: 0.7003124898765236\n",
      "Iteration: 18240, Loss: 0.15429724752902985, Accuracy: 0.6998259087558836\n",
      "Iteration: 18304, Loss: 0.09244135767221451, Accuracy: 0.7034234465099871\n",
      "Iteration: 18368, Loss: 0.1477392464876175, Accuracy: 0.6997330880258232\n",
      "Iteration: 18432, Loss: 0.14198912680149078, Accuracy: 0.707382578169927\n",
      "Iteration: 18496, Loss: 0.09469594806432724, Accuracy: 0.7105163263622671\n",
      "Iteration: 18560, Loss: 0.12937353551387787, Accuracy: 0.7202389934100211\n",
      "Iteration: 18624, Loss: 0.14426618814468384, Accuracy: 0.7037751551251858\n",
      "Iteration: 18688, Loss: 0.10448969155550003, Accuracy: 0.7126088065560907\n",
      "Iteration: 18752, Loss: 0.2137456089258194, Accuracy: 0.7054595854133368\n",
      "Iteration: 18816, Loss: 0.10124685615301132, Accuracy: 0.7248909207992256\n",
      "Iteration: 18880, Loss: 0.13204337656497955, Accuracy: 0.7331728178542107\n",
      "Iteration: 18944, Loss: 0.09208778291940689, Accuracy: 0.7239236545283347\n",
      "Iteration: 19008, Loss: 0.11223441362380981, Accuracy: 0.7426681090146303\n",
      "Iteration: 19072, Loss: 0.10446971654891968, Accuracy: 0.7371193470899016\n",
      "Iteration: 19136, Loss: 0.13518039882183075, Accuracy: 0.731923732208088\n",
      "Iteration: 19200, Loss: 0.09145242720842361, Accuracy: 0.7448319185059518\n",
      "Iteration: 19264, Loss: 0.2642793357372284, Accuracy: 0.7411586956586689\n",
      "Iteration: 19328, Loss: 0.10543784499168396, Accuracy: 0.7407966572791338\n",
      "Iteration: 19392, Loss: 0.10118704289197922, Accuracy: 0.7386324680410326\n",
      "Iteration: 19456, Loss: 0.09464355558156967, Accuracy: 0.757264546584338\n",
      "Iteration: 19520, Loss: 0.10264619439840317, Accuracy: 0.7431778160389513\n",
      "Iteration: 19584, Loss: 0.23475320637226105, Accuracy: 0.7516201809048653\n",
      "Iteration: 19648, Loss: 0.10223452001810074, Accuracy: 0.7444431507028639\n",
      "Iteration: 19712, Loss: 0.07842423021793365, Accuracy: 0.760286683915183\n",
      "Iteration: 19776, Loss: 0.08360912650823593, Accuracy: 0.7694084332324564\n",
      "Iteration: 19840, Loss: 0.0940181314945221, Accuracy: 0.7709866079967469\n",
      "Iteration: 19904, Loss: 0.09644072502851486, Accuracy: 0.7614940365310758\n",
      "Iteration: 19968, Loss: 0.08818494528532028, Accuracy: 0.7603253840934485\n",
      "Iteration: 20032, Loss: 0.08787456899881363, Accuracy: 0.778062000637874\n",
      "Iteration: 20096, Loss: 0.08804544061422348, Accuracy: 0.7847849542740732\n",
      "Iteration: 20160, Loss: 0.09436555951833725, Accuracy: 0.7725460093934089\n",
      "Iteration: 20224, Loss: 0.0879698321223259, Accuracy: 0.7797309788875282\n",
      "Iteration: 20288, Loss: 0.09054248780012131, Accuracy: 0.7616976501885802\n",
      "Iteration: 20352, Loss: 0.09050624817609787, Accuracy: 0.7706964970566332\n",
      "Iteration: 20416, Loss: 0.08916738629341125, Accuracy: 0.7709954699967057\n",
      "Iteration: 20480, Loss: 0.09537572413682938, Accuracy: 0.770657911663875\n",
      "Iteration: 20544, Loss: 0.09123417735099792, Accuracy: 0.7802533796057105\n",
      "Iteration: 20608, Loss: 0.08691681176424026, Accuracy: 0.7718421595636755\n",
      "Iteration: 20672, Loss: 0.09352421015501022, Accuracy: 0.7734804982319474\n",
      "Iteration: 20736, Loss: 0.08533099293708801, Accuracy: 0.7756890861783177\n",
      "Iteration: 20800, Loss: 0.08700685948133469, Accuracy: 0.7872977135702968\n",
      "Iteration: 20864, Loss: 0.09792667627334595, Accuracy: 0.7813017307780683\n",
      "Iteration: 20928, Loss: 0.0874946191906929, Accuracy: 0.7909804743248969\n",
      "Iteration: 20992, Loss: 0.0966283306479454, Accuracy: 0.7836447192821652\n",
      "Iteration: 21056, Loss: 0.08784198760986328, Accuracy: 0.7562124831601977\n",
      "Iteration: 21120, Loss: 0.09108550101518631, Accuracy: 0.7848368673585355\n",
      "Iteration: 21184, Loss: 0.2551383376121521, Accuracy: 0.7917197840288281\n",
      "Iteration: 21248, Loss: 0.10120541602373123, Accuracy: 0.7801659847609699\n",
      "Iteration: 21312, Loss: 0.08431380987167358, Accuracy: 0.7949886010028422\n",
      "Iteration: 21376, Loss: 0.09125906974077225, Accuracy: 0.7803843782749027\n",
      "Iteration: 21440, Loss: 0.08547970652580261, Accuracy: 0.7795561540406197\n",
      "Iteration: 21504, Loss: 0.08264536410570145, Accuracy: 0.7928548771888018\n",
      "Iteration: 21568, Loss: 0.08216189593076706, Accuracy: 0.7980811691377312\n",
      "Iteration: 21632, Loss: 0.07944867014884949, Accuracy: 0.7844450662378222\n",
      "Iteration: 21696, Loss: 0.09015262871980667, Accuracy: 0.7818387888837606\n",
      "Iteration: 21760, Loss: 0.08257243782281876, Accuracy: 0.7888701220508665\n",
      "Iteration: 21824, Loss: 0.08384370058774948, Accuracy: 0.7961196852847934\n",
      "Iteration: 21888, Loss: 0.08380433171987534, Accuracy: 0.7912341572809964\n",
      "Iteration: 21952, Loss: 0.08782164007425308, Accuracy: 0.8029662659391761\n",
      "Iteration: 22016, Loss: 0.08606589585542679, Accuracy: 0.7890768784563988\n",
      "Iteration: 22080, Loss: 0.08256787806749344, Accuracy: 0.7703467858955264\n",
      "Iteration: 22144, Loss: 0.36239519715309143, Accuracy: 0.7901599244214594\n",
      "Iteration: 22208, Loss: 0.08405790477991104, Accuracy: 0.7918025425169617\n",
      "Iteration: 22272, Loss: 0.08434731513261795, Accuracy: 0.7903170231729746\n",
      "Iteration: 22336, Loss: 0.08952295035123825, Accuracy: 0.7954484086949378\n",
      "Iteration: 22400, Loss: 0.093897245824337, Accuracy: 0.7975252573378384\n",
      "Iteration: 22464, Loss: 0.0883878692984581, Accuracy: 0.7868496545124799\n",
      "Iteration: 22528, Loss: 0.08897655457258224, Accuracy: 0.7934314364101738\n",
      "Iteration: 22592, Loss: 0.08568019419908524, Accuracy: 0.7914766534231603\n",
      "Iteration: 22656, Loss: 0.08214211463928223, Accuracy: 0.8007261073216796\n",
      "Iteration: 22720, Loss: 0.08522319048643112, Accuracy: 0.7964054262265563\n",
      "Iteration: 22784, Loss: 0.08992424607276917, Accuracy: 0.8009312518406659\n",
      "Iteration: 22848, Loss: 0.08606228977441788, Accuracy: 0.7902633701451123\n",
      "Iteration: 22912, Loss: 0.09162767976522446, Accuracy: 0.7935064733028412\n",
      "Iteration: 22976, Loss: 0.08903231471776962, Accuracy: 0.7968471851199865\n",
      "Iteration: 23040, Loss: 0.08067610114812851, Accuracy: 0.8014266157988459\n",
      "Iteration: 23104, Loss: 0.08554921299219131, Accuracy: 0.7935211088042706\n",
      "Iteration: 23168, Loss: 0.08049207180738449, Accuracy: 0.8080107378773391\n",
      "Iteration: 23232, Loss: 0.08444684743881226, Accuracy: 0.8052321122959256\n",
      "Iteration: 23296, Loss: 0.09165868163108826, Accuracy: 0.7974608952645212\n",
      "Iteration: 23360, Loss: 0.0820113942027092, Accuracy: 0.7980584530159831\n",
      "Iteration: 23424, Loss: 0.19394367933273315, Accuracy: 0.7986660052556545\n",
      "Iteration: 23488, Loss: 0.08986693620681763, Accuracy: 0.7992475996725261\n",
      "Iteration: 23552, Loss: 0.08133527636528015, Accuracy: 0.8009296318050474\n",
      "Iteration: 23616, Loss: 0.08706731349229813, Accuracy: 0.8049124756362289\n",
      "Iteration: 23680, Loss: 0.08566683530807495, Accuracy: 0.8049893621355295\n",
      "Iteration: 23744, Loss: 0.09239530563354492, Accuracy: 0.8028298385906965\n",
      "Iteration: 23808, Loss: 0.08367175608873367, Accuracy: 0.8009041941259056\n",
      "Iteration: 23872, Loss: 0.08828387409448624, Accuracy: 0.7953606927767396\n",
      "Iteration: 23936, Loss: 0.08608463406562805, Accuracy: 0.8034976040944457\n",
      "Iteration: 24000, Loss: 0.07352480292320251, Accuracy: 0.796601538779214\n",
      "Iteration: 24064, Loss: 0.09380698204040527, Accuracy: 0.8052697638049722\n",
      "Iteration: 24128, Loss: 0.08451929688453674, Accuracy: 0.8014102117158473\n",
      "Iteration: 24192, Loss: 0.0876854956150055, Accuracy: 0.8100175454746932\n",
      "Iteration: 24256, Loss: 0.08162199705839157, Accuracy: 0.8074515834450722\n",
      "Iteration: 24320, Loss: 0.07420664280653, Accuracy: 0.8051565843634307\n",
      "Iteration: 24384, Loss: 0.06303376704454422, Accuracy: 0.8123678553383797\n",
      "Iteration: 24448, Loss: 0.09415638446807861, Accuracy: 0.8153980080969632\n",
      "Iteration: 24512, Loss: 0.12790265679359436, Accuracy: 0.8141617234796286\n",
      "Iteration: 24576, Loss: 0.09179288893938065, Accuracy: 0.8145483580883592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 24640, Loss: 0.08027029782533646, Accuracy: 0.8065636637620628\n",
      "Iteration: 24704, Loss: 0.06517332047224045, Accuracy: 0.8108724735211581\n",
      "Iteration: 24768, Loss: 0.08631718903779984, Accuracy: 0.8098125956021249\n",
      "Iteration: 24832, Loss: 0.08258867263793945, Accuracy: 0.8142541542183608\n",
      "Iteration: 24896, Loss: 0.06027624011039734, Accuracy: 0.8104755855165422\n",
      "Iteration: 24960, Loss: 0.05604039505124092, Accuracy: 0.8068088435102254\n",
      "Iteration: 25024, Loss: 0.0813940241932869, Accuracy: 0.806017171125859\n",
      "Iteration: 25088, Loss: 0.08594271540641785, Accuracy: 0.8095748836640269\n",
      "Iteration: 25152, Loss: 0.049037933349609375, Accuracy: 0.8174779240507632\n",
      "Iteration: 25216, Loss: 0.04624681547284126, Accuracy: 0.8230226382147521\n",
      "Iteration: 25280, Loss: 0.08536005765199661, Accuracy: 0.814932782901451\n",
      "Iteration: 25344, Loss: 0.08525947481393814, Accuracy: 0.8074295201804489\n",
      "Iteration: 25408, Loss: 0.08201143890619278, Accuracy: 0.8223400791175663\n",
      "Iteration: 25472, Loss: 0.0864681527018547, Accuracy: 0.8160911083687097\n",
      "Iteration: 25536, Loss: 0.09109806269407272, Accuracy: 0.819348769960925\n",
      "Iteration: 25600, Loss: 0.0871255174279213, Accuracy: 0.8152934783138335\n",
      "Iteration: 25664, Loss: 0.08081008493900299, Accuracy: 0.8197113894857466\n",
      "Iteration: 25728, Loss: 0.08081761747598648, Accuracy: 0.8202460561878979\n",
      "Iteration: 25792, Loss: 0.07401067763566971, Accuracy: 0.8286315242294222\n",
      "Iteration: 25856, Loss: 0.031079664826393127, Accuracy: 0.8303184245014563\n",
      "Iteration: 25920, Loss: 0.0885530412197113, Accuracy: 0.8050757528981194\n",
      "Iteration: 25984, Loss: 0.07348089665174484, Accuracy: 0.8289284240454435\n",
      "Iteration: 26048, Loss: 0.08347264677286148, Accuracy: 0.82572738872841\n",
      "Iteration: 26112, Loss: 0.07887079566717148, Accuracy: 0.8227644308935851\n",
      "Iteration: 26176, Loss: 0.0771866887807846, Accuracy: 0.8322006982052699\n",
      "Iteration: 26240, Loss: 0.08478144556283951, Accuracy: 0.8168740682303905\n",
      "Iteration: 26304, Loss: 0.024102861061692238, Accuracy: 0.8215193804353476\n",
      "Iteration: 26368, Loss: 0.08936625719070435, Accuracy: 0.8268095726380125\n",
      "Iteration: 26432, Loss: 0.3580612242221832, Accuracy: 0.8262784335529432\n",
      "Iteration: 26496, Loss: 0.08163528144359589, Accuracy: 0.8341121474513784\n",
      "Iteration: 26560, Loss: 0.019451893866062164, Accuracy: 0.8318205516552553\n",
      "Iteration: 26624, Loss: 0.09618308395147324, Accuracy: 0.8352519333129749\n",
      "Iteration: 26688, Loss: 0.08848533034324646, Accuracy: 0.8195841524284333\n",
      "Iteration: 26752, Loss: 0.07638121396303177, Accuracy: 0.823665133677423\n",
      "Iteration: 26816, Loss: 0.06228150799870491, Accuracy: 0.8388587321387604\n",
      "Iteration: 26880, Loss: 0.08590235561132431, Accuracy: 0.8375935314688832\n",
      "Iteration: 26944, Loss: 0.07866839319467545, Accuracy: 0.8304482097737491\n",
      "Iteration: 27008, Loss: 0.08577645570039749, Accuracy: 0.8281477263662964\n",
      "Iteration: 27072, Loss: 0.0803518071770668, Accuracy: 0.8411154570057988\n",
      "Iteration: 27136, Loss: 0.08364194631576538, Accuracy: 0.8292895710328594\n",
      "Iteration: 27200, Loss: 0.09053876250982285, Accuracy: 0.8364873774116859\n",
      "Iteration: 27264, Loss: 0.33121299743652344, Accuracy: 0.8388880861457437\n",
      "Iteration: 27328, Loss: 0.012966138310730457, Accuracy: 0.823790262802504\n",
      "Iteration: 27392, Loss: 0.01403146330267191, Accuracy: 0.8252782373456284\n",
      "Iteration: 27456, Loss: 0.07233922928571701, Accuracy: 0.8261173765640706\n",
      "Iteration: 27520, Loss: 0.09856591373682022, Accuracy: 0.842095576110296\n",
      "Iteration: 27584, Loss: 0.06861811876296997, Accuracy: 0.8278590132249519\n",
      "Iteration: 27648, Loss: 0.011966449208557606, Accuracy: 0.8382246328983456\n",
      "Iteration: 27712, Loss: 0.08690793067216873, Accuracy: 0.8301758071174845\n",
      "Iteration: 27776, Loss: 0.07988022267818451, Accuracy: 0.8411900609498844\n",
      "Iteration: 27840, Loss: 0.09431438893079758, Accuracy: 0.832727502565831\n",
      "Iteration: 27904, Loss: 0.08984709531068802, Accuracy: 0.8466834533028305\n",
      "Iteration: 27968, Loss: 0.16463714838027954, Accuracy: 0.8382733232574537\n",
      "Iteration: 28032, Loss: 0.07401258498430252, Accuracy: 0.8417735771508887\n",
      "Iteration: 28096, Loss: 0.008969937451183796, Accuracy: 0.844113026978448\n",
      "Iteration: 28160, Loss: 0.08367323875427246, Accuracy: 0.8350247293710709\n",
      "Iteration: 28224, Loss: 0.19713282585144043, Accuracy: 0.8337141796946526\n",
      "Iteration: 28288, Loss: 0.06735209375619888, Accuracy: 0.7908652890473604\n",
      "Iteration: 28352, Loss: 0.010928013361990452, Accuracy: 0.846352067310363\n",
      "Iteration: 28416, Loss: 0.17555253207683563, Accuracy: 0.8404760237317532\n",
      "Iteration: 28480, Loss: 0.094232477247715, Accuracy: 0.8323571014916524\n",
      "Iteration: 28544, Loss: 0.09178170561790466, Accuracy: 0.8461881467374042\n",
      "Iteration: 28608, Loss: 0.06999441236257553, Accuracy: 0.849786325241439\n",
      "Iteration: 28672, Loss: 0.03339438512921333, Accuracy: 0.8441815119003877\n",
      "Iteration: 28736, Loss: 0.02123217098414898, Accuracy: 0.8409718560287729\n",
      "Iteration: 28800, Loss: 0.009730679914355278, Accuracy: 0.8477936256676912\n",
      "Iteration: 28864, Loss: 0.0924675241112709, Accuracy: 0.8524676158558577\n",
      "Iteration: 28928, Loss: 0.08066481351852417, Accuracy: 0.8514687496935949\n",
      "Iteration: 28992, Loss: 0.088048554956913, Accuracy: 0.8350231650983915\n",
      "Iteration: 29056, Loss: 0.0843895971775055, Accuracy: 0.8496648485888727\n",
      "Iteration: 29120, Loss: 0.07013338804244995, Accuracy: 0.8532386633451097\n",
      "Iteration: 29184, Loss: 0.08660048246383667, Accuracy: 0.8517390183988027\n",
      "Iteration: 29248, Loss: 0.08383595198392868, Accuracy: 0.85523678077152\n",
      "Iteration: 29312, Loss: 0.10200020670890808, Accuracy: 0.831050290085841\n",
      "Iteration: 29376, Loss: 0.023815633729100227, Accuracy: 0.8498351664165966\n",
      "Iteration: 29440, Loss: 0.07649632543325424, Accuracy: 0.8512448381516151\n",
      "Iteration: 29504, Loss: 0.098859041929245, Accuracy: 0.8517959076561965\n",
      "Iteration: 29568, Loss: 0.08118881285190582, Accuracy: 0.8442439585924149\n",
      "Iteration: 29632, Loss: 0.07408823817968369, Accuracy: 0.8523874278180301\n",
      "Iteration: 29696, Loss: 0.007019018288701773, Accuracy: 0.8610888400580734\n",
      "Iteration: 29760, Loss: 0.11422457545995712, Accuracy: 0.8630707353004254\n",
      "Iteration: 29824, Loss: 0.004563028458505869, Accuracy: 0.8592792651616037\n",
      "Iteration: 29888, Loss: 0.06606217473745346, Accuracy: 0.8647805759101175\n",
      "Iteration: 29952, Loss: 0.09117881208658218, Accuracy: 0.8592116638901643\n",
      "Iteration: 30016, Loss: 0.015127338469028473, Accuracy: 0.8625534950988367\n",
      "Iteration: 30080, Loss: 0.007153091486543417, Accuracy: 0.8677080589113757\n",
      "Iteration: 30144, Loss: 0.10154464840888977, Accuracy: 0.8569051281665452\n",
      "Iteration: 30208, Loss: 0.004403611179441214, Accuracy: 0.865234509925358\n",
      "Iteration: 30272, Loss: 0.0077343652956187725, Accuracy: 0.8549065783154219\n",
      "Iteration: 30336, Loss: 0.10042404383420944, Accuracy: 0.8549668305786327\n",
      "Iteration: 30400, Loss: 0.003699131077155471, Accuracy: 0.8680521424394101\n",
      "Iteration: 30464, Loss: 0.0060873087495565414, Accuracy: 0.8721390927676111\n",
      "Iteration: 30528, Loss: 0.07004248350858688, Accuracy: 0.8667274345643818\n",
      "Iteration: 30592, Loss: 0.0031857409048825502, Accuracy: 0.8637190347071737\n",
      "Iteration: 30656, Loss: 0.09195956587791443, Accuracy: 0.8712303763022646\n",
      "Iteration: 30720, Loss: 0.10416028648614883, Accuracy: 0.8634394448599778\n",
      "Iteration: 30784, Loss: 0.08912446349859238, Accuracy: 0.873941102239769\n",
      "Iteration: 30848, Loss: 0.10341581702232361, Accuracy: 0.8644580008112825\n",
      "Iteration: 30912, Loss: 0.004279032349586487, Accuracy: 0.8706363512901589\n",
      "Iteration: 30976, Loss: 0.010052324272692204, Accuracy: 0.8666354474262334\n",
      "Iteration: 31040, Loss: 0.007701733615249395, Accuracy: 0.8668209692696109\n",
      "Iteration: 31104, Loss: 0.0029896118212491274, Accuracy: 0.8702553809853271\n",
      "Iteration: 31168, Loss: 0.07852653414011002, Accuracy: 0.8738433971302584\n",
      "Iteration: 31232, Loss: 0.10130862146615982, Accuracy: 0.8740610662498511\n",
      "Iteration: 31296, Loss: 0.0847519263625145, Accuracy: 0.8627611850388348\n",
      "Iteration: 31360, Loss: 0.07947804778814316, Accuracy: 0.8745952625758946\n",
      "Iteration: 31424, Loss: 0.003970438614487648, Accuracy: 0.8750564203946851\n",
      "Iteration: 31488, Loss: 0.05533008277416229, Accuracy: 0.8728914434323087\n",
      "Iteration: 31552, Loss: 0.08781513571739197, Accuracy: 0.8732551786815748\n",
      "Iteration: 31616, Loss: 0.07604479789733887, Accuracy: 0.8732933215796947\n",
      "Iteration: 31680, Loss: 0.035516489297151566, Accuracy: 0.8699646136956289\n",
      "Iteration: 31744, Loss: 0.004665575455874205, Accuracy: 0.8699826187221333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 31808, Loss: 0.09699111431837082, Accuracy: 0.8794069018331356\n",
      "Iteration: 31872, Loss: 0.004217845853418112, Accuracy: 0.8590570725500584\n",
      "Iteration: 31936, Loss: 0.09514421224594116, Accuracy: 0.8752133611706086\n",
      "Iteration: 32000, Loss: 0.011045608669519424, Accuracy: 0.8784663825063035\n",
      "Iteration: 32064, Loss: 0.09099312871694565, Accuracy: 0.8810301178600639\n",
      "Iteration: 32128, Loss: 0.10115300863981247, Accuracy: 0.8732359760324471\n",
      "Iteration: 32192, Loss: 0.0668034628033638, Accuracy: 0.8706466267467476\n",
      "Iteration: 32256, Loss: 0.01395141426473856, Accuracy: 0.8717877112212591\n",
      "Iteration: 32320, Loss: 0.005502570420503616, Accuracy: 0.8840224459418096\n",
      "Iteration: 32384, Loss: 0.0035609055776149035, Accuracy: 0.8846961979288608\n",
      "Iteration: 32448, Loss: 0.002954033436253667, Accuracy: 0.8805909326765686\n",
      "Iteration: 32512, Loss: 0.0020012513268738985, Accuracy: 0.887639747641515\n",
      "Iteration: 32576, Loss: 0.09336206316947937, Accuracy: 0.8863848887267523\n",
      "Iteration: 32640, Loss: 0.0029176489915698767, Accuracy: 0.8854316434008069\n",
      "Iteration: 32704, Loss: 0.06802157312631607, Accuracy: 0.8860587270464748\n",
      "Iteration: 32768, Loss: 0.07625778764486313, Accuracy: 0.8835019382531755\n",
      "Iteration: 32832, Loss: 0.063896544277668, Accuracy: 0.879057350277435\n",
      "Iteration: 32896, Loss: 0.10123156756162643, Accuracy: 0.8803261721041054\n",
      "Iteration: 32960, Loss: 0.10358325392007828, Accuracy: 0.8877017992781475\n",
      "Iteration: 33024, Loss: 0.05072900280356407, Accuracy: 0.8896229259262327\n",
      "Iteration: 33088, Loss: 0.005456952378153801, Accuracy: 0.8860184950463008\n",
      "Iteration: 33152, Loss: 0.08037864416837692, Accuracy: 0.8656011977000162\n",
      "Iteration: 33216, Loss: 0.004021256696432829, Accuracy: 0.8738440162269399\n",
      "Iteration: 33280, Loss: 0.08822214603424072, Accuracy: 0.8809716484684031\n",
      "Iteration: 33344, Loss: 0.0887206569314003, Accuracy: 0.8847844053525478\n",
      "Iteration: 33408, Loss: 0.0982232317328453, Accuracy: 0.8788852471043356\n",
      "Iteration: 33472, Loss: 0.11861906200647354, Accuracy: 0.8812068376573734\n",
      "Iteration: 33536, Loss: 0.003851083107292652, Accuracy: 0.8665118929056916\n",
      "Iteration: 33600, Loss: 0.10595845431089401, Accuracy: 0.8644985125865787\n",
      "Iteration: 33664, Loss: 0.1517423391342163, Accuracy: 0.878463857807219\n",
      "Iteration: 33728, Loss: 0.0025178438518196344, Accuracy: 0.8822137804527301\n",
      "Iteration: 33792, Loss: 0.1018589660525322, Accuracy: 0.8631004421913531\n",
      "Iteration: 33856, Loss: 0.10027942061424255, Accuracy: 0.8853621561720502\n",
      "Iteration: 33920, Loss: 0.09032528847455978, Accuracy: 0.8740657234739047\n",
      "Iteration: 33984, Loss: 0.004806772340089083, Accuracy: 0.8612371700291988\n",
      "Iteration: 34048, Loss: 0.0022049855906516314, Accuracy: 0.8795106846664567\n",
      "Iteration: 34112, Loss: 0.002195400418713689, Accuracy: 0.8850465847935993\n",
      "Iteration: 34176, Loss: 0.0757484883069992, Accuracy: 0.8888898748555221\n",
      "Iteration: 34240, Loss: 0.0020207297056913376, Accuracy: 0.8802622813673224\n",
      "Iteration: 34304, Loss: 0.0964842140674591, Accuracy: 0.8906708831491414\n",
      "Iteration: 34368, Loss: 0.0029673671815544367, Accuracy: 0.8867334004316945\n",
      "Iteration: 34432, Loss: 0.04564274474978447, Accuracy: 0.8928644754050765\n",
      "Iteration: 34496, Loss: 0.09360960870981216, Accuracy: 0.8916362930031028\n",
      "Iteration: 34560, Loss: 0.004440669901669025, Accuracy: 0.8966000087093562\n",
      "Iteration: 34624, Loss: 0.045087795704603195, Accuracy: 0.8949457909329794\n",
      "Iteration: 34688, Loss: 0.002204485470429063, Accuracy: 0.8935553912888281\n",
      "Iteration: 34752, Loss: 0.008721515536308289, Accuracy: 0.8927041628630832\n",
      "Iteration: 34816, Loss: 0.001861613243818283, Accuracy: 0.885133775183931\n",
      "Iteration: 34880, Loss: 0.003881769487634301, Accuracy: 0.8798907798773143\n",
      "Iteration: 34944, Loss: 0.0023789654951542616, Accuracy: 0.8948622742318548\n",
      "Iteration: 35008, Loss: 0.12128034979104996, Accuracy: 0.8980500805191696\n",
      "Iteration: 35072, Loss: 0.12254250794649124, Accuracy: 0.8842234201147221\n",
      "Iteration: 35136, Loss: 0.08390208333730698, Accuracy: 0.8986342176795006\n",
      "Iteration: 35200, Loss: 0.0015793839702382684, Accuracy: 0.8942028138844762\n",
      "Iteration: 35264, Loss: 0.0012044963659718633, Accuracy: 0.8922270422626752\n",
      "Iteration: 35328, Loss: 0.08535919338464737, Accuracy: 0.8772457780432887\n",
      "Iteration: 35392, Loss: 0.00235096481628716, Accuracy: 0.8734107599593699\n",
      "Iteration: 35456, Loss: 0.002322335261851549, Accuracy: 0.8794664450106211\n",
      "Iteration: 35520, Loss: 0.07653036713600159, Accuracy: 0.8743187478976324\n",
      "Iteration: 35584, Loss: 0.07557617127895355, Accuracy: 0.8757919438066892\n",
      "Iteration: 35648, Loss: 0.42858049273490906, Accuracy: 0.8905642325698864\n",
      "Iteration: 35712, Loss: 0.07670821994543076, Accuracy: 0.8951516360102687\n",
      "Iteration: 35776, Loss: 0.05049392953515053, Accuracy: 0.8962169404549059\n",
      "Iteration: 35840, Loss: 0.0439935140311718, Accuracy: 0.8866697180492338\n",
      "Iteration: 35904, Loss: 0.07888486236333847, Accuracy: 0.8914345171069726\n",
      "Iteration: 35968, Loss: 0.09415262937545776, Accuracy: 0.8891872951062396\n",
      "Iteration: 36032, Loss: 0.0009294726769439876, Accuracy: 0.887812900240533\n",
      "Iteration: 36096, Loss: 0.031802643090486526, Accuracy: 0.9057982229278423\n",
      "Iteration: 36160, Loss: 0.02809849940240383, Accuracy: 0.9124514734430704\n",
      "Iteration: 36224, Loss: 0.0008262799237854779, Accuracy: 0.8989836362597998\n",
      "Iteration: 36288, Loss: 0.0020165324676781893, Accuracy: 0.8940765137667768\n",
      "Iteration: 36352, Loss: 0.002177444053813815, Accuracy: 0.8998362608544994\n",
      "Iteration: 36416, Loss: 0.0020801909267902374, Accuracy: 0.9046848591824528\n",
      "Iteration: 36480, Loss: 0.022774601355195045, Accuracy: 0.89765459834598\n",
      "Iteration: 36544, Loss: 0.002976890653371811, Accuracy: 0.9021055585471913\n",
      "Iteration: 36608, Loss: 0.00240704626776278, Accuracy: 0.8906687000417151\n",
      "Iteration: 36672, Loss: 0.002145066624507308, Accuracy: 0.9022024116420653\n",
      "Iteration: 36736, Loss: 0.0020639991853386164, Accuracy: 0.9032287631125655\n",
      "Iteration: 36800, Loss: 0.09066281467676163, Accuracy: 0.9092872554028872\n",
      "Iteration: 36864, Loss: 0.055766377598047256, Accuracy: 0.9032692426408175\n",
      "Iteration: 36928, Loss: 0.0025773898232728243, Accuracy: 0.9085852532007266\n",
      "Iteration: 36992, Loss: 0.000683500140439719, Accuracy: 0.9054468654212542\n",
      "Iteration: 37056, Loss: 0.0696646049618721, Accuracy: 0.901054517540615\n",
      "Iteration: 37120, Loss: 0.0021353051997721195, Accuracy: 0.9069631284219213\n",
      "Iteration: 37184, Loss: 0.001910973689518869, Accuracy: 0.8986283630656544\n",
      "Iteration: 37248, Loss: 0.0016748443013057113, Accuracy: 0.9097345875634346\n",
      "Iteration: 37312, Loss: 0.186648890376091, Accuracy: 0.8871920161182061\n",
      "Iteration: 37376, Loss: 0.0013818981824442744, Accuracy: 0.9074390478781424\n",
      "Iteration: 37440, Loss: 0.1518051028251648, Accuracy: 0.903036345000146\n",
      "Iteration: 37504, Loss: 0.01933463104069233, Accuracy: 0.9068660025368445\n",
      "Iteration: 37568, Loss: 0.0014359914930537343, Accuracy: 0.9029409422946628\n",
      "Iteration: 37632, Loss: 0.0016208345768973231, Accuracy: 0.9002277358958963\n",
      "Iteration: 37696, Loss: 0.0017752902349457145, Accuracy: 0.8869647996325511\n",
      "Iteration: 37760, Loss: 0.001515580341219902, Accuracy: 0.907290213071974\n",
      "Iteration: 37824, Loss: 0.0015489673241972923, Accuracy: 0.9089500767586287\n",
      "Iteration: 37888, Loss: 0.11508762091398239, Accuracy: 0.9143425821675919\n",
      "Iteration: 37952, Loss: 0.07965048402547836, Accuracy: 0.9184985045867506\n",
      "Iteration: 38016, Loss: 0.10438146442174911, Accuracy: 0.9146233644860331\n",
      "Iteration: 38080, Loss: 0.0015052111120894551, Accuracy: 0.8922734619991388\n",
      "Iteration: 38144, Loss: 0.06368785351514816, Accuracy: 0.9180362026963849\n",
      "Iteration: 38208, Loss: 0.015937956050038338, Accuracy: 0.9056699507927988\n",
      "Iteration: 38272, Loss: 0.0019344445317983627, Accuracy: 0.9015133195498493\n",
      "Iteration: 38336, Loss: 0.09718788415193558, Accuracy: 0.9143450143747032\n",
      "Iteration: 38400, Loss: 0.01922956109046936, Accuracy: 0.9097368907823693\n",
      "Iteration: 38464, Loss: 0.0005401606322266161, Accuracy: 0.9172748349519679\n",
      "Iteration: 38528, Loss: 0.09181668609380722, Accuracy: 0.9201055473968154\n",
      "Iteration: 38592, Loss: 0.08434499055147171, Accuracy: 0.9187797822232824\n",
      "Iteration: 38656, Loss: 0.008771833032369614, Accuracy: 0.9198664292925969\n",
      "Iteration: 38720, Loss: 0.0013615897623822093, Accuracy: 0.9153743159113219\n",
      "Iteration: 38784, Loss: 0.0820230022072792, Accuracy: 0.9168782563501736\n",
      "Iteration: 38848, Loss: 0.00032861597719602287, Accuracy: 0.9034456813678844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 38912, Loss: 0.0002854808699339628, Accuracy: 0.9209772250032984\n",
      "Iteration: 38976, Loss: 0.0008201599703170359, Accuracy: 0.9144231124664657\n",
      "Iteration: 39040, Loss: 0.07368097454309464, Accuracy: 0.9159386450628517\n",
      "Iteration: 39104, Loss: 0.05778239294886589, Accuracy: 0.9123178695590468\n",
      "Iteration: 39168, Loss: 0.08915529400110245, Accuracy: 0.9140305397158954\n",
      "Iteration: 39232, Loss: 0.003517713164910674, Accuracy: 0.9145839199190959\n",
      "Iteration: 39296, Loss: 0.02881164848804474, Accuracy: 0.9167110371199669\n",
      "Iteration: 39360, Loss: 0.008928036317229271, Accuracy: 0.898822068789741\n",
      "Iteration: 39424, Loss: 0.07502143830060959, Accuracy: 0.9200277521158569\n",
      "Iteration: 39488, Loss: 0.041076961904764175, Accuracy: 0.9163402243575547\n",
      "Iteration: 39552, Loss: 0.09798262268304825, Accuracy: 0.9140434079890838\n",
      "Iteration: 39616, Loss: 0.09360060840845108, Accuracy: 0.925054090548656\n",
      "Iteration: 39680, Loss: 0.01173565536737442, Accuracy: 0.8974441093887435\n",
      "Iteration: 39744, Loss: 0.07727956026792526, Accuracy: 0.924536232065293\n",
      "Iteration: 39808, Loss: 0.01709798537194729, Accuracy: 0.9220086462300969\n",
      "Iteration: 39872, Loss: 0.00032256977283395827, Accuracy: 0.9241364548506681\n",
      "Iteration: 39936, Loss: 0.0008889308082871139, Accuracy: 0.9110326784284553\n",
      "Iteration: 40000, Loss: 0.0009280501981265843, Accuracy: 0.9106421320902882\n",
      "Iteration: 40064, Loss: 0.0010412404080852866, Accuracy: 0.8989124114159495\n",
      "Iteration: 40128, Loss: 0.0004431112902238965, Accuracy: 0.9285626647615572\n",
      "Iteration: 40192, Loss: 0.004198590759187937, Accuracy: 0.9283663576497929\n",
      "Iteration: 40256, Loss: 0.07625029236078262, Accuracy: 0.913367012530216\n",
      "Iteration: 40320, Loss: 0.06796561926603317, Accuracy: 0.9224683850625297\n",
      "Iteration: 40384, Loss: 0.0006470638909377158, Accuracy: 0.9257669518556213\n",
      "Iteration: 40448, Loss: 0.08040984719991684, Accuracy: 0.9221609102532966\n",
      "Iteration: 40512, Loss: 0.0011995281092822552, Accuracy: 0.9224148089851951\n",
      "Iteration: 40576, Loss: 0.0006023976020514965, Accuracy: 0.927022361123818\n",
      "Iteration: 40640, Loss: 0.08454882353544235, Accuracy: 0.9094618075032486\n",
      "Iteration: 40704, Loss: 0.09796091914176941, Accuracy: 0.9280639484786661\n",
      "Iteration: 40768, Loss: 0.00021553078840952367, Accuracy: 0.9322433582565282\n",
      "Iteration: 40832, Loss: 0.0007011869456619024, Accuracy: 0.928697669703979\n",
      "Iteration: 40896, Loss: 0.0003499175363685936, Accuracy: 0.925808353262255\n",
      "Iteration: 40960, Loss: 0.07967201620340347, Accuracy: 0.9245137840043753\n",
      "Iteration: 41024, Loss: 0.00028117248439230025, Accuracy: 0.9275813575950451\n",
      "Iteration: 41088, Loss: 0.0009872358059510589, Accuracy: 0.9328299107291969\n",
      "Iteration: 41152, Loss: 0.0007393921841867268, Accuracy: 0.931530789937824\n",
      "Iteration: 41216, Loss: 0.07573998719453812, Accuracy: 0.9275737981370185\n",
      "Iteration: 41280, Loss: 0.005459396634250879, Accuracy: 0.9188263430260122\n",
      "Iteration: 41344, Loss: 0.0011476923245936632, Accuracy: 0.9287939407804515\n",
      "Iteration: 41408, Loss: 0.00027071009390056133, Accuracy: 0.9254696649295511\n",
      "Iteration: 41472, Loss: 0.0002621385792735964, Accuracy: 0.9184227894147625\n",
      "Iteration: 41536, Loss: 0.0002512761566322297, Accuracy: 0.9339968920685351\n",
      "Iteration: 41600, Loss: 0.10289659351110458, Accuracy: 0.9180625889566727\n",
      "Iteration: 41664, Loss: 0.10008769482374191, Accuracy: 0.9172208021918777\n",
      "Iteration: 41728, Loss: 0.00023773541033733636, Accuracy: 0.9177380846085725\n",
      "Iteration: 41792, Loss: 0.08126088231801987, Accuracy: 0.922132139428868\n",
      "Iteration: 41856, Loss: 0.07021384686231613, Accuracy: 0.9251946131116711\n",
      "Iteration: 41920, Loss: 0.000789535406511277, Accuracy: 0.9305680804682197\n",
      "Iteration: 41984, Loss: 0.09255654364824295, Accuracy: 0.9238155322673265\n",
      "Iteration: 42048, Loss: 0.0011266154469922185, Accuracy: 0.9274678384099388\n",
      "Iteration: 42112, Loss: 0.00028232179465703666, Accuracy: 0.92116030890611\n",
      "Iteration: 42176, Loss: 0.007489915471524, Accuracy: 0.9133025409682887\n",
      "Iteration: 42240, Loss: 0.0020461787935346365, Accuracy: 0.9159374919545371\n",
      "Iteration: 42304, Loss: 0.07633129507303238, Accuracy: 0.9309529530728469\n",
      "Iteration: 42368, Loss: 0.000763758784160018, Accuracy: 0.9281897822656902\n",
      "Iteration: 42432, Loss: 0.08767599612474442, Accuracy: 0.9168388155812863\n",
      "Iteration: 42496, Loss: 0.008957960642874241, Accuracy: 0.9255411390186055\n",
      "Iteration: 42560, Loss: 0.0004081290680915117, Accuracy: 0.9313661268242868\n",
      "Iteration: 42624, Loss: 0.004196817986667156, Accuracy: 0.9253660989488708\n",
      "Iteration: 42688, Loss: 0.08194155991077423, Accuracy: 0.933836344309384\n",
      "Iteration: 42752, Loss: 0.0002564833266660571, Accuracy: 0.9355169021582697\n",
      "Iteration: 42816, Loss: 0.010045009665191174, Accuracy: 0.9334916073421482\n",
      "Iteration: 42880, Loss: 0.0371781550347805, Accuracy: 0.9292472340457607\n",
      "Iteration: 42944, Loss: 0.00097581249428913, Accuracy: 0.9360400717996527\n",
      "Iteration: 43008, Loss: 0.015276987105607986, Accuracy: 0.9233469720784342\n",
      "Iteration: 43072, Loss: 0.09084974974393845, Accuracy: 0.9336743305029813\n",
      "Iteration: 43136, Loss: 0.0730714350938797, Accuracy: 0.9371502739813877\n",
      "Iteration: 43200, Loss: 0.000907677283976227, Accuracy: 0.9330355782149127\n",
      "Iteration: 43264, Loss: 0.08907241374254227, Accuracy: 0.9306201260624221\n",
      "Iteration: 43328, Loss: 0.0010637593222782016, Accuracy: 0.8940923348127399\n",
      "Iteration: 43392, Loss: 0.00022303586592897773, Accuracy: 0.9337231208046433\n",
      "Iteration: 43456, Loss: 0.0014454055344685912, Accuracy: 0.9248497422668152\n",
      "Iteration: 43520, Loss: 0.0032625561580061913, Accuracy: 0.9337460328242742\n",
      "Iteration: 43584, Loss: 0.0002681732003111392, Accuracy: 0.9337937460222747\n",
      "Iteration: 43648, Loss: 0.10271813720464706, Accuracy: 0.9269576424412662\n",
      "Iteration: 43712, Loss: 0.006770930718630552, Accuracy: 0.9346594882808859\n",
      "Iteration: 43776, Loss: 0.0007287287735380232, Accuracy: 0.937280395446578\n",
      "Iteration: 43840, Loss: 0.0003509644593577832, Accuracy: 0.9267415634094505\n",
      "Iteration: 43904, Loss: 0.0008282479248009622, Accuracy: 0.9376952620514203\n",
      "Iteration: 43968, Loss: 0.0001776434510247782, Accuracy: 0.9371502107969718\n",
      "Iteration: 44032, Loss: 0.0026928549632430077, Accuracy: 0.9336599542875774\n",
      "Iteration: 44096, Loss: 0.0008340750355273485, Accuracy: 0.934337779704947\n",
      "Iteration: 44160, Loss: 0.00017364441009704024, Accuracy: 0.9240523733169539\n",
      "Iteration: 44224, Loss: 0.0727473646402359, Accuracy: 0.937018178330618\n",
      "Iteration: 44288, Loss: 0.00091956602409482, Accuracy: 0.9313325510156574\n",
      "Iteration: 44352, Loss: 0.0021029470954090357, Accuracy: 0.9211628557677614\n",
      "Iteration: 44416, Loss: 0.0005736648454330862, Accuracy: 0.9228328509489074\n",
      "Iteration: 44480, Loss: 0.0002604419132694602, Accuracy: 0.9344517064018873\n",
      "Iteration: 44544, Loss: 0.0003244298277422786, Accuracy: 0.9255442957946798\n",
      "Iteration: 44608, Loss: 0.07943668216466904, Accuracy: 0.9206341371900635\n",
      "Iteration: 44672, Loss: 0.06451186537742615, Accuracy: 0.9308110763377044\n",
      "Iteration: 44736, Loss: 0.002124730497598648, Accuracy: 0.9317043577029835\n",
      "Iteration: 44800, Loss: 0.0687151774764061, Accuracy: 0.926355138013605\n",
      "Iteration: 44864, Loss: 0.0001892220025183633, Accuracy: 0.9096454773680307\n",
      "Iteration: 44928, Loss: 0.09992512315511703, Accuracy: 0.9366912047698861\n",
      "Iteration: 44992, Loss: 0.0007926792022772133, Accuracy: 0.936960384962731\n",
      "Iteration: 45056, Loss: 0.0009948756778612733, Accuracy: 0.9257155702653108\n",
      "Iteration: 45120, Loss: 0.09514956921339035, Accuracy: 0.9308104821830057\n",
      "Iteration: 45184, Loss: 0.0026827894616872072, Accuracy: 0.9361415877210675\n",
      "Iteration: 45248, Loss: 0.0029552460182458162, Accuracy: 0.9378378274122952\n",
      "Iteration: 45312, Loss: 0.07227543741464615, Accuracy: 0.9303309464885388\n",
      "Iteration: 45376, Loss: 0.00047263226588256657, Accuracy: 0.9210115915338974\n",
      "Iteration: 45440, Loss: 0.0007876834715716541, Accuracy: 0.934267316290061\n",
      "Iteration: 45504, Loss: 0.0002963004226330668, Accuracy: 0.9373386937804753\n",
      "Iteration: 45568, Loss: 0.00012693922326434404, Accuracy: 0.9215901564457454\n",
      "Iteration: 45632, Loss: 0.0757874920964241, Accuracy: 0.9258340175147168\n",
      "Iteration: 45696, Loss: 0.0005802839295938611, Accuracy: 0.9303454626351595\n",
      "Iteration: 45760, Loss: 0.0027628641109913588, Accuracy: 0.939171126083238\n",
      "Iteration: 45824, Loss: 0.07573438435792923, Accuracy: 0.9334485055442201\n",
      "Iteration: 45888, Loss: 0.0017537666717544198, Accuracy: 0.9241813141125022\n",
      "Iteration: 45952, Loss: 0.1465662717819214, Accuracy: 0.9317220887023723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 46016, Loss: 0.00018532300600782037, Accuracy: 0.9368431181064807\n",
      "Iteration: 46080, Loss: 0.08001083880662918, Accuracy: 0.9397072730935179\n",
      "Iteration: 46144, Loss: 0.010583914816379547, Accuracy: 0.9401489392184885\n",
      "Iteration: 46208, Loss: 0.0030149321537464857, Accuracy: 0.9377419768861728\n",
      "Iteration: 46272, Loss: 0.001486137043684721, Accuracy: 0.9332737302174792\n",
      "Iteration: 46336, Loss: 0.0004892557626590133, Accuracy: 0.9373740086739417\n",
      "Iteration: 46400, Loss: 0.0999654158949852, Accuracy: 0.9387012546067126\n",
      "Iteration: 46464, Loss: 0.00039853298221714795, Accuracy: 0.9418875681294594\n",
      "Iteration: 46528, Loss: 0.0004399484023451805, Accuracy: 0.9408903022267623\n",
      "Iteration: 46592, Loss: 0.0009638009942136705, Accuracy: 0.9410785581712844\n",
      "Iteration: 46656, Loss: 0.0004835207655560225, Accuracy: 0.9401283060724381\n",
      "Iteration: 46720, Loss: 0.0009479733998887241, Accuracy: 0.9382610303000547\n",
      "Iteration: 46784, Loss: 0.07153821736574173, Accuracy: 0.9403208056319272\n",
      "Iteration: 46848, Loss: 0.00013148777361493558, Accuracy: 0.9365490475611296\n",
      "Iteration: 46912, Loss: 0.07075607031583786, Accuracy: 0.9354132712323917\n",
      "Iteration: 46976, Loss: 0.0073229242116212845, Accuracy: 0.9323961086920463\n",
      "Iteration: 47040, Loss: 0.0005533389048650861, Accuracy: 0.9403121357318014\n",
      "Iteration: 47104, Loss: 0.00016648194286972284, Accuracy: 0.9272870150889503\n",
      "Iteration: 47168, Loss: 0.0011967293685302138, Accuracy: 0.9416138636588585\n",
      "Iteration: 47232, Loss: 0.08272410184144974, Accuracy: 0.9328707064560149\n",
      "Iteration: 47296, Loss: 0.0005490021430887282, Accuracy: 0.9336403554916615\n",
      "Iteration: 47360, Loss: 0.08043558895587921, Accuracy: 0.936321477041929\n",
      "Iteration: 47424, Loss: 0.08635096997022629, Accuracy: 0.9429880015231902\n",
      "Iteration: 47488, Loss: 0.0004749227373395115, Accuracy: 0.9344451703509549\n",
      "Iteration: 47552, Loss: 0.07554659247398376, Accuracy: 0.9261182223417563\n",
      "Iteration: 47616, Loss: 0.0016540208598598838, Accuracy: 0.9367695299733896\n",
      "Iteration: 47680, Loss: 0.0001648877077968791, Accuracy: 0.9405717632471351\n",
      "Iteration: 47744, Loss: 0.0001875441666925326, Accuracy: 0.9372049939847784\n",
      "Iteration: 47808, Loss: 0.002259467961266637, Accuracy: 0.9425004258228\n",
      "Iteration: 47872, Loss: 0.07076498866081238, Accuracy: 0.932238225126639\n",
      "Iteration: 47936, Loss: 0.0004403644416015595, Accuracy: 0.9386988004407613\n",
      "Iteration: 48000, Loss: 0.08732378482818604, Accuracy: 0.9380916204827372\n",
      "Iteration: 48064, Loss: 0.002684303792193532, Accuracy: 0.9373318146244856\n",
      "Iteration: 48128, Loss: 0.0001291121734539047, Accuracy: 0.9391535656177439\n",
      "Iteration: 48192, Loss: 0.08506754785776138, Accuracy: 0.928819859676878\n",
      "Iteration: 48256, Loss: 0.06054055690765381, Accuracy: 0.9254874605248915\n",
      "Iteration: 48320, Loss: 0.00032531440956518054, Accuracy: 0.883314497754327\n",
      "Iteration: 48384, Loss: 0.07871628552675247, Accuracy: 0.9374603033502353\n",
      "Iteration: 48448, Loss: 0.00033563084434717894, Accuracy: 0.9415780807903502\n",
      "Iteration: 48512, Loss: 0.00020070612663403153, Accuracy: 0.9386961180862272\n",
      "Iteration: 48576, Loss: 0.0034442066680639982, Accuracy: 0.9355281101161381\n",
      "Iteration: 48640, Loss: 0.0012426412431523204, Accuracy: 0.9380691623955499\n",
      "Iteration: 48704, Loss: 0.04332404211163521, Accuracy: 0.9405151330429362\n",
      "Iteration: 48768, Loss: 0.0005611152737401426, Accuracy: 0.9331192410172662\n",
      "Iteration: 48832, Loss: 0.00020222090824972838, Accuracy: 0.9392899645172292\n",
      "Iteration: 48896, Loss: 0.0032449231948703527, Accuracy: 0.9436079523729859\n",
      "Iteration: 48960, Loss: 0.0014581038849428296, Accuracy: 0.942075258717523\n",
      "Iteration: 49024, Loss: 0.02704523503780365, Accuracy: 0.9424067865475081\n",
      "Iteration: 49088, Loss: 0.005946242716163397, Accuracy: 0.9368888684257399\n",
      "Iteration: 49152, Loss: 0.03287697583436966, Accuracy: 0.9421567500103265\n",
      "Iteration: 49216, Loss: 0.0017262473702430725, Accuracy: 0.9468016031314619\n",
      "Iteration: 49280, Loss: 0.004105334635823965, Accuracy: 0.9530493043421302\n",
      "Iteration: 49344, Loss: 0.0015198924811556935, Accuracy: 0.9447915686760098\n",
      "Iteration: 49408, Loss: 0.00031014796695671976, Accuracy: 0.9615814589196816\n",
      "Iteration: 49472, Loss: 0.0015375330112874508, Accuracy: 0.9543989887024509\n",
      "Iteration: 49536, Loss: 0.00015525320486631244, Accuracy: 0.9483052140712971\n",
      "Iteration: 49600, Loss: 0.0012652757577598095, Accuracy: 0.9585404203826329\n",
      "Iteration: 49664, Loss: 0.0005195398698560894, Accuracy: 0.9637962298584171\n",
      "Iteration: 49728, Loss: 0.0026625453028827906, Accuracy: 0.9566382072516717\n",
      "Iteration: 49792, Loss: 0.0002865330025088042, Accuracy: 0.9591355553420726\n",
      "Iteration: 49856, Loss: 0.007590638007968664, Accuracy: 0.9654522775817895\n",
      "Iteration: 49920, Loss: 0.0065251546911895275, Accuracy: 0.9704163996793795\n",
      "Saved fullModel_dr[4]_replicate3.model\n",
      "Saved W_dr[4]_replicate3.p\n",
      "4 0.9895833333333334 [0.984375, 0.984375, 1.0]\n",
      "Saved w_dr[4]_replicate3.p\n",
      "Replicate 3 completed\n",
      "Time elapsed: 703.03125 seconds\n",
      "Iteration: 64, Loss: 0.24622105062007904, Accuracy: 0.49919513054192066\n",
      "Iteration: 128, Loss: 0.24554292857646942, Accuracy: 0.5017242128960788\n",
      "Iteration: 192, Loss: 0.20804108679294586, Accuracy: 0.5288786254823208\n",
      "Iteration: 256, Loss: 0.17686422169208527, Accuracy: 0.5807420811615884\n",
      "Iteration: 320, Loss: 0.16480752825737, Accuracy: 0.6097781066782773\n",
      "Iteration: 384, Loss: 0.18146765232086182, Accuracy: 0.6215101666748524\n",
      "Iteration: 448, Loss: 0.1642269641160965, Accuracy: 0.6298424429260194\n",
      "Iteration: 512, Loss: 0.15717537701129913, Accuracy: 0.6342946169897914\n",
      "Iteration: 576, Loss: 0.1684214025735855, Accuracy: 0.6382529120892286\n",
      "Iteration: 640, Loss: 0.17196381092071533, Accuracy: 0.6411934732459486\n",
      "Iteration: 704, Loss: 0.17468710243701935, Accuracy: 0.6438417132012546\n",
      "Iteration: 768, Loss: 0.18159978091716766, Accuracy: 0.6453797896392643\n",
      "Iteration: 832, Loss: 0.17976927757263184, Accuracy: 0.6467927470803261\n",
      "Iteration: 896, Loss: 0.17146353423595428, Accuracy: 0.6485281740315259\n",
      "Iteration: 960, Loss: 0.1749792844057083, Accuracy: 0.6493802866898477\n",
      "Iteration: 1024, Loss: 0.17979735136032104, Accuracy: 0.6501989094540477\n",
      "Iteration: 1088, Loss: 0.17491967976093292, Accuracy: 0.6520301322452724\n",
      "Iteration: 1152, Loss: 0.17686939239501953, Accuracy: 0.6522846301086247\n",
      "Iteration: 1216, Loss: 0.17379039525985718, Accuracy: 0.6530169304460287\n",
      "Iteration: 1280, Loss: 0.17886744439601898, Accuracy: 0.6535393269732594\n",
      "Iteration: 1344, Loss: 0.1690041422843933, Accuracy: 0.6535550369881094\n",
      "Iteration: 1408, Loss: 0.16624745726585388, Accuracy: 0.6547766476869583\n",
      "Iteration: 1472, Loss: 0.1655341237783432, Accuracy: 0.6552720656618476\n",
      "Iteration: 1536, Loss: 0.16530148684978485, Accuracy: 0.6553211924619973\n",
      "Iteration: 1600, Loss: 0.16445313394069672, Accuracy: 0.6559300571680069\n",
      "Iteration: 1664, Loss: 0.18670426309108734, Accuracy: 0.6478667939081788\n",
      "Iteration: 1728, Loss: 0.1643480360507965, Accuracy: 0.6545138573274016\n",
      "Iteration: 1792, Loss: 0.17218302190303802, Accuracy: 0.6559544396586716\n",
      "Iteration: 1856, Loss: 0.1660066395998001, Accuracy: 0.6564012048766017\n",
      "Iteration: 1920, Loss: 0.17108114063739777, Accuracy: 0.6571903452277184\n",
      "Iteration: 1984, Loss: 0.1621602177619934, Accuracy: 0.6573133915662766\n",
      "Iteration: 2048, Loss: 0.17205524444580078, Accuracy: 0.6574829500168562\n",
      "Iteration: 2112, Loss: 0.16568544507026672, Accuracy: 0.6579064135439694\n",
      "Iteration: 2176, Loss: 0.16567985713481903, Accuracy: 0.6583842085674405\n",
      "Iteration: 2240, Loss: 0.17154236137866974, Accuracy: 0.6586950914934278\n",
      "Iteration: 2304, Loss: 0.1680210828781128, Accuracy: 0.65856470214203\n",
      "Iteration: 2368, Loss: 0.16617299616336823, Accuracy: 0.6588703175075352\n",
      "Iteration: 2432, Loss: 0.16713522374629974, Accuracy: 0.6592201832681894\n",
      "Iteration: 2496, Loss: 0.17005927860736847, Accuracy: 0.6590609909035265\n",
      "Iteration: 2560, Loss: 0.1681874543428421, Accuracy: 0.659603395499289\n",
      "Iteration: 2624, Loss: 0.16503296792507172, Accuracy: 0.6596460998989642\n",
      "Iteration: 2688, Loss: 0.16918939352035522, Accuracy: 0.6600152482278645\n",
      "Iteration: 2752, Loss: 0.1696559339761734, Accuracy: 0.6597506040707231\n",
      "Iteration: 2816, Loss: 0.16993026435375214, Accuracy: 0.660207899287343\n",
      "Iteration: 2880, Loss: 0.16903914511203766, Accuracy: 0.6604387955740094\n",
      "Iteration: 2944, Loss: 0.16796593368053436, Accuracy: 0.6605087528005242\n",
      "Iteration: 3008, Loss: 0.16504521667957306, Accuracy: 0.6604145136661828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3072, Loss: 0.16809944808483124, Accuracy: 0.6608495158143342\n",
      "Iteration: 3136, Loss: 0.16761361062526703, Accuracy: 0.6607520710676908\n",
      "Iteration: 3200, Loss: 0.16580504179000854, Accuracy: 0.6610149326734245\n",
      "Iteration: 3264, Loss: 0.1639130562543869, Accuracy: 0.6602299041114748\n",
      "Iteration: 3328, Loss: 0.16843773424625397, Accuracy: 0.6612644158303738\n",
      "Iteration: 3392, Loss: 0.16772182285785675, Accuracy: 0.661220848094672\n",
      "Iteration: 3456, Loss: 0.16974812746047974, Accuracy: 0.6610275628045201\n",
      "Iteration: 3520, Loss: 0.16865964233875275, Accuracy: 0.6613279837183654\n",
      "Iteration: 3584, Loss: 0.1661980003118515, Accuracy: 0.6611454021185637\n",
      "Iteration: 3648, Loss: 0.1668880581855774, Accuracy: 0.6615531076677144\n",
      "Iteration: 3712, Loss: 0.1653314232826233, Accuracy: 0.6606773841194808\n",
      "Iteration: 3776, Loss: 0.1758480668067932, Accuracy: 0.6587547683157027\n",
      "Iteration: 3840, Loss: 0.17018146812915802, Accuracy: 0.6616849796846509\n",
      "Iteration: 3904, Loss: 0.16483362019062042, Accuracy: 0.6598826618865132\n",
      "Iteration: 3968, Loss: 0.1686159372329712, Accuracy: 0.6619680444709957\n",
      "Iteration: 4032, Loss: 0.17009620368480682, Accuracy: 0.6623924993909895\n",
      "Iteration: 4096, Loss: 0.16640913486480713, Accuracy: 0.6619731313548982\n",
      "Iteration: 4160, Loss: 0.16958419978618622, Accuracy: 0.6619314840063453\n",
      "Iteration: 4224, Loss: 0.16325373947620392, Accuracy: 0.6623450890183449\n",
      "Iteration: 4288, Loss: 0.16853933036327362, Accuracy: 0.6624614163301885\n",
      "Iteration: 4352, Loss: 0.16648530960083008, Accuracy: 0.6624406008049846\n",
      "Iteration: 4416, Loss: 0.17020682990550995, Accuracy: 0.6625539697706699\n",
      "Iteration: 4480, Loss: 0.1665433943271637, Accuracy: 0.6624055462889373\n",
      "Iteration: 4544, Loss: 0.16885310411453247, Accuracy: 0.6622575777582824\n",
      "Iteration: 4608, Loss: 0.16690693795681, Accuracy: 0.6629403447732329\n",
      "Iteration: 4672, Loss: 0.16595739126205444, Accuracy: 0.6628527739085257\n",
      "Iteration: 4736, Loss: 0.16597233712673187, Accuracy: 0.6626722640357912\n",
      "Iteration: 4800, Loss: 0.17026905715465546, Accuracy: 0.6629086509346962\n",
      "Iteration: 4864, Loss: 0.16818659007549286, Accuracy: 0.6630880143493414\n",
      "Iteration: 4928, Loss: 0.1681545376777649, Accuracy: 0.6627483777701855\n",
      "Iteration: 4992, Loss: 0.16707436740398407, Accuracy: 0.6626997720450163\n",
      "Iteration: 5056, Loss: 0.16874070465564728, Accuracy: 0.6632253685966134\n",
      "Iteration: 5120, Loss: 0.17009860277175903, Accuracy: 0.6629633074626327\n",
      "Iteration: 5184, Loss: 0.16842196881771088, Accuracy: 0.6632507322356105\n",
      "Iteration: 5248, Loss: 0.16883398592472076, Accuracy: 0.6631642603315413\n",
      "Iteration: 5312, Loss: 0.16979284584522247, Accuracy: 0.6637253826484084\n",
      "Iteration: 5376, Loss: 0.16738493740558624, Accuracy: 0.6634687837213278\n",
      "Iteration: 5440, Loss: 0.16988418996334076, Accuracy: 0.6631178990937769\n",
      "Iteration: 5504, Loss: 0.1686650514602661, Accuracy: 0.6634810515679419\n",
      "Iteration: 5568, Loss: 0.16835658252239227, Accuracy: 0.663394152186811\n",
      "Iteration: 5632, Loss: 0.16845399141311646, Accuracy: 0.6634973241016269\n",
      "Iteration: 5696, Loss: 0.16712148487567902, Accuracy: 0.6634274730458856\n",
      "Iteration: 5760, Loss: 0.16883599758148193, Accuracy: 0.663474150467664\n",
      "Iteration: 5824, Loss: 0.1694014072418213, Accuracy: 0.6636604657396674\n",
      "Iteration: 5888, Loss: 0.16960889101028442, Accuracy: 0.6633950942195952\n",
      "Iteration: 5952, Loss: 0.1695934534072876, Accuracy: 0.6634970060549676\n",
      "Iteration: 6016, Loss: 0.16936075687408447, Accuracy: 0.6635561506263912\n",
      "Iteration: 6080, Loss: 0.1690431833267212, Accuracy: 0.6635433593764901\n",
      "Iteration: 6144, Loss: 0.1691083163022995, Accuracy: 0.6637606909498572\n",
      "Iteration: 6208, Loss: 0.16573373973369598, Accuracy: 0.6637079282663763\n",
      "Iteration: 6272, Loss: 0.1703590750694275, Accuracy: 0.6637534536421299\n",
      "Iteration: 6336, Loss: 0.16700653731822968, Accuracy: 0.6640606378205121\n",
      "Iteration: 6400, Loss: 0.16957199573516846, Accuracy: 0.6638767514377832\n",
      "Iteration: 6464, Loss: 0.16904932260513306, Accuracy: 0.6637394996359944\n",
      "Iteration: 6528, Loss: 0.16443662345409393, Accuracy: 0.6638095160014927\n",
      "Iteration: 6592, Loss: 0.170059934258461, Accuracy: 0.6639056145213544\n",
      "Iteration: 6656, Loss: 0.16654640436172485, Accuracy: 0.664254070725292\n",
      "Iteration: 6720, Loss: 0.16900783777236938, Accuracy: 0.663948155939579\n",
      "Iteration: 6784, Loss: 0.16693918406963348, Accuracy: 0.6641208156943321\n",
      "Iteration: 6848, Loss: 0.16520674526691437, Accuracy: 0.6643060203641653\n",
      "Iteration: 6912, Loss: 0.16776151955127716, Accuracy: 0.6642674254253507\n",
      "Iteration: 6976, Loss: 0.16743440926074982, Accuracy: 0.664302496239543\n",
      "Iteration: 7040, Loss: 0.16770301759243011, Accuracy: 0.6641535311937332\n",
      "Iteration: 7104, Loss: 0.16655467450618744, Accuracy: 0.6643589525483549\n",
      "Iteration: 7168, Loss: 0.16621409356594086, Accuracy: 0.6643747566267848\n",
      "Iteration: 7232, Loss: 0.16542606055736542, Accuracy: 0.6642873529344797\n",
      "Iteration: 7296, Loss: 0.16754214465618134, Accuracy: 0.6641873149201274\n",
      "Iteration: 7360, Loss: 0.16655333340168, Accuracy: 0.6638503144495189\n",
      "Iteration: 7424, Loss: 0.1682531237602234, Accuracy: 0.6644696136936545\n",
      "Iteration: 7488, Loss: 0.16857875883579254, Accuracy: 0.6645180936902761\n",
      "Iteration: 7552, Loss: 0.16843058168888092, Accuracy: 0.6645614579319954\n",
      "Iteration: 7616, Loss: 0.16887526214122772, Accuracy: 0.664485783316195\n",
      "Iteration: 7680, Loss: 0.1674695461988449, Accuracy: 0.6645531575195491\n",
      "Iteration: 7744, Loss: 0.16729383170604706, Accuracy: 0.6646616659127176\n",
      "Iteration: 7808, Loss: 0.16931448876857758, Accuracy: 0.6646894635632634\n",
      "Iteration: 7872, Loss: 0.16828949749469757, Accuracy: 0.66456976858899\n",
      "Iteration: 7936, Loss: 0.1699017733335495, Accuracy: 0.6649153479374945\n",
      "Iteration: 8000, Loss: 0.1717773675918579, Accuracy: 0.6644810377620161\n",
      "Iteration: 8064, Loss: 0.16817109286785126, Accuracy: 0.6647949633188546\n",
      "Iteration: 8128, Loss: 0.16751034557819366, Accuracy: 0.6647407794371247\n",
      "Iteration: 8192, Loss: 0.16980832815170288, Accuracy: 0.6644595982506871\n",
      "Iteration: 8256, Loss: 0.1666555404663086, Accuracy: 0.6647265926003456\n",
      "Iteration: 8320, Loss: 0.1686757206916809, Accuracy: 0.664582705590874\n",
      "Iteration: 8384, Loss: 0.16757893562316895, Accuracy: 0.6648325612768531\n",
      "Iteration: 8448, Loss: 0.16899634897708893, Accuracy: 0.6650339816696942\n",
      "Iteration: 8512, Loss: 0.1711990237236023, Accuracy: 0.664888187777251\n",
      "Iteration: 8576, Loss: 0.16735725104808807, Accuracy: 0.6649761949665844\n",
      "Iteration: 8640, Loss: 0.16863656044006348, Accuracy: 0.664598829112947\n",
      "Iteration: 8704, Loss: 0.16935451328754425, Accuracy: 0.6647501047700644\n",
      "Iteration: 8768, Loss: 0.16864436864852905, Accuracy: 0.6649224907159805\n",
      "Iteration: 8832, Loss: 0.16553543508052826, Accuracy: 0.6649028197862208\n",
      "Iteration: 8896, Loss: 0.17020529508590698, Accuracy: 0.6650946750305593\n",
      "Iteration: 8960, Loss: 0.16958798468112946, Accuracy: 0.6650212192907929\n",
      "Iteration: 9024, Loss: 0.17002637684345245, Accuracy: 0.6647453010082245\n",
      "Iteration: 9088, Loss: 0.1662033647298813, Accuracy: 0.6644594860263169\n",
      "Iteration: 9152, Loss: 0.16905038058757782, Accuracy: 0.6652409434318542\n",
      "Iteration: 9216, Loss: 0.16901864111423492, Accuracy: 0.6648017643019557\n",
      "Iteration: 9280, Loss: 0.16783373057842255, Accuracy: 0.6647219643928111\n",
      "Iteration: 9344, Loss: 0.16858161985874176, Accuracy: 0.6652025850489736\n",
      "Iteration: 9408, Loss: 0.16871923208236694, Accuracy: 0.665006463881582\n",
      "Iteration: 9472, Loss: 0.1694607138633728, Accuracy: 0.6649209619499743\n",
      "Iteration: 9536, Loss: 0.1666717529296875, Accuracy: 0.6650990727357566\n",
      "Iteration: 9600, Loss: 0.17013753950595856, Accuracy: 0.6651319894008338\n",
      "Iteration: 9664, Loss: 0.17016150057315826, Accuracy: 0.6650978922843933\n",
      "Iteration: 9728, Loss: 0.1686633676290512, Accuracy: 0.6652692318893969\n",
      "Iteration: 9792, Loss: 0.16784775257110596, Accuracy: 0.6649489826522768\n",
      "Iteration: 9856, Loss: 0.17117159068584442, Accuracy: 0.664816698525101\n",
      "Iteration: 9920, Loss: 0.16588757932186127, Accuracy: 0.6648411280475557\n",
      "Iteration: 9984, Loss: 0.16653268039226532, Accuracy: 0.6651488021016121\n",
      "Iteration: 10048, Loss: 0.1689131110906601, Accuracy: 0.6651166495867074\n",
      "Iteration: 10112, Loss: 0.16710220277309418, Accuracy: 0.6649778545834124\n",
      "Iteration: 10176, Loss: 0.1678098887205124, Accuracy: 0.6650974303483963\n",
      "Iteration: 10240, Loss: 0.1699911206960678, Accuracy: 0.6650489629246294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10304, Loss: 0.1681305319070816, Accuracy: 0.6652525928802788\n",
      "Iteration: 10368, Loss: 0.1680305451154709, Accuracy: 0.665209383238107\n",
      "Iteration: 10432, Loss: 0.16368772089481354, Accuracy: 0.6653277976438403\n",
      "Iteration: 10496, Loss: 0.16671232879161835, Accuracy: 0.6653783796355128\n",
      "Iteration: 10560, Loss: 0.1680934876203537, Accuracy: 0.6650479943491518\n",
      "Iteration: 10624, Loss: 0.16936159133911133, Accuracy: 0.6650173962116241\n",
      "Iteration: 10688, Loss: 0.16851140558719635, Accuracy: 0.6651784610003233\n",
      "Iteration: 10752, Loss: 0.16852007806301117, Accuracy: 0.6648668870329857\n",
      "Iteration: 10816, Loss: 0.16862107813358307, Accuracy: 0.6651442861184478\n",
      "Iteration: 10880, Loss: 0.16522276401519775, Accuracy: 0.6650724182836711\n",
      "Iteration: 10944, Loss: 0.16857147216796875, Accuracy: 0.6650731074623764\n",
      "Iteration: 11008, Loss: 0.16644775867462158, Accuracy: 0.6653773132711649\n",
      "Iteration: 11072, Loss: 0.16684174537658691, Accuracy: 0.6647567804902792\n",
      "Iteration: 11136, Loss: 0.16644515097141266, Accuracy: 0.664725910872221\n",
      "Iteration: 11200, Loss: 0.17359964549541473, Accuracy: 0.663687011692673\n",
      "Iteration: 11264, Loss: 0.16672392189502716, Accuracy: 0.6656241454184055\n",
      "Iteration: 11328, Loss: 0.17051976919174194, Accuracy: 0.6656380915082991\n",
      "Iteration: 11392, Loss: 0.1665164828300476, Accuracy: 0.6653071804903448\n",
      "Iteration: 11456, Loss: 0.16983090341091156, Accuracy: 0.6651986087672412\n",
      "Iteration: 11520, Loss: 0.16773973405361176, Accuracy: 0.665618518833071\n",
      "Iteration: 11584, Loss: 0.16647163033485413, Accuracy: 0.6654685512185097\n",
      "Iteration: 11648, Loss: 0.16670458018779755, Accuracy: 0.6652683853171766\n",
      "Iteration: 11712, Loss: 0.16728176176548004, Accuracy: 0.6653363686054945\n",
      "Iteration: 11776, Loss: 0.1709105521440506, Accuracy: 0.6563508315011859\n",
      "Iteration: 11840, Loss: 0.16816283762454987, Accuracy: 0.6656804517842829\n",
      "Iteration: 11904, Loss: 0.16928422451019287, Accuracy: 0.6653540339320898\n",
      "Iteration: 11968, Loss: 0.16496579349040985, Accuracy: 0.6656557857058942\n",
      "Iteration: 12032, Loss: 0.16474932432174683, Accuracy: 0.6656086831353605\n",
      "Iteration: 12096, Loss: 0.16813944280147552, Accuracy: 0.6657835366204381\n",
      "Iteration: 12160, Loss: 0.16779781877994537, Accuracy: 0.6654613148421049\n",
      "Iteration: 12224, Loss: 0.16636675596237183, Accuracy: 0.6656010397709906\n",
      "Iteration: 12288, Loss: 0.16587500274181366, Accuracy: 0.6654425486922264\n",
      "Iteration: 12352, Loss: 0.1657131463289261, Accuracy: 0.6652930956333876\n",
      "Iteration: 12416, Loss: 0.1692415475845337, Accuracy: 0.6655029030516744\n",
      "Iteration: 12480, Loss: 0.16716623306274414, Accuracy: 0.6654867711476982\n",
      "Iteration: 12544, Loss: 0.16793151199817657, Accuracy: 0.6652994705364108\n",
      "Iteration: 12608, Loss: 0.17010481655597687, Accuracy: 0.6650621187873185\n",
      "Iteration: 12672, Loss: 0.1682121604681015, Accuracy: 0.6648303386755288\n",
      "Iteration: 12736, Loss: 0.16497556865215302, Accuracy: 0.6644399878568947\n",
      "Iteration: 12800, Loss: 0.1690480262041092, Accuracy: 0.6645522173494101\n",
      "Iteration: 12864, Loss: 0.16572360694408417, Accuracy: 0.6643193569034338\n",
      "Iteration: 12928, Loss: 0.17169106006622314, Accuracy: 0.6640193928033113\n",
      "Iteration: 12992, Loss: 0.16898106038570404, Accuracy: 0.6633953675627708\n",
      "Iteration: 13056, Loss: 0.17210251092910767, Accuracy: 0.6644854112528265\n",
      "Iteration: 13120, Loss: 0.1685052514076233, Accuracy: 0.6639685402624309\n",
      "Iteration: 13184, Loss: 0.1635492891073227, Accuracy: 0.664973211940378\n",
      "Iteration: 13248, Loss: 0.1680825799703598, Accuracy: 0.6646575555205345\n",
      "Iteration: 13312, Loss: 0.17367857694625854, Accuracy: 0.6628348408266902\n",
      "Iteration: 13376, Loss: 0.16533225774765015, Accuracy: 0.6655887039378285\n",
      "Iteration: 13440, Loss: 0.16353556513786316, Accuracy: 0.6654978701844811\n",
      "Iteration: 13504, Loss: 0.1713445782661438, Accuracy: 0.6655558757483959\n",
      "Iteration: 13568, Loss: 0.171547994017601, Accuracy: 0.6652925158850849\n",
      "Iteration: 13632, Loss: 0.16188007593154907, Accuracy: 0.6652385350316763\n",
      "Iteration: 13696, Loss: 0.16698795557022095, Accuracy: 0.66538339946419\n",
      "Iteration: 13760, Loss: 0.16852331161499023, Accuracy: 0.66530328290537\n",
      "Iteration: 13824, Loss: 0.16683320701122284, Accuracy: 0.6602149163372815\n",
      "Iteration: 13888, Loss: 0.1682063788175583, Accuracy: 0.6654427675530314\n",
      "Iteration: 13952, Loss: 0.1663764864206314, Accuracy: 0.6642473693937063\n",
      "Iteration: 14016, Loss: 0.16647276282310486, Accuracy: 0.664059606846422\n",
      "Iteration: 14080, Loss: 0.1684400588274002, Accuracy: 0.6643063281662762\n",
      "Iteration: 14144, Loss: 0.16778413951396942, Accuracy: 0.6648186179809272\n",
      "Iteration: 14208, Loss: 0.16565173864364624, Accuracy: 0.6640973803587258\n",
      "Iteration: 14272, Loss: 0.16458530724048615, Accuracy: 0.6645034565590322\n",
      "Iteration: 14336, Loss: 0.16999705135822296, Accuracy: 0.6634377613663673\n",
      "Iteration: 14400, Loss: 0.17028570175170898, Accuracy: 0.664115899708122\n",
      "Iteration: 14464, Loss: 0.1555110663175583, Accuracy: 0.666281056124717\n",
      "Iteration: 14528, Loss: 0.17055028676986694, Accuracy: 0.6655889279209077\n",
      "Iteration: 14592, Loss: 0.16585306823253632, Accuracy: 0.6655087750405073\n",
      "Iteration: 14656, Loss: 0.15696550905704498, Accuracy: 0.6650873594917357\n",
      "Iteration: 14720, Loss: 0.1713946908712387, Accuracy: 0.6644490463659167\n",
      "Iteration: 14784, Loss: 0.14615310728549957, Accuracy: 0.665832796599716\n",
      "Iteration: 14848, Loss: 0.1635708063840866, Accuracy: 0.6661352808587253\n",
      "Iteration: 14912, Loss: 0.16042190790176392, Accuracy: 0.6700191535055637\n",
      "Iteration: 14976, Loss: 0.1577228456735611, Accuracy: 0.6710382206365466\n",
      "Iteration: 15040, Loss: 0.14514346420764923, Accuracy: 0.674664206802845\n",
      "Iteration: 15104, Loss: 0.202257439494133, Accuracy: 0.6806780961342156\n",
      "Iteration: 15168, Loss: 0.10679390281438828, Accuracy: 0.6873950716108084\n",
      "Iteration: 15232, Loss: 0.11547861248254776, Accuracy: 0.6937716053798795\n",
      "Iteration: 15296, Loss: 0.12013670057058334, Accuracy: 0.6871906735468656\n",
      "Iteration: 15360, Loss: 0.14799590408802032, Accuracy: 0.70123908855021\n",
      "Iteration: 15424, Loss: 0.13853798806667328, Accuracy: 0.7041390768717974\n",
      "Iteration: 15488, Loss: 0.18608249723911285, Accuracy: 0.7094588924665004\n",
      "Iteration: 15552, Loss: 0.06484092026948929, Accuracy: 0.7098262479994446\n",
      "Iteration: 15616, Loss: 0.0731615200638771, Accuracy: 0.7106356082949787\n",
      "Iteration: 15680, Loss: 0.12223299592733383, Accuracy: 0.7261556580197066\n",
      "Iteration: 15744, Loss: 0.2032291740179062, Accuracy: 0.7274111863225698\n",
      "Iteration: 15808, Loss: 0.24494993686676025, Accuracy: 0.7261579311452806\n",
      "Iteration: 15872, Loss: 0.13037709891796112, Accuracy: 0.741515182191506\n",
      "Iteration: 15936, Loss: 0.055641938000917435, Accuracy: 0.7316115198191255\n",
      "Iteration: 16000, Loss: 0.17433516681194305, Accuracy: 0.7376867076382041\n",
      "Iteration: 16064, Loss: 0.04195212200284004, Accuracy: 0.7511920121032745\n",
      "Iteration: 16128, Loss: 0.18895365297794342, Accuracy: 0.7604826644528657\n",
      "Iteration: 16192, Loss: 0.12553009390830994, Accuracy: 0.750956306932494\n",
      "Iteration: 16256, Loss: 0.07767526805400848, Accuracy: 0.7643182328902185\n",
      "Iteration: 16320, Loss: 0.07720903307199478, Accuracy: 0.7558568508829921\n",
      "Iteration: 16384, Loss: 0.05616568401455879, Accuracy: 0.7746259495615959\n",
      "Iteration: 16448, Loss: 0.038065891712903976, Accuracy: 0.7825095041189343\n",
      "Iteration: 16512, Loss: 0.03826657310128212, Accuracy: 0.7723475431557745\n",
      "Iteration: 16576, Loss: 0.06592653691768646, Accuracy: 0.7787509716581553\n",
      "Iteration: 16640, Loss: 0.11727264523506165, Accuracy: 0.7882104539312422\n",
      "Iteration: 16704, Loss: 0.043470848351716995, Accuracy: 0.7927106600254774\n",
      "Iteration: 16768, Loss: 0.028461240231990814, Accuracy: 0.7879109523491934\n",
      "Iteration: 16832, Loss: 0.050202157348394394, Accuracy: 0.7938476140843704\n",
      "Iteration: 16896, Loss: 0.16292785108089447, Accuracy: 0.8036986145889387\n",
      "Iteration: 16960, Loss: 0.027032995596528053, Accuracy: 0.7991933311568573\n",
      "Iteration: 17024, Loss: 0.1841861605644226, Accuracy: 0.8044247978832573\n",
      "Iteration: 17088, Loss: 0.17097018659114838, Accuracy: 0.8007792523130774\n",
      "Iteration: 17152, Loss: 0.020475177094340324, Accuracy: 0.8007771915290505\n",
      "Iteration: 17216, Loss: 0.11077918857336044, Accuracy: 0.7954626764403656\n",
      "Iteration: 17280, Loss: 0.01487687136977911, Accuracy: 0.7989014222985134\n",
      "Iteration: 17344, Loss: 0.04878316819667816, Accuracy: 0.7993726881686598\n",
      "Iteration: 17408, Loss: 0.024389013648033142, Accuracy: 0.7982673968654126\n",
      "Iteration: 17472, Loss: 0.1626676470041275, Accuracy: 0.7973409239202738\n",
      "Iteration: 17536, Loss: 0.2518554627895355, Accuracy: 0.7971011362969875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 17600, Loss: 0.023533960804343224, Accuracy: 0.8100570775568485\n",
      "Iteration: 17664, Loss: 0.2251468151807785, Accuracy: 0.8171460202429444\n",
      "Iteration: 17728, Loss: 0.0187511183321476, Accuracy: 0.8002687812549993\n",
      "Iteration: 17792, Loss: 0.03813214972615242, Accuracy: 0.8131310242461041\n",
      "Iteration: 17856, Loss: 0.12713707983493805, Accuracy: 0.8199806582415476\n",
      "Iteration: 17920, Loss: 0.058101993054151535, Accuracy: 0.8217211634619161\n",
      "Iteration: 17984, Loss: 0.021811379119753838, Accuracy: 0.8299896622775123\n",
      "Iteration: 18048, Loss: 0.07177851349115372, Accuracy: 0.8207740124780685\n",
      "Iteration: 18112, Loss: 0.01047421619296074, Accuracy: 0.8274386673001572\n",
      "Iteration: 18176, Loss: 0.18232055008411407, Accuracy: 0.8249686617637053\n",
      "Iteration: 18240, Loss: 0.013507627882063389, Accuracy: 0.8380521481158212\n",
      "Iteration: 18304, Loss: 0.07316506654024124, Accuracy: 0.8353670556098223\n",
      "Iteration: 18368, Loss: 0.014066358096897602, Accuracy: 0.8132070491556078\n",
      "Iteration: 18432, Loss: 0.018486814573407173, Accuracy: 0.8199085321975872\n",
      "Iteration: 18496, Loss: 0.0924694612622261, Accuracy: 0.8398393954848871\n",
      "Iteration: 18560, Loss: 0.024677777662873268, Accuracy: 0.8359484672546387\n",
      "Iteration: 18624, Loss: 0.008412866853177547, Accuracy: 0.8359298367286101\n",
      "Iteration: 18688, Loss: 0.07622707635164261, Accuracy: 0.821423786575906\n",
      "Iteration: 18752, Loss: 0.10761040449142456, Accuracy: 0.8357618550071493\n",
      "Iteration: 18816, Loss: 0.010263792239129543, Accuracy: 0.8340776348486543\n",
      "Iteration: 18880, Loss: 0.007194263394922018, Accuracy: 0.8446047469042242\n",
      "Iteration: 18944, Loss: 0.014201682060956955, Accuracy: 0.8546499733347446\n",
      "Iteration: 19008, Loss: 0.012761610560119152, Accuracy: 0.8520176376914605\n",
      "Iteration: 19072, Loss: 0.022376565262675285, Accuracy: 0.8431552448309958\n",
      "Iteration: 19136, Loss: 0.008256036788225174, Accuracy: 0.8555861064232886\n",
      "Iteration: 19200, Loss: 0.01754521019756794, Accuracy: 0.8354917021933943\n",
      "Iteration: 19264, Loss: 0.03343543782830238, Accuracy: 0.8602350116707385\n",
      "Iteration: 19328, Loss: 0.04525594413280487, Accuracy: 0.8597723839920945\n",
      "Iteration: 19392, Loss: 0.046559493988752365, Accuracy: 0.8547101992298849\n",
      "Iteration: 19456, Loss: 0.03998195379972458, Accuracy: 0.8466261413996108\n",
      "Iteration: 19520, Loss: 0.15181078016757965, Accuracy: 0.8489315132028423\n",
      "Iteration: 19584, Loss: 0.02883663773536682, Accuracy: 0.84939913143171\n",
      "Iteration: 19648, Loss: 0.013819684274494648, Accuracy: 0.8535824017599225\n",
      "Iteration: 19712, Loss: 0.09189239889383316, Accuracy: 0.8616322402376682\n",
      "Iteration: 19776, Loss: 0.0914248526096344, Accuracy: 0.8701212354353629\n",
      "Iteration: 19840, Loss: 0.012763847596943378, Accuracy: 0.8777219222974963\n",
      "Iteration: 19904, Loss: 0.06120549142360687, Accuracy: 0.8646559471380897\n",
      "Iteration: 19968, Loss: 0.0047712549567222595, Accuracy: 0.8459690262679942\n",
      "Iteration: 20032, Loss: 0.008281922899186611, Accuracy: 0.8677859459421597\n",
      "Iteration: 20096, Loss: 0.01290974486619234, Accuracy: 0.8725326380808838\n",
      "Iteration: 20160, Loss: 0.003975212574005127, Accuracy: 0.8762807354796678\n",
      "Iteration: 20224, Loss: 0.06609037518501282, Accuracy: 0.8674149453290738\n",
      "Iteration: 20288, Loss: 0.024966159835457802, Accuracy: 0.8538376677315682\n",
      "Iteration: 20352, Loss: 0.03061681054532528, Accuracy: 0.8682939441059716\n",
      "Iteration: 20416, Loss: 0.06985586136579514, Accuracy: 0.880932415719144\n",
      "Iteration: 20480, Loss: 0.029877588152885437, Accuracy: 0.8888446651399136\n",
      "Iteration: 20544, Loss: 0.027431780472397804, Accuracy: 0.8726762506994419\n",
      "Iteration: 20608, Loss: 0.012099708430469036, Accuracy: 0.8906965691712685\n",
      "Iteration: 20672, Loss: 0.01753534935414791, Accuracy: 0.8853794157039374\n",
      "Iteration: 20736, Loss: 0.011399277485907078, Accuracy: 0.8847921049455181\n",
      "Iteration: 20800, Loss: 0.02437376044690609, Accuracy: 0.8978725533816032\n",
      "Iteration: 20864, Loss: 0.029391057789325714, Accuracy: 0.893673961632885\n",
      "Iteration: 20928, Loss: 0.03205486014485359, Accuracy: 0.902583567542024\n",
      "Iteration: 20992, Loss: 0.01781841367483139, Accuracy: 0.8945755263557658\n",
      "Iteration: 21056, Loss: 0.01915600895881653, Accuracy: 0.8806723844027147\n",
      "Iteration: 21120, Loss: 0.031125502660870552, Accuracy: 0.8919338181149215\n",
      "Iteration: 21184, Loss: 0.018833445385098457, Accuracy: 0.8879883253830485\n",
      "Iteration: 21248, Loss: 0.02722524106502533, Accuracy: 0.9093287902651355\n",
      "Iteration: 21312, Loss: 0.04808124527335167, Accuracy: 0.8938421885832213\n",
      "Iteration: 21376, Loss: 0.027927376329898834, Accuracy: 0.9097194756031968\n",
      "Iteration: 21440, Loss: 0.01124646607786417, Accuracy: 0.8921214300207794\n",
      "Iteration: 21504, Loss: 0.21991638839244843, Accuracy: 0.8898962555394974\n",
      "Iteration: 21568, Loss: 0.006171582732349634, Accuracy: 0.9099828904436436\n",
      "Iteration: 21632, Loss: 0.001234236522577703, Accuracy: 0.9116498341027182\n",
      "Iteration: 21696, Loss: 0.031181126832962036, Accuracy: 0.9082629562180955\n",
      "Iteration: 21760, Loss: 0.0025667892768979073, Accuracy: 0.9040992580994498\n",
      "Iteration: 21824, Loss: 0.01066023949533701, Accuracy: 0.9038837066618726\n",
      "Iteration: 21888, Loss: 0.03438704088330269, Accuracy: 0.91191335656913\n",
      "Iteration: 21952, Loss: 0.007771675940603018, Accuracy: 0.9167247196019161\n",
      "Iteration: 22016, Loss: 0.02368093468248844, Accuracy: 0.8777799506497104\n",
      "Iteration: 22080, Loss: 0.006207992788404226, Accuracy: 0.9152701236016583\n",
      "Iteration: 22144, Loss: 0.0009534416603855789, Accuracy: 0.9183550148445647\n",
      "Iteration: 22208, Loss: 0.004946525674313307, Accuracy: 0.92061538802227\n",
      "Iteration: 22272, Loss: 0.008832409977912903, Accuracy: 0.8933499321283307\n",
      "Iteration: 22336, Loss: 0.005266187712550163, Accuracy: 0.9205887497810181\n",
      "Iteration: 22400, Loss: 0.003393637714907527, Accuracy: 0.9250559429638088\n",
      "Iteration: 22464, Loss: 0.0021409529726952314, Accuracy: 0.9092049316968769\n",
      "Iteration: 22528, Loss: 0.011232971213757992, Accuracy: 0.9239661976171192\n",
      "Iteration: 22592, Loss: 0.038117002695798874, Accuracy: 0.9239888003503438\n",
      "Iteration: 22656, Loss: 0.04966266453266144, Accuracy: 0.9262031235266477\n",
      "Iteration: 22720, Loss: 0.0017578696133568883, Accuracy: 0.9221058852272108\n",
      "Iteration: 22784, Loss: 0.017425350844860077, Accuracy: 0.9166695443564095\n",
      "Iteration: 22848, Loss: 0.001239208155311644, Accuracy: 0.9196033201296814\n",
      "Iteration: 22912, Loss: 0.003399263834580779, Accuracy: 0.9348500155902002\n",
      "Iteration: 22976, Loss: 0.0007291766232810915, Accuracy: 0.9318173729698174\n",
      "Iteration: 23040, Loss: 0.002057644771412015, Accuracy: 0.9144929335743655\n",
      "Iteration: 23104, Loss: 0.09464776515960693, Accuracy: 0.9164612401509658\n",
      "Iteration: 23168, Loss: 0.013365772552788258, Accuracy: 0.9333408993843477\n",
      "Iteration: 23232, Loss: 0.004753246903419495, Accuracy: 0.9401863131788559\n",
      "Iteration: 23296, Loss: 0.00038209519698284566, Accuracy: 0.9206422921270132\n",
      "Iteration: 23360, Loss: 0.005413783714175224, Accuracy: 0.9206710860016756\n",
      "Iteration: 23424, Loss: 0.007395206019282341, Accuracy: 0.9285513533395715\n",
      "Iteration: 23488, Loss: 0.001509547233581543, Accuracy: 0.9248088748427108\n",
      "Iteration: 23552, Loss: 0.0015370668843388557, Accuracy: 0.9175832469481975\n",
      "Iteration: 23616, Loss: 0.0004100441874470562, Accuracy: 0.9368535139947198\n",
      "Iteration: 23680, Loss: 0.0004213836509734392, Accuracy: 0.9249497122364119\n",
      "Iteration: 23744, Loss: 0.0023525019641965628, Accuracy: 0.933606106438674\n",
      "Iteration: 23808, Loss: 0.18674302101135254, Accuracy: 0.9336086728726514\n",
      "Iteration: 23872, Loss: 0.018123773857951164, Accuracy: 0.9331395440385677\n",
      "Iteration: 23936, Loss: 0.017742104828357697, Accuracy: 0.9325862179102842\n",
      "Iteration: 24000, Loss: 0.007730834651738405, Accuracy: 0.938753139518667\n",
      "Iteration: 24064, Loss: 0.0010581240057945251, Accuracy: 0.9429290035914164\n",
      "Iteration: 24128, Loss: 0.003247198648750782, Accuracy: 0.9437442721682601\n",
      "Iteration: 24192, Loss: 0.0006651798612438142, Accuracy: 0.9407138968381332\n",
      "Iteration: 24256, Loss: 0.0009739830275066197, Accuracy: 0.9272664035233902\n",
      "Iteration: 24320, Loss: 0.0036218389868736267, Accuracy: 0.9379665699816542\n",
      "Iteration: 24384, Loss: 0.07949000597000122, Accuracy: 0.9169686009554425\n",
      "Iteration: 24448, Loss: 0.003171817632392049, Accuracy: 0.9416727499192348\n",
      "Iteration: 24512, Loss: 0.000946747837588191, Accuracy: 0.9507387625053525\n",
      "Iteration: 24576, Loss: 0.0025906043592840433, Accuracy: 0.9470615487953182\n",
      "Iteration: 24640, Loss: 0.0054747480899095535, Accuracy: 0.9469465764559573\n",
      "Iteration: 24704, Loss: 0.02256435714662075, Accuracy: 0.9425938809872605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 24768, Loss: 0.0038778886664658785, Accuracy: 0.9426610673544928\n",
      "Iteration: 24832, Loss: 0.005337929353117943, Accuracy: 0.941095871035941\n",
      "Iteration: 24896, Loss: 0.021575646474957466, Accuracy: 0.9541032867709873\n",
      "Iteration: 24960, Loss: 0.0016185692511498928, Accuracy: 0.9530030895984964\n",
      "Iteration: 25024, Loss: 0.0007491949945688248, Accuracy: 0.9443750045174966\n",
      "Iteration: 25088, Loss: 0.002561792964115739, Accuracy: 0.9454272412112914\n",
      "Iteration: 25152, Loss: 0.002531994367018342, Accuracy: 0.9394280641718069\n",
      "Iteration: 25216, Loss: 0.007087984587997198, Accuracy: 0.9433577263116604\n",
      "Iteration: 25280, Loss: 0.009236752055585384, Accuracy: 0.9483607608271996\n",
      "Iteration: 25344, Loss: 0.0020743203349411488, Accuracy: 0.9368303286610171\n",
      "Iteration: 25408, Loss: 0.029560163617134094, Accuracy: 0.9420179900043877\n",
      "Iteration: 25472, Loss: 0.00032470389851368964, Accuracy: 0.9328106941684382\n",
      "Iteration: 25536, Loss: 0.19518232345581055, Accuracy: 0.9514786022773478\n",
      "Iteration: 25600, Loss: 0.004695635288953781, Accuracy: 0.9489457087474875\n",
      "Iteration: 25664, Loss: 0.008147896267473698, Accuracy: 0.9422918839845806\n",
      "Iteration: 25728, Loss: 0.004554073791950941, Accuracy: 0.9436058297142154\n",
      "Iteration: 25792, Loss: 0.0008635224658064544, Accuracy: 0.9564765521354275\n",
      "Iteration: 25856, Loss: 0.001517513650469482, Accuracy: 0.9419457027979661\n",
      "Iteration: 25920, Loss: 0.0028270448092371225, Accuracy: 0.9345471013075439\n",
      "Iteration: 25984, Loss: 0.0009682087111286819, Accuracy: 0.956473225101945\n",
      "Iteration: 26048, Loss: 0.0022531861905008554, Accuracy: 0.9473969244136242\n",
      "Iteration: 26112, Loss: 0.0012678303755819798, Accuracy: 0.9539347143145278\n",
      "Iteration: 26176, Loss: 0.0016930672572925687, Accuracy: 0.9506831466133008\n",
      "Iteration: 26240, Loss: 0.002539093606173992, Accuracy: 0.9508512667380273\n",
      "Iteration: 26304, Loss: 0.003253922099247575, Accuracy: 0.9517147914884845\n",
      "Iteration: 26368, Loss: 0.001316924230195582, Accuracy: 0.9577690886653727\n",
      "Iteration: 26432, Loss: 0.0010881932685151696, Accuracy: 0.961660783723346\n",
      "Iteration: 26496, Loss: 0.0019029459217563272, Accuracy: 0.9517754446424078\n",
      "Iteration: 26560, Loss: 0.010838214308023453, Accuracy: 0.9557814950821921\n",
      "Iteration: 26624, Loss: 0.0016123955138027668, Accuracy: 0.9340552652283804\n",
      "Iteration: 26688, Loss: 0.0002591116644907743, Accuracy: 0.9329537510639057\n",
      "Iteration: 26752, Loss: 0.008879139088094234, Accuracy: 0.9513902052713092\n",
      "Iteration: 26816, Loss: 0.002714114962145686, Accuracy: 0.9504258412198396\n",
      "Iteration: 26880, Loss: 0.002225899137556553, Accuracy: 0.9529524499521358\n",
      "Iteration: 26944, Loss: 0.001252947491593659, Accuracy: 0.9493783327779965\n",
      "Iteration: 27008, Loss: 0.0006832185317762196, Accuracy: 0.9498639734956669\n",
      "Iteration: 27072, Loss: 0.0008852087776176631, Accuracy: 0.9435735907172784\n",
      "Iteration: 27136, Loss: 0.0048242174088954926, Accuracy: 0.9654884158371715\n",
      "Iteration: 27200, Loss: 0.0005478388047777116, Accuracy: 0.9621199909306597\n",
      "Iteration: 27264, Loss: 0.004279811400920153, Accuracy: 0.951237361485255\n",
      "Iteration: 27328, Loss: 0.002333942335098982, Accuracy: 0.9576704384526238\n",
      "Iteration: 27392, Loss: 0.0035534538328647614, Accuracy: 0.9185284921113634\n",
      "Iteration: 27456, Loss: 0.0007153847254812717, Accuracy: 0.964355625139433\n",
      "Iteration: 27520, Loss: 0.002939285011962056, Accuracy: 0.9614543244097149\n",
      "Iteration: 27584, Loss: 0.0024491576477885246, Accuracy: 0.9545490125310607\n",
      "Iteration: 27648, Loss: 0.0006463879835791886, Accuracy: 0.952834064810304\n",
      "Iteration: 27712, Loss: 0.007287661079317331, Accuracy: 0.9663824488088721\n",
      "Iteration: 27776, Loss: 0.0006712750182487071, Accuracy: 0.9649281553429319\n",
      "Iteration: 27840, Loss: 0.0008205990307033062, Accuracy: 0.9618701893195976\n",
      "Iteration: 27904, Loss: 0.000860248226672411, Accuracy: 0.9494976971036522\n",
      "Iteration: 27968, Loss: 0.011213909834623337, Accuracy: 0.9599860359885497\n",
      "Iteration: 28032, Loss: 0.0006851362413726747, Accuracy: 0.967346376288333\n",
      "Iteration: 28096, Loss: 0.0007158469525165856, Accuracy: 0.9546955324622104\n",
      "Iteration: 28160, Loss: 0.0007815827266313136, Accuracy: 0.9556438774743583\n",
      "Iteration: 28224, Loss: 0.0028397005517035723, Accuracy: 0.9605023313779384\n",
      "Iteration: 28288, Loss: 0.00032294061384163797, Accuracy: 0.9533205935149454\n",
      "Iteration: 28352, Loss: 0.0006635200697928667, Accuracy: 0.9639132711017737\n",
      "Iteration: 28416, Loss: 0.0034716445952653885, Accuracy: 0.957243381999433\n",
      "Iteration: 28480, Loss: 0.002378880511969328, Accuracy: 0.9594108498131391\n",
      "Iteration: 28544, Loss: 0.3334710896015167, Accuracy: 0.9483867150702281\n",
      "Iteration: 28608, Loss: 0.0005536261014640331, Accuracy: 0.9570441228279378\n",
      "Iteration: 28672, Loss: 0.00028090900741517544, Accuracy: 0.9688034177816007\n",
      "Iteration: 28736, Loss: 0.0010555126937106252, Accuracy: 0.9589455655805068\n",
      "Iteration: 28800, Loss: 0.0001267970073968172, Accuracy: 0.9518411270692013\n",
      "Iteration: 28864, Loss: 0.0016875569708645344, Accuracy: 0.959846366167767\n",
      "Iteration: 28928, Loss: 0.0026948563754558563, Accuracy: 0.9583855110686272\n",
      "Iteration: 28992, Loss: 0.0012500797165557742, Accuracy: 0.9670918837073259\n",
      "Iteration: 29056, Loss: 0.0006503378390334547, Accuracy: 0.9592834711365867\n",
      "Iteration: 29120, Loss: 0.001169217168353498, Accuracy: 0.96278432442341\n",
      "Iteration: 29184, Loss: 0.0019643025007098913, Accuracy: 0.9655832774151349\n",
      "Iteration: 29248, Loss: 0.0069069466553628445, Accuracy: 0.9465002630895469\n",
      "Iteration: 29312, Loss: 8.631005766801536e-05, Accuracy: 0.955832922438276\n",
      "Iteration: 29376, Loss: 0.0001379943423671648, Accuracy: 0.9713853549474152\n",
      "Saved fullModel_dr[4]_replicate4.model\n",
      "Saved W_dr[4]_replicate4.p\n",
      "4 1.0 [1.0, 1.0, 1.0]\n",
      "Saved w_dr[4]_replicate4.p\n",
      "Replicate 4 completed\n",
      "Time elapsed: 736.140625 seconds\n",
      "Training for delay range [5]...\n",
      "Iteration: 64, Loss: 0.24392499029636383, Accuracy: 0.49896462308242917\n",
      "Iteration: 128, Loss: 0.25822800397872925, Accuracy: 0.49958985624834895\n",
      "Iteration: 192, Loss: 0.2532910108566284, Accuracy: 0.49968171771615744\n",
      "Iteration: 256, Loss: 0.23636429011821747, Accuracy: 0.5023180185817182\n",
      "Iteration: 320, Loss: 0.20260106027126312, Accuracy: 0.5192966447211802\n",
      "Iteration: 384, Loss: 0.17259328067302704, Accuracy: 0.5688047856092453\n",
      "Iteration: 448, Loss: 0.19491513073444366, Accuracy: 0.5978773678652942\n",
      "Iteration: 512, Loss: 0.15493936836719513, Accuracy: 0.6140413843095303\n",
      "Iteration: 576, Loss: 0.1827811449766159, Accuracy: 0.6235469407401979\n",
      "Iteration: 640, Loss: 0.15415231883525848, Accuracy: 0.6311349621973932\n",
      "Iteration: 704, Loss: 0.13709379732608795, Accuracy: 0.6341016734950244\n",
      "Iteration: 768, Loss: 0.17734043300151825, Accuracy: 0.638562576379627\n",
      "Iteration: 832, Loss: 0.20331068336963654, Accuracy: 0.6405167710036039\n",
      "Iteration: 896, Loss: 0.15962296724319458, Accuracy: 0.648037277162075\n",
      "Iteration: 960, Loss: 0.1513165384531021, Accuracy: 0.6504777725785971\n",
      "Iteration: 1024, Loss: 0.15236645936965942, Accuracy: 0.652526780962944\n",
      "Iteration: 1088, Loss: 0.1585025191307068, Accuracy: 0.6557472497224808\n",
      "Iteration: 1152, Loss: 0.17827273905277252, Accuracy: 0.6552556953392923\n",
      "Iteration: 1216, Loss: 0.17713747918605804, Accuracy: 0.6598478523083031\n",
      "Iteration: 1280, Loss: 0.10331425070762634, Accuracy: 0.6615754277445376\n",
      "Iteration: 1344, Loss: 0.15626536309719086, Accuracy: 0.6627319362014532\n",
      "Iteration: 1408, Loss: 0.1516585648059845, Accuracy: 0.6631136001087725\n",
      "Iteration: 1472, Loss: 0.1676730513572693, Accuracy: 0.6669940184801817\n",
      "Iteration: 1536, Loss: 0.09736893326044083, Accuracy: 0.6681469338946044\n",
      "Iteration: 1600, Loss: 0.1708492487668991, Accuracy: 0.6688302271068096\n",
      "Iteration: 1664, Loss: 0.16400502622127533, Accuracy: 0.6765736686065793\n",
      "Iteration: 1728, Loss: 0.09335681051015854, Accuracy: 0.6813062790315598\n",
      "Iteration: 1792, Loss: 0.1682833433151245, Accuracy: 0.6813696464523673\n",
      "Iteration: 1856, Loss: 0.11691490560770035, Accuracy: 0.6829262501560152\n",
      "Iteration: 1920, Loss: 0.16294372081756592, Accuracy: 0.6883068126626313\n",
      "Iteration: 1984, Loss: 0.08528459072113037, Accuracy: 0.6886152608785778\n",
      "Iteration: 2048, Loss: 0.13378101587295532, Accuracy: 0.6850603925995529\n",
      "Iteration: 2112, Loss: 0.09034023433923721, Accuracy: 0.6940227230079472\n",
      "Iteration: 2176, Loss: 0.11276312917470932, Accuracy: 0.7054538216907531\n",
      "Iteration: 2240, Loss: 0.171328604221344, Accuracy: 0.7099943654611707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2304, Loss: 0.05003906413912773, Accuracy: 0.7083208411931992\n",
      "Iteration: 2368, Loss: 0.11732683330774307, Accuracy: 0.702030265936628\n",
      "Iteration: 2432, Loss: 0.14477410912513733, Accuracy: 0.713814917486161\n",
      "Iteration: 2496, Loss: 0.18304942548274994, Accuracy: 0.719592364737764\n",
      "Iteration: 2560, Loss: 0.165446475148201, Accuracy: 0.7130371043458581\n",
      "Iteration: 2624, Loss: 0.1907597780227661, Accuracy: 0.729988245293498\n",
      "Iteration: 2688, Loss: 0.06554942578077316, Accuracy: 0.7192331047262996\n",
      "Iteration: 2752, Loss: 0.11498627066612244, Accuracy: 0.7315571624785662\n",
      "Iteration: 2816, Loss: 0.030375413596630096, Accuracy: 0.7370527239982039\n",
      "Iteration: 2880, Loss: 0.1537841111421585, Accuracy: 0.7396833843085915\n",
      "Iteration: 2944, Loss: 0.1859540492296219, Accuracy: 0.7378390561789274\n",
      "Iteration: 3008, Loss: 0.19269905984401703, Accuracy: 0.7371969355735928\n",
      "Iteration: 3072, Loss: 0.05050443112850189, Accuracy: 0.7438733328599483\n",
      "Iteration: 3136, Loss: 0.06130659207701683, Accuracy: 0.7457856051623821\n",
      "Iteration: 3200, Loss: 0.21067798137664795, Accuracy: 0.747075118124485\n",
      "Iteration: 3264, Loss: 0.05046805739402771, Accuracy: 0.7517968227621168\n",
      "Iteration: 3328, Loss: 0.17240263521671295, Accuracy: 0.7524607484228909\n",
      "Iteration: 3392, Loss: 0.059394657611846924, Accuracy: 0.7369840065948665\n",
      "Iteration: 3456, Loss: 0.14384372532367706, Accuracy: 0.7518011352512985\n",
      "Iteration: 3520, Loss: 0.0617058165371418, Accuracy: 0.7545210748212412\n",
      "Iteration: 3584, Loss: 0.04828463867306709, Accuracy: 0.7520052205072716\n",
      "Iteration: 3648, Loss: 0.10357560962438583, Accuracy: 0.7519132273737341\n",
      "Iteration: 3712, Loss: 0.161642923951149, Accuracy: 0.7582453716313466\n",
      "Iteration: 3776, Loss: 0.16987378895282745, Accuracy: 0.7566310741240159\n",
      "Iteration: 3840, Loss: 0.0181917455047369, Accuracy: 0.7549959435127676\n",
      "Iteration: 3904, Loss: 0.22718274593353271, Accuracy: 0.7644895726116374\n",
      "Iteration: 3968, Loss: 0.22038064897060394, Accuracy: 0.7487468712497503\n",
      "Iteration: 4032, Loss: 0.14631205797195435, Accuracy: 0.7604815743397921\n",
      "Iteration: 4096, Loss: 0.18261726200580597, Accuracy: 0.7642943218816072\n",
      "Iteration: 4160, Loss: 0.04481949284672737, Accuracy: 0.7642438969342038\n",
      "Iteration: 4224, Loss: 0.17279766499996185, Accuracy: 0.7664408792043105\n",
      "Iteration: 4288, Loss: 0.2441723346710205, Accuracy: 0.7630279635777697\n",
      "Iteration: 4352, Loss: 0.058512892574071884, Accuracy: 0.7635221168166026\n",
      "Iteration: 4416, Loss: 0.20951640605926514, Accuracy: 0.7695162082090974\n",
      "Iteration: 4480, Loss: 0.02174038626253605, Accuracy: 0.7719057655194774\n",
      "Iteration: 4544, Loss: 0.05149884149432182, Accuracy: 0.7752506198594347\n",
      "Iteration: 4608, Loss: 0.03345804661512375, Accuracy: 0.7742503738263622\n",
      "Iteration: 4672, Loss: 0.1693437546491623, Accuracy: 0.7689516519894823\n",
      "Iteration: 4736, Loss: 0.033145952969789505, Accuracy: 0.774514633230865\n",
      "Iteration: 4800, Loss: 0.167131707072258, Accuracy: 0.7702480790903792\n",
      "Iteration: 4864, Loss: 0.02208513207733631, Accuracy: 0.7727270553587005\n",
      "Iteration: 4928, Loss: 0.16113941371440887, Accuracy: 0.7753009758889675\n",
      "Iteration: 4992, Loss: 0.1753637045621872, Accuracy: 0.7774656215915456\n",
      "Iteration: 5056, Loss: 0.15410205721855164, Accuracy: 0.7798231742344797\n",
      "Iteration: 5120, Loss: 0.17167483270168304, Accuracy: 0.7742663261014968\n",
      "Iteration: 5184, Loss: 0.019000181928277016, Accuracy: 0.776647440623492\n",
      "Iteration: 5248, Loss: 0.020458558574318886, Accuracy: 0.7824762157397345\n",
      "Iteration: 5312, Loss: 0.021488720551133156, Accuracy: 0.7843406919855624\n",
      "Iteration: 5376, Loss: 0.02512935735285282, Accuracy: 0.7755861846962944\n",
      "Iteration: 5440, Loss: 0.15215317904949188, Accuracy: 0.7810953805455938\n",
      "Iteration: 5504, Loss: 0.01950749196112156, Accuracy: 0.791893329587765\n",
      "Iteration: 5568, Loss: 0.05409547686576843, Accuracy: 0.7805373702431098\n",
      "Iteration: 5632, Loss: 0.17212235927581787, Accuracy: 0.7716913934564218\n",
      "Iteration: 5696, Loss: 0.029286270961165428, Accuracy: 0.7769274597521871\n",
      "Iteration: 5760, Loss: 0.019864371046423912, Accuracy: 0.7821537882555276\n",
      "Iteration: 5824, Loss: 0.15858925879001617, Accuracy: 0.7726042567519471\n",
      "Iteration: 5888, Loss: 0.1503428965806961, Accuracy: 0.780737096676603\n",
      "Iteration: 5952, Loss: 0.033501047641038895, Accuracy: 0.7810858899028972\n",
      "Iteration: 6016, Loss: 0.027824578806757927, Accuracy: 0.7866644605528563\n",
      "Iteration: 6080, Loss: 0.13687178492546082, Accuracy: 0.77549231890589\n",
      "Iteration: 6144, Loss: 0.16836905479431152, Accuracy: 0.7840570729458705\n",
      "Iteration: 6208, Loss: 0.1554860770702362, Accuracy: 0.7858328694710508\n",
      "Iteration: 6272, Loss: 0.03151673451066017, Accuracy: 0.7849210380809382\n",
      "Iteration: 6336, Loss: 0.1391356736421585, Accuracy: 0.7851381850196049\n",
      "Iteration: 6400, Loss: 0.02695099264383316, Accuracy: 0.787939194124192\n",
      "Iteration: 6464, Loss: 0.027118472382426262, Accuracy: 0.7984433923847973\n",
      "Iteration: 6528, Loss: 0.07844196259975433, Accuracy: 0.7944975687423721\n",
      "Iteration: 6592, Loss: 0.13885553181171417, Accuracy: 0.787425541668199\n",
      "Iteration: 6656, Loss: 0.12858262658119202, Accuracy: 0.7871953840367496\n",
      "Iteration: 6720, Loss: 0.028214367106556892, Accuracy: 0.7885738869663328\n",
      "Iteration: 6784, Loss: 0.07822924107313156, Accuracy: 0.7863213974051178\n",
      "Iteration: 6848, Loss: 0.15215158462524414, Accuracy: 0.7926284752320498\n",
      "Iteration: 6912, Loss: 0.028054209426045418, Accuracy: 0.7975806202739477\n",
      "Iteration: 6976, Loss: 0.17519675195217133, Accuracy: 0.7893847310915589\n",
      "Iteration: 7040, Loss: 0.14254599809646606, Accuracy: 0.7946129331830889\n",
      "Iteration: 7104, Loss: 0.15297070145606995, Accuracy: 0.7953612188575789\n",
      "Iteration: 7168, Loss: 0.05142250657081604, Accuracy: 0.7944107218645513\n",
      "Iteration: 7232, Loss: 0.02711752988398075, Accuracy: 0.7961997034726664\n",
      "Iteration: 7296, Loss: 0.03994809463620186, Accuracy: 0.788110293680802\n",
      "Iteration: 7360, Loss: 0.127725288271904, Accuracy: 0.7881426151143387\n",
      "Iteration: 7424, Loss: 0.12844783067703247, Accuracy: 0.8037316208938137\n",
      "Iteration: 7488, Loss: 0.13996939361095428, Accuracy: 0.7999685944523662\n",
      "Iteration: 7552, Loss: 0.1523536592721939, Accuracy: 0.7967532101320103\n",
      "Iteration: 7616, Loss: 0.13252556324005127, Accuracy: 0.8036428351188079\n",
      "Iteration: 7680, Loss: 0.10746229439973831, Accuracy: 0.7985070241848007\n",
      "Iteration: 7744, Loss: 0.15903988480567932, Accuracy: 0.7981966970255598\n",
      "Iteration: 7808, Loss: 0.07785165309906006, Accuracy: 0.7965009601321071\n",
      "Iteration: 7872, Loss: 0.025551587343215942, Accuracy: 0.793329602573067\n",
      "Iteration: 7936, Loss: 0.030886752530932426, Accuracy: 0.8027869060169905\n",
      "Iteration: 8000, Loss: 0.16921581327915192, Accuracy: 0.798719807411544\n",
      "Iteration: 8064, Loss: 0.1695408821105957, Accuracy: 0.7966646170243621\n",
      "Iteration: 8128, Loss: 0.13723592460155487, Accuracy: 0.8089507680851966\n",
      "Iteration: 8192, Loss: 0.28278660774230957, Accuracy: 0.8007544127758592\n",
      "Iteration: 8256, Loss: 0.1249784603714943, Accuracy: 0.7943890956230462\n",
      "Iteration: 8320, Loss: 0.12244963645935059, Accuracy: 0.8054132151883096\n",
      "Iteration: 8384, Loss: 0.06701751053333282, Accuracy: 0.8065108772134408\n",
      "Iteration: 8448, Loss: 0.11218713968992233, Accuracy: 0.7974546318873763\n",
      "Iteration: 8512, Loss: 0.11932767182588577, Accuracy: 0.8076043406035751\n",
      "Iteration: 8576, Loss: 0.03379550948739052, Accuracy: 0.8049483546055853\n",
      "Iteration: 8640, Loss: 0.07822311669588089, Accuracy: 0.7971931082429364\n",
      "Iteration: 8704, Loss: 0.04956340789794922, Accuracy: 0.8018530709668994\n",
      "Iteration: 8768, Loss: 0.15343208611011505, Accuracy: 0.811871291953139\n",
      "Iteration: 8832, Loss: 0.10430540889501572, Accuracy: 0.8090901537798345\n",
      "Iteration: 8896, Loss: 0.036283139139413834, Accuracy: 0.8069140481529757\n",
      "Iteration: 8960, Loss: 0.18029837310314178, Accuracy: 0.8158955188700929\n",
      "Iteration: 9024, Loss: 0.1545477658510208, Accuracy: 0.8114625344751403\n",
      "Iteration: 9088, Loss: 0.09765470772981644, Accuracy: 0.8103908157208934\n",
      "Iteration: 9152, Loss: 0.1255507469177246, Accuracy: 0.8087661964818835\n",
      "Iteration: 9216, Loss: 0.026274358853697777, Accuracy: 0.8160473130410537\n",
      "Iteration: 9280, Loss: 0.11574111133813858, Accuracy: 0.8101383033208549\n",
      "Iteration: 9344, Loss: 0.1350705474615097, Accuracy: 0.807617912068963\n",
      "Iteration: 9408, Loss: 0.037978533655405045, Accuracy: 0.8164365777047351\n",
      "Iteration: 9472, Loss: 0.045705389231443405, Accuracy: 0.8143328055739403\n",
      "Iteration: 9536, Loss: 0.08701064437627792, Accuracy: 0.8005787375150248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 9600, Loss: 0.054702844470739365, Accuracy: 0.807257276494056\n",
      "Iteration: 9664, Loss: 0.12577779591083527, Accuracy: 0.8128037836868316\n",
      "Iteration: 9728, Loss: 0.038648687303066254, Accuracy: 0.8157498739892617\n",
      "Iteration: 9792, Loss: 0.10984794050455093, Accuracy: 0.8221421639900655\n",
      "Iteration: 9856, Loss: 0.21166354417800903, Accuracy: 0.7951342787127942\n",
      "Iteration: 9920, Loss: 0.11410274356603622, Accuracy: 0.8195771591272205\n",
      "Iteration: 9984, Loss: 0.13205312192440033, Accuracy: 0.8174493028782308\n",
      "Iteration: 10048, Loss: 0.09241422265768051, Accuracy: 0.814203429967165\n",
      "Iteration: 10112, Loss: 0.11281991750001907, Accuracy: 0.8213289027335122\n",
      "Iteration: 10176, Loss: 0.1275714486837387, Accuracy: 0.8229978429153562\n",
      "Iteration: 10240, Loss: 0.18289248645305634, Accuracy: 0.8257377538830042\n",
      "Iteration: 10304, Loss: 0.04514293000102043, Accuracy: 0.8210176979191601\n",
      "Iteration: 10368, Loss: 0.1295156627893448, Accuracy: 0.8139456142671406\n",
      "Iteration: 10432, Loss: 0.10236846655607224, Accuracy: 0.8175517164636403\n",
      "Iteration: 10496, Loss: 0.046984072774648666, Accuracy: 0.8184078565100208\n",
      "Iteration: 10560, Loss: 0.050584763288497925, Accuracy: 0.8156030086101964\n",
      "Iteration: 10624, Loss: 0.026314789429306984, Accuracy: 0.8230513345915824\n",
      "Iteration: 10688, Loss: 0.0477852039039135, Accuracy: 0.8240051628090441\n",
      "Iteration: 10752, Loss: 0.029369307681918144, Accuracy: 0.8212089664302766\n",
      "Iteration: 10816, Loss: 0.029171623289585114, Accuracy: 0.8225962657015771\n",
      "Iteration: 10880, Loss: 0.1083325520157814, Accuracy: 0.8117297119461\n",
      "Iteration: 10944, Loss: 0.07042258977890015, Accuracy: 0.8294642799301073\n",
      "Iteration: 11008, Loss: 0.1223454475402832, Accuracy: 0.827176850871183\n",
      "Iteration: 11072, Loss: 0.3893611431121826, Accuracy: 0.8142366562969983\n",
      "Iteration: 11136, Loss: 0.06759683042764664, Accuracy: 0.8226932194083929\n",
      "Iteration: 11200, Loss: 0.053787197917699814, Accuracy: 0.8242165470728651\n",
      "Iteration: 11264, Loss: 0.034305114299058914, Accuracy: 0.8278191781137139\n",
      "Iteration: 11328, Loss: 0.0778530016541481, Accuracy: 0.8080441935453564\n",
      "Iteration: 11392, Loss: 0.05575278401374817, Accuracy: 0.8207178490702063\n",
      "Iteration: 11456, Loss: 0.06635729968547821, Accuracy: 0.8195792755577713\n",
      "Iteration: 11520, Loss: 0.1078263521194458, Accuracy: 0.8312911445973441\n",
      "Iteration: 11584, Loss: 0.05486447736620903, Accuracy: 0.830221826559864\n",
      "Iteration: 11648, Loss: 0.06395017355680466, Accuracy: 0.8278707128483802\n",
      "Iteration: 11712, Loss: 0.06669942289590836, Accuracy: 0.8238600540207699\n",
      "Iteration: 11776, Loss: 0.06149626150727272, Accuracy: 0.8306410218356177\n",
      "Iteration: 11840, Loss: 0.056948352605104446, Accuracy: 0.8292747773230076\n",
      "Iteration: 11904, Loss: 0.030316269025206566, Accuracy: 0.8349722363054752\n",
      "Iteration: 11968, Loss: 0.028425583615899086, Accuracy: 0.8355639928486198\n",
      "Iteration: 12032, Loss: 0.04678497090935707, Accuracy: 0.8328266591997817\n",
      "Iteration: 12096, Loss: 0.11660435050725937, Accuracy: 0.8376696897903457\n",
      "Iteration: 12160, Loss: 0.027356518432497978, Accuracy: 0.8377351725939661\n",
      "Iteration: 12224, Loss: 0.057504307478666306, Accuracy: 0.831561591825448\n",
      "Iteration: 12288, Loss: 0.0580114871263504, Accuracy: 0.837604574742727\n",
      "Iteration: 12352, Loss: 0.027269305661320686, Accuracy: 0.8350022403756157\n",
      "Iteration: 12416, Loss: 0.05516062304377556, Accuracy: 0.8325998488580808\n",
      "Iteration: 12480, Loss: 0.11893651634454727, Accuracy: 0.8376129496609792\n",
      "Iteration: 12544, Loss: 0.042486827820539474, Accuracy: 0.8330577367451042\n",
      "Iteration: 12608, Loss: 0.05158750340342522, Accuracy: 0.8266770156333223\n",
      "Iteration: 12672, Loss: 0.11983034014701843, Accuracy: 0.8391956214327365\n",
      "Iteration: 12736, Loss: 0.10798931866884232, Accuracy: 0.8438401557505131\n",
      "Iteration: 12800, Loss: 0.10493377596139908, Accuracy: 0.8438880245666951\n",
      "Iteration: 12864, Loss: 0.025021927431225777, Accuracy: 0.8353358249878511\n",
      "Iteration: 12928, Loss: 0.062452998012304306, Accuracy: 0.84307745937258\n",
      "Iteration: 12992, Loss: 0.0801895335316658, Accuracy: 0.8289979984983802\n",
      "Iteration: 13056, Loss: 0.06382452696561813, Accuracy: 0.8302574082044885\n",
      "Iteration: 13120, Loss: 0.060131367295980453, Accuracy: 0.8353762704646215\n",
      "Iteration: 13184, Loss: 0.02364037185907364, Accuracy: 0.8427296378649771\n",
      "Iteration: 13248, Loss: 0.02165832184255123, Accuracy: 0.8332823717501014\n",
      "Iteration: 13312, Loss: 0.0818072110414505, Accuracy: 0.8415162385208532\n",
      "Iteration: 13376, Loss: 0.10042786598205566, Accuracy: 0.8451304391492158\n",
      "Iteration: 13440, Loss: 0.0807032510638237, Accuracy: 0.8424039415549487\n",
      "Iteration: 13504, Loss: 0.10080582648515701, Accuracy: 0.8480545167112723\n",
      "Iteration: 13568, Loss: 0.02130681835114956, Accuracy: 0.8380617742659524\n",
      "Iteration: 13632, Loss: 0.06614192575216293, Accuracy: 0.8340581414522603\n",
      "Iteration: 13696, Loss: 0.035120490938425064, Accuracy: 0.8387849677819759\n",
      "Iteration: 13760, Loss: 0.10451292246580124, Accuracy: 0.8314202125184238\n",
      "Iteration: 13824, Loss: 0.02880956418812275, Accuracy: 0.8363432856276631\n",
      "Iteration: 13888, Loss: 0.10536843538284302, Accuracy: 0.8433941821567714\n",
      "Iteration: 13952, Loss: 0.033608246594667435, Accuracy: 0.8256071117939427\n",
      "Iteration: 14016, Loss: 0.03887200355529785, Accuracy: 0.8450966133968905\n",
      "Iteration: 14080, Loss: 0.05247919261455536, Accuracy: 0.8461355763720348\n",
      "Iteration: 14144, Loss: 0.1099604144692421, Accuracy: 0.8507110315840691\n",
      "Iteration: 14208, Loss: 0.06707843393087387, Accuracy: 0.8286103951977566\n",
      "Iteration: 14272, Loss: 0.03393177688121796, Accuracy: 0.8479972834466025\n",
      "Iteration: 14336, Loss: 0.059608522802591324, Accuracy: 0.8474692252930254\n",
      "Iteration: 14400, Loss: 0.1096009686589241, Accuracy: 0.8502060924656689\n",
      "Iteration: 14464, Loss: 0.06426947563886642, Accuracy: 0.8422423800220713\n",
      "Iteration: 14528, Loss: 0.06687230616807938, Accuracy: 0.8397200771141797\n",
      "Iteration: 14592, Loss: 0.11272943764925003, Accuracy: 0.8520968178054318\n",
      "Iteration: 14656, Loss: 0.038330644369125366, Accuracy: 0.8405522432876751\n",
      "Iteration: 14720, Loss: 0.06932219117879868, Accuracy: 0.8338587789330631\n",
      "Iteration: 14784, Loss: 0.10211672633886337, Accuracy: 0.8475033576833084\n",
      "Iteration: 14848, Loss: 0.17306071519851685, Accuracy: 0.850288045941852\n",
      "Iteration: 14912, Loss: 0.04332549870014191, Accuracy: 0.8383363498141989\n",
      "Iteration: 14976, Loss: 0.0662752240896225, Accuracy: 0.854522701818496\n",
      "Iteration: 15040, Loss: 0.04418353736400604, Accuracy: 0.8537047922145575\n",
      "Iteration: 15104, Loss: 0.4163229465484619, Accuracy: 0.8328788276994601\n",
      "Iteration: 15168, Loss: 0.10193575173616409, Accuracy: 0.8376166780944914\n",
      "Iteration: 15232, Loss: 0.10199794173240662, Accuracy: 0.8393161706626415\n",
      "Iteration: 15296, Loss: 0.10234976559877396, Accuracy: 0.8492112566018477\n",
      "Iteration: 15360, Loss: 0.06725290417671204, Accuracy: 0.8416062138276175\n",
      "Iteration: 15424, Loss: 0.06932856142520905, Accuracy: 0.8550141758751124\n",
      "Iteration: 15488, Loss: 0.062153905630111694, Accuracy: 0.850610529538244\n",
      "Iteration: 15552, Loss: 0.01850488968193531, Accuracy: 0.8504787198035046\n",
      "Iteration: 15616, Loss: 0.028621532022953033, Accuracy: 0.8387452183524147\n",
      "Iteration: 15680, Loss: 0.0636976882815361, Accuracy: 0.8315814767265692\n",
      "Iteration: 15744, Loss: 0.015552692115306854, Accuracy: 0.8318456973647699\n",
      "Iteration: 15808, Loss: 0.02855406515300274, Accuracy: 0.849244108540006\n",
      "Iteration: 15872, Loss: 0.07576664537191391, Accuracy: 0.8548105505760759\n",
      "Iteration: 15936, Loss: 0.0271394532173872, Accuracy: 0.8512177258962765\n",
      "Iteration: 16000, Loss: 0.014372363686561584, Accuracy: 0.8500110452296212\n",
      "Iteration: 16064, Loss: 0.03159962221980095, Accuracy: 0.8559044285211712\n",
      "Iteration: 16128, Loss: 0.015945706516504288, Accuracy: 0.8469507740810513\n",
      "Iteration: 16192, Loss: 0.046802353113889694, Accuracy: 0.8496187744894996\n",
      "Iteration: 16256, Loss: 0.014593124389648438, Accuracy: 0.8579822980100289\n",
      "Iteration: 16320, Loss: 0.01432926207780838, Accuracy: 0.8587631216505542\n",
      "Iteration: 16384, Loss: 0.03401602804660797, Accuracy: 0.8547878367244266\n",
      "Iteration: 16448, Loss: 0.18457229435443878, Accuracy: 0.851750856381841\n",
      "Iteration: 16512, Loss: 0.0941489115357399, Accuracy: 0.855166303110309\n",
      "Iteration: 16576, Loss: 0.102457195520401, Accuracy: 0.8578967016655952\n",
      "Iteration: 16640, Loss: 0.02796180546283722, Accuracy: 0.8548482684418559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 16704, Loss: 0.3551202118396759, Accuracy: 0.8465292402543128\n",
      "Iteration: 16768, Loss: 0.06278874725103378, Accuracy: 0.8339702188386582\n",
      "Iteration: 16832, Loss: 0.09088102728128433, Accuracy: 0.8393315692665055\n",
      "Iteration: 16896, Loss: 0.06936632841825485, Accuracy: 0.8572181873605587\n",
      "Iteration: 16960, Loss: 0.06795986741781235, Accuracy: 0.8593431091867387\n",
      "Iteration: 17024, Loss: 0.021738821640610695, Accuracy: 0.8458471298217773\n",
      "Iteration: 17088, Loss: 0.021860817447304726, Accuracy: 0.8553579520084895\n",
      "Iteration: 17152, Loss: 0.07008662074804306, Accuracy: 0.864902648027055\n",
      "Iteration: 17216, Loss: 0.25821876525878906, Accuracy: 0.8546703163301572\n",
      "Iteration: 17280, Loss: 0.011949978768825531, Accuracy: 0.8554796118987724\n",
      "Iteration: 17344, Loss: 0.11170133948326111, Accuracy: 0.8610088506247848\n",
      "Iteration: 17408, Loss: 0.032659389078617096, Accuracy: 0.8608609148068354\n",
      "Iteration: 17472, Loss: 0.07044794410467148, Accuracy: 0.8645106583717279\n",
      "Iteration: 17536, Loss: 0.10139439254999161, Accuracy: 0.8597817010595463\n",
      "Iteration: 17600, Loss: 0.06926358491182327, Accuracy: 0.8553638784214854\n",
      "Iteration: 17664, Loss: 0.0251782089471817, Accuracy: 0.8507624602061696\n",
      "Iteration: 17728, Loss: 0.008717349730432034, Accuracy: 0.8609230230213143\n",
      "Iteration: 17792, Loss: 0.08469638973474503, Accuracy: 0.8577558833640069\n",
      "Iteration: 17856, Loss: 0.09829544275999069, Accuracy: 0.8627543700276874\n",
      "Iteration: 17920, Loss: 0.10271216183900833, Accuracy: 0.86071155796526\n",
      "Iteration: 17984, Loss: 0.35148343443870544, Accuracy: 0.8533574451575987\n",
      "Iteration: 18048, Loss: 0.0767279863357544, Accuracy: 0.8479454079642892\n",
      "Iteration: 18112, Loss: 0.06258340924978256, Accuracy: 0.8648562182788737\n",
      "Iteration: 18176, Loss: 0.10372229665517807, Accuracy: 0.846843128441833\n",
      "Iteration: 18240, Loss: 0.06247243285179138, Accuracy: 0.8434412608039565\n",
      "Iteration: 18304, Loss: 0.09614205360412598, Accuracy: 0.8477659015334211\n",
      "Iteration: 18368, Loss: 0.07530374825000763, Accuracy: 0.8561605692957528\n",
      "Iteration: 18432, Loss: 0.011943738907575607, Accuracy: 0.8568475109059364\n",
      "Iteration: 18496, Loss: 0.03100396879017353, Accuracy: 0.8580970225739293\n",
      "Iteration: 18560, Loss: 0.10327720642089844, Accuracy: 0.8592040741932578\n",
      "Iteration: 18624, Loss: 0.03461423143744469, Accuracy: 0.8458806680282578\n",
      "Iteration: 18688, Loss: 0.009795403108000755, Accuracy: 0.8659806689829566\n",
      "Iteration: 18752, Loss: 0.009728698991239071, Accuracy: 0.8674719105474651\n",
      "Iteration: 18816, Loss: 0.093569315969944, Accuracy: 0.8697051191120408\n",
      "Iteration: 18880, Loss: 0.10196828097105026, Accuracy: 0.8588398091960698\n",
      "Iteration: 18944, Loss: 0.0821574404835701, Accuracy: 0.8641794924042188\n",
      "Iteration: 19008, Loss: 0.02425791136920452, Accuracy: 0.849654839374125\n",
      "Iteration: 19072, Loss: 0.06742900609970093, Accuracy: 0.8652583748917095\n",
      "Iteration: 19136, Loss: 0.02786816842854023, Accuracy: 0.8759818677208386\n",
      "Iteration: 19200, Loss: 0.07063143700361252, Accuracy: 0.8650458570336923\n",
      "Iteration: 19264, Loss: 0.07237491756677628, Accuracy: 0.8711344718467444\n",
      "Iteration: 19328, Loss: 0.023742780089378357, Accuracy: 0.8624210720299743\n",
      "Iteration: 19392, Loss: 0.060642678290605545, Accuracy: 0.876993078738451\n",
      "Iteration: 19456, Loss: 0.0962960347533226, Accuracy: 0.8718985989689827\n",
      "Iteration: 19520, Loss: 0.007647126913070679, Accuracy: 0.8690927774878219\n",
      "Iteration: 19584, Loss: 0.009211487136781216, Accuracy: 0.867353500565514\n",
      "Iteration: 19648, Loss: 0.12924052774906158, Accuracy: 0.8624449322815053\n",
      "Iteration: 19712, Loss: 0.014246943406760693, Accuracy: 0.870833414257504\n",
      "Iteration: 19776, Loss: 0.08938028663396835, Accuracy: 0.8699026293470524\n",
      "Iteration: 19840, Loss: 0.05171911418437958, Accuracy: 0.8712553507648408\n",
      "Iteration: 19904, Loss: 0.0877503827214241, Accuracy: 0.8712949054315686\n",
      "Iteration: 19968, Loss: 0.09739670157432556, Accuracy: 0.865911423577927\n",
      "Iteration: 20032, Loss: 0.005443979520350695, Accuracy: 0.8711702258442529\n",
      "Iteration: 20096, Loss: 0.02766215242445469, Accuracy: 0.8621581625193357\n",
      "Iteration: 20160, Loss: 0.11574789881706238, Accuracy: 0.8644976275390945\n",
      "Iteration: 20224, Loss: 0.006670233327895403, Accuracy: 0.8572670574649237\n",
      "Iteration: 20288, Loss: 0.042609404772520065, Accuracy: 0.8610780159942806\n",
      "Iteration: 20352, Loss: 0.10186150670051575, Accuracy: 0.8667000798741356\n",
      "Iteration: 20416, Loss: 0.015260509215295315, Accuracy: 0.8608085511950776\n",
      "Iteration: 20480, Loss: 0.08417022973299026, Accuracy: 0.8718065447756089\n",
      "Iteration: 20544, Loss: 0.014729361049830914, Accuracy: 0.8698965533985756\n",
      "Iteration: 20608, Loss: 0.006414053495973349, Accuracy: 0.855734470882453\n",
      "Iteration: 20672, Loss: 0.006455200258642435, Accuracy: 0.8517885854234919\n",
      "Iteration: 20736, Loss: 0.07819413393735886, Accuracy: 0.876920300652273\n",
      "Iteration: 20800, Loss: 0.09257405996322632, Accuracy: 0.867264133237768\n",
      "Iteration: 20864, Loss: 0.013926279731094837, Accuracy: 0.8805001105065458\n",
      "Iteration: 20928, Loss: 0.015759136527776718, Accuracy: 0.874054160725791\n",
      "Iteration: 20992, Loss: 0.08401615172624588, Accuracy: 0.8684611062053591\n",
      "Iteration: 21056, Loss: 0.015411905013024807, Accuracy: 0.874390032608062\n",
      "Iteration: 21120, Loss: 0.09480363130569458, Accuracy: 0.8738755968515761\n",
      "Iteration: 21184, Loss: 0.004069950897246599, Accuracy: 0.8602517811232246\n",
      "Iteration: 21248, Loss: 0.07252199947834015, Accuracy: 0.8768182847998105\n",
      "Iteration: 21312, Loss: 0.0288267582654953, Accuracy: 0.8741293078637682\n",
      "Iteration: 21376, Loss: 0.09383227676153183, Accuracy: 0.8702263176091947\n",
      "Iteration: 21440, Loss: 0.08148570358753204, Accuracy: 0.8590136106940918\n",
      "Iteration: 21504, Loss: 0.5099908709526062, Accuracy: 0.8665686994208954\n",
      "Iteration: 21568, Loss: 0.013700897805392742, Accuracy: 0.8710099151940085\n",
      "Iteration: 21632, Loss: 0.004764514043927193, Accuracy: 0.8731227339012548\n",
      "Iteration: 21696, Loss: 0.044911354780197144, Accuracy: 0.8700530951609835\n",
      "Iteration: 21760, Loss: 0.0038643423467874527, Accuracy: 0.871225992043037\n",
      "Iteration: 21824, Loss: 0.014016066677868366, Accuracy: 0.8705438523320481\n",
      "Iteration: 21888, Loss: 0.08032428473234177, Accuracy: 0.8669956176890992\n",
      "Iteration: 21952, Loss: 0.003838570090010762, Accuracy: 0.8741085677174851\n",
      "Iteration: 22016, Loss: 0.07211966067552567, Accuracy: 0.8630889492342249\n",
      "Iteration: 22080, Loss: 0.013506240211427212, Accuracy: 0.8746474179206416\n",
      "Iteration: 22144, Loss: 0.004616037011146545, Accuracy: 0.8727782690548338\n",
      "Iteration: 22208, Loss: 0.045384909957647324, Accuracy: 0.8790899226441979\n",
      "Iteration: 22272, Loss: 0.02562195062637329, Accuracy: 0.8744270365568809\n",
      "Iteration: 22336, Loss: 0.004307897295802832, Accuracy: 0.8828317638253793\n",
      "Iteration: 22400, Loss: 0.0036575018893927336, Accuracy: 0.8833120340714231\n",
      "Iteration: 22464, Loss: 0.013148274272680283, Accuracy: 0.8684795343433507\n",
      "Iteration: 22528, Loss: 0.007499832659959793, Accuracy: 0.8829092154628597\n",
      "Iteration: 22592, Loss: 0.021515222266316414, Accuracy: 0.8860534026753157\n",
      "Iteration: 22656, Loss: 0.003966441843658686, Accuracy: 0.8884165480849333\n",
      "Iteration: 22720, Loss: 0.012994415126740932, Accuracy: 0.8735526303062215\n",
      "Iteration: 22784, Loss: 0.01223398745059967, Accuracy: 0.8804324726224877\n",
      "Iteration: 22848, Loss: 0.004883479792624712, Accuracy: 0.8777570743695833\n",
      "Iteration: 22912, Loss: 0.0049344501458108425, Accuracy: 0.8798180471058004\n",
      "Iteration: 22976, Loss: 0.1055583655834198, Accuracy: 0.8836849317885935\n",
      "Iteration: 23040, Loss: 0.07664705812931061, Accuracy: 0.8740424647112377\n",
      "Iteration: 23104, Loss: 0.01224055141210556, Accuracy: 0.871721854666248\n",
      "Iteration: 23168, Loss: 0.1508549004793167, Accuracy: 0.8708813844714314\n",
      "Iteration: 23232, Loss: 0.013977372087538242, Accuracy: 0.8887564687756822\n",
      "Iteration: 23296, Loss: 0.03127178177237511, Accuracy: 0.8853290809784085\n",
      "Iteration: 23360, Loss: 0.00660422770306468, Accuracy: 0.8555337881552987\n",
      "Iteration: 23424, Loss: 0.0029141574632376432, Accuracy: 0.8756836931861471\n",
      "Iteration: 23488, Loss: 0.062185753136873245, Accuracy: 0.8623629288340453\n",
      "Iteration: 23552, Loss: 0.01744915544986725, Accuracy: 0.8783661189954728\n",
      "Iteration: 23616, Loss: 0.029699617996811867, Accuracy: 0.8842656072520185\n",
      "Iteration: 23680, Loss: 0.06006060913205147, Accuracy: 0.888739053538302\n",
      "Iteration: 23744, Loss: 0.014754793606698513, Accuracy: 0.8891896779241506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 23808, Loss: 0.0283480454236269, Accuracy: 0.8867497334431391\n",
      "Iteration: 23872, Loss: 0.022251909598708153, Accuracy: 0.891835204034578\n",
      "Iteration: 23936, Loss: 0.01505123358219862, Accuracy: 0.8712199339352082\n",
      "Iteration: 24000, Loss: 0.07095233350992203, Accuracy: 0.8912270333094057\n",
      "Iteration: 24064, Loss: 0.026859648525714874, Accuracy: 0.8865451867459342\n",
      "Iteration: 24128, Loss: 0.06964515894651413, Accuracy: 0.8952292399480939\n",
      "Iteration: 24192, Loss: 0.08440259844064713, Accuracy: 0.8855333490646444\n",
      "Iteration: 24256, Loss: 0.019856369122862816, Accuracy: 0.8951802148949355\n",
      "Iteration: 24320, Loss: 0.06800895184278488, Accuracy: 0.8863688717246987\n",
      "Iteration: 24384, Loss: 0.07499067485332489, Accuracy: 0.8835124569595791\n",
      "Iteration: 24448, Loss: 0.040438685566186905, Accuracy: 0.8912078667490277\n",
      "Iteration: 24512, Loss: 0.0026474075857549906, Accuracy: 0.8921146293869242\n",
      "Iteration: 24576, Loss: 0.018292216584086418, Accuracy: 0.8922928585088812\n",
      "Iteration: 24640, Loss: 0.0025794494431465864, Accuracy: 0.8930668514512945\n",
      "Iteration: 24704, Loss: 0.04704275354743004, Accuracy: 0.8978728718066122\n",
      "Iteration: 24768, Loss: 0.042465101927518845, Accuracy: 0.8964649616973475\n",
      "Iteration: 24832, Loss: 0.009552438743412495, Accuracy: 0.8964498532877769\n",
      "Iteration: 24896, Loss: 0.04282718524336815, Accuracy: 0.8795673659187742\n",
      "Iteration: 24960, Loss: 0.0456068255007267, Accuracy: 0.8529708562709857\n",
      "Iteration: 25024, Loss: 0.002710518427193165, Accuracy: 0.8808255385083612\n",
      "Iteration: 25088, Loss: 0.06556526571512222, Accuracy: 0.8926556207297835\n",
      "Iteration: 25152, Loss: 0.003360670991241932, Accuracy: 0.8955387868336402\n",
      "Iteration: 25216, Loss: 0.0019380748271942139, Accuracy: 0.8884679450711701\n",
      "Iteration: 25280, Loss: 0.05410374701023102, Accuracy: 0.8961470641661435\n",
      "Iteration: 25344, Loss: 0.012623303569853306, Accuracy: 0.8974018612352666\n",
      "Iteration: 25408, Loss: 0.015557155944406986, Accuracy: 0.8981001230713446\n",
      "Iteration: 25472, Loss: 0.09218374639749527, Accuracy: 0.8983009264047723\n",
      "Iteration: 25536, Loss: 0.24383024871349335, Accuracy: 0.8739225086756051\n",
      "Iteration: 25600, Loss: 0.04989148676395416, Accuracy: 0.8824766312609427\n",
      "Iteration: 25664, Loss: 0.014817889779806137, Accuracy: 0.9003927251615096\n",
      "Iteration: 25728, Loss: 0.020288249477744102, Accuracy: 0.8950694298546296\n",
      "Iteration: 25792, Loss: 0.0017969314940273762, Accuracy: 0.9006375162280165\n",
      "Iteration: 25856, Loss: 0.021580733358860016, Accuracy: 0.9076895437319763\n",
      "Iteration: 25920, Loss: 0.04249848797917366, Accuracy: 0.9098064592690207\n",
      "Iteration: 25984, Loss: 0.037297237664461136, Accuracy: 0.9066297846729867\n",
      "Iteration: 26048, Loss: 0.013587050139904022, Accuracy: 0.9090498478035443\n",
      "Iteration: 26112, Loss: 0.0162892434746027, Accuracy: 0.8958578032325022\n",
      "Iteration: 26176, Loss: 0.026732509955763817, Accuracy: 0.8630624348588753\n",
      "Iteration: 26240, Loss: 0.01402225811034441, Accuracy: 0.9045732760860119\n",
      "Iteration: 26304, Loss: 0.002213005442172289, Accuracy: 0.9109917078749277\n",
      "Iteration: 26368, Loss: 0.002029325580224395, Accuracy: 0.9022094281681348\n",
      "Iteration: 26432, Loss: 0.045109327882528305, Accuracy: 0.9140235385566484\n",
      "Iteration: 26496, Loss: 0.013497390784323215, Accuracy: 0.9149102836963721\n",
      "Iteration: 26560, Loss: 0.030913233757019043, Accuracy: 0.909169287973782\n",
      "Iteration: 26624, Loss: 0.01277571078389883, Accuracy: 0.9210818639548961\n",
      "Iteration: 26688, Loss: 0.009702342562377453, Accuracy: 0.9181771621515509\n",
      "Iteration: 26752, Loss: 0.001376032829284668, Accuracy: 0.9194315768545493\n",
      "Iteration: 26816, Loss: 0.16932626068592072, Accuracy: 0.9103419282764662\n",
      "Iteration: 26880, Loss: 0.013426869176328182, Accuracy: 0.9150324721413199\n",
      "Iteration: 26944, Loss: 0.0014889194862917066, Accuracy: 0.906749897316331\n",
      "Iteration: 27008, Loss: 0.013703028671443462, Accuracy: 0.9118420468294062\n",
      "Iteration: 27072, Loss: 0.10442619770765305, Accuracy: 0.8893780858779792\n",
      "Iteration: 27136, Loss: 0.01570260338485241, Accuracy: 0.9184599338623229\n",
      "Iteration: 27200, Loss: 0.0794246569275856, Accuracy: 0.9106548569980077\n",
      "Iteration: 27264, Loss: 0.020767195150256157, Accuracy: 0.9119204469607212\n",
      "Iteration: 27328, Loss: 0.024261003360152245, Accuracy: 0.9235424530634191\n",
      "Iteration: 27392, Loss: 0.019851742312312126, Accuracy: 0.9259618881624192\n",
      "Iteration: 27456, Loss: 0.017151033505797386, Accuracy: 0.9271223221439868\n",
      "Iteration: 27520, Loss: 0.014251715503633022, Accuracy: 0.9282440273964312\n",
      "Iteration: 27584, Loss: 0.005174898076802492, Accuracy: 0.9211457021010574\n",
      "Iteration: 27648, Loss: 0.0227836761623621, Accuracy: 0.9239330245472956\n",
      "Iteration: 27712, Loss: 0.011562242172658443, Accuracy: 0.9305331906361971\n",
      "Iteration: 27776, Loss: 0.011227569542825222, Accuracy: 0.9267997296701651\n",
      "Iteration: 27840, Loss: 0.014877361245453358, Accuracy: 0.9279755897296127\n",
      "Iteration: 27904, Loss: 0.0039106025360524654, Accuracy: 0.9281835177680477\n",
      "Iteration: 27968, Loss: 0.0024788619484752417, Accuracy: 0.9325121844594833\n",
      "Iteration: 28032, Loss: 0.0016607224242761731, Accuracy: 0.9160744725959376\n",
      "Iteration: 28096, Loss: 0.03566330298781395, Accuracy: 0.9308295769733377\n",
      "Iteration: 28160, Loss: 0.005337687209248543, Accuracy: 0.9375295393401757\n",
      "Iteration: 28224, Loss: 0.014563504606485367, Accuracy: 0.9364187314640731\n",
      "Iteration: 28288, Loss: 0.024404793977737427, Accuracy: 0.9338894224201795\n",
      "Iteration: 28352, Loss: 0.0026637555565685034, Accuracy: 0.9174113607150503\n",
      "Iteration: 28416, Loss: 0.007374835666269064, Accuracy: 0.9309112310002092\n",
      "Iteration: 28480, Loss: 0.014487768523395061, Accuracy: 0.9143411972618196\n",
      "Iteration: 28544, Loss: 0.005290270317345858, Accuracy: 0.9228666911367327\n",
      "Iteration: 28608, Loss: 0.004306544549763203, Accuracy: 0.930950984795345\n",
      "Iteration: 28672, Loss: 0.002440084470435977, Accuracy: 0.9415710588509683\n",
      "Iteration: 28736, Loss: 0.0014593456871807575, Accuracy: 0.9395359018817544\n",
      "Iteration: 28800, Loss: 0.007396046072244644, Accuracy: 0.9437716998509131\n",
      "Iteration: 28864, Loss: 0.006814330350607634, Accuracy: 0.9369411054940429\n",
      "Iteration: 28928, Loss: 0.007900317199528217, Accuracy: 0.9428929724963382\n",
      "Iteration: 28992, Loss: 0.008514937944710255, Accuracy: 0.9293183142144699\n",
      "Iteration: 29056, Loss: 0.01050824299454689, Accuracy: 0.913051781244576\n",
      "Iteration: 29120, Loss: 0.0012657548068091273, Accuracy: 0.938281169772381\n",
      "Iteration: 29184, Loss: 0.014159243553876877, Accuracy: 0.9258859014953487\n",
      "Iteration: 29248, Loss: 0.0011825250694528222, Accuracy: 0.932382496423088\n",
      "Iteration: 29312, Loss: 0.007043054327368736, Accuracy: 0.910242799873231\n",
      "Iteration: 29376, Loss: 0.0008099475526250899, Accuracy: 0.9263483782415278\n",
      "Iteration: 29440, Loss: 0.013187850825488567, Accuracy: 0.9297174944367725\n",
      "Iteration: 29504, Loss: 0.013110675849020481, Accuracy: 0.9452126144315116\n",
      "Iteration: 29568, Loss: 0.005135850980877876, Accuracy: 0.9434756153495982\n",
      "Iteration: 29632, Loss: 0.013775194995105267, Accuracy: 0.9461925743380561\n",
      "Iteration: 29696, Loss: 0.0005956824170425534, Accuracy: 0.9332859077258036\n",
      "Iteration: 29760, Loss: 0.0008397668716497719, Accuracy: 0.9399275257601403\n",
      "Iteration: 29824, Loss: 0.0031063074711710215, Accuracy: 0.9219765571178868\n",
      "Iteration: 29888, Loss: 0.008412732742726803, Accuracy: 0.9523082731175236\n",
      "Iteration: 29952, Loss: 0.0025457723531872034, Accuracy: 0.9440903532959055\n",
      "Iteration: 30016, Loss: 0.008868567645549774, Accuracy: 0.9537288922874723\n",
      "Iteration: 30080, Loss: 0.014121238142251968, Accuracy: 0.9438543127616867\n",
      "Iteration: 30144, Loss: 0.002478113630786538, Accuracy: 0.9500211231352296\n",
      "Iteration: 30208, Loss: 0.0009477972635067999, Accuracy: 0.9510694029740989\n",
      "Iteration: 30272, Loss: 0.010264726355671883, Accuracy: 0.952639858762268\n",
      "Iteration: 30336, Loss: 0.00223653856664896, Accuracy: 0.9512620893656276\n",
      "Iteration: 30400, Loss: 0.002585148671641946, Accuracy: 0.957349656324368\n",
      "Iteration: 30464, Loss: 0.007501035928726196, Accuracy: 0.9515481472190004\n",
      "Iteration: 30528, Loss: 0.5640624165534973, Accuracy: 0.934060717409011\n",
      "Iteration: 30592, Loss: 0.0016669683391228318, Accuracy: 0.9536435209447518\n",
      "Iteration: 30656, Loss: 0.005616065114736557, Accuracy: 0.9531822656863369\n",
      "Iteration: 30720, Loss: 0.0029328775126487017, Accuracy: 0.954331528802868\n",
      "Iteration: 30784, Loss: 0.0029043161775916815, Accuracy: 0.9560022493824363\n",
      "Iteration: 30848, Loss: 0.0036336358170956373, Accuracy: 0.9580394019430969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 30912, Loss: 0.0006457227864302695, Accuracy: 0.958495629747631\n",
      "Iteration: 30976, Loss: 0.001182649633847177, Accuracy: 0.9603805991646368\n",
      "Iteration: 31040, Loss: 0.00046953209675848484, Accuracy: 0.9629766916914377\n",
      "Iteration: 31104, Loss: 0.00612442335113883, Accuracy: 0.9625512835336849\n",
      "Iteration: 31168, Loss: 0.005231356248259544, Accuracy: 0.9542029151634779\n",
      "Iteration: 31232, Loss: 0.003735676407814026, Accuracy: 0.8970426524756476\n",
      "Iteration: 31296, Loss: 0.5661638379096985, Accuracy: 0.9011043724603951\n",
      "Iteration: 31360, Loss: 0.005005855578929186, Accuracy: 0.9155879978497978\n",
      "Iteration: 31424, Loss: 0.001023083576001227, Accuracy: 0.9103282226715237\n",
      "Iteration: 31488, Loss: 0.03529364615678787, Accuracy: 0.9011472111742478\n",
      "Iteration: 31552, Loss: 0.0071663330309093, Accuracy: 0.9288665283238515\n",
      "Iteration: 31616, Loss: 0.0006190425483509898, Accuracy: 0.9031018680689158\n",
      "Iteration: 31680, Loss: 0.001319456030614674, Accuracy: 0.919112055154983\n",
      "Iteration: 31744, Loss: 0.0010350971715524793, Accuracy: 0.9112283423601184\n",
      "Iteration: 31808, Loss: 0.005156018305569887, Accuracy: 0.9374918406101642\n",
      "Iteration: 31872, Loss: 0.005739273969084024, Accuracy: 0.9580114545824472\n",
      "Iteration: 31936, Loss: 0.007257334887981415, Accuracy: 0.9611182864464354\n",
      "Iteration: 32000, Loss: 0.451653391122818, Accuracy: 0.9414885691803647\n",
      "Iteration: 32064, Loss: 0.005263158585876226, Accuracy: 0.9452995094761718\n",
      "Iteration: 32128, Loss: 0.1745195984840393, Accuracy: 0.9489437218580861\n",
      "Iteration: 32192, Loss: 0.0016818019794300199, Accuracy: 0.960040526901139\n",
      "Iteration: 32256, Loss: 0.00981410127133131, Accuracy: 0.9600794586731354\n",
      "Iteration: 32320, Loss: 0.0014366585528478026, Accuracy: 0.9647729119024007\n",
      "Iteration: 32384, Loss: 0.21762655675411224, Accuracy: 0.9204688047029776\n",
      "Iteration: 32448, Loss: 0.0006635146564804018, Accuracy: 0.9432251881517004\n",
      "Iteration: 32512, Loss: 0.001174352946691215, Accuracy: 0.944895639520837\n",
      "Iteration: 32576, Loss: 0.0005962934228591621, Accuracy: 0.9567939049593406\n",
      "Iteration: 32640, Loss: 0.0008943742723204195, Accuracy: 0.927838230112684\n",
      "Iteration: 32704, Loss: 0.0021642264910042286, Accuracy: 0.9095125480380375\n",
      "Iteration: 32768, Loss: 0.014931820333003998, Accuracy: 0.9168331933324225\n",
      "Iteration: 32832, Loss: 0.005091091152280569, Accuracy: 0.9268950590922032\n",
      "Iteration: 32896, Loss: 0.0007860641344450414, Accuracy: 0.9664738541614497\n",
      "Iteration: 32960, Loss: 0.004276401363313198, Accuracy: 0.9694044752977788\n",
      "Iteration: 33024, Loss: 0.0038521597161889076, Accuracy: 0.9682976392650744\n",
      "Iteration: 33088, Loss: 0.0007988338475115597, Accuracy: 0.9582183007150888\n",
      "Iteration: 33152, Loss: 0.003904108190909028, Accuracy: 0.9598412042396376\n",
      "Iteration: 33216, Loss: 0.005444856360554695, Accuracy: 0.9609783711202908\n",
      "Iteration: 33280, Loss: 0.002057295059785247, Accuracy: 0.9576217836729484\n",
      "Iteration: 33344, Loss: 0.0006694148178212345, Accuracy: 0.9592651364800986\n",
      "Iteration: 33408, Loss: 0.0005861961399205029, Accuracy: 0.9595746434642933\n",
      "Iteration: 33472, Loss: 0.0013844688655808568, Accuracy: 0.9638000996346818\n",
      "Iteration: 33536, Loss: 0.0021485586185008287, Accuracy: 0.9593565714021679\n",
      "Iteration: 33600, Loss: 0.001037881476804614, Accuracy: 0.9644252463331213\n",
      "Iteration: 33664, Loss: 0.003971026744693518, Accuracy: 0.9081136206368683\n",
      "Iteration: 33728, Loss: 0.0012771751498803496, Accuracy: 0.9344325160200242\n",
      "Iteration: 33792, Loss: 0.0025428130757063627, Accuracy: 0.9546373085613595\n",
      "Iteration: 33856, Loss: 0.02007254585623741, Accuracy: 0.9427260559750721\n",
      "Iteration: 33920, Loss: 0.0029709143564105034, Accuracy: 0.9646752643020591\n",
      "Iteration: 33984, Loss: 0.0029110328759998083, Accuracy: 0.9680376519536367\n",
      "Iteration: 34048, Loss: 0.007640914525836706, Accuracy: 0.9401620154967532\n",
      "Iteration: 34112, Loss: 0.0033095013350248337, Accuracy: 0.9567382068053121\n",
      "Iteration: 34176, Loss: 0.003372426377609372, Accuracy: 0.9651337891700678\n",
      "Iteration: 34240, Loss: 0.0016196627402678132, Accuracy: 0.9688614387268899\n",
      "Iteration: 34304, Loss: 0.0004736771807074547, Accuracy: 0.961386025257525\n",
      "Iteration: 34368, Loss: 0.0013890755362808704, Accuracy: 0.9593000107415719\n",
      "Iteration: 34432, Loss: 0.0049219150096178055, Accuracy: 0.9672565776272677\n",
      "Iteration: 34496, Loss: 0.00020079156092833728, Accuracy: 0.9674694339337293\n",
      "Iteration: 34560, Loss: 0.002911509247496724, Accuracy: 0.9671116686804453\n",
      "Iteration: 34624, Loss: 0.00167097058147192, Accuracy: 0.969783420485328\n",
      "Iteration: 34688, Loss: 0.0008911141776479781, Accuracy: 0.9708761327638058\n",
      "Saved fullModel_dr[5]_replicate0.model\n",
      "Saved W_dr[5]_replicate0.p\n",
      "5 1.0 [1.0, 1.0, 1.0]\n",
      "Saved w_dr[5]_replicate0.p\n",
      "Replicate 0 completed\n",
      "Time elapsed: 776.625 seconds\n",
      "Iteration: 64, Loss: 0.258872389793396, Accuracy: 0.49910973897203803\n",
      "Iteration: 128, Loss: 0.26071855425834656, Accuracy: 0.49914683820679784\n",
      "Iteration: 192, Loss: 0.26367977261543274, Accuracy: 0.49972384283319116\n",
      "Iteration: 256, Loss: 0.2600884735584259, Accuracy: 0.4994853353127837\n",
      "Iteration: 320, Loss: 0.24691925942897797, Accuracy: 0.4991752980276942\n",
      "Iteration: 384, Loss: 0.24984413385391235, Accuracy: 0.4993611010722816\n",
      "Iteration: 448, Loss: 0.25579833984375, Accuracy: 0.49943560268729925\n",
      "Iteration: 512, Loss: 0.2595634162425995, Accuracy: 0.4999084793962538\n",
      "Iteration: 576, Loss: 0.24000616371631622, Accuracy: 0.5012517566792667\n",
      "Iteration: 640, Loss: 0.22951112687587738, Accuracy: 0.5226543326862156\n",
      "Iteration: 704, Loss: 0.16529448330402374, Accuracy: 0.5726002138108015\n",
      "Iteration: 768, Loss: 0.16317106783390045, Accuracy: 0.6004290306009352\n",
      "Iteration: 832, Loss: 0.16355302929878235, Accuracy: 0.6157038272358477\n",
      "Iteration: 896, Loss: 0.16298441588878632, Accuracy: 0.6207012184895575\n",
      "Iteration: 960, Loss: 0.1797795444726944, Accuracy: 0.6298587238416076\n",
      "Iteration: 1024, Loss: 0.16438722610473633, Accuracy: 0.6350442026741803\n",
      "Iteration: 1088, Loss: 0.17575328052043915, Accuracy: 0.6389175187796354\n",
      "Iteration: 1152, Loss: 0.17777585983276367, Accuracy: 0.6416411362588406\n",
      "Iteration: 1216, Loss: 0.16314277052879333, Accuracy: 0.6433542286977172\n",
      "Iteration: 1280, Loss: 0.1776091307401657, Accuracy: 0.645282803568989\n",
      "Iteration: 1344, Loss: 0.18020689487457275, Accuracy: 0.6469447705894709\n",
      "Iteration: 1408, Loss: 0.16414348781108856, Accuracy: 0.6476176748983562\n",
      "Iteration: 1472, Loss: 0.17589181661605835, Accuracy: 0.6485196896828711\n",
      "Iteration: 1536, Loss: 0.1630878448486328, Accuracy: 0.6501725646667182\n",
      "Iteration: 1600, Loss: 0.1652861386537552, Accuracy: 0.650844968855381\n",
      "Iteration: 1664, Loss: 0.17703859508037567, Accuracy: 0.6517550912685692\n",
      "Iteration: 1728, Loss: 0.17653973400592804, Accuracy: 0.6518940785899758\n",
      "Iteration: 1792, Loss: 0.17632095515727997, Accuracy: 0.6529262051917613\n",
      "Iteration: 1856, Loss: 0.17405737936496735, Accuracy: 0.6534895957447588\n",
      "Iteration: 1920, Loss: 0.16182617843151093, Accuracy: 0.6539375800639391\n",
      "Iteration: 1984, Loss: 0.16204221546649933, Accuracy: 0.6543659307062626\n",
      "Iteration: 2048, Loss: 0.17418313026428223, Accuracy: 0.6544168200343847\n",
      "Iteration: 2112, Loss: 0.17170590162277222, Accuracy: 0.6548789120279253\n",
      "Iteration: 2176, Loss: 0.1771494299173355, Accuracy: 0.6492605172097683\n",
      "Iteration: 2240, Loss: 0.17405541241168976, Accuracy: 0.6549322595819831\n",
      "Iteration: 2304, Loss: 0.17434300482273102, Accuracy: 0.6557689965702593\n",
      "Iteration: 2368, Loss: 0.17072200775146484, Accuracy: 0.6561389160342515\n",
      "Iteration: 2432, Loss: 0.1639866977930069, Accuracy: 0.6565187233500183\n",
      "Iteration: 2496, Loss: 0.16540084779262543, Accuracy: 0.6564854276366532\n",
      "Iteration: 2560, Loss: 0.16791655123233795, Accuracy: 0.6569820176810026\n",
      "Iteration: 2624, Loss: 0.1684504896402359, Accuracy: 0.6571197472512722\n",
      "Iteration: 2688, Loss: 0.17169193923473358, Accuracy: 0.6575512574054301\n",
      "Iteration: 2752, Loss: 0.16666251420974731, Accuracy: 0.6579697178676724\n",
      "Iteration: 2816, Loss: 0.16815944015979767, Accuracy: 0.6574218249879777\n",
      "Iteration: 2880, Loss: 0.1718553751707077, Accuracy: 0.6581551106646657\n",
      "Iteration: 2944, Loss: 0.16552896797657013, Accuracy: 0.6582213784568012\n",
      "Iteration: 3008, Loss: 0.16667775809764862, Accuracy: 0.6584661430679262\n",
      "Iteration: 3072, Loss: 0.1690443754196167, Accuracy: 0.6589474859647453\n",
      "Iteration: 3136, Loss: 0.16838395595550537, Accuracy: 0.6592168351635337\n",
      "Iteration: 3200, Loss: 0.17298787832260132, Accuracy: 0.6587347681634128\n",
      "Iteration: 3264, Loss: 0.16582931578159332, Accuracy: 0.6594242141582072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3328, Loss: 0.1654224544763565, Accuracy: 0.6593473460525274\n",
      "Iteration: 3392, Loss: 0.16445444524288177, Accuracy: 0.6593493055552244\n",
      "Iteration: 3456, Loss: 0.174100860953331, Accuracy: 0.6599432537332177\n",
      "Iteration: 3520, Loss: 0.1637813001871109, Accuracy: 0.6600167308934033\n",
      "Iteration: 3584, Loss: 0.16941821575164795, Accuracy: 0.6602612328715622\n",
      "Iteration: 3648, Loss: 0.16779464483261108, Accuracy: 0.6602635649032891\n",
      "Iteration: 3712, Loss: 0.16442732512950897, Accuracy: 0.6602730080485344\n",
      "Iteration: 3776, Loss: 0.16692321002483368, Accuracy: 0.6604702407494187\n",
      "Iteration: 3840, Loss: 0.16701547801494598, Accuracy: 0.6606703321449459\n",
      "Iteration: 3904, Loss: 0.16650108993053436, Accuracy: 0.6606357474811375\n",
      "Iteration: 3968, Loss: 0.16704916954040527, Accuracy: 0.660950964782387\n",
      "Iteration: 4032, Loss: 0.170065239071846, Accuracy: 0.6606840523891151\n",
      "Iteration: 4096, Loss: 0.16611666977405548, Accuracy: 0.6610821587964892\n",
      "Iteration: 4160, Loss: 0.16976682841777802, Accuracy: 0.6613552868366241\n",
      "Iteration: 4224, Loss: 0.16708385944366455, Accuracy: 0.661422782111913\n",
      "Iteration: 4288, Loss: 0.16704507172107697, Accuracy: 0.6612223382107913\n",
      "Iteration: 4352, Loss: 0.16895021498203278, Accuracy: 0.6614063503220677\n",
      "Iteration: 4416, Loss: 0.16791920363903046, Accuracy: 0.6618950311094522\n",
      "Iteration: 4480, Loss: 0.17153270542621613, Accuracy: 0.6615212080068886\n",
      "Iteration: 4544, Loss: 0.16657550632953644, Accuracy: 0.6620379267260432\n",
      "Iteration: 4608, Loss: 0.16795140504837036, Accuracy: 0.6620792001485825\n",
      "Iteration: 4672, Loss: 0.16872739791870117, Accuracy: 0.6619871500879526\n",
      "Iteration: 4736, Loss: 0.1692676991224289, Accuracy: 0.6621484295465052\n",
      "Iteration: 4800, Loss: 0.16931425034999847, Accuracy: 0.6622741101309657\n",
      "Iteration: 4864, Loss: 0.1654655486345291, Accuracy: 0.662224184256047\n",
      "Iteration: 4928, Loss: 0.1679433435201645, Accuracy: 0.662019151262939\n",
      "Iteration: 4992, Loss: 0.16979442536830902, Accuracy: 0.6623329860158265\n",
      "Iteration: 5056, Loss: 0.16914592683315277, Accuracy: 0.6623113178648055\n",
      "Iteration: 5120, Loss: 0.1682308465242386, Accuracy: 0.6625305661000311\n",
      "Iteration: 5184, Loss: 0.1712489277124405, Accuracy: 0.6625946178101003\n",
      "Iteration: 5248, Loss: 0.16801317036151886, Accuracy: 0.6621038280427456\n",
      "Iteration: 5312, Loss: 0.17029352486133575, Accuracy: 0.6623632218688726\n",
      "Iteration: 5376, Loss: 0.166873037815094, Accuracy: 0.663096078671515\n",
      "Iteration: 5440, Loss: 0.16505888104438782, Accuracy: 0.6631725202314556\n",
      "Iteration: 5504, Loss: 0.16968466341495514, Accuracy: 0.6631520544178784\n",
      "Iteration: 5568, Loss: 0.165122851729393, Accuracy: 0.6628030496649444\n",
      "Iteration: 5632, Loss: 0.16583658754825592, Accuracy: 0.6629169597290456\n",
      "Iteration: 5696, Loss: 0.1678030639886856, Accuracy: 0.6627222434617579\n",
      "Iteration: 5760, Loss: 0.16589632630348206, Accuracy: 0.6632691938430071\n",
      "Iteration: 5824, Loss: 0.16813598573207855, Accuracy: 0.6628230758942664\n",
      "Iteration: 5888, Loss: 0.17241132259368896, Accuracy: 0.663227656390518\n",
      "Iteration: 5952, Loss: 0.16774123907089233, Accuracy: 0.6631955257616937\n",
      "Iteration: 6016, Loss: 0.1687697172164917, Accuracy: 0.6635329346172512\n",
      "Iteration: 6080, Loss: 0.1662287563085556, Accuracy: 0.6632728115655482\n",
      "Iteration: 6144, Loss: 0.16764436662197113, Accuracy: 0.6632502810098231\n",
      "Iteration: 6208, Loss: 0.16843827068805695, Accuracy: 0.6633202214725316\n",
      "Iteration: 6272, Loss: 0.16999579966068268, Accuracy: 0.6634105024859309\n",
      "Iteration: 6336, Loss: 0.1671830266714096, Accuracy: 0.6635530740022659\n",
      "Iteration: 6400, Loss: 0.16528616845607758, Accuracy: 0.6632785443216562\n",
      "Iteration: 6464, Loss: 0.16586513817310333, Accuracy: 0.6633654730394483\n",
      "Iteration: 6528, Loss: 0.17019812762737274, Accuracy: 0.6631772872060537\n",
      "Iteration: 6592, Loss: 0.17056502401828766, Accuracy: 0.6636268640868366\n",
      "Iteration: 6656, Loss: 0.16668559610843658, Accuracy: 0.6636766153387725\n",
      "Iteration: 6720, Loss: 0.1676311492919922, Accuracy: 0.6635187421925366\n",
      "Iteration: 6784, Loss: 0.16976787149906158, Accuracy: 0.6640683123841882\n",
      "Iteration: 6848, Loss: 0.16676302254199982, Accuracy: 0.6640357654541731\n",
      "Iteration: 6912, Loss: 0.16827334463596344, Accuracy: 0.6641677333973348\n",
      "Iteration: 6976, Loss: 0.16312366724014282, Accuracy: 0.6635875478386879\n",
      "Iteration: 7040, Loss: 0.16870276629924774, Accuracy: 0.664150845259428\n",
      "Iteration: 7104, Loss: 0.1678183227777481, Accuracy: 0.6640932862646878\n",
      "Iteration: 7168, Loss: 0.16931666433811188, Accuracy: 0.6640783166512847\n",
      "Iteration: 7232, Loss: 0.16441386938095093, Accuracy: 0.6641695606522262\n",
      "Iteration: 7296, Loss: 0.16760875284671783, Accuracy: 0.6643012342974544\n",
      "Iteration: 7360, Loss: 0.16612929105758667, Accuracy: 0.6640486023388803\n",
      "Iteration: 7424, Loss: 0.1682785004377365, Accuracy: 0.6643366469070315\n",
      "Iteration: 7488, Loss: 0.16817016899585724, Accuracy: 0.6643324326723814\n",
      "Iteration: 7552, Loss: 0.16997943818569183, Accuracy: 0.6645932528190315\n",
      "Iteration: 7616, Loss: 0.16660292446613312, Accuracy: 0.6641335873864591\n",
      "Iteration: 7680, Loss: 0.1701948195695877, Accuracy: 0.6643978077918291\n",
      "Iteration: 7744, Loss: 0.16853421926498413, Accuracy: 0.6643771016970277\n",
      "Iteration: 7808, Loss: 0.17270201444625854, Accuracy: 0.6642100089229643\n",
      "Iteration: 7872, Loss: 0.16858504712581635, Accuracy: 0.6646150480955839\n",
      "Iteration: 7936, Loss: 0.1678938865661621, Accuracy: 0.664497310295701\n",
      "Iteration: 8000, Loss: 0.16519947350025177, Accuracy: 0.6644013808108866\n",
      "Iteration: 8064, Loss: 0.16708524525165558, Accuracy: 0.6644608625210822\n",
      "Iteration: 8128, Loss: 0.16640682518482208, Accuracy: 0.664454024285078\n",
      "Iteration: 8192, Loss: 0.16691996157169342, Accuracy: 0.6645460212603211\n",
      "Iteration: 8256, Loss: 0.17001472413539886, Accuracy: 0.6647173357196152\n",
      "Iteration: 8320, Loss: 0.16942580044269562, Accuracy: 0.6646192665211856\n",
      "Iteration: 8384, Loss: 0.16718952357769012, Accuracy: 0.6643815552815795\n",
      "Iteration: 8448, Loss: 0.1677730530500412, Accuracy: 0.6647278182208538\n",
      "Iteration: 8512, Loss: 0.16668455302715302, Accuracy: 0.6645215307362378\n",
      "Iteration: 8576, Loss: 0.170074462890625, Accuracy: 0.6647993000224233\n",
      "Iteration: 8640, Loss: 0.16749469935894012, Accuracy: 0.6648149318061769\n",
      "Iteration: 8704, Loss: 0.1693684458732605, Accuracy: 0.66446802765131\n",
      "Iteration: 8768, Loss: 0.16530127823352814, Accuracy: 0.665174922440201\n",
      "Iteration: 8832, Loss: 0.16885702311992645, Accuracy: 0.664515046402812\n",
      "Iteration: 8896, Loss: 0.16419801115989685, Accuracy: 0.6647471436299384\n",
      "Iteration: 8960, Loss: 0.1659451574087143, Accuracy: 0.6647396804764867\n",
      "Iteration: 9024, Loss: 0.17191077768802643, Accuracy: 0.6646606619469821\n",
      "Iteration: 9088, Loss: 0.16366195678710938, Accuracy: 0.6649531736038625\n",
      "Iteration: 9152, Loss: 0.16808100044727325, Accuracy: 0.664962203707546\n",
      "Iteration: 9216, Loss: 0.16513903439044952, Accuracy: 0.6649144147522748\n",
      "Iteration: 9280, Loss: 0.17288537323474884, Accuracy: 0.6644417569041252\n",
      "Iteration: 9344, Loss: 0.16501842439174652, Accuracy: 0.6650244216434658\n",
      "Iteration: 9408, Loss: 0.16788959503173828, Accuracy: 0.6645303778350353\n",
      "Iteration: 9472, Loss: 0.16712354123592377, Accuracy: 0.6648852922953665\n",
      "Iteration: 9536, Loss: 0.16700315475463867, Accuracy: 0.6649843538179994\n",
      "Iteration: 9600, Loss: 0.16594259440898895, Accuracy: 0.6650497866794467\n",
      "Iteration: 9664, Loss: 0.1690540462732315, Accuracy: 0.6647406779229641\n",
      "Iteration: 9728, Loss: 0.16533756256103516, Accuracy: 0.6652186247520149\n",
      "Iteration: 9792, Loss: 0.1659882813692093, Accuracy: 0.6650854828767478\n",
      "Iteration: 9856, Loss: 0.16721154749393463, Accuracy: 0.6650568437762558\n",
      "Iteration: 9920, Loss: 0.1693643182516098, Accuracy: 0.6652851216495037\n",
      "Iteration: 9984, Loss: 0.16583380103111267, Accuracy: 0.665205127093941\n",
      "Iteration: 10048, Loss: 0.170044407248497, Accuracy: 0.665041830856353\n",
      "Iteration: 10112, Loss: 0.16891656816005707, Accuracy: 0.6652014660649002\n",
      "Iteration: 10176, Loss: 0.16837601363658905, Accuracy: 0.6653210059739649\n",
      "Iteration: 10240, Loss: 0.16868357360363007, Accuracy: 0.6651524272747338\n",
      "Iteration: 10304, Loss: 0.1698237508535385, Accuracy: 0.6650897464714944\n",
      "Iteration: 10368, Loss: 0.16473643481731415, Accuracy: 0.6650794143788517\n",
      "Iteration: 10432, Loss: 0.16918103396892548, Accuracy: 0.665251197759062\n",
      "Iteration: 10496, Loss: 0.1639573723077774, Accuracy: 0.665041780564934\n",
      "Iteration: 10560, Loss: 0.16440917551517487, Accuracy: 0.6651620683260262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10624, Loss: 0.16859841346740723, Accuracy: 0.6653265291824937\n",
      "Iteration: 10688, Loss: 0.17093652486801147, Accuracy: 0.6653840630315244\n",
      "Iteration: 10752, Loss: 0.16609667241573334, Accuracy: 0.6655423901975155\n",
      "Iteration: 10816, Loss: 0.1683652549982071, Accuracy: 0.6651416518725455\n",
      "Iteration: 10880, Loss: 0.1677597165107727, Accuracy: 0.6650494756177068\n",
      "Iteration: 10944, Loss: 0.16807503998279572, Accuracy: 0.6647448241710663\n",
      "Iteration: 11008, Loss: 0.1659519523382187, Accuracy: 0.6652894695289433\n",
      "Iteration: 11072, Loss: 0.16741664707660675, Accuracy: 0.6650765938684344\n",
      "Iteration: 11136, Loss: 0.16817884147167206, Accuracy: 0.6655626860447228\n",
      "Iteration: 11200, Loss: 0.1666908711194992, Accuracy: 0.6654780795797706\n",
      "Iteration: 11264, Loss: 0.17017753422260284, Accuracy: 0.6649368973448873\n",
      "Iteration: 11328, Loss: 0.16792170703411102, Accuracy: 0.6653466313146055\n",
      "Iteration: 11392, Loss: 0.1669800728559494, Accuracy: 0.6654592473059893\n",
      "Iteration: 11456, Loss: 0.16698665916919708, Accuracy: 0.6655337833799422\n",
      "Iteration: 11520, Loss: 0.16628235578536987, Accuracy: 0.6650805580429733\n",
      "Iteration: 11584, Loss: 0.16676251590251923, Accuracy: 0.6653468725271523\n",
      "Iteration: 11648, Loss: 0.16603614389896393, Accuracy: 0.665490884333849\n",
      "Iteration: 11712, Loss: 0.16618932783603668, Accuracy: 0.6652342537418008\n",
      "Iteration: 11776, Loss: 0.16562974452972412, Accuracy: 0.6656842660158873\n",
      "Iteration: 11840, Loss: 0.16902631521224976, Accuracy: 0.6651974590495229\n",
      "Iteration: 11904, Loss: 0.16878752410411835, Accuracy: 0.665049048140645\n",
      "Iteration: 11968, Loss: 0.16724546253681183, Accuracy: 0.6654828344471753\n",
      "Iteration: 12032, Loss: 0.16863732039928436, Accuracy: 0.6654391270130873\n",
      "Iteration: 12096, Loss: 0.1707555502653122, Accuracy: 0.6651802742853761\n",
      "Iteration: 12160, Loss: 0.16680262982845306, Accuracy: 0.665550209581852\n",
      "Iteration: 12224, Loss: 0.17049948871135712, Accuracy: 0.6652812515385449\n",
      "Iteration: 12288, Loss: 0.1691574901342392, Accuracy: 0.6653836141340435\n",
      "Iteration: 12352, Loss: 0.16961835324764252, Accuracy: 0.665394923184067\n",
      "Iteration: 12416, Loss: 0.16690249741077423, Accuracy: 0.6654684967361391\n",
      "Iteration: 12480, Loss: 0.1663127988576889, Accuracy: 0.6655110060237348\n",
      "Iteration: 12544, Loss: 0.16706305742263794, Accuracy: 0.665631762240082\n",
      "Iteration: 12608, Loss: 0.166987344622612, Accuracy: 0.6656564851291478\n",
      "Iteration: 12672, Loss: 0.16828034818172455, Accuracy: 0.6655796370469034\n",
      "Iteration: 12736, Loss: 0.16964846849441528, Accuracy: 0.6653364188969135\n",
      "Iteration: 12800, Loss: 0.16752159595489502, Accuracy: 0.6654924186877906\n",
      "Iteration: 12864, Loss: 0.1661226749420166, Accuracy: 0.6655588047578931\n",
      "Iteration: 12928, Loss: 0.16796188056468964, Accuracy: 0.6655419254675508\n",
      "Iteration: 12992, Loss: 0.1793811321258545, Accuracy: 0.5705193905159831\n",
      "Iteration: 13056, Loss: 0.15474192798137665, Accuracy: 0.6589335738681257\n",
      "Iteration: 13120, Loss: 0.17195625603199005, Accuracy: 0.6639208071865141\n",
      "Iteration: 13184, Loss: 0.17801253497600555, Accuracy: 0.6637853737920523\n",
      "Iteration: 13248, Loss: 0.17631421983242035, Accuracy: 0.6641403394751251\n",
      "Iteration: 13312, Loss: 0.1647786647081375, Accuracy: 0.6642184276133776\n",
      "Iteration: 13376, Loss: 0.16248144209384918, Accuracy: 0.6591952736489475\n",
      "Iteration: 13440, Loss: 0.16072678565979004, Accuracy: 0.6589852031320333\n",
      "Iteration: 13504, Loss: 0.15971225500106812, Accuracy: 0.6589794089086354\n",
      "Iteration: 13568, Loss: 0.16982817649841309, Accuracy: 0.6640349295921624\n",
      "Iteration: 13632, Loss: 0.17459696531295776, Accuracy: 0.6640173429623246\n",
      "Iteration: 13696, Loss: 0.1687171906232834, Accuracy: 0.6639035595580935\n",
      "Iteration: 13760, Loss: 0.16841362416744232, Accuracy: 0.664066500030458\n",
      "Iteration: 13824, Loss: 0.16802358627319336, Accuracy: 0.659086701925844\n",
      "Iteration: 13888, Loss: 0.16850268840789795, Accuracy: 0.6638095038942993\n",
      "Iteration: 13952, Loss: 0.16808469593524933, Accuracy: 0.6641948651522398\n",
      "Iteration: 14016, Loss: 0.1694170981645584, Accuracy: 0.6644100127741694\n",
      "Iteration: 14080, Loss: 0.16795016825199127, Accuracy: 0.6541843777522445\n",
      "Iteration: 14144, Loss: 0.16881507635116577, Accuracy: 0.6536220004782081\n",
      "Iteration: 14208, Loss: 0.1652296632528305, Accuracy: 0.6636472470127046\n",
      "Iteration: 14272, Loss: 0.1696857213973999, Accuracy: 0.6583418934606016\n",
      "Iteration: 14336, Loss: 0.17474551498889923, Accuracy: 0.6581393089145422\n",
      "Iteration: 14400, Loss: 0.16558919847011566, Accuracy: 0.6631956160999835\n",
      "Iteration: 14464, Loss: 0.1674058437347412, Accuracy: 0.6633585286326706\n",
      "Iteration: 14528, Loss: 0.1621190309524536, Accuracy: 0.6636572382412851\n",
      "Iteration: 14592, Loss: 0.16846410930156708, Accuracy: 0.6635572025552392\n",
      "Iteration: 14656, Loss: 0.16737718880176544, Accuracy: 0.6638401336967945\n",
      "Iteration: 14720, Loss: 0.17087145149707794, Accuracy: 0.6636786474846303\n",
      "Iteration: 14784, Loss: 0.17068469524383545, Accuracy: 0.658653624355793\n",
      "Iteration: 14848, Loss: 0.16810555756092072, Accuracy: 0.6633420339785516\n",
      "Iteration: 14912, Loss: 0.1692524403333664, Accuracy: 0.6630766983143985\n",
      "Iteration: 14976, Loss: 0.16991405189037323, Accuracy: 0.6633605873212218\n",
      "Iteration: 15040, Loss: 0.16750244796276093, Accuracy: 0.6635209321975708\n",
      "Iteration: 15104, Loss: 0.16560065746307373, Accuracy: 0.6635739374905825\n",
      "Iteration: 15168, Loss: 0.1699264496564865, Accuracy: 0.6638923464342952\n",
      "Iteration: 15232, Loss: 0.1677578240633011, Accuracy: 0.6638911906629801\n",
      "Iteration: 15296, Loss: 0.1620468646287918, Accuracy: 0.663613052573055\n",
      "Iteration: 15360, Loss: 0.17255647480487823, Accuracy: 0.6638276190496981\n",
      "Iteration: 15424, Loss: 0.16648277640342712, Accuracy: 0.6639523492194712\n",
      "Iteration: 15488, Loss: 0.16698886454105377, Accuracy: 0.6641250867396593\n",
      "Iteration: 15552, Loss: 0.1689734011888504, Accuracy: 0.6639959998428822\n",
      "Iteration: 15616, Loss: 0.16828636825084686, Accuracy: 0.6639420022256672\n",
      "Iteration: 15680, Loss: 0.16794221103191376, Accuracy: 0.6640219399705529\n",
      "Iteration: 15744, Loss: 0.16958659887313843, Accuracy: 0.6641794475726783\n",
      "Iteration: 15808, Loss: 0.16943009197711945, Accuracy: 0.6641673287376761\n",
      "Iteration: 15872, Loss: 0.1676303595304489, Accuracy: 0.6644200095906854\n",
      "Iteration: 15936, Loss: 0.16790233552455902, Accuracy: 0.6643815231509507\n",
      "Iteration: 16000, Loss: 0.16761742532253265, Accuracy: 0.6641422212123871\n",
      "Iteration: 16064, Loss: 0.17104347050189972, Accuracy: 0.6640698607079685\n",
      "Iteration: 16128, Loss: 0.16754919290542603, Accuracy: 0.664267051499337\n",
      "Iteration: 16192, Loss: 0.16817300021648407, Accuracy: 0.6643391405232251\n",
      "Iteration: 16256, Loss: 0.1670270413160324, Accuracy: 0.6646504662930965\n",
      "Iteration: 16320, Loss: 0.17069560289382935, Accuracy: 0.6644240380264819\n",
      "Iteration: 16384, Loss: 0.16849899291992188, Accuracy: 0.6644994919188321\n",
      "Iteration: 16448, Loss: 0.1687808483839035, Accuracy: 0.6646628989838064\n",
      "Iteration: 16512, Loss: 0.1679324358701706, Accuracy: 0.6646224395371974\n",
      "Iteration: 16576, Loss: 0.1684509962797165, Accuracy: 0.6646269150078297\n",
      "Iteration: 16640, Loss: 0.1679980754852295, Accuracy: 0.6595691754482687\n",
      "Iteration: 16704, Loss: 0.16738896071910858, Accuracy: 0.6643103938549757\n",
      "Iteration: 16768, Loss: 0.17199480533599854, Accuracy: 0.6643590172752738\n",
      "Iteration: 16832, Loss: 0.16951984167099, Accuracy: 0.6647901777178049\n",
      "Iteration: 16896, Loss: 0.16784369945526123, Accuracy: 0.6647871430031955\n",
      "Iteration: 16960, Loss: 0.1688024252653122, Accuracy: 0.6645420966669917\n",
      "Iteration: 17024, Loss: 0.16685454547405243, Accuracy: 0.6648450810462236\n",
      "Iteration: 17088, Loss: 0.16879023611545563, Accuracy: 0.6646975316107273\n",
      "Iteration: 17152, Loss: 0.16730646789073944, Accuracy: 0.6647984692826867\n",
      "Iteration: 17216, Loss: 0.16660334169864655, Accuracy: 0.6649488522671163\n",
      "Iteration: 17280, Loss: 0.1681448072195053, Accuracy: 0.6645021857693791\n",
      "Iteration: 17344, Loss: 0.1694124937057495, Accuracy: 0.6647668266668916\n",
      "Iteration: 17408, Loss: 0.17138011753559113, Accuracy: 0.6645782995037735\n",
      "Iteration: 17472, Loss: 0.16576392948627472, Accuracy: 0.6643222803249955\n",
      "Iteration: 17536, Loss: 0.16530589759349823, Accuracy: 0.6646591327153146\n",
      "Iteration: 17600, Loss: 0.16796745359897614, Accuracy: 0.6647143382579088\n",
      "Iteration: 17664, Loss: 0.16809618473052979, Accuracy: 0.6647290475666523\n",
      "Iteration: 17728, Loss: 0.16944466531276703, Accuracy: 0.664742564316839\n",
      "Iteration: 17792, Loss: 0.16744659841060638, Accuracy: 0.6649815174750984\n",
      "Iteration: 17856, Loss: 0.17078812420368195, Accuracy: 0.6648623147048056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 17920, Loss: 0.1673090010881424, Accuracy: 0.6648589726537466\n",
      "Iteration: 17984, Loss: 0.16971801221370697, Accuracy: 0.6576240924187005\n",
      "Iteration: 18048, Loss: 0.16489969193935394, Accuracy: 0.6616556784138083\n",
      "Iteration: 18112, Loss: 0.16631610691547394, Accuracy: 0.66465785773471\n",
      "Iteration: 18176, Loss: 0.167622372508049, Accuracy: 0.6647809902206063\n",
      "Iteration: 18240, Loss: 0.16888605058193207, Accuracy: 0.6647584014572203\n",
      "Iteration: 18304, Loss: 0.1683816760778427, Accuracy: 0.6648963736370206\n",
      "Iteration: 18368, Loss: 0.16797463595867157, Accuracy: 0.6647169124335051\n",
      "Iteration: 18432, Loss: 0.1683034896850586, Accuracy: 0.6648003403097391\n",
      "Iteration: 18496, Loss: 0.16940613090991974, Accuracy: 0.6648343522101641\n",
      "Iteration: 18560, Loss: 0.16988253593444824, Accuracy: 0.6649205074645579\n",
      "Iteration: 18624, Loss: 0.1679244488477707, Accuracy: 0.6647082907147706\n",
      "Iteration: 18688, Loss: 0.16783089935779572, Accuracy: 0.6647526486776769\n",
      "Iteration: 18752, Loss: 0.1662687361240387, Accuracy: 0.6649068896658719\n",
      "Iteration: 18816, Loss: 0.1663445234298706, Accuracy: 0.6650302321650088\n",
      "Iteration: 18880, Loss: 0.1677684783935547, Accuracy: 0.6649683387950063\n",
      "Iteration: 18944, Loss: 0.1687989979982376, Accuracy: 0.6650844397954643\n",
      "Iteration: 19008, Loss: 0.16733001172542572, Accuracy: 0.6648476333357394\n",
      "Iteration: 19072, Loss: 0.17107929289340973, Accuracy: 0.6650654398836195\n",
      "Iteration: 19136, Loss: 0.16609767079353333, Accuracy: 0.6651724348776042\n",
      "Iteration: 19200, Loss: 0.16897588968276978, Accuracy: 0.6649897219613194\n",
      "Iteration: 19264, Loss: 0.16514401137828827, Accuracy: 0.6647291937842965\n",
      "Iteration: 19328, Loss: 0.16954530775547028, Accuracy: 0.6649584081023932\n",
      "Iteration: 19392, Loss: 0.16842800378799438, Accuracy: 0.6650906344875693\n",
      "Iteration: 19456, Loss: 0.16971558332443237, Accuracy: 0.6651249695569277\n",
      "Iteration: 19520, Loss: 0.16707395017147064, Accuracy: 0.6651548123918474\n",
      "Iteration: 19584, Loss: 0.16664831340312958, Accuracy: 0.6650192057713866\n",
      "Iteration: 19648, Loss: 0.16837769746780396, Accuracy: 0.6651439368724823\n",
      "Iteration: 19712, Loss: 0.16788841784000397, Accuracy: 0.6651455005630851\n",
      "Iteration: 19776, Loss: 0.16696922481060028, Accuracy: 0.6651717694476247\n",
      "Iteration: 19840, Loss: 0.1683162897825241, Accuracy: 0.6653167186304927\n",
      "Iteration: 19904, Loss: 0.16629146039485931, Accuracy: 0.6651154207065701\n",
      "Iteration: 19968, Loss: 0.16932068765163422, Accuracy: 0.6650628843344748\n",
      "Iteration: 20032, Loss: 0.1675892472267151, Accuracy: 0.6650774138979614\n",
      "Iteration: 20096, Loss: 0.1667853742837906, Accuracy: 0.6652813092805445\n",
      "Iteration: 20160, Loss: 0.16949261724948883, Accuracy: 0.6651285137049854\n",
      "Iteration: 20224, Loss: 0.16602100431919098, Accuracy: 0.6652113734744489\n",
      "Iteration: 20288, Loss: 0.16684114933013916, Accuracy: 0.664924425072968\n",
      "Iteration: 20352, Loss: 0.16861313581466675, Accuracy: 0.6652964451350272\n",
      "Iteration: 20416, Loss: 0.1679072231054306, Accuracy: 0.665311373770237\n",
      "Iteration: 20480, Loss: 0.16839289665222168, Accuracy: 0.6650507408194244\n",
      "Iteration: 20544, Loss: 0.1668097823858261, Accuracy: 0.6652582888491452\n",
      "Iteration: 20608, Loss: 0.16767551004886627, Accuracy: 0.6647448083385825\n",
      "Iteration: 20672, Loss: 0.16848571598529816, Accuracy: 0.6653803642839193\n",
      "Iteration: 20736, Loss: 0.16719503700733185, Accuracy: 0.6652472955174744\n",
      "Iteration: 20800, Loss: 0.1661166399717331, Accuracy: 0.6653803703375161\n",
      "Iteration: 20864, Loss: 0.16966046392917633, Accuracy: 0.6648741355165839\n",
      "Iteration: 20928, Loss: 0.17059624195098877, Accuracy: 0.6653041956014931\n",
      "Iteration: 20992, Loss: 0.1676563173532486, Accuracy: 0.6655405219644308\n",
      "Iteration: 21056, Loss: 0.16908417642116547, Accuracy: 0.6653804504312575\n",
      "Iteration: 21120, Loss: 0.16772104799747467, Accuracy: 0.6653859629295766\n",
      "Iteration: 21184, Loss: 0.16746188700199127, Accuracy: 0.6655475813895464\n",
      "Iteration: 21248, Loss: 0.16645605862140656, Accuracy: 0.665353415068239\n",
      "Iteration: 21312, Loss: 0.16859154403209686, Accuracy: 0.6652371222153306\n",
      "Iteration: 21376, Loss: 0.16874609887599945, Accuracy: 0.6652270290069282\n",
      "Iteration: 21440, Loss: 0.16682304441928864, Accuracy: 0.6652982328087091\n",
      "Iteration: 21504, Loss: 0.16879801452159882, Accuracy: 0.6652077152393758\n",
      "Iteration: 21568, Loss: 0.16904592514038086, Accuracy: 0.665727483574301\n",
      "Iteration: 21632, Loss: 0.16541968286037445, Accuracy: 0.6652946271933615\n",
      "Iteration: 21696, Loss: 0.16739968955516815, Accuracy: 0.6650863103568554\n",
      "Iteration: 21760, Loss: 0.17000329494476318, Accuracy: 0.6654263976961374\n",
      "Iteration: 21824, Loss: 0.16826897859573364, Accuracy: 0.6655092053115368\n",
      "Iteration: 21888, Loss: 0.17032240331172943, Accuracy: 0.6652692332863808\n",
      "Iteration: 21952, Loss: 0.16855241358280182, Accuracy: 0.6652450766414404\n",
      "Iteration: 22016, Loss: 0.16871464252471924, Accuracy: 0.6655306639149785\n",
      "Iteration: 22080, Loss: 0.16515739262104034, Accuracy: 0.6655104798264802\n",
      "Iteration: 22144, Loss: 0.16914184391498566, Accuracy: 0.6655827984213829\n",
      "Iteration: 22208, Loss: 0.16738282144069672, Accuracy: 0.6656236741691828\n",
      "Iteration: 22272, Loss: 0.16697515547275543, Accuracy: 0.6653278032317758\n",
      "Iteration: 22336, Loss: 0.16774626076221466, Accuracy: 0.6652152710594237\n",
      "Iteration: 22400, Loss: 0.16822881996631622, Accuracy: 0.6657228698022664\n",
      "Iteration: 22464, Loss: 0.1685236096382141, Accuracy: 0.6655901996418834\n",
      "Iteration: 22528, Loss: 0.16576898097991943, Accuracy: 0.6652773469686508\n",
      "Iteration: 22592, Loss: 0.16631008684635162, Accuracy: 0.6653852770105004\n",
      "Iteration: 22656, Loss: 0.16847150027751923, Accuracy: 0.6656289948150516\n",
      "Iteration: 22720, Loss: 0.16679970920085907, Accuracy: 0.6655668327584863\n",
      "Iteration: 22784, Loss: 0.16703087091445923, Accuracy: 0.6656543710269034\n",
      "Iteration: 22848, Loss: 0.17193086445331573, Accuracy: 0.6653989125043154\n",
      "Iteration: 22912, Loss: 0.16577373445034027, Accuracy: 0.6655492726713419\n",
      "Iteration: 22976, Loss: 0.16504788398742676, Accuracy: 0.6652375059202313\n",
      "Iteration: 23040, Loss: 0.16874851286411285, Accuracy: 0.665726340841502\n",
      "Iteration: 23104, Loss: 0.16606180369853973, Accuracy: 0.6655534729361534\n",
      "Iteration: 23168, Loss: 0.16714631021022797, Accuracy: 0.6658457340672612\n",
      "Iteration: 23232, Loss: 0.1664988249540329, Accuracy: 0.665699162054807\n",
      "Iteration: 23296, Loss: 0.167525053024292, Accuracy: 0.6656589056365192\n",
      "Iteration: 23360, Loss: 0.16486388444900513, Accuracy: 0.665925701148808\n",
      "Iteration: 23424, Loss: 0.165917307138443, Accuracy: 0.6656369990669191\n",
      "Iteration: 23488, Loss: 0.16819584369659424, Accuracy: 0.6657391465269029\n",
      "Iteration: 23552, Loss: 0.16679303348064423, Accuracy: 0.6656070472672582\n",
      "Iteration: 23616, Loss: 0.16839605569839478, Accuracy: 0.6654785815626383\n",
      "Iteration: 23680, Loss: 0.16761858761310577, Accuracy: 0.6656609489582479\n",
      "Iteration: 23744, Loss: 0.16603024303913116, Accuracy: 0.6657966217026114\n",
      "Iteration: 23808, Loss: 0.16676871478557587, Accuracy: 0.6656546336598694\n",
      "Iteration: 23872, Loss: 0.17000479996204376, Accuracy: 0.6655455152504146\n",
      "Iteration: 23936, Loss: 0.16514043509960175, Accuracy: 0.6655260995030403\n",
      "Iteration: 24000, Loss: 0.16888730227947235, Accuracy: 0.6654117684811354\n",
      "Iteration: 24064, Loss: 0.1702575832605362, Accuracy: 0.6650259080342948\n",
      "Iteration: 24128, Loss: 0.16755901277065277, Accuracy: 0.6654856926761568\n",
      "Iteration: 24192, Loss: 0.16806219518184662, Accuracy: 0.6655138358473778\n",
      "Iteration: 24256, Loss: 0.16688507795333862, Accuracy: 0.665850022342056\n",
      "Iteration: 24320, Loss: 0.16742010414600372, Accuracy: 0.6658582435920835\n",
      "Iteration: 24384, Loss: 0.16653195023536682, Accuracy: 0.6658969279378653\n",
      "Iteration: 24448, Loss: 0.1693585366010666, Accuracy: 0.6654972014948726\n",
      "Iteration: 24512, Loss: 0.16680383682250977, Accuracy: 0.665718431584537\n",
      "Iteration: 24576, Loss: 0.167947456240654, Accuracy: 0.6656656619161367\n",
      "Iteration: 24640, Loss: 0.1700383871793747, Accuracy: 0.6656107134185731\n",
      "Iteration: 24704, Loss: 0.16932696104049683, Accuracy: 0.665601753629744\n",
      "Iteration: 24768, Loss: 0.1691310852766037, Accuracy: 0.665944020729512\n",
      "Iteration: 24832, Loss: 0.16875076293945312, Accuracy: 0.6658081077039242\n",
      "Iteration: 24896, Loss: 0.16932280361652374, Accuracy: 0.6656432510353625\n",
      "Iteration: 24960, Loss: 0.16703741252422333, Accuracy: 0.6658985670655966\n",
      "Iteration: 25024, Loss: 0.16767168045043945, Accuracy: 0.6656591249629855\n",
      "Iteration: 25088, Loss: 0.1666773557662964, Accuracy: 0.6655860454775393\n",
      "Iteration: 25152, Loss: 0.1631278544664383, Accuracy: 0.6655314052477479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 25216, Loss: 0.17108218371868134, Accuracy: 0.6650422266684473\n",
      "Iteration: 25280, Loss: 0.17057055234909058, Accuracy: 0.6664082263596356\n",
      "Iteration: 25344, Loss: 0.17074786126613617, Accuracy: 0.6685823504813015\n",
      "Iteration: 25408, Loss: 0.17087101936340332, Accuracy: 0.6774906222708523\n",
      "Iteration: 25472, Loss: 0.16693079471588135, Accuracy: 0.6841011014766991\n",
      "Iteration: 25536, Loss: 0.09714104980230331, Accuracy: 0.686186789534986\n",
      "Iteration: 25600, Loss: 0.1638849526643753, Accuracy: 0.6955650970339775\n",
      "Iteration: 25664, Loss: 0.12405398488044739, Accuracy: 0.6998170195147395\n",
      "Iteration: 25728, Loss: 0.1613774448633194, Accuracy: 0.7033905363641679\n",
      "Iteration: 25792, Loss: 0.17313148081302643, Accuracy: 0.701157073257491\n",
      "Iteration: 25856, Loss: 0.12656302750110626, Accuracy: 0.7080511704552919\n",
      "Iteration: 25920, Loss: 0.08625861257314682, Accuracy: 0.7110418216325343\n",
      "Iteration: 25984, Loss: 0.11342457681894302, Accuracy: 0.7140822091605514\n",
      "Iteration: 26048, Loss: 0.08686396479606628, Accuracy: 0.7160021285526454\n",
      "Iteration: 26112, Loss: 0.16885875165462494, Accuracy: 0.716458085924387\n",
      "Iteration: 26176, Loss: 0.16816620528697968, Accuracy: 0.718781347386539\n",
      "Iteration: 26240, Loss: 0.17627227306365967, Accuracy: 0.7191226719878614\n",
      "Iteration: 26304, Loss: 0.16530831158161163, Accuracy: 0.7206069941166788\n",
      "Iteration: 26368, Loss: 0.07239776104688644, Accuracy: 0.7219884141813964\n",
      "Iteration: 26432, Loss: 0.17373616993427277, Accuracy: 0.7237708831671625\n",
      "Iteration: 26496, Loss: 0.09975475072860718, Accuracy: 0.721931557636708\n",
      "Iteration: 26560, Loss: 0.09598825126886368, Accuracy: 0.7242226342204958\n",
      "Iteration: 26624, Loss: 0.07942257076501846, Accuracy: 0.7254825965501368\n",
      "Iteration: 26688, Loss: 0.07357069104909897, Accuracy: 0.7242388250306249\n",
      "Iteration: 26752, Loss: 0.06681084632873535, Accuracy: 0.7263217102736235\n",
      "Iteration: 26816, Loss: 0.1629553586244583, Accuracy: 0.7299012169241905\n",
      "Iteration: 26880, Loss: 0.17556311190128326, Accuracy: 0.7271966610569507\n",
      "Iteration: 26944, Loss: 0.15933068096637726, Accuracy: 0.7291939002461731\n",
      "Iteration: 27008, Loss: 0.06972891837358475, Accuracy: 0.7309403044637293\n",
      "Iteration: 27072, Loss: 0.1674557477235794, Accuracy: 0.7253336692228913\n",
      "Iteration: 27136, Loss: 0.09026214480400085, Accuracy: 0.7342121105175465\n",
      "Iteration: 27200, Loss: 0.05431785061955452, Accuracy: 0.7359747919254005\n",
      "Iteration: 27264, Loss: 0.08778593689203262, Accuracy: 0.7374845459125936\n",
      "Iteration: 27328, Loss: 0.05117304250597954, Accuracy: 0.733250517398119\n",
      "Iteration: 27392, Loss: 0.166929230093956, Accuracy: 0.7406434426084161\n",
      "Iteration: 27456, Loss: 0.07304968684911728, Accuracy: 0.7386836749501526\n",
      "Iteration: 27520, Loss: 0.1799604892730713, Accuracy: 0.7443626017775387\n",
      "Iteration: 27584, Loss: 0.17102943360805511, Accuracy: 0.7438431442715228\n",
      "Iteration: 27648, Loss: 0.17501987516880035, Accuracy: 0.7469639501068741\n",
      "Iteration: 27712, Loss: 0.16442519426345825, Accuracy: 0.7466084843035787\n",
      "Iteration: 27776, Loss: 0.16986775398254395, Accuracy: 0.7428037694189698\n",
      "Iteration: 27840, Loss: 0.18020248413085938, Accuracy: 0.7478810239117593\n",
      "Iteration: 27904, Loss: 0.17386431992053986, Accuracy: 0.7496879731770605\n",
      "Iteration: 27968, Loss: 0.13459332287311554, Accuracy: 0.7531895532738417\n",
      "Iteration: 28032, Loss: 0.13708126544952393, Accuracy: 0.7582940147258341\n",
      "Iteration: 28096, Loss: 0.18426001071929932, Accuracy: 0.7586409950163215\n",
      "Iteration: 28160, Loss: 0.15334269404411316, Accuracy: 0.7571423482149839\n",
      "Iteration: 28224, Loss: 0.042769286781549454, Accuracy: 0.7612505226861686\n",
      "Iteration: 28288, Loss: 0.028352880850434303, Accuracy: 0.7617122395895422\n",
      "Iteration: 28352, Loss: 0.16076098382472992, Accuracy: 0.7703263445291668\n",
      "Iteration: 28416, Loss: 0.023076167330145836, Accuracy: 0.7812898360425606\n",
      "Iteration: 28480, Loss: 0.15924227237701416, Accuracy: 0.7723300331272185\n",
      "Iteration: 28544, Loss: 0.13131603598594666, Accuracy: 0.7691801281180233\n",
      "Iteration: 28608, Loss: 0.022089460864663124, Accuracy: 0.7844010815024376\n",
      "Iteration: 28672, Loss: 0.1146291196346283, Accuracy: 0.791992180631496\n",
      "Iteration: 28736, Loss: 0.02730431593954563, Accuracy: 0.782525462564081\n",
      "Iteration: 28800, Loss: 0.019161881878972054, Accuracy: 0.7998303329804912\n",
      "Iteration: 28864, Loss: 0.10626331716775894, Accuracy: 0.7946984200971201\n",
      "Iteration: 28928, Loss: 0.10161034017801285, Accuracy: 0.798878732486628\n",
      "Iteration: 28992, Loss: 0.021822936832904816, Accuracy: 0.8051983279874548\n",
      "Iteration: 29056, Loss: 0.126170352101326, Accuracy: 0.8052504976512864\n",
      "Iteration: 29120, Loss: 0.07848896086215973, Accuracy: 0.8061295093502849\n",
      "Iteration: 29184, Loss: 0.10982916504144669, Accuracy: 0.7939898737240583\n",
      "Iteration: 29248, Loss: 0.017341913655400276, Accuracy: 0.7884142436087132\n",
      "Iteration: 29312, Loss: 0.09884053468704224, Accuracy: 0.8175485839601606\n",
      "Iteration: 29376, Loss: 0.08365658670663834, Accuracy: 0.8229324739659205\n",
      "Iteration: 29440, Loss: 0.09980351477861404, Accuracy: 0.826249968027696\n",
      "Iteration: 29504, Loss: 0.10280672460794449, Accuracy: 0.8251869963714853\n",
      "Iteration: 29568, Loss: 0.0204628799110651, Accuracy: 0.8133440798847005\n",
      "Iteration: 29632, Loss: 0.01009880006313324, Accuracy: 0.8307350256945938\n",
      "Iteration: 29696, Loss: 0.10087650269269943, Accuracy: 0.8325854496797547\n",
      "Iteration: 29760, Loss: 0.07903773337602615, Accuracy: 0.8364454609109089\n",
      "Iteration: 29824, Loss: 0.01054383721202612, Accuracy: 0.8331985388649628\n",
      "Iteration: 29888, Loss: 0.08434703946113586, Accuracy: 0.8387796066235751\n",
      "Iteration: 29952, Loss: 0.008998456411063671, Accuracy: 0.8265495803207159\n",
      "Iteration: 30016, Loss: 0.29093000292778015, Accuracy: 0.8012859381269664\n",
      "Iteration: 30080, Loss: 0.010351399891078472, Accuracy: 0.8245008628582582\n",
      "Iteration: 30144, Loss: 0.104684978723526, Accuracy: 0.8394973429385573\n",
      "Iteration: 30208, Loss: 0.07860671728849411, Accuracy: 0.826896152109839\n",
      "Iteration: 30272, Loss: 0.0809478759765625, Accuracy: 0.8393320052418858\n",
      "Iteration: 30336, Loss: 0.08237085491418839, Accuracy: 0.820048779132776\n",
      "Iteration: 30400, Loss: 0.09830810874700546, Accuracy: 0.8456400341819972\n",
      "Iteration: 30464, Loss: 0.010310783050954342, Accuracy: 0.8383922333596274\n",
      "Iteration: 30528, Loss: 0.09654229134321213, Accuracy: 0.8483467030455358\n",
      "Iteration: 30592, Loss: 0.0061499737203121185, Accuracy: 0.8502669938025065\n",
      "Iteration: 30656, Loss: 0.09387964755296707, Accuracy: 0.8573661676491611\n",
      "Iteration: 30720, Loss: 0.09823556989431381, Accuracy: 0.8566936504794285\n",
      "Iteration: 30784, Loss: 0.0988612100481987, Accuracy: 0.852111678570509\n",
      "Iteration: 30848, Loss: 0.0057733082212507725, Accuracy: 0.8563894559629261\n",
      "Iteration: 30912, Loss: 0.008746065199375153, Accuracy: 0.8562718034372665\n",
      "Iteration: 30976, Loss: 0.006042563822120428, Accuracy: 0.8503749809460714\n",
      "Iteration: 31040, Loss: 0.008513166569173336, Accuracy: 0.8437328237341717\n",
      "Iteration: 31104, Loss: 0.09599503129720688, Accuracy: 0.8497091669705696\n",
      "Iteration: 31168, Loss: 0.005120652262121439, Accuracy: 0.835256448131986\n",
      "Iteration: 31232, Loss: 0.006894534919410944, Accuracy: 0.8442356255836785\n",
      "Iteration: 31296, Loss: 0.004799444694072008, Accuracy: 0.8574398940545507\n",
      "Iteration: 31360, Loss: 0.004508734215050936, Accuracy: 0.8544656739686616\n",
      "Iteration: 31424, Loss: 0.003817515214905143, Accuracy: 0.8397113811224699\n",
      "Iteration: 31488, Loss: 0.004325975198298693, Accuracy: 0.8559249012032524\n",
      "Iteration: 31552, Loss: 0.08109648525714874, Accuracy: 0.8281642579822801\n",
      "Iteration: 31616, Loss: 0.07484938949346542, Accuracy: 0.8600072639528662\n",
      "Iteration: 31680, Loss: 0.084083192050457, Accuracy: 0.8530666849110276\n",
      "Iteration: 31744, Loss: 0.0039491597563028336, Accuracy: 0.8552600994007662\n",
      "Iteration: 31808, Loss: 0.09282632917165756, Accuracy: 0.842290883185342\n",
      "Iteration: 31872, Loss: 0.005075535271316767, Accuracy: 0.8497569801984355\n",
      "Iteration: 31936, Loss: 0.08027268201112747, Accuracy: 0.8674290900235064\n",
      "Iteration: 32000, Loss: 0.09714404493570328, Accuracy: 0.8492158619337715\n",
      "Iteration: 32064, Loss: 0.0039213583804667, Accuracy: 0.8674205102142878\n",
      "Iteration: 32128, Loss: 0.0885053351521492, Accuracy: 0.8587972419918515\n",
      "Iteration: 32192, Loss: 0.0033422803971916437, Accuracy: 0.856854083831422\n",
      "Iteration: 32256, Loss: 0.003533080918714404, Accuracy: 0.864420807978604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 32320, Loss: 0.0037669066805392504, Accuracy: 0.8621108692605048\n",
      "Iteration: 32384, Loss: 0.0036279363557696342, Accuracy: 0.8579955809982494\n",
      "Iteration: 32448, Loss: 0.0035773925483226776, Accuracy: 0.8464771946310066\n",
      "Iteration: 32512, Loss: 0.0024261062499135733, Accuracy: 0.8649772811913863\n",
      "Iteration: 32576, Loss: 0.08974292129278183, Accuracy: 0.8722263398813084\n",
      "Iteration: 32640, Loss: 0.0032308672089129686, Accuracy: 0.8587589849485084\n",
      "Iteration: 32704, Loss: 0.0032443413510918617, Accuracy: 0.8091044702450745\n",
      "Iteration: 32768, Loss: 0.0034163801465183496, Accuracy: 0.853170644142665\n",
      "Iteration: 32832, Loss: 0.09373239427804947, Accuracy: 0.8611928530735895\n",
      "Iteration: 32896, Loss: 0.09057403355836868, Accuracy: 0.8684087172150612\n",
      "Iteration: 32960, Loss: 0.08760759979486465, Accuracy: 0.8840524188126437\n",
      "Iteration: 33024, Loss: 0.0027190521359443665, Accuracy: 0.8766909443074837\n",
      "Iteration: 33088, Loss: 0.0023633933160454035, Accuracy: 0.8693998189992271\n",
      "Iteration: 33152, Loss: 0.003218376077711582, Accuracy: 0.8798487853491679\n",
      "Iteration: 33216, Loss: 0.002238505519926548, Accuracy: 0.8829732633312233\n",
      "Iteration: 33280, Loss: 0.04789060726761818, Accuracy: 0.8643141516949981\n",
      "Iteration: 33344, Loss: 0.012328573502600193, Accuracy: 0.8865634824614972\n",
      "Iteration: 33408, Loss: 0.0435202531516552, Accuracy: 0.8851651092409156\n",
      "Iteration: 33472, Loss: 0.0029302153270691633, Accuracy: 0.8835168639197946\n",
      "Iteration: 33536, Loss: 0.0027150071691721678, Accuracy: 0.8812646885635331\n",
      "Iteration: 33600, Loss: 0.00206167995929718, Accuracy: 0.8802743557607755\n",
      "Iteration: 33664, Loss: 0.004181392956525087, Accuracy: 0.8971848645014688\n",
      "Iteration: 33728, Loss: 0.3070416748523712, Accuracy: 0.8807004496338777\n",
      "Iteration: 33792, Loss: 0.0029049981385469437, Accuracy: 0.8906466227490455\n",
      "Iteration: 33856, Loss: 0.005018203053623438, Accuracy: 0.9006753350258805\n",
      "Iteration: 33920, Loss: 0.001970953308045864, Accuracy: 0.9119515715865418\n",
      "Iteration: 33984, Loss: 0.0124055789783597, Accuracy: 0.8910497418255545\n",
      "Iteration: 34048, Loss: 0.002567324787378311, Accuracy: 0.8926353871938772\n",
      "Iteration: 34112, Loss: 0.0018594457069411874, Accuracy: 0.9110904476838186\n",
      "Iteration: 34176, Loss: 0.04484749957919121, Accuracy: 0.9098566807224415\n",
      "Iteration: 34240, Loss: 0.004002304747700691, Accuracy: 0.8889223440783098\n",
      "Iteration: 34304, Loss: 0.004220447037369013, Accuracy: 0.9094175589852966\n",
      "Iteration: 34368, Loss: 0.0025628122966736555, Accuracy: 0.9210877464502119\n",
      "Iteration: 34432, Loss: 0.02794455550611019, Accuracy: 0.9236353986780159\n",
      "Iteration: 34496, Loss: 0.0064666979014873505, Accuracy: 0.9244213623460382\n",
      "Iteration: 34560, Loss: 0.005037331022322178, Accuracy: 0.9293768144561909\n",
      "Iteration: 34624, Loss: 0.013586893677711487, Accuracy: 0.934427397325635\n",
      "Iteration: 34688, Loss: 0.0018054913962259889, Accuracy: 0.9318514097249135\n",
      "Iteration: 34752, Loss: 0.011645638383924961, Accuracy: 0.9334434132906608\n",
      "Iteration: 34816, Loss: 0.0014007504796609282, Accuracy: 0.9394666845619213\n",
      "Iteration: 34880, Loss: 0.0015434263041242957, Accuracy: 0.932716859417269\n",
      "Iteration: 34944, Loss: 0.014948897063732147, Accuracy: 0.9363865670748055\n",
      "Iteration: 35008, Loss: 0.0025614395271986723, Accuracy: 0.9465095420309808\n",
      "Iteration: 35072, Loss: 0.004232862498611212, Accuracy: 0.9363886965438724\n",
      "Iteration: 35136, Loss: 0.0013135457411408424, Accuracy: 0.9345137716736645\n",
      "Iteration: 35200, Loss: 0.0014971703058108687, Accuracy: 0.9447039736842271\n",
      "Iteration: 35264, Loss: 0.010653473436832428, Accuracy: 0.939086001511896\n",
      "Iteration: 35328, Loss: 0.12501412630081177, Accuracy: 0.9315130313916598\n",
      "Iteration: 35392, Loss: 0.011292067356407642, Accuracy: 0.9263241670269053\n",
      "Iteration: 35456, Loss: 0.11727286130189896, Accuracy: 0.9367156534281094\n",
      "Iteration: 35520, Loss: 0.0019833394326269627, Accuracy: 0.9493545682053082\n",
      "Iteration: 35584, Loss: 0.003550733672454953, Accuracy: 0.9525562553317286\n",
      "Iteration: 35648, Loss: 0.0022754797246307135, Accuracy: 0.9394935359887313\n",
      "Iteration: 35712, Loss: 0.0024204340297728777, Accuracy: 0.9502567363961134\n",
      "Iteration: 35776, Loss: 0.00499352952465415, Accuracy: 0.9560666444594972\n",
      "Iteration: 35840, Loss: 0.007315280381590128, Accuracy: 0.9480720764549915\n",
      "Iteration: 35904, Loss: 0.0020587723702192307, Accuracy: 0.9452405069023371\n",
      "Iteration: 35968, Loss: 0.0017369553679600358, Accuracy: 0.9472678491147235\n",
      "Iteration: 36032, Loss: 0.002027683425694704, Accuracy: 0.9253662006522063\n",
      "Iteration: 36096, Loss: 0.0015129480743780732, Accuracy: 0.9493529101309832\n",
      "Iteration: 36160, Loss: 0.0007731832447461784, Accuracy: 0.9598897794494405\n",
      "Iteration: 36224, Loss: 0.0008805403485894203, Accuracy: 0.9459835849702358\n",
      "Iteration: 36288, Loss: 0.0030826351139694452, Accuracy: 0.9581729189085308\n",
      "Iteration: 36352, Loss: 0.000853716628625989, Accuracy: 0.9525162591889966\n",
      "Iteration: 36416, Loss: 0.0010346747003495693, Accuracy: 0.9560854556912091\n",
      "Iteration: 36480, Loss: 0.0018101133173331618, Accuracy: 0.9574634533491917\n",
      "Iteration: 36544, Loss: 0.001985965995118022, Accuracy: 0.9352818143088371\n",
      "Iteration: 36608, Loss: 0.0010933146113529801, Accuracy: 0.947900890983874\n",
      "Iteration: 36672, Loss: 0.001175219309516251, Accuracy: 0.9543032326037064\n",
      "Iteration: 36736, Loss: 0.0009211269789375365, Accuracy: 0.9506960358121432\n",
      "Iteration: 36800, Loss: 0.0028193348553031683, Accuracy: 0.9568938252632506\n",
      "Iteration: 36864, Loss: 0.002436657203361392, Accuracy: 0.9632666333054658\n",
      "Iteration: 36928, Loss: 0.0005722008063457906, Accuracy: 0.9568061568133999\n",
      "Iteration: 36992, Loss: 0.001035152468830347, Accuracy: 0.9586309467267711\n",
      "Iteration: 37056, Loss: 0.015585874207317829, Accuracy: 0.9328823623072822\n",
      "Iteration: 37120, Loss: 0.0017980645643547177, Accuracy: 0.9570258153544273\n",
      "Iteration: 37184, Loss: 0.0018678084015846252, Accuracy: 0.9642545205133501\n",
      "Iteration: 37248, Loss: 0.0013959468342363834, Accuracy: 0.9645308213366661\n",
      "Iteration: 37312, Loss: 0.01030911784619093, Accuracy: 0.9602839912986383\n",
      "Iteration: 37376, Loss: 0.0020956036169081926, Accuracy: 0.9501514635630883\n",
      "Iteration: 37440, Loss: 0.0029648032505065203, Accuracy: 0.9511430007405579\n",
      "Iteration: 37504, Loss: 0.0027771133463829756, Accuracy: 0.9615082096424885\n",
      "Iteration: 37568, Loss: 0.0009297188371419907, Accuracy: 0.9634245305205695\n",
      "Iteration: 37632, Loss: 0.0020993289072066545, Accuracy: 0.96696454306948\n",
      "Iteration: 37696, Loss: 0.003140692599117756, Accuracy: 0.9638684158126125\n",
      "Iteration: 37760, Loss: 0.0013385239290073514, Accuracy: 0.9678168626705883\n",
      "Iteration: 37824, Loss: 0.0006172530120238662, Accuracy: 0.9655516468919814\n",
      "Iteration: 37888, Loss: 0.20692765712738037, Accuracy: 0.9536903692933265\n",
      "Iteration: 37952, Loss: 0.0006638009217567742, Accuracy: 0.9592215146985836\n",
      "Iteration: 38016, Loss: 0.0008426926215179265, Accuracy: 0.9591926524008159\n",
      "Iteration: 38080, Loss: 0.0009802250424399972, Accuracy: 0.9621744501200737\n",
      "Iteration: 38144, Loss: 0.0009324064012616873, Accuracy: 0.9557268728967756\n",
      "Iteration: 38208, Loss: 0.0028138523921370506, Accuracy: 0.9469042414275464\n",
      "Iteration: 38272, Loss: 0.0005344173405319452, Accuracy: 0.9471132008911809\n",
      "Iteration: 38336, Loss: 0.0008692434639669955, Accuracy: 0.9578551090089604\n",
      "Iteration: 38400, Loss: 0.0023946415167301893, Accuracy: 0.9665518295223592\n",
      "Iteration: 38464, Loss: 0.0010710455244407058, Accuracy: 0.9673172228212934\n",
      "Iteration: 38528, Loss: 0.0006336983060464263, Accuracy: 0.9659777272609062\n",
      "Iteration: 38592, Loss: 0.000557479215785861, Accuracy: 0.9523784446355421\n",
      "Iteration: 38656, Loss: 0.0002952710201498121, Accuracy: 0.9607736829930218\n",
      "Iteration: 38720, Loss: 0.0012836660025641322, Accuracy: 0.9659014576900518\n",
      "Iteration: 38784, Loss: 0.0003055687702726573, Accuracy: 0.9687290849542478\n",
      "Iteration: 38848, Loss: 0.0015350872417911887, Accuracy: 0.9570958159747534\n",
      "Iteration: 38912, Loss: 0.0003279819793533534, Accuracy: 0.9700126669631572\n",
      "Saved fullModel_dr[5]_replicate1.model\n",
      "Saved W_dr[5]_replicate1.p\n",
      "5 1.0 [1.0, 1.0, 1.0]\n",
      "Saved w_dr[5]_replicate1.p\n",
      "Replicate 1 completed\n",
      "Time elapsed: 821.453125 seconds\n",
      "Iteration: 64, Loss: 0.25039246678352356, Accuracy: 0.49926287261769176\n",
      "Iteration: 128, Loss: 0.2386520504951477, Accuracy: 0.5001812186092138\n",
      "Iteration: 192, Loss: 0.22898995876312256, Accuracy: 0.4989910791628063\n",
      "Iteration: 256, Loss: 0.25464919209480286, Accuracy: 0.49948946200311184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 320, Loss: 0.2644405663013458, Accuracy: 0.4996121237054467\n",
      "Iteration: 384, Loss: 0.2608173191547394, Accuracy: 0.4990028403699398\n",
      "Iteration: 448, Loss: 0.24860350787639618, Accuracy: 0.49978705029934645\n",
      "Iteration: 512, Loss: 0.2539011240005493, Accuracy: 0.4991743885912001\n",
      "Iteration: 576, Loss: 0.26604950428009033, Accuracy: 0.4999579661525786\n",
      "Iteration: 640, Loss: 0.25536975264549255, Accuracy: 0.49928963417187333\n",
      "Iteration: 704, Loss: 0.2557593584060669, Accuracy: 0.4995436519384384\n",
      "Iteration: 768, Loss: 0.25161728262901306, Accuracy: 0.4994509294629097\n",
      "Iteration: 832, Loss: 0.2544015347957611, Accuracy: 0.49930126359686255\n",
      "Iteration: 896, Loss: 0.255871444940567, Accuracy: 0.5007208897732198\n",
      "Iteration: 960, Loss: 0.22504903376102448, Accuracy: 0.507521390914917\n",
      "Iteration: 1024, Loss: 0.19712983071804047, Accuracy: 0.5503145954571664\n",
      "Iteration: 1088, Loss: 0.19106554985046387, Accuracy: 0.5942426081746817\n",
      "Iteration: 1152, Loss: 0.19156856834888458, Accuracy: 0.6140744751319289\n",
      "Iteration: 1216, Loss: 0.16293613612651825, Accuracy: 0.619869202375412\n",
      "Iteration: 1280, Loss: 0.20713774859905243, Accuracy: 0.6317823179997504\n",
      "Iteration: 1344, Loss: 0.1522756814956665, Accuracy: 0.6366291418671608\n",
      "Iteration: 1408, Loss: 0.1934828907251358, Accuracy: 0.6373532419092953\n",
      "Iteration: 1472, Loss: 0.14672647416591644, Accuracy: 0.6410925113596022\n",
      "Iteration: 1536, Loss: 0.14389878511428833, Accuracy: 0.642580792773515\n",
      "Iteration: 1600, Loss: 0.1424129158258438, Accuracy: 0.6477321675047278\n",
      "Iteration: 1664, Loss: 0.1455059051513672, Accuracy: 0.6460619941353798\n",
      "Iteration: 1728, Loss: 0.15432406961917877, Accuracy: 0.6522354348562658\n",
      "Iteration: 1792, Loss: 0.1755801886320114, Accuracy: 0.6536714839749038\n",
      "Iteration: 1856, Loss: 0.20566225051879883, Accuracy: 0.6558146057650447\n",
      "Iteration: 1920, Loss: 0.13955242931842804, Accuracy: 0.656360502820462\n",
      "Iteration: 1984, Loss: 0.15758009254932404, Accuracy: 0.6578666712157428\n",
      "Iteration: 2048, Loss: 0.13910137116909027, Accuracy: 0.6577848354354501\n",
      "Iteration: 2112, Loss: 0.10692233592271805, Accuracy: 0.6619640453718603\n",
      "Iteration: 2176, Loss: 0.16178230941295624, Accuracy: 0.6605606945231557\n",
      "Iteration: 2240, Loss: 0.16134102642536163, Accuracy: 0.6632117889821529\n",
      "Iteration: 2304, Loss: 0.15901686251163483, Accuracy: 0.6654941202141345\n",
      "Iteration: 2368, Loss: 0.15554417669773102, Accuracy: 0.6694831624627113\n",
      "Iteration: 2432, Loss: 0.15486891567707062, Accuracy: 0.6706009767949581\n",
      "Iteration: 2496, Loss: 0.19102203845977783, Accuracy: 0.6730097094550729\n",
      "Iteration: 2560, Loss: 0.13802073895931244, Accuracy: 0.6754552251659334\n",
      "Iteration: 2624, Loss: 0.16244740784168243, Accuracy: 0.6738176941871643\n",
      "Iteration: 2688, Loss: 0.194704070687294, Accuracy: 0.6767340423539281\n",
      "Iteration: 2752, Loss: 0.13615447282791138, Accuracy: 0.676572633208707\n",
      "Iteration: 2816, Loss: 0.15129579603672028, Accuracy: 0.6748368036933243\n",
      "Iteration: 2880, Loss: 0.13607139885425568, Accuracy: 0.679892644751817\n",
      "Iteration: 2944, Loss: 0.08618271350860596, Accuracy: 0.6835482397582382\n",
      "Iteration: 3008, Loss: 0.08982771635055542, Accuracy: 0.6853111067321151\n",
      "Iteration: 3072, Loss: 0.12263069301843643, Accuracy: 0.6823839114513248\n",
      "Iteration: 3136, Loss: 0.1987878829240799, Accuracy: 0.6875277881044894\n",
      "Iteration: 3200, Loss: 0.08491554111242294, Accuracy: 0.6876437203027308\n",
      "Iteration: 3264, Loss: 0.08848942071199417, Accuracy: 0.6890674910973758\n",
      "Iteration: 3328, Loss: 0.1443173736333847, Accuracy: 0.6846104578580707\n",
      "Iteration: 3392, Loss: 0.07283999770879745, Accuracy: 0.692085144110024\n",
      "Iteration: 3456, Loss: 0.0899122953414917, Accuracy: 0.6941584243904799\n",
      "Iteration: 3520, Loss: 0.07831571251153946, Accuracy: 0.6894866919610649\n",
      "Iteration: 3584, Loss: 0.20277082920074463, Accuracy: 0.6908712678123266\n",
      "Iteration: 3648, Loss: 0.08028239756822586, Accuracy: 0.6892998379189521\n",
      "Iteration: 3712, Loss: 0.19036489725112915, Accuracy: 0.7000832629855722\n",
      "Iteration: 3776, Loss: 0.09139382094144821, Accuracy: 0.6972591087687761\n",
      "Iteration: 3840, Loss: 0.18851585686206818, Accuracy: 0.6989870939869434\n",
      "Iteration: 3904, Loss: 0.09167886525392532, Accuracy: 0.6989224357530475\n",
      "Iteration: 3968, Loss: 0.1399320513010025, Accuracy: 0.6996166864410043\n",
      "Iteration: 4032, Loss: 0.07524143159389496, Accuracy: 0.7044521721545607\n",
      "Iteration: 4096, Loss: 0.13360513746738434, Accuracy: 0.7005970687605441\n",
      "Iteration: 4160, Loss: 0.14422035217285156, Accuracy: 0.7026890779379755\n",
      "Iteration: 4224, Loss: 0.07519799470901489, Accuracy: 0.7067509212065488\n",
      "Iteration: 4288, Loss: 0.130689337849617, Accuracy: 0.707301652058959\n",
      "Iteration: 4352, Loss: 0.0870313048362732, Accuracy: 0.7088049636222422\n",
      "Iteration: 4416, Loss: 0.1279563158750534, Accuracy: 0.7041531999129802\n",
      "Iteration: 4480, Loss: 0.17006222903728485, Accuracy: 0.7093498616013676\n",
      "Iteration: 4544, Loss: 0.1983109563589096, Accuracy: 0.7109822023194283\n",
      "Iteration: 4608, Loss: 0.11122173070907593, Accuracy: 0.6975499731488526\n",
      "Iteration: 4672, Loss: 0.07794501632452011, Accuracy: 0.7100958803202957\n",
      "Iteration: 4736, Loss: 0.15484942495822906, Accuracy: 0.7100966814905405\n",
      "Iteration: 4800, Loss: 0.07251926511526108, Accuracy: 0.6953388978727162\n",
      "Iteration: 4864, Loss: 0.1495872288942337, Accuracy: 0.7027937220409513\n",
      "Iteration: 4928, Loss: 0.11062847822904587, Accuracy: 0.7087910368572921\n",
      "Iteration: 4992, Loss: 0.1449345499277115, Accuracy: 0.7141336288768798\n",
      "Iteration: 5056, Loss: 0.13420318067073822, Accuracy: 0.7116781212389469\n",
      "Iteration: 5120, Loss: 0.19109880924224854, Accuracy: 0.7068076345603913\n",
      "Iteration: 5184, Loss: 0.1382872760295868, Accuracy: 0.7128448921721429\n",
      "Iteration: 5248, Loss: 0.18114884197711945, Accuracy: 0.7117429934442043\n",
      "Iteration: 5312, Loss: 0.14853443205356598, Accuracy: 0.7124983333051205\n",
      "Iteration: 5376, Loss: 0.08050712198019028, Accuracy: 0.7018046288285404\n",
      "Iteration: 5440, Loss: 0.1990709900856018, Accuracy: 0.7147408674936742\n",
      "Iteration: 5504, Loss: 0.15096378326416016, Accuracy: 0.715926676755771\n",
      "Iteration: 5568, Loss: 0.11856294423341751, Accuracy: 0.7067359094507992\n",
      "Iteration: 5632, Loss: 0.14284145832061768, Accuracy: 0.7173202740959823\n",
      "Iteration: 5696, Loss: 0.11622723191976547, Accuracy: 0.7122357855550945\n",
      "Iteration: 5760, Loss: 0.07524924725294113, Accuracy: 0.7200147381518036\n",
      "Iteration: 5824, Loss: 0.07205762714147568, Accuracy: 0.7164508891291916\n",
      "Iteration: 5888, Loss: 0.16902513802051544, Accuracy: 0.7186675772536546\n",
      "Iteration: 5952, Loss: 0.1164940819144249, Accuracy: 0.7257406730204821\n",
      "Iteration: 6016, Loss: 0.16382940113544464, Accuracy: 0.7195208396296948\n",
      "Iteration: 6080, Loss: 0.1250314563512802, Accuracy: 0.7258717834483832\n",
      "Iteration: 6144, Loss: 0.16080765426158905, Accuracy: 0.7278277380391955\n",
      "Iteration: 6208, Loss: 0.11210855096578598, Accuracy: 0.7276652753353119\n",
      "Iteration: 6272, Loss: 0.11056812852621078, Accuracy: 0.730728410417214\n",
      "Iteration: 6336, Loss: 0.13678991794586182, Accuracy: 0.728717170888558\n",
      "Iteration: 6400, Loss: 0.10664878040552139, Accuracy: 0.7289635832421482\n",
      "Iteration: 6464, Loss: 0.09763499349355698, Accuracy: 0.7367904661223292\n",
      "Iteration: 6528, Loss: 0.2680612802505493, Accuracy: 0.7305316196288913\n",
      "Iteration: 6592, Loss: 0.0909334048628807, Accuracy: 0.7219045006204396\n",
      "Iteration: 6656, Loss: 0.12251999229192734, Accuracy: 0.737872626632452\n",
      "Iteration: 6720, Loss: 0.0653962716460228, Accuracy: 0.7393932505510747\n",
      "Iteration: 6784, Loss: 0.06463626772165298, Accuracy: 0.7368931071832776\n",
      "Iteration: 6848, Loss: 0.06578615307807922, Accuracy: 0.7481542583554983\n",
      "Iteration: 6912, Loss: 0.09177590161561966, Accuracy: 0.7526581101119518\n",
      "Iteration: 6976, Loss: 0.06594061851501465, Accuracy: 0.7512872198130935\n",
      "Iteration: 7040, Loss: 0.0651388168334961, Accuracy: 0.7429836776573211\n",
      "Iteration: 7104, Loss: 0.10970211029052734, Accuracy: 0.7514967476017773\n",
      "Iteration: 7168, Loss: 0.17217719554901123, Accuracy: 0.7558392765931785\n",
      "Iteration: 7232, Loss: 0.08117306977510452, Accuracy: 0.7574214630294591\n",
      "Iteration: 7296, Loss: 0.07543563097715378, Accuracy: 0.7611593757756054\n",
      "Iteration: 7360, Loss: 0.11500627547502518, Accuracy: 0.763214458245784\n",
      "Iteration: 7424, Loss: 0.07614191621541977, Accuracy: 0.7633094482589513\n",
      "Iteration: 7488, Loss: 0.07422957569360733, Accuracy: 0.7666541608050466\n",
      "Iteration: 7552, Loss: 0.15370866656303406, Accuracy: 0.7643083948642015\n",
      "Iteration: 7616, Loss: 0.07612073421478271, Accuracy: 0.7627160595729947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 7680, Loss: 0.07276401668787003, Accuracy: 0.7678051847033203\n",
      "Iteration: 7744, Loss: 0.06543389707803726, Accuracy: 0.7625640893820673\n",
      "Iteration: 7808, Loss: 0.07689186930656433, Accuracy: 0.7402703640982509\n",
      "Iteration: 7872, Loss: 0.1295887976884842, Accuracy: 0.7732522010337561\n",
      "Iteration: 7936, Loss: 0.09622012823820114, Accuracy: 0.7763463854789734\n",
      "Iteration: 8000, Loss: 0.12476558238267899, Accuracy: 0.7759192532394081\n",
      "Iteration: 8064, Loss: 0.1143072172999382, Accuracy: 0.7684579226188362\n",
      "Iteration: 8128, Loss: 0.11496544629335403, Accuracy: 0.7691373571287841\n",
      "Iteration: 8192, Loss: 0.11041825264692307, Accuracy: 0.775264902273193\n",
      "Iteration: 8256, Loss: 0.10930579900741577, Accuracy: 0.7766002169810236\n",
      "Iteration: 8320, Loss: 0.08142782747745514, Accuracy: 0.7773212336469442\n",
      "Iteration: 8384, Loss: 0.11271248012781143, Accuracy: 0.7741086047608405\n",
      "Iteration: 8448, Loss: 0.11110350489616394, Accuracy: 0.75954425544478\n",
      "Iteration: 8512, Loss: 0.07134822756052017, Accuracy: 0.7862768799532205\n",
      "Iteration: 8576, Loss: 0.07446976751089096, Accuracy: 0.7708606526721269\n",
      "Iteration: 8640, Loss: 0.07095382362604141, Accuracy: 0.7896067618858069\n",
      "Iteration: 8704, Loss: 0.0727742612361908, Accuracy: 0.7753961824346334\n",
      "Iteration: 8768, Loss: 0.10762247443199158, Accuracy: 0.7826612943317741\n",
      "Iteration: 8832, Loss: 0.09712570905685425, Accuracy: 0.7805446973070502\n",
      "Iteration: 8896, Loss: 0.07201672345399857, Accuracy: 0.7825827221386135\n",
      "Iteration: 8960, Loss: 0.1135476604104042, Accuracy: 0.7794828857295215\n",
      "Iteration: 9024, Loss: 0.10977189987897873, Accuracy: 0.7747698477469385\n",
      "Iteration: 9088, Loss: 0.10879526287317276, Accuracy: 0.795437985798344\n",
      "Iteration: 9152, Loss: 0.10313393920660019, Accuracy: 0.7900379078928381\n",
      "Iteration: 9216, Loss: 0.09927362948656082, Accuracy: 0.7881441339850426\n",
      "Iteration: 9280, Loss: 0.07097557187080383, Accuracy: 0.7718458564486355\n",
      "Iteration: 9344, Loss: 0.08570456504821777, Accuracy: 0.7901828824542463\n",
      "Iteration: 9408, Loss: 0.06176033243536949, Accuracy: 0.7909265952184796\n",
      "Iteration: 9472, Loss: 0.10019009560346603, Accuracy: 0.790249016135931\n",
      "Iteration: 9536, Loss: 0.08691970258951187, Accuracy: 0.7990990036632866\n",
      "Iteration: 9600, Loss: 0.08508250117301941, Accuracy: 0.7953520745504647\n",
      "Iteration: 9664, Loss: 0.0993528738617897, Accuracy: 0.802250933367759\n",
      "Iteration: 9728, Loss: 0.07628287374973297, Accuracy: 0.7945890303235501\n",
      "Iteration: 9792, Loss: 0.0858214795589447, Accuracy: 0.8024543386418372\n",
      "Iteration: 9856, Loss: 0.08553538471460342, Accuracy: 0.799879839643836\n",
      "Iteration: 9920, Loss: 0.09631537646055222, Accuracy: 0.8005134463310242\n",
      "Iteration: 9984, Loss: 0.08022163063287735, Accuracy: 0.7857068530283868\n",
      "Iteration: 10048, Loss: 0.09055144339799881, Accuracy: 0.7928503532893956\n",
      "Iteration: 10112, Loss: 0.08349781483411789, Accuracy: 0.7953574422281235\n",
      "Iteration: 10176, Loss: 0.07596942037343979, Accuracy: 0.8028961741365492\n",
      "Iteration: 10240, Loss: 0.09041014313697815, Accuracy: 0.796737713040784\n",
      "Iteration: 10304, Loss: 0.07866672426462173, Accuracy: 0.7962210238911211\n",
      "Iteration: 10368, Loss: 0.07365334779024124, Accuracy: 0.8064667722210288\n",
      "Iteration: 10432, Loss: 0.0919443741440773, Accuracy: 0.8005928613711149\n",
      "Iteration: 10496, Loss: 0.10138505697250366, Accuracy: 0.804514299845323\n",
      "Iteration: 10560, Loss: 0.07693154364824295, Accuracy: 0.7918779235333204\n",
      "Iteration: 10624, Loss: 0.08006743341684341, Accuracy: 0.7868344981689006\n",
      "Iteration: 10688, Loss: 0.07470637559890747, Accuracy: 0.8055542949587107\n",
      "Iteration: 10752, Loss: 0.07713601738214493, Accuracy: 0.7963567660190165\n",
      "Iteration: 10816, Loss: 0.08078441768884659, Accuracy: 0.8055498963221908\n",
      "Iteration: 10880, Loss: 0.09001621603965759, Accuracy: 0.7927235492970794\n",
      "Iteration: 10944, Loss: 0.09659674763679504, Accuracy: 0.8082302766852081\n",
      "Iteration: 11008, Loss: 0.08231193572282791, Accuracy: 0.7927681729197502\n",
      "Iteration: 11072, Loss: 0.05892178788781166, Accuracy: 0.7953660893253982\n",
      "Iteration: 11136, Loss: 0.08632589131593704, Accuracy: 0.8079453276004642\n",
      "Iteration: 11200, Loss: 0.09558331221342087, Accuracy: 0.8000618738587946\n",
      "Iteration: 11264, Loss: 0.10039564222097397, Accuracy: 0.8045253306627274\n",
      "Iteration: 11328, Loss: 0.08610475063323975, Accuracy: 0.8065680146683007\n",
      "Iteration: 11392, Loss: 0.08081691712141037, Accuracy: 0.7962457479443401\n",
      "Iteration: 11456, Loss: 0.07912874221801758, Accuracy: 0.8103990943636745\n",
      "Iteration: 11520, Loss: 0.09556064754724503, Accuracy: 0.7926492199767381\n",
      "Iteration: 11584, Loss: 0.07105661183595657, Accuracy: 0.8002411352936178\n",
      "Iteration: 11648, Loss: 0.09956001490354538, Accuracy: 0.7915669733192772\n",
      "Iteration: 11712, Loss: 0.0859910249710083, Accuracy: 0.8081998750567436\n",
      "Iteration: 11776, Loss: 0.08754810690879822, Accuracy: 0.7869220385327935\n",
      "Iteration: 11840, Loss: 0.10342254489660263, Accuracy: 0.7849014301318675\n",
      "Iteration: 11904, Loss: 0.09469462186098099, Accuracy: 0.8055448026861995\n",
      "Iteration: 11968, Loss: 0.08109886944293976, Accuracy: 0.7908701018895954\n",
      "Iteration: 12032, Loss: 0.07440273463726044, Accuracy: 0.8013481684029102\n",
      "Iteration: 12096, Loss: 0.07931604981422424, Accuracy: 0.8109541852027178\n",
      "Iteration: 12160, Loss: 0.08047399669885635, Accuracy: 0.8086901819333434\n",
      "Iteration: 12224, Loss: 0.09471842646598816, Accuracy: 0.8106039876583964\n",
      "Iteration: 12288, Loss: 0.09850132465362549, Accuracy: 0.8118703193031251\n",
      "Iteration: 12352, Loss: 0.07479076832532883, Accuracy: 0.8028701306320727\n",
      "Iteration: 12416, Loss: 0.07834766060113907, Accuracy: 0.8119434281252325\n",
      "Iteration: 12480, Loss: 0.0796593725681305, Accuracy: 0.8018586982507259\n",
      "Iteration: 12544, Loss: 0.0837554931640625, Accuracy: 0.805561262415722\n",
      "Iteration: 12608, Loss: 0.3342050015926361, Accuracy: 0.7984414512757212\n",
      "Iteration: 12672, Loss: 0.07862111181020737, Accuracy: 0.7961838254705071\n",
      "Iteration: 12736, Loss: 0.08968696743249893, Accuracy: 0.8141725941095501\n",
      "Iteration: 12800, Loss: 0.08510047197341919, Accuracy: 0.8102023517712951\n",
      "Iteration: 12864, Loss: 0.08593219518661499, Accuracy: 0.8026299271732569\n",
      "Iteration: 12928, Loss: 0.07677540928125381, Accuracy: 0.8157039557117969\n",
      "Iteration: 12992, Loss: 0.07430828362703323, Accuracy: 0.8118658501189202\n",
      "Iteration: 13056, Loss: 0.08341846615076065, Accuracy: 0.8138762407470495\n",
      "Iteration: 13120, Loss: 0.08687087148427963, Accuracy: 0.8166991975158453\n",
      "Iteration: 13184, Loss: 0.09348464012145996, Accuracy: 0.8163931856397539\n",
      "Iteration: 13248, Loss: 0.07575765252113342, Accuracy: 0.8124984302558005\n",
      "Iteration: 13312, Loss: 0.08774171024560928, Accuracy: 0.8075232615228742\n",
      "Iteration: 13376, Loss: 0.07862894982099533, Accuracy: 0.8119231648743153\n",
      "Iteration: 13440, Loss: 0.08749333769083023, Accuracy: 0.8172543789260089\n",
      "Iteration: 13504, Loss: 0.08074671775102615, Accuracy: 0.7958105069119483\n",
      "Iteration: 13568, Loss: 0.07816542685031891, Accuracy: 0.8141234966460615\n",
      "Iteration: 13632, Loss: 0.07799135893583298, Accuracy: 0.8009561072103679\n",
      "Iteration: 13696, Loss: 0.08064963668584824, Accuracy: 0.8010783917270601\n",
      "Iteration: 13760, Loss: 0.08170091360807419, Accuracy: 0.815393737051636\n",
      "Iteration: 13824, Loss: 0.07795669138431549, Accuracy: 0.80882788146846\n",
      "Iteration: 13888, Loss: 0.0771077498793602, Accuracy: 0.8156656436622143\n",
      "Iteration: 13952, Loss: 0.08265607804059982, Accuracy: 0.8119782374706119\n",
      "Iteration: 14016, Loss: 0.08760430663824081, Accuracy: 0.8082621400244534\n",
      "Iteration: 14080, Loss: 0.07961659878492355, Accuracy: 0.8140518004074693\n",
      "Iteration: 14144, Loss: 0.0836273729801178, Accuracy: 0.814922088291496\n",
      "Iteration: 14208, Loss: 0.08177372068166733, Accuracy: 0.8155691020656377\n",
      "Iteration: 14272, Loss: 0.08777806907892227, Accuracy: 0.8120579819660634\n",
      "Iteration: 14336, Loss: 0.08745303004980087, Accuracy: 0.7982100115623325\n",
      "Iteration: 14400, Loss: 0.0863821879029274, Accuracy: 0.818811705801636\n",
      "Iteration: 14464, Loss: 0.08715372532606125, Accuracy: 0.8082773704081774\n",
      "Iteration: 14528, Loss: 0.08021185547113419, Accuracy: 0.8131165644153953\n",
      "Iteration: 14592, Loss: 0.08899253606796265, Accuracy: 0.8003905753139406\n",
      "Iteration: 14656, Loss: 0.08252597600221634, Accuracy: 0.8114581457339227\n",
      "Iteration: 14720, Loss: 0.087944895029068, Accuracy: 0.8178287344053388\n",
      "Iteration: 14784, Loss: 0.07933065295219421, Accuracy: 0.8137661998625845\n",
      "Iteration: 14848, Loss: 0.09045834094285965, Accuracy: 0.8180374526418746\n",
      "Iteration: 14912, Loss: 0.07660219818353653, Accuracy: 0.7852931851521134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 14976, Loss: 0.0898556336760521, Accuracy: 0.8192840218544006\n",
      "Iteration: 15040, Loss: 0.0891624465584755, Accuracy: 0.8038641950115561\n",
      "Iteration: 15104, Loss: 0.36609122157096863, Accuracy: 0.8041727438103408\n",
      "Iteration: 15168, Loss: 0.0959165096282959, Accuracy: 0.8147121747024357\n",
      "Iteration: 15232, Loss: 0.08446169644594193, Accuracy: 0.8034668616019189\n",
      "Iteration: 15296, Loss: 0.08757702261209488, Accuracy: 0.8069387308787555\n",
      "Iteration: 15360, Loss: 0.08305070549249649, Accuracy: 0.8175371163524687\n",
      "Iteration: 15424, Loss: 0.08316425234079361, Accuracy: 0.804295739158988\n",
      "Iteration: 15488, Loss: 0.08593279868364334, Accuracy: 0.8031099271029234\n",
      "Iteration: 15552, Loss: 0.08615226298570633, Accuracy: 0.813802698161453\n",
      "Iteration: 15616, Loss: 0.0857686921954155, Accuracy: 0.8191410913132131\n",
      "Iteration: 15680, Loss: 0.08320211619138718, Accuracy: 0.8194225910119712\n",
      "Iteration: 15744, Loss: 0.08563709259033203, Accuracy: 0.7997577742207795\n",
      "Iteration: 15808, Loss: 0.08321357518434525, Accuracy: 0.817528031533584\n",
      "Iteration: 15872, Loss: 0.08301644027233124, Accuracy: 0.8187968437559903\n",
      "Iteration: 15936, Loss: 0.08249995857477188, Accuracy: 0.8199002607725561\n",
      "Iteration: 16000, Loss: 0.08336200565099716, Accuracy: 0.8146387736778706\n",
      "Iteration: 16064, Loss: 0.08642974495887756, Accuracy: 0.8108821746427566\n",
      "Iteration: 16128, Loss: 0.09066026657819748, Accuracy: 0.8152216551825404\n",
      "Iteration: 16192, Loss: 0.08726901561021805, Accuracy: 0.8205134177114815\n",
      "Iteration: 16256, Loss: 0.08347854018211365, Accuracy: 0.8113020060118288\n",
      "Iteration: 16320, Loss: 0.07670284807682037, Accuracy: 0.8184782268945128\n",
      "Iteration: 16384, Loss: 0.08267535269260406, Accuracy: 0.8107317357789725\n",
      "Iteration: 16448, Loss: 0.08602563291788101, Accuracy: 0.8144060738850385\n",
      "Iteration: 16512, Loss: 0.0788440927863121, Accuracy: 0.8085349244065583\n",
      "Iteration: 16576, Loss: 0.08288142830133438, Accuracy: 0.8144103952217847\n",
      "Iteration: 16640, Loss: 0.08304660767316818, Accuracy: 0.817041888833046\n",
      "Iteration: 16704, Loss: 0.0861627459526062, Accuracy: 0.8180251074954867\n",
      "Iteration: 16768, Loss: 0.09005991369485855, Accuracy: 0.8150854869745672\n",
      "Iteration: 16832, Loss: 0.09610094875097275, Accuracy: 0.809816159773618\n",
      "Iteration: 16896, Loss: 0.08701486140489578, Accuracy: 0.8175414251163602\n",
      "Iteration: 16960, Loss: 0.07975568622350693, Accuracy: 0.815071924822405\n",
      "Iteration: 17024, Loss: 0.09824174642562866, Accuracy: 0.789790588663891\n",
      "Iteration: 17088, Loss: 0.0739605501294136, Accuracy: 0.8031583270058036\n",
      "Iteration: 17152, Loss: 0.08117394894361496, Accuracy: 0.8013277326244861\n",
      "Iteration: 17216, Loss: 0.3899330794811249, Accuracy: 0.8086664997972548\n",
      "Iteration: 17280, Loss: 0.08910542726516724, Accuracy: 0.8119714267086238\n",
      "Iteration: 17344, Loss: 0.07614851742982864, Accuracy: 0.812135943910107\n",
      "Iteration: 17408, Loss: 0.08807780593633652, Accuracy: 0.816417861264199\n",
      "Iteration: 17472, Loss: 0.08129085600376129, Accuracy: 0.8133443940896541\n",
      "Iteration: 17536, Loss: 0.40518736839294434, Accuracy: 0.745711785973981\n",
      "Iteration: 17600, Loss: 0.09738600254058838, Accuracy: 0.7960105647798628\n",
      "Iteration: 17664, Loss: 0.09449511021375656, Accuracy: 0.8113513707648963\n",
      "Iteration: 17728, Loss: 0.11516401171684265, Accuracy: 0.809572157682851\n",
      "Iteration: 17792, Loss: 0.0743810161948204, Accuracy: 0.8077306242194027\n",
      "Iteration: 17856, Loss: 0.07564054429531097, Accuracy: 0.8048464960884303\n",
      "Iteration: 17920, Loss: 0.07193807512521744, Accuracy: 0.8055066305678338\n",
      "Iteration: 17984, Loss: 0.08748454600572586, Accuracy: 0.7957134321331978\n",
      "Iteration: 18048, Loss: 0.11479603499174118, Accuracy: 0.8161413965281099\n",
      "Iteration: 18112, Loss: 0.08943779021501541, Accuracy: 0.8174404914025217\n",
      "Iteration: 18176, Loss: 0.09041255712509155, Accuracy: 0.8106689106207341\n",
      "Iteration: 18240, Loss: 0.07975897938013077, Accuracy: 0.8166977898217738\n",
      "Iteration: 18304, Loss: 0.09465962648391724, Accuracy: 0.8155482481233776\n",
      "Iteration: 18368, Loss: 0.0752301961183548, Accuracy: 0.8059094629716128\n",
      "Iteration: 18432, Loss: 0.09326458722352982, Accuracy: 0.8144978596828878\n",
      "Iteration: 18496, Loss: 0.09768224507570267, Accuracy: 0.8168169173877686\n",
      "Iteration: 18560, Loss: 0.09151503443717957, Accuracy: 0.8201122374739498\n",
      "Iteration: 18624, Loss: 0.07069865614175797, Accuracy: 0.820164896780625\n",
      "Iteration: 18688, Loss: 0.0580444298684597, Accuracy: 0.8201258764602244\n",
      "Iteration: 18752, Loss: 0.07638770341873169, Accuracy: 0.820486918091774\n",
      "Iteration: 18816, Loss: 0.09258424490690231, Accuracy: 0.8143971939571202\n",
      "Iteration: 18880, Loss: 0.0759756788611412, Accuracy: 0.8221317471470684\n",
      "Iteration: 18944, Loss: 0.08962950110435486, Accuracy: 0.8120156088843942\n",
      "Iteration: 19008, Loss: 0.07370903342962265, Accuracy: 0.8169814248103648\n",
      "Iteration: 19072, Loss: 0.07914472371339798, Accuracy: 0.8157882576342672\n",
      "Iteration: 19136, Loss: 0.3918789327144623, Accuracy: 0.8112155015114695\n",
      "Iteration: 19200, Loss: 0.1298380196094513, Accuracy: 0.8129306868650019\n",
      "Iteration: 19264, Loss: 0.07095930725336075, Accuracy: 0.8144061020575464\n",
      "Iteration: 19328, Loss: 0.07437397539615631, Accuracy: 0.8224988956935704\n",
      "Iteration: 19392, Loss: 0.07282751053571701, Accuracy: 0.8119427100755274\n",
      "Iteration: 19456, Loss: 0.09786847978830338, Accuracy: 0.8157897309865803\n",
      "Iteration: 19520, Loss: 0.10457820445299149, Accuracy: 0.8096112736966461\n",
      "Iteration: 19584, Loss: 0.09482681751251221, Accuracy: 0.8196130665019155\n",
      "Iteration: 19648, Loss: 0.07394318282604218, Accuracy: 0.8114372012205422\n",
      "Iteration: 19712, Loss: 0.07328758388757706, Accuracy: 0.8180840185377747\n",
      "Iteration: 19776, Loss: 0.07126940786838531, Accuracy: 0.8219390753656626\n",
      "Iteration: 19840, Loss: 0.09031350165605545, Accuracy: 0.8221585457213223\n",
      "Iteration: 19904, Loss: 0.06870647519826889, Accuracy: 0.8180490280501544\n",
      "Iteration: 19968, Loss: 0.09429744631052017, Accuracy: 0.8140089197549969\n",
      "Iteration: 20032, Loss: 0.04610686004161835, Accuracy: 0.8052779380232096\n",
      "Iteration: 20096, Loss: 0.07213610410690308, Accuracy: 0.7855563759803772\n",
      "Iteration: 20160, Loss: 0.07483871281147003, Accuracy: 0.8191625447943807\n",
      "Iteration: 20224, Loss: 0.09182814508676529, Accuracy: 0.8234333964064717\n",
      "Iteration: 20288, Loss: 0.09090468287467957, Accuracy: 0.8190131529700011\n",
      "Iteration: 20352, Loss: 0.09449822455644608, Accuracy: 0.8159449812956154\n",
      "Iteration: 20416, Loss: 0.09644155949354172, Accuracy: 0.8145617195405066\n",
      "Iteration: 20480, Loss: 0.08795120567083359, Accuracy: 0.8198818720411509\n",
      "Iteration: 20544, Loss: 0.07834374904632568, Accuracy: 0.8213202126789838\n",
      "Iteration: 20608, Loss: 0.07334186881780624, Accuracy: 0.8177964887581766\n",
      "Iteration: 20672, Loss: 0.07261040061712265, Accuracy: 0.8184320305008441\n",
      "Iteration: 20736, Loss: 0.10048510879278183, Accuracy: 0.8166425039526075\n",
      "Iteration: 20800, Loss: 0.09140601009130478, Accuracy: 0.8197090674657375\n",
      "Iteration: 20864, Loss: 0.07281628996133804, Accuracy: 0.8231975415255874\n",
      "Iteration: 20928, Loss: 0.09167883545160294, Accuracy: 0.8223311139736325\n",
      "Iteration: 20992, Loss: 0.09571054577827454, Accuracy: 0.8199103476945311\n",
      "Iteration: 21056, Loss: 0.06917337328195572, Accuracy: 0.8187503500375897\n",
      "Iteration: 21120, Loss: 0.09139594435691833, Accuracy: 0.8134432032238692\n",
      "Iteration: 21184, Loss: 0.09396976232528687, Accuracy: 0.8128240702208132\n",
      "Iteration: 21248, Loss: 0.09542319178581238, Accuracy: 0.8257234813645482\n",
      "Iteration: 21312, Loss: 0.36911535263061523, Accuracy: 0.8211220998782665\n",
      "Iteration: 21376, Loss: 0.07080533355474472, Accuracy: 0.8221562751568854\n",
      "Iteration: 21440, Loss: 0.07376498728990555, Accuracy: 0.8209150731563568\n",
      "Iteration: 21504, Loss: 0.06834468990564346, Accuracy: 0.8261774727143347\n",
      "Iteration: 21568, Loss: 0.06979789584875107, Accuracy: 0.8259476884268224\n",
      "Iteration: 21632, Loss: 0.06750494986772537, Accuracy: 0.8115930771455169\n",
      "Iteration: 21696, Loss: 0.06820594519376755, Accuracy: 0.8111356468871236\n",
      "Iteration: 21760, Loss: 0.07403605431318283, Accuracy: 0.82386041758582\n",
      "Iteration: 21824, Loss: 0.07047472149133682, Accuracy: 0.7926349155604839\n",
      "Iteration: 21888, Loss: 0.0704704225063324, Accuracy: 0.8096996205858886\n",
      "Iteration: 21952, Loss: 0.0726294219493866, Accuracy: 0.8077747540082783\n",
      "Iteration: 22016, Loss: 0.09336680918931961, Accuracy: 0.8213749418500811\n",
      "Iteration: 22080, Loss: 0.09810638427734375, Accuracy: 0.8253075603861362\n",
      "Iteration: 22144, Loss: 0.09806236624717712, Accuracy: 0.8257373336236924\n",
      "Iteration: 22208, Loss: 0.07347848266363144, Accuracy: 0.8274754465091974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 22272, Loss: 0.09798646718263626, Accuracy: 0.8250468871556222\n",
      "Iteration: 22336, Loss: 0.042910125106573105, Accuracy: 0.8180932512041181\n",
      "Iteration: 22400, Loss: 0.07172880321741104, Accuracy: 0.8220013519749045\n",
      "Iteration: 22464, Loss: 0.06812257319688797, Accuracy: 0.8144573469180614\n",
      "Iteration: 22528, Loss: 0.07659526914358139, Accuracy: 0.8207966901827604\n",
      "Iteration: 22592, Loss: 0.08656834810972214, Accuracy: 0.8156790377106518\n",
      "Iteration: 22656, Loss: 0.09817776829004288, Accuracy: 0.8255948054138571\n",
      "Iteration: 22720, Loss: 0.06964757293462753, Accuracy: 0.824574354919605\n",
      "Iteration: 22784, Loss: 0.10207054764032364, Accuracy: 0.8051673644222319\n",
      "Iteration: 22848, Loss: 0.1049094870686531, Accuracy: 0.8161862990818918\n",
      "Iteration: 22912, Loss: 0.0694274976849556, Accuracy: 0.8116901952307671\n",
      "Iteration: 22976, Loss: 0.06945779919624329, Accuracy: 0.8269793097861111\n",
      "Iteration: 23040, Loss: 0.06446477770805359, Accuracy: 0.8227366580395028\n",
      "Iteration: 23104, Loss: 0.06750433892011642, Accuracy: 0.813121133018285\n",
      "Iteration: 23168, Loss: 0.09476535767316818, Accuracy: 0.8254571668803692\n",
      "Iteration: 23232, Loss: 0.10433196276426315, Accuracy: 0.8272528061643243\n",
      "Iteration: 23296, Loss: 0.095917247235775, Accuracy: 0.8183630413841456\n",
      "Iteration: 23360, Loss: 0.09628885239362717, Accuracy: 0.8271752700675279\n",
      "Iteration: 23424, Loss: 0.06633909046649933, Accuracy: 0.8273842391790822\n",
      "Iteration: 23488, Loss: 0.06158476695418358, Accuracy: 0.8293674697633833\n",
      "Iteration: 23552, Loss: 0.07326232641935349, Accuracy: 0.8183298469521105\n",
      "Iteration: 23616, Loss: 0.09652059525251389, Accuracy: 0.8141098781488836\n",
      "Iteration: 23680, Loss: 0.0633479431271553, Accuracy: 0.8223988618701696\n",
      "Iteration: 23744, Loss: 0.06607123464345932, Accuracy: 0.8257400523871183\n",
      "Iteration: 23808, Loss: 0.074174664914608, Accuracy: 0.8171570744598284\n",
      "Iteration: 23872, Loss: 0.06847086548805237, Accuracy: 0.8175484371604398\n",
      "Iteration: 23936, Loss: 0.06916021555662155, Accuracy: 0.827878134092316\n",
      "Iteration: 24000, Loss: 0.06705903261899948, Accuracy: 0.8295805515954271\n",
      "Iteration: 24064, Loss: 0.0940413847565651, Accuracy: 0.8239581638481468\n",
      "Iteration: 24128, Loss: 0.10934635996818542, Accuracy: 0.816137878340669\n",
      "Iteration: 24192, Loss: 0.09447541832923889, Accuracy: 0.8198581341421232\n",
      "Iteration: 24256, Loss: 0.09591881185770035, Accuracy: 0.8145810337737203\n",
      "Iteration: 24320, Loss: 0.06435513496398926, Accuracy: 0.821820639190264\n",
      "Iteration: 24384, Loss: 0.059897422790527344, Accuracy: 0.8189766437280923\n",
      "Iteration: 24448, Loss: 0.07240534573793411, Accuracy: 0.8281082498142496\n",
      "Iteration: 24512, Loss: 0.0949229896068573, Accuracy: 0.8144665586296469\n",
      "Iteration: 24576, Loss: 0.0639183446764946, Accuracy: 0.825778340222314\n",
      "Iteration: 24640, Loss: 0.06143326684832573, Accuracy: 0.8304743687622249\n",
      "Iteration: 24704, Loss: 0.10862717777490616, Accuracy: 0.8219179654261097\n",
      "Iteration: 24768, Loss: 0.07013877481222153, Accuracy: 0.8254574622260407\n",
      "Iteration: 24832, Loss: 0.11930833011865616, Accuracy: 0.8158970479853451\n",
      "Iteration: 24896, Loss: 0.06286966800689697, Accuracy: 0.8228539797710255\n",
      "Iteration: 24960, Loss: 0.07138530910015106, Accuracy: 0.828245360753499\n",
      "Iteration: 25024, Loss: 0.06049374118447304, Accuracy: 0.832999606966041\n",
      "Iteration: 25088, Loss: 0.06151946261525154, Accuracy: 0.8264969808515161\n",
      "Iteration: 25152, Loss: 0.10372507572174072, Accuracy: 0.8215117981890216\n",
      "Iteration: 25216, Loss: 0.11466003209352493, Accuracy: 0.8237971840426326\n",
      "Iteration: 25280, Loss: 0.1131475567817688, Accuracy: 0.8257053305860609\n",
      "Iteration: 25344, Loss: 0.06070436164736748, Accuracy: 0.8332089857431129\n",
      "Iteration: 25408, Loss: 0.06288980692625046, Accuracy: 0.8320616298587993\n",
      "Iteration: 25472, Loss: 0.07378803938627243, Accuracy: 0.831880436046049\n",
      "Iteration: 25536, Loss: 0.034739378839731216, Accuracy: 0.8333274559117854\n",
      "Iteration: 25600, Loss: 0.0714874342083931, Accuracy: 0.8287175302393734\n",
      "Iteration: 25664, Loss: 0.11580527573823929, Accuracy: 0.8286179887363687\n",
      "Iteration: 25728, Loss: 0.0597606785595417, Accuracy: 0.8307334572309628\n",
      "Iteration: 25792, Loss: 0.10480263829231262, Accuracy: 0.8300840046722442\n",
      "Iteration: 25856, Loss: 0.10739853233098984, Accuracy: 0.826964020030573\n",
      "Iteration: 25920, Loss: 0.09653627127408981, Accuracy: 0.8333308356814086\n",
      "Iteration: 25984, Loss: 0.06121158227324486, Accuracy: 0.8285201699472964\n",
      "Iteration: 26048, Loss: 0.06420449912548065, Accuracy: 0.8330340032698587\n",
      "Iteration: 26112, Loss: 0.05555636063218117, Accuracy: 0.831108245998621\n",
      "Iteration: 26176, Loss: 0.09463039040565491, Accuracy: 0.8276414542924613\n",
      "Iteration: 26240, Loss: 0.056951384991407394, Accuracy: 0.8228916154475883\n",
      "Iteration: 26304, Loss: 0.11761768907308578, Accuracy: 0.827555583557114\n",
      "Iteration: 26368, Loss: 0.05958177149295807, Accuracy: 0.8276363337645307\n",
      "Iteration: 26432, Loss: 0.06490704417228699, Accuracy: 0.8300408481154591\n",
      "Iteration: 26496, Loss: 0.15923728048801422, Accuracy: 0.8251032822299749\n",
      "Iteration: 26560, Loss: 0.05085812136530876, Accuracy: 0.8254034091951326\n",
      "Iteration: 26624, Loss: 0.05585601553320885, Accuracy: 0.8336273634340614\n",
      "Iteration: 26688, Loss: 0.031567756086587906, Accuracy: 0.8279415357392281\n",
      "Iteration: 26752, Loss: 0.07241247594356537, Accuracy: 0.8256556104170159\n",
      "Iteration: 26816, Loss: 0.04830099269747734, Accuracy: 0.8344104358693585\n",
      "Iteration: 26880, Loss: 0.1154153123497963, Accuracy: 0.8352014063857496\n",
      "Iteration: 26944, Loss: 0.1212359145283699, Accuracy: 0.8206784513313323\n",
      "Iteration: 27008, Loss: 0.07004117220640182, Accuracy: 0.8179746823152527\n",
      "Iteration: 27072, Loss: 0.06570277363061905, Accuracy: 0.8256236903835088\n",
      "Iteration: 27136, Loss: 0.10436966270208359, Accuracy: 0.8326153678353876\n",
      "Iteration: 27200, Loss: 0.10528314858675003, Accuracy: 0.8289627828635275\n",
      "Iteration: 27264, Loss: 0.09540817141532898, Accuracy: 0.8248311313800514\n",
      "Iteration: 27328, Loss: 0.0646909549832344, Accuracy: 0.8256606925278902\n",
      "Iteration: 27392, Loss: 0.07583370804786682, Accuracy: 0.8298044558614492\n",
      "Iteration: 27456, Loss: 0.05600084364414215, Accuracy: 0.8329518295358866\n",
      "Iteration: 27520, Loss: 0.04876190423965454, Accuracy: 0.8261914527975023\n",
      "Iteration: 27584, Loss: 0.11427813023328781, Accuracy: 0.8368624526774511\n",
      "Iteration: 27648, Loss: 0.03631902113556862, Accuracy: 0.8353598675457761\n",
      "Iteration: 27712, Loss: 0.12020982056856155, Accuracy: 0.8333820652915165\n",
      "Iteration: 27776, Loss: 0.08880221098661423, Accuracy: 0.8350018061464652\n",
      "Iteration: 27840, Loss: 0.033059071749448776, Accuracy: 0.8270464753732085\n",
      "Iteration: 27904, Loss: 0.1085369661450386, Accuracy: 0.8332522860728204\n",
      "Iteration: 27968, Loss: 0.06981723755598068, Accuracy: 0.8368392861448228\n",
      "Iteration: 28032, Loss: 0.06875872611999512, Accuracy: 0.8364673053147271\n",
      "Iteration: 28096, Loss: 0.04246946796774864, Accuracy: 0.8249327554367483\n",
      "Iteration: 28160, Loss: 0.06463006883859634, Accuracy: 0.8254008254734799\n",
      "Iteration: 28224, Loss: 0.06731914728879929, Accuracy: 0.824964476749301\n",
      "Iteration: 28288, Loss: 0.058436423540115356, Accuracy: 0.8218018769985065\n",
      "Iteration: 28352, Loss: 0.06626928597688675, Accuracy: 0.8248821615707129\n",
      "Iteration: 28416, Loss: 0.055162329226732254, Accuracy: 0.8270197770325467\n",
      "Iteration: 28480, Loss: 0.03899617865681648, Accuracy: 0.8318005761830136\n",
      "Iteration: 28544, Loss: 0.09882384538650513, Accuracy: 0.827637463924475\n",
      "Iteration: 28608, Loss: 0.09583443403244019, Accuracy: 0.8368173005292192\n",
      "Iteration: 28672, Loss: 0.11637388914823532, Accuracy: 0.8362263838062063\n",
      "Iteration: 28736, Loss: 0.032642606645822525, Accuracy: 0.8354285900713876\n",
      "Iteration: 28800, Loss: 0.10798230767250061, Accuracy: 0.8269217824563384\n",
      "Iteration: 28864, Loss: 0.09710884839296341, Accuracy: 0.8377317602280527\n",
      "Iteration: 28928, Loss: 0.029619062319397926, Accuracy: 0.822323439642787\n",
      "Iteration: 28992, Loss: 0.0956898108124733, Accuracy: 0.8391754830954596\n",
      "Iteration: 29056, Loss: 0.41515102982521057, Accuracy: 0.8272470603697002\n",
      "Iteration: 29120, Loss: 0.11750531941652298, Accuracy: 0.8097504216711968\n",
      "Iteration: 29184, Loss: 0.11275354027748108, Accuracy: 0.8214918978046626\n",
      "Iteration: 29248, Loss: 0.07631459832191467, Accuracy: 0.8274644282646477\n",
      "Iteration: 29312, Loss: 0.08994225412607193, Accuracy: 0.8349726973101497\n",
      "Iteration: 29376, Loss: 0.1136937364935875, Accuracy: 0.8298268601065502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 29440, Loss: 0.06097884848713875, Accuracy: 0.8324401521822438\n",
      "Iteration: 29504, Loss: 0.10979410260915756, Accuracy: 0.8311959560960531\n",
      "Iteration: 29568, Loss: 0.05553986132144928, Accuracy: 0.8184796669520438\n",
      "Iteration: 29632, Loss: 0.06317661702632904, Accuracy: 0.8262118073180318\n",
      "Iteration: 29696, Loss: 0.10225161164999008, Accuracy: 0.831743968767114\n",
      "Iteration: 29760, Loss: 0.05955095589160919, Accuracy: 0.8295464501716197\n",
      "Iteration: 29824, Loss: 0.059310510754585266, Accuracy: 0.8326725001679733\n",
      "Iteration: 29888, Loss: 0.11093636602163315, Accuracy: 0.8383689151378348\n",
      "Iteration: 29952, Loss: 0.03682226315140724, Accuracy: 0.8363697612658143\n",
      "Iteration: 30016, Loss: 0.07934211194515228, Accuracy: 0.837909642374143\n",
      "Iteration: 30080, Loss: 0.11789777874946594, Accuracy: 0.8308849144959822\n",
      "Iteration: 30144, Loss: 0.11439498513936996, Accuracy: 0.8332906953291968\n",
      "Iteration: 30208, Loss: 0.024187957867980003, Accuracy: 0.8401531300041825\n",
      "Iteration: 30272, Loss: 0.11002857238054276, Accuracy: 0.8396806879900396\n",
      "Iteration: 30336, Loss: 0.06209198758006096, Accuracy: 0.8367636643815786\n",
      "Iteration: 30400, Loss: 0.05835932493209839, Accuracy: 0.8404609702993184\n",
      "Iteration: 30464, Loss: 0.06394866853952408, Accuracy: 0.828605713439174\n",
      "Iteration: 30528, Loss: 0.06376675516366959, Accuracy: 0.8399745186325163\n",
      "Iteration: 30592, Loss: 0.06302373856306076, Accuracy: 0.83284979138989\n",
      "Iteration: 30656, Loss: 0.09423878788948059, Accuracy: 0.8356601706473157\n",
      "Iteration: 30720, Loss: 0.07918811589479446, Accuracy: 0.8376059061847627\n",
      "Iteration: 30784, Loss: 0.09156391024589539, Accuracy: 0.834633961902\n",
      "Iteration: 30848, Loss: 0.07380371540784836, Accuracy: 0.8393844191450626\n",
      "Iteration: 30912, Loss: 0.09533678740262985, Accuracy: 0.8350300289457664\n",
      "Iteration: 30976, Loss: 0.09611060470342636, Accuracy: 0.8400818287627771\n",
      "Iteration: 31040, Loss: 0.029302747920155525, Accuracy: 0.8269863658351824\n",
      "Iteration: 31104, Loss: 0.11225869506597519, Accuracy: 0.8332322669448331\n",
      "Iteration: 31168, Loss: 0.0615517683327198, Accuracy: 0.8329926319420338\n",
      "Iteration: 31232, Loss: 0.06303063780069351, Accuracy: 0.840761473053135\n",
      "Iteration: 31296, Loss: 0.09108015894889832, Accuracy: 0.8301180915441364\n",
      "Iteration: 31360, Loss: 0.034171078354120255, Accuracy: 0.8408814354334027\n",
      "Iteration: 31424, Loss: 0.07696544378995895, Accuracy: 0.8343346226029098\n",
      "Iteration: 31488, Loss: 0.02792937494814396, Accuracy: 0.8356949496082962\n",
      "Iteration: 31552, Loss: 0.10852798819541931, Accuracy: 0.8430449410807341\n",
      "Iteration: 31616, Loss: 0.06010597571730614, Accuracy: 0.8405818128958344\n",
      "Iteration: 31680, Loss: 0.02653573267161846, Accuracy: 0.8389153262833133\n",
      "Iteration: 31744, Loss: 0.02585417591035366, Accuracy: 0.8433424603426829\n",
      "Iteration: 31808, Loss: 0.09328749030828476, Accuracy: 0.8414721279405057\n",
      "Iteration: 31872, Loss: 0.09241385012865067, Accuracy: 0.8369401131058112\n",
      "Iteration: 31936, Loss: 0.07736153155565262, Accuracy: 0.8449287773109972\n",
      "Iteration: 32000, Loss: 0.03423699736595154, Accuracy: 0.8352486508665606\n",
      "Iteration: 32064, Loss: 0.09960615634918213, Accuracy: 0.8370661898516119\n",
      "Iteration: 32128, Loss: 0.10018346458673477, Accuracy: 0.8363538720877841\n",
      "Iteration: 32192, Loss: 0.0896826758980751, Accuracy: 0.8429847516817972\n",
      "Iteration: 32256, Loss: 0.0804198607802391, Accuracy: 0.8369970940984786\n",
      "Iteration: 32320, Loss: 0.06861020624637604, Accuracy: 0.8449464258737862\n",
      "Iteration: 32384, Loss: 0.08979406207799911, Accuracy: 0.8439563625724986\n",
      "Iteration: 32448, Loss: 0.1110653504729271, Accuracy: 0.8275051184464246\n",
      "Iteration: 32512, Loss: 0.06003379821777344, Accuracy: 0.8454695648979396\n",
      "Iteration: 32576, Loss: 0.08309611678123474, Accuracy: 0.8444161807419732\n",
      "Iteration: 32640, Loss: 0.06292117387056351, Accuracy: 0.8173284374643117\n",
      "Iteration: 32704, Loss: 0.05797508731484413, Accuracy: 0.8427269500680268\n",
      "Iteration: 32768, Loss: 0.09763014316558838, Accuracy: 0.8351938152918592\n",
      "Iteration: 32832, Loss: 0.07560769468545914, Accuracy: 0.8396784926299006\n",
      "Iteration: 32896, Loss: 0.06943157315254211, Accuracy: 0.8444973092991859\n",
      "Iteration: 32960, Loss: 0.09937185794115067, Accuracy: 0.8430703482590616\n",
      "Iteration: 33024, Loss: 0.023762693628668785, Accuracy: 0.8443930214270949\n",
      "Iteration: 33088, Loss: 0.020909251645207405, Accuracy: 0.845131505979225\n",
      "Iteration: 33152, Loss: 0.06282158941030502, Accuracy: 0.8440817688824609\n",
      "Iteration: 33216, Loss: 0.10398077219724655, Accuracy: 0.8412604122422636\n",
      "Iteration: 33280, Loss: 0.07394102215766907, Accuracy: 0.8336502236779779\n",
      "Iteration: 33344, Loss: 0.14536769688129425, Accuracy: 0.8352736618835479\n",
      "Iteration: 33408, Loss: 0.09463712573051453, Accuracy: 0.8383737553376704\n",
      "Iteration: 33472, Loss: 0.07923368364572525, Accuracy: 0.8377905997913331\n",
      "Iteration: 33536, Loss: 0.06506910175085068, Accuracy: 0.8332090332405642\n",
      "Iteration: 33600, Loss: 0.024864980950951576, Accuracy: 0.8251763045554981\n",
      "Iteration: 33664, Loss: 0.09956562519073486, Accuracy: 0.8378992835059762\n",
      "Iteration: 33728, Loss: 0.09264540672302246, Accuracy: 0.8455444196006283\n",
      "Iteration: 33792, Loss: 0.08769270777702332, Accuracy: 0.8405073635512963\n",
      "Iteration: 33856, Loss: 0.06657399237155914, Accuracy: 0.8442724228370935\n",
      "Iteration: 33920, Loss: 0.09864354133605957, Accuracy: 0.8406878492096439\n",
      "Iteration: 33984, Loss: 0.09109797328710556, Accuracy: 0.8405172061175108\n",
      "Iteration: 34048, Loss: 0.07014334201812744, Accuracy: 0.838051080936566\n",
      "Iteration: 34112, Loss: 0.0841328576207161, Accuracy: 0.8491459746146575\n",
      "Iteration: 34176, Loss: 0.10383669286966324, Accuracy: 0.8420979257207364\n",
      "Iteration: 34240, Loss: 0.09415633231401443, Accuracy: 0.8479932561749592\n",
      "Iteration: 34304, Loss: 0.09553123265504837, Accuracy: 0.8468362245475873\n",
      "Iteration: 34368, Loss: 0.01860451139509678, Accuracy: 0.845771350665018\n",
      "Iteration: 34432, Loss: 0.06649424880743027, Accuracy: 0.8326290162513033\n",
      "Iteration: 34496, Loss: 0.09676165133714676, Accuracy: 0.8482794351875782\n",
      "Iteration: 34560, Loss: 0.09100392460823059, Accuracy: 0.8437713676830754\n",
      "Iteration: 34624, Loss: 0.09558272361755371, Accuracy: 0.8455741079524159\n",
      "Iteration: 34688, Loss: 0.017366912215948105, Accuracy: 0.8437433396466076\n",
      "Iteration: 34752, Loss: 0.017414838075637817, Accuracy: 0.8285839405143633\n",
      "Iteration: 34816, Loss: 0.10257437080144882, Accuracy: 0.8354609578382224\n",
      "Iteration: 34880, Loss: 0.07764626294374466, Accuracy: 0.8429376387502998\n",
      "Iteration: 34944, Loss: 0.09831839054822922, Accuracy: 0.846221090760082\n",
      "Iteration: 35008, Loss: 0.08099028468132019, Accuracy: 0.8471870578359812\n",
      "Iteration: 35072, Loss: 0.0721721425652504, Accuracy: 0.8475381147582084\n",
      "Iteration: 35136, Loss: 0.10883575677871704, Accuracy: 0.8508440720615909\n",
      "Iteration: 35200, Loss: 0.016795875504612923, Accuracy: 0.843714316142723\n",
      "Iteration: 35264, Loss: 0.0719716027379036, Accuracy: 0.8396716266288422\n",
      "Iteration: 35328, Loss: 0.06473201513290405, Accuracy: 0.8441302549326792\n",
      "Iteration: 35392, Loss: 0.018143510445952415, Accuracy: 0.8299532706150785\n",
      "Iteration: 35456, Loss: 0.08660721033811569, Accuracy: 0.8379464809549972\n",
      "Iteration: 35520, Loss: 0.09297039359807968, Accuracy: 0.8470081143314019\n",
      "Iteration: 35584, Loss: 0.060655657202005386, Accuracy: 0.855325290991459\n",
      "Iteration: 35648, Loss: 0.09167937189340591, Accuracy: 0.8477415320230648\n",
      "Iteration: 35712, Loss: 0.055469706654548645, Accuracy: 0.8616693048388697\n",
      "Iteration: 35776, Loss: 0.0729665607213974, Accuracy: 0.8643060902832076\n",
      "Iteration: 35840, Loss: 0.05255145952105522, Accuracy: 0.8591948616667651\n",
      "Iteration: 35904, Loss: 0.06263197958469391, Accuracy: 0.8494986795121804\n",
      "Iteration: 35968, Loss: 0.051409777253866196, Accuracy: 0.8549758744775318\n",
      "Iteration: 36032, Loss: 0.013473552651703358, Accuracy: 0.8448523047845811\n",
      "Iteration: 36096, Loss: 0.14087073504924774, Accuracy: 0.852474159153644\n",
      "Iteration: 36160, Loss: 0.016014890745282173, Accuracy: 0.8683815099066123\n",
      "Iteration: 36224, Loss: 0.01375240832567215, Accuracy: 0.8524148195865564\n",
      "Iteration: 36288, Loss: 0.06069574132561684, Accuracy: 0.8656318505527452\n",
      "Iteration: 36352, Loss: 0.08428213745355606, Accuracy: 0.8489664735388942\n",
      "Iteration: 36416, Loss: 0.031095022335648537, Accuracy: 0.8652580611524172\n",
      "Iteration: 36480, Loss: 0.08924493938684464, Accuracy: 0.8669388714479282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 36544, Loss: 0.05542421713471413, Accuracy: 0.8745595329673961\n",
      "Iteration: 36608, Loss: 0.009407510049641132, Accuracy: 0.8700172598473728\n",
      "Iteration: 36672, Loss: 0.033285558223724365, Accuracy: 0.8611617171554826\n",
      "Iteration: 36736, Loss: 0.09271129965782166, Accuracy: 0.8616243611322716\n",
      "Iteration: 36800, Loss: 0.00816216692328453, Accuracy: 0.8709121408755891\n",
      "Iteration: 36864, Loss: 0.08116324990987778, Accuracy: 0.876343205338344\n",
      "Iteration: 36928, Loss: 0.08058047294616699, Accuracy: 0.8780436837114394\n",
      "Iteration: 36992, Loss: 0.08173192292451859, Accuracy: 0.8771045461762697\n",
      "Iteration: 37056, Loss: 0.06240944564342499, Accuracy: 0.8784912340925075\n",
      "Iteration: 37120, Loss: 0.10939466208219528, Accuracy: 0.8691251194686629\n",
      "Iteration: 37184, Loss: 0.014805805869400501, Accuracy: 0.8691191868274473\n",
      "Iteration: 37248, Loss: 0.009114907123148441, Accuracy: 0.8754410784458742\n",
      "Iteration: 37312, Loss: 0.00871619489043951, Accuracy: 0.8696059663780034\n",
      "Iteration: 37376, Loss: 0.009261494502425194, Accuracy: 0.8754351285751909\n",
      "Iteration: 37440, Loss: 0.011494122445583344, Accuracy: 0.8772982703521848\n",
      "Iteration: 37504, Loss: 0.07123701274394989, Accuracy: 0.8766087486874312\n",
      "Iteration: 37568, Loss: 0.016404511407017708, Accuracy: 0.8705646287999116\n",
      "Iteration: 37632, Loss: 0.014862782321870327, Accuracy: 0.8818074321025051\n",
      "Iteration: 37696, Loss: 0.009058262221515179, Accuracy: 0.880188444047235\n",
      "Iteration: 37760, Loss: 0.05954493582248688, Accuracy: 0.8792167010833509\n",
      "Iteration: 37824, Loss: 0.14176268875598907, Accuracy: 0.872575041197706\n",
      "Iteration: 37888, Loss: 0.007722442504018545, Accuracy: 0.8854870097129606\n",
      "Iteration: 37952, Loss: 0.09480580687522888, Accuracy: 0.8780616789008491\n",
      "Iteration: 38016, Loss: 0.10617978125810623, Accuracy: 0.8622171551105566\n",
      "Iteration: 38080, Loss: 0.014133970253169537, Accuracy: 0.8629574468941428\n",
      "Iteration: 38144, Loss: 0.09890488535165787, Accuracy: 0.8720702789141797\n",
      "Iteration: 38208, Loss: 0.06640946120023727, Accuracy: 0.8663843413232826\n",
      "Iteration: 38272, Loss: 0.007962659001350403, Accuracy: 0.8799782504793257\n",
      "Iteration: 38336, Loss: 0.09786718338727951, Accuracy: 0.8630600199685432\n",
      "Iteration: 38400, Loss: 0.01078500971198082, Accuracy: 0.8836010446539149\n",
      "Iteration: 38464, Loss: 0.011753651313483715, Accuracy: 0.8790368012269028\n",
      "Iteration: 38528, Loss: 0.004759669303894043, Accuracy: 0.8818639204837382\n",
      "Iteration: 38592, Loss: 0.007554242387413979, Accuracy: 0.8820012353826314\n",
      "Iteration: 38656, Loss: 0.012994532473385334, Accuracy: 0.8827759642736055\n",
      "Iteration: 38720, Loss: 0.008550798520445824, Accuracy: 0.880369865859393\n",
      "Iteration: 38784, Loss: 0.10941270738840103, Accuracy: 0.8883546832366847\n",
      "Iteration: 38848, Loss: 0.10060898214578629, Accuracy: 0.8831367021775804\n",
      "Iteration: 38912, Loss: 0.16462452709674835, Accuracy: 0.8784511840785854\n",
      "Iteration: 38976, Loss: 0.010263334959745407, Accuracy: 0.8763724052114412\n",
      "Iteration: 39040, Loss: 0.07034566253423691, Accuracy: 0.8871594988158904\n",
      "Iteration: 39104, Loss: 0.04980430379509926, Accuracy: 0.8841480078408495\n",
      "Iteration: 39168, Loss: 0.050503697246313095, Accuracy: 0.8863702382077463\n",
      "Iteration: 39232, Loss: 0.009808865375816822, Accuracy: 0.8938258981215768\n",
      "Iteration: 39296, Loss: 0.00494759576395154, Accuracy: 0.888015755394008\n",
      "Iteration: 39360, Loss: 0.0663103237748146, Accuracy: 0.8889758296427317\n",
      "Iteration: 39424, Loss: 0.011609673500061035, Accuracy: 0.8962429410894401\n",
      "Iteration: 39488, Loss: 0.03909997269511223, Accuracy: 0.8755136324325576\n",
      "Iteration: 39552, Loss: 0.008267706260085106, Accuracy: 0.8701393412193283\n",
      "Iteration: 39616, Loss: 0.004640897270292044, Accuracy: 0.8813566042226739\n",
      "Iteration: 39680, Loss: 0.003842035075649619, Accuracy: 0.8876322755822912\n",
      "Iteration: 39744, Loss: 0.08742031455039978, Accuracy: 0.8862636974663474\n",
      "Iteration: 39808, Loss: 0.07274474948644638, Accuracy: 0.8908879044465721\n",
      "Iteration: 39872, Loss: 0.007488598581403494, Accuracy: 0.8758880769601092\n",
      "Iteration: 39936, Loss: 0.005308327730745077, Accuracy: 0.8878543542232364\n",
      "Iteration: 40000, Loss: 0.011322173289954662, Accuracy: 0.8850081356940791\n",
      "Iteration: 40064, Loss: 0.006819567177444696, Accuracy: 0.8888743113493547\n",
      "Iteration: 40128, Loss: 0.016961321234703064, Accuracy: 0.881844048621133\n",
      "Iteration: 40192, Loss: 0.039131272584199905, Accuracy: 0.878645527176559\n",
      "Iteration: 40256, Loss: 0.06143782660365105, Accuracy: 0.8927885866141878\n",
      "Iteration: 40320, Loss: 0.00822490081191063, Accuracy: 0.8910601792158559\n",
      "Iteration: 40384, Loss: 0.0065615978091955185, Accuracy: 0.8957911976613104\n",
      "Iteration: 40448, Loss: 0.007918099872767925, Accuracy: 0.8765737050562166\n",
      "Iteration: 40512, Loss: 0.004631164483726025, Accuracy: 0.8874924990232103\n",
      "Iteration: 40576, Loss: 0.07051922380924225, Accuracy: 0.876123028981965\n",
      "Iteration: 40640, Loss: 0.004905026871711016, Accuracy: 0.8898982988321222\n",
      "Iteration: 40704, Loss: 0.006992437411099672, Accuracy: 0.8867118592024781\n",
      "Iteration: 40768, Loss: 0.0380910187959671, Accuracy: 0.8726670111645944\n",
      "Iteration: 40832, Loss: 0.006833191961050034, Accuracy: 0.8971277257078327\n",
      "Iteration: 40896, Loss: 0.017064547166228294, Accuracy: 0.894188313104678\n",
      "Iteration: 40960, Loss: 0.005019750911742449, Accuracy: 0.8941363068879582\n",
      "Iteration: 41024, Loss: 0.04482040926814079, Accuracy: 0.8970791911124252\n",
      "Iteration: 41088, Loss: 0.11626709252595901, Accuracy: 0.8888801824068651\n",
      "Iteration: 41152, Loss: 0.09437262266874313, Accuracy: 0.8805884728790261\n",
      "Iteration: 41216, Loss: 0.06433572620153427, Accuracy: 0.8888476458960213\n",
      "Iteration: 41280, Loss: 0.003927613142877817, Accuracy: 0.8854361104313284\n",
      "Iteration: 41344, Loss: 0.10698583722114563, Accuracy: 0.9002366808708757\n",
      "Iteration: 41408, Loss: 0.07665374875068665, Accuracy: 0.8835310468566604\n",
      "Iteration: 41472, Loss: 0.09325581789016724, Accuracy: 0.8865218327846378\n",
      "Iteration: 41536, Loss: 0.0038383223582059145, Accuracy: 0.8852941145887598\n",
      "Iteration: 41600, Loss: 0.081711545586586, Accuracy: 0.8921089235227555\n",
      "Iteration: 41664, Loss: 0.09356211870908737, Accuracy: 0.8838452227064408\n",
      "Iteration: 41728, Loss: 0.10365559905767441, Accuracy: 0.891389965050621\n",
      "Iteration: 41792, Loss: 0.07719382643699646, Accuracy: 0.8919733423681464\n",
      "Iteration: 41856, Loss: 0.08883172273635864, Accuracy: 0.8998107606603298\n",
      "Iteration: 41920, Loss: 0.07667981088161469, Accuracy: 0.8961914042884018\n",
      "Iteration: 41984, Loss: 0.006822050083428621, Accuracy: 0.8995267015416175\n",
      "Iteration: 42048, Loss: 0.026948297396302223, Accuracy: 0.902603204944171\n",
      "Iteration: 42112, Loss: 0.004997791722416878, Accuracy: 0.9001929743681103\n",
      "Iteration: 42176, Loss: 0.008513767272233963, Accuracy: 0.8988098293193616\n",
      "Iteration: 42240, Loss: 0.003850555047392845, Accuracy: 0.897750763077056\n",
      "Iteration: 42304, Loss: 0.0895029604434967, Accuracy: 0.9038567354436964\n",
      "Iteration: 42368, Loss: 0.08805858343839645, Accuracy: 0.8972763289057184\n",
      "Iteration: 42432, Loss: 0.002673227107152343, Accuracy: 0.891908886784222\n",
      "Iteration: 42496, Loss: 0.0772106945514679, Accuracy: 0.9084162472281605\n",
      "Iteration: 42560, Loss: 0.08255975693464279, Accuracy: 0.9062969152000733\n",
      "Iteration: 42624, Loss: 0.002037704922258854, Accuracy: 0.8940398257982451\n",
      "Iteration: 42688, Loss: 0.08771239966154099, Accuracy: 0.8946913321269676\n",
      "Iteration: 42752, Loss: 0.004122893791645765, Accuracy: 0.9052735937584657\n",
      "Iteration: 42816, Loss: 0.016241740435361862, Accuracy: 0.9015428206475917\n",
      "Iteration: 42880, Loss: 0.0956159308552742, Accuracy: 0.8932980851386674\n",
      "Iteration: 42944, Loss: 0.005234160926192999, Accuracy: 0.9078706021828111\n",
      "Iteration: 43008, Loss: 0.02261890284717083, Accuracy: 0.8993194189388305\n",
      "Iteration: 43072, Loss: 0.251228004693985, Accuracy: 0.8969178672414273\n",
      "Iteration: 43136, Loss: 0.07630052417516708, Accuracy: 0.8995572360872757\n",
      "Iteration: 43200, Loss: 0.04544127359986305, Accuracy: 0.9004071420931723\n",
      "Iteration: 43264, Loss: 0.07461542636156082, Accuracy: 0.8950699881534092\n",
      "Iteration: 43328, Loss: 0.18200671672821045, Accuracy: 0.9077649464306887\n",
      "Iteration: 43392, Loss: 0.16743306815624237, Accuracy: 0.9038080328027718\n",
      "Iteration: 43456, Loss: 0.0034013118129223585, Accuracy: 0.9034507171600126\n",
      "Iteration: 43520, Loss: 0.07359614223241806, Accuracy: 0.8916026723745745\n",
      "Iteration: 43584, Loss: 0.004307227674871683, Accuracy: 0.9055149956839159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 43648, Loss: 0.0044062091037631035, Accuracy: 0.9094012502464466\n",
      "Iteration: 43712, Loss: 0.014575175940990448, Accuracy: 0.9067550623731222\n",
      "Iteration: 43776, Loss: 0.002580854343250394, Accuracy: 0.9072818169661332\n",
      "Iteration: 43840, Loss: 0.08349854499101639, Accuracy: 0.9091228728357237\n",
      "Iteration: 43904, Loss: 0.0036455269437283278, Accuracy: 0.9047336005605757\n",
      "Iteration: 43968, Loss: 0.013045351020991802, Accuracy: 0.90341834386345\n",
      "Iteration: 44032, Loss: 0.022752655670046806, Accuracy: 0.9043053530913312\n",
      "Iteration: 44096, Loss: 0.00751844234764576, Accuracy: 0.9139286485442426\n",
      "Iteration: 44160, Loss: 0.002889169380068779, Accuracy: 0.9055038563674316\n",
      "Iteration: 44224, Loss: 0.0838155448436737, Accuracy: 0.9096865577157587\n",
      "Iteration: 44288, Loss: 0.0044830976985394955, Accuracy: 0.9120869982580189\n",
      "Iteration: 44352, Loss: 0.02403024397790432, Accuracy: 0.9052916937216651\n",
      "Iteration: 44416, Loss: 0.0033411735203117132, Accuracy: 0.9047500938759185\n",
      "Iteration: 44480, Loss: 0.0035148293245583773, Accuracy: 0.902968608570518\n",
      "Iteration: 44544, Loss: 0.004942379426211119, Accuracy: 0.9041145817900542\n",
      "Iteration: 44608, Loss: 0.0036697268951684237, Accuracy: 0.9089576487895101\n",
      "Iteration: 44672, Loss: 0.0019849862437695265, Accuracy: 0.9114342998072971\n",
      "Iteration: 44736, Loss: 0.003223146079108119, Accuracy: 0.9101471163448878\n",
      "Iteration: 44800, Loss: 0.0047485982067883015, Accuracy: 0.9105108975491021\n",
      "Iteration: 44864, Loss: 0.0032032032031565905, Accuracy: 0.9104431059968192\n",
      "Iteration: 44928, Loss: 0.00567872216925025, Accuracy: 0.9147132234356832\n",
      "Iteration: 44992, Loss: 0.08577053993940353, Accuracy: 0.9120855953660794\n",
      "Iteration: 45056, Loss: 0.0018890093779191375, Accuracy: 0.9134362575423438\n",
      "Iteration: 45120, Loss: 0.003688845783472061, Accuracy: 0.9121441510505974\n",
      "Iteration: 45184, Loss: 0.005286290775984526, Accuracy: 0.9167717342788819\n",
      "Iteration: 45248, Loss: 0.0035026108380407095, Accuracy: 0.9081627675041091\n",
      "Iteration: 45312, Loss: 0.07332731038331985, Accuracy: 0.9174438529589679\n",
      "Iteration: 45376, Loss: 0.030109569430351257, Accuracy: 0.9158957139006816\n",
      "Iteration: 45440, Loss: 0.287648469209671, Accuracy: 0.9109907090896741\n",
      "Iteration: 45504, Loss: 0.010896795429289341, Accuracy: 0.9090710058808327\n",
      "Iteration: 45568, Loss: 0.005289169494062662, Accuracy: 0.9211036786437035\n",
      "Iteration: 45632, Loss: 0.000997658004052937, Accuracy: 0.9187356901238672\n",
      "Iteration: 45696, Loss: 0.08545758575201035, Accuracy: 0.9169333857425954\n",
      "Iteration: 45760, Loss: 0.006900545209646225, Accuracy: 0.905173891573213\n",
      "Iteration: 45824, Loss: 0.007059273775666952, Accuracy: 0.9190316525055096\n",
      "Iteration: 45888, Loss: 0.006186649203300476, Accuracy: 0.9153982529824134\n",
      "Iteration: 45952, Loss: 0.005193129647523165, Accuracy: 0.9229649882181548\n",
      "Iteration: 46016, Loss: 0.2777913510799408, Accuracy: 0.9166133016697131\n",
      "Iteration: 46080, Loss: 0.0028028690721839666, Accuracy: 0.9221340427757241\n",
      "Iteration: 46144, Loss: 0.001529789064079523, Accuracy: 0.9185400337155443\n",
      "Iteration: 46208, Loss: 0.001097806147299707, Accuracy: 0.9116085020359606\n",
      "Iteration: 46272, Loss: 0.005026413593441248, Accuracy: 0.904714834789047\n",
      "Iteration: 46336, Loss: 0.0027351335156708956, Accuracy: 0.9119606456370093\n",
      "Iteration: 46400, Loss: 0.0034911565016955137, Accuracy: 0.9228335088700987\n",
      "Iteration: 46464, Loss: 0.0018842885037884116, Accuracy: 0.91206421359675\n",
      "Iteration: 46528, Loss: 0.003211802802979946, Accuracy: 0.9074307764531113\n",
      "Iteration: 46592, Loss: 0.08535685390233994, Accuracy: 0.9204834542179015\n",
      "Iteration: 46656, Loss: 0.10594051331281662, Accuracy: 0.9176586165267508\n",
      "Iteration: 46720, Loss: 0.005451067816466093, Accuracy: 0.9129577738349326\n",
      "Iteration: 46784, Loss: 0.005122499540448189, Accuracy: 0.921152804949088\n",
      "Iteration: 46848, Loss: 0.0037080803886055946, Accuracy: 0.9190579403948504\n",
      "Iteration: 46912, Loss: 0.0072936248034238815, Accuracy: 0.9129368893918581\n",
      "Iteration: 46976, Loss: 0.0025851803366094828, Accuracy: 0.9203967860375997\n",
      "Iteration: 47040, Loss: 0.009145550429821014, Accuracy: 0.9162400273489766\n",
      "Iteration: 47104, Loss: 0.00783583428710699, Accuracy: 0.9189196247025393\n",
      "Iteration: 47168, Loss: 0.0877801850438118, Accuracy: 0.9188528703234624\n",
      "Iteration: 47232, Loss: 0.0028781506698578596, Accuracy: 0.9162290727254003\n",
      "Iteration: 47296, Loss: 0.0006287750438787043, Accuracy: 0.9075321867130697\n",
      "Iteration: 47360, Loss: 0.002201933180913329, Accuracy: 0.9225241336389445\n",
      "Iteration: 47424, Loss: 0.0843220055103302, Accuracy: 0.91569740648265\n",
      "Iteration: 47488, Loss: 0.002301750471815467, Accuracy: 0.9199269627570175\n",
      "Iteration: 47552, Loss: 0.0037120915949344635, Accuracy: 0.924648039508611\n",
      "Iteration: 47616, Loss: 0.004300966858863831, Accuracy: 0.9153694919659756\n",
      "Iteration: 47680, Loss: 0.002046528970822692, Accuracy: 0.9181908101600129\n",
      "Iteration: 47744, Loss: 0.0035869732964783907, Accuracy: 0.923347222385928\n",
      "Iteration: 47808, Loss: 0.0030351884197443724, Accuracy: 0.9223440435889643\n",
      "Iteration: 47872, Loss: 0.006064266432076693, Accuracy: 0.9084970257827081\n",
      "Iteration: 47936, Loss: 0.0017329733818769455, Accuracy: 0.9228654806502163\n",
      "Iteration: 48000, Loss: 0.0010869965190067887, Accuracy: 0.9272159292595461\n",
      "Iteration: 48064, Loss: 0.003975185565650463, Accuracy: 0.921309414843563\n",
      "Iteration: 48128, Loss: 0.004448292311280966, Accuracy: 0.9216972252470441\n",
      "Iteration: 48192, Loss: 0.0006880552391521633, Accuracy: 0.9236813531606458\n",
      "Iteration: 48256, Loss: 0.008393432013690472, Accuracy: 0.9171995500219055\n",
      "Iteration: 48320, Loss: 0.002936752513051033, Accuracy: 0.9227502019202802\n",
      "Iteration: 48384, Loss: 0.021045340225100517, Accuracy: 0.9239794531022198\n",
      "Iteration: 48448, Loss: 0.001864851568825543, Accuracy: 0.9151143286435399\n",
      "Iteration: 48512, Loss: 0.002302979351952672, Accuracy: 0.9070519748493098\n",
      "Iteration: 48576, Loss: 0.0025395993143320084, Accuracy: 0.9073298599687405\n",
      "Iteration: 48640, Loss: 0.08946508914232254, Accuracy: 0.9148877815750893\n",
      "Iteration: 48704, Loss: 0.0020400132052600384, Accuracy: 0.9193839121726342\n",
      "Iteration: 48768, Loss: 0.00445414986461401, Accuracy: 0.9189475177845452\n",
      "Iteration: 48832, Loss: 0.003063587239012122, Accuracy: 0.9270494877418969\n",
      "Iteration: 48896, Loss: 0.0022998331114649773, Accuracy: 0.9267409533495083\n",
      "Iteration: 48960, Loss: 0.0019323155283927917, Accuracy: 0.92854683790938\n",
      "Iteration: 49024, Loss: 0.0027864950243383646, Accuracy: 0.9285087363678031\n",
      "Iteration: 49088, Loss: 0.0016370901139453053, Accuracy: 0.9175422253319994\n",
      "Iteration: 49152, Loss: 0.0016300386050716043, Accuracy: 0.9274116732412949\n",
      "Iteration: 49216, Loss: 0.09272090345621109, Accuracy: 0.9256860489840619\n",
      "Iteration: 49280, Loss: 0.06181680038571358, Accuracy: 0.9293947015539743\n",
      "Iteration: 49344, Loss: 0.0008474876522086561, Accuracy: 0.9295720534282736\n",
      "Iteration: 49408, Loss: 0.0003706941206473857, Accuracy: 0.9294003147369949\n",
      "Iteration: 49472, Loss: 0.002112245187163353, Accuracy: 0.9189854652795475\n",
      "Iteration: 49536, Loss: 0.001756478101015091, Accuracy: 0.9237288363656262\n",
      "Iteration: 49600, Loss: 0.005864146631211042, Accuracy: 0.9299536241451278\n",
      "Iteration: 49664, Loss: 0.0006379462429322302, Accuracy: 0.9172974881075788\n",
      "Iteration: 49728, Loss: 0.003944628406316042, Accuracy: 0.9290473507717252\n",
      "Iteration: 49792, Loss: 0.001305767917074263, Accuracy: 0.9248939210374374\n",
      "Iteration: 49856, Loss: 0.001774702570401132, Accuracy: 0.9290653003845364\n",
      "Iteration: 49920, Loss: 0.0015064134495332837, Accuracy: 0.9266188086476177\n",
      "Iteration: 49984, Loss: 0.0017353217117488384, Accuracy: 0.9217012602603063\n",
      "Iteration: 50048, Loss: 0.0016641784459352493, Accuracy: 0.9230382249224931\n",
      "Iteration: 50112, Loss: 0.0004940801882185042, Accuracy: 0.9274004867475014\n",
      "Iteration: 50176, Loss: 0.06874999403953552, Accuracy: 0.9263161286362447\n",
      "Iteration: 50240, Loss: 0.002556433202698827, Accuracy: 0.9258541224407963\n",
      "Iteration: 50304, Loss: 0.0015085898339748383, Accuracy: 0.9253307574545033\n",
      "Iteration: 50368, Loss: 0.0019485079683363438, Accuracy: 0.9233596973353997\n",
      "Iteration: 50432, Loss: 0.0023625651374459267, Accuracy: 0.9307483242009766\n",
      "Iteration: 50496, Loss: 0.11759746819734573, Accuracy: 0.9259988590783905\n",
      "Iteration: 50560, Loss: 0.0034535396844148636, Accuracy: 0.928539302200079\n",
      "Iteration: 50624, Loss: 0.1032993495464325, Accuracy: 0.9126486371969804\n",
      "Iteration: 50688, Loss: 0.004180030431598425, Accuracy: 0.9287809359957464\n",
      "Iteration: 50752, Loss: 0.003425632370635867, Accuracy: 0.9324859116459265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 50816, Loss: 0.0016483053332194686, Accuracy: 0.9269942810642533\n",
      "Iteration: 50880, Loss: 0.10584542900323868, Accuracy: 0.9256616434431635\n",
      "Iteration: 50944, Loss: 0.0014161108992993832, Accuracy: 0.9331249155220576\n",
      "Iteration: 51008, Loss: 0.0016334826359525323, Accuracy: 0.923529465275351\n",
      "Iteration: 51072, Loss: 0.003377423621714115, Accuracy: 0.9287669502373319\n",
      "Iteration: 51136, Loss: 0.0020751229021698236, Accuracy: 0.9290353946271352\n",
      "Iteration: 51200, Loss: 0.0028146151453256607, Accuracy: 0.9250178872025572\n",
      "Iteration: 51264, Loss: 0.0019716420210897923, Accuracy: 0.9281284141470678\n",
      "Iteration: 51328, Loss: 0.1040579155087471, Accuracy: 0.9249834567017388\n",
      "Iteration: 51392, Loss: 0.09452550858259201, Accuracy: 0.9211984808789566\n",
      "Iteration: 51456, Loss: 0.0021889798808842897, Accuracy: 0.9149816366261803\n",
      "Iteration: 51520, Loss: 0.0017488243756815791, Accuracy: 0.9211220293072984\n",
      "Iteration: 51584, Loss: 0.0027659458573907614, Accuracy: 0.9281078810745385\n",
      "Iteration: 51648, Loss: 0.0018092371756210923, Accuracy: 0.9301888931368012\n",
      "Iteration: 51712, Loss: 0.0018968883669003844, Accuracy: 0.92913467931794\n",
      "Iteration: 51776, Loss: 0.06438103318214417, Accuracy: 0.9294104523141868\n",
      "Iteration: 51840, Loss: 0.0030955669935792685, Accuracy: 0.9343912085168995\n",
      "Iteration: 51904, Loss: 0.06258326768875122, Accuracy: 0.926734611421125\n",
      "Iteration: 51968, Loss: 0.0010679190745577216, Accuracy: 0.9279736506287009\n",
      "Iteration: 52032, Loss: 0.0006550450925715268, Accuracy: 0.9286350762995426\n",
      "Iteration: 52096, Loss: 0.0034713437780737877, Accuracy: 0.9298708109563449\n",
      "Iteration: 52160, Loss: 0.018792517483234406, Accuracy: 0.93667294253828\n",
      "Iteration: 52224, Loss: 0.07417679578065872, Accuracy: 0.9303106129082153\n",
      "Iteration: 52288, Loss: 0.003281994489952922, Accuracy: 0.9327211220079334\n",
      "Iteration: 52352, Loss: 0.0010594722116366029, Accuracy: 0.9314928265084745\n",
      "Iteration: 52416, Loss: 0.0017051241593435407, Accuracy: 0.9352752411214169\n",
      "Iteration: 52480, Loss: 0.0014437297359108925, Accuracy: 0.93356249651697\n",
      "Iteration: 52544, Loss: 0.0012893761740997434, Accuracy: 0.9254808218538528\n",
      "Iteration: 52608, Loss: 0.080195352435112, Accuracy: 0.9139336383959744\n",
      "Iteration: 52672, Loss: 0.05854608491063118, Accuracy: 0.9277392485673772\n",
      "Iteration: 52736, Loss: 0.0013786304043605924, Accuracy: 0.9399564858176745\n",
      "Iteration: 52800, Loss: 0.12266593426465988, Accuracy: 0.9343060871906346\n",
      "Iteration: 52864, Loss: 0.0011805304093286395, Accuracy: 0.9312338722520508\n",
      "Iteration: 52928, Loss: 0.07497997581958771, Accuracy: 0.9332787927123718\n",
      "Iteration: 52992, Loss: 0.0006193890585564077, Accuracy: 0.9293922362412559\n",
      "Iteration: 53056, Loss: 0.2954002618789673, Accuracy: 0.92333234185935\n",
      "Iteration: 53120, Loss: 0.07705926150083542, Accuracy: 0.9344043942110147\n",
      "Iteration: 53184, Loss: 0.001789133995771408, Accuracy: 0.9273381540406263\n",
      "Iteration: 53248, Loss: 0.0007900508935563266, Accuracy: 0.9343878444342408\n",
      "Iteration: 53312, Loss: 0.001081795315258205, Accuracy: 0.9244971200532746\n",
      "Iteration: 53376, Loss: 0.0004326562338974327, Accuracy: 0.9388457917521009\n",
      "Iteration: 53440, Loss: 0.05664679408073425, Accuracy: 0.9416603244171711\n",
      "Iteration: 53504, Loss: 0.015347134321928024, Accuracy: 0.908086103736423\n",
      "Iteration: 53568, Loss: 0.0007962462841533124, Accuracy: 0.9268943217175547\n",
      "Iteration: 53632, Loss: 0.00023705071362201124, Accuracy: 0.9361299706215505\n",
      "Iteration: 53696, Loss: 0.008030219934880733, Accuracy: 0.9394598807411967\n",
      "Iteration: 53760, Loss: 0.03226616606116295, Accuracy: 0.9397697744861944\n",
      "Iteration: 53824, Loss: 0.00042987571214325726, Accuracy: 0.9253059269685764\n",
      "Iteration: 53888, Loss: 0.08236891776323318, Accuracy: 0.9376142387627624\n",
      "Iteration: 53952, Loss: 0.0007764463662169874, Accuracy: 0.9375599062186666\n",
      "Iteration: 54016, Loss: 0.0008477339870296419, Accuracy: 0.945615924327285\n",
      "Iteration: 54080, Loss: 0.00019123085075989366, Accuracy: 0.9315325653587934\n",
      "Iteration: 54144, Loss: 0.0008721924968995154, Accuracy: 0.9475807991111651\n",
      "Iteration: 54208, Loss: 0.02018938772380352, Accuracy: 0.9410327679215698\n",
      "Iteration: 54272, Loss: 0.00038235439569689333, Accuracy: 0.9421544682409149\n",
      "Iteration: 54336, Loss: 0.00013670348562300205, Accuracy: 0.9396166315564187\n",
      "Iteration: 54400, Loss: 0.004228964913636446, Accuracy: 0.9466030999756185\n",
      "Iteration: 54464, Loss: 0.018159737810492516, Accuracy: 0.9296472283749608\n",
      "Iteration: 54528, Loss: 0.00016120423970278352, Accuracy: 0.9337244796188315\n",
      "Iteration: 54592, Loss: 0.0034073705319315195, Accuracy: 0.9436042998713674\n",
      "Iteration: 54656, Loss: 0.0004311313387006521, Accuracy: 0.936318584572291\n",
      "Iteration: 54720, Loss: 0.00036252359859645367, Accuracy: 0.923556060748524\n",
      "Iteration: 54784, Loss: 0.00043655524495989084, Accuracy: 0.9435642465250567\n",
      "Iteration: 54848, Loss: 0.007394701242446899, Accuracy: 0.945035808646935\n",
      "Iteration: 54912, Loss: 0.015131454914808273, Accuracy: 0.940425399778178\n",
      "Iteration: 54976, Loss: 0.015952518209815025, Accuracy: 0.9389604778407374\n",
      "Iteration: 55040, Loss: 0.0008342431974597275, Accuracy: 0.9404977107915329\n",
      "Iteration: 55104, Loss: 0.024615494534373283, Accuracy: 0.9399711662554182\n",
      "Iteration: 55168, Loss: 0.03456335514783859, Accuracy: 0.9430268572759815\n",
      "Iteration: 55232, Loss: 0.03190017119050026, Accuracy: 0.9477988532162271\n",
      "Iteration: 55296, Loss: 0.002299307379871607, Accuracy: 0.9423665211943444\n",
      "Iteration: 55360, Loss: 8.342196815647185e-05, Accuracy: 0.9369503892521607\n",
      "Iteration: 55424, Loss: 0.000304869026876986, Accuracy: 0.9368500465425313\n",
      "Iteration: 55488, Loss: 0.003842008300125599, Accuracy: 0.9431370904349023\n",
      "Iteration: 55552, Loss: 0.00025414180709049106, Accuracy: 0.9472389182556071\n",
      "Iteration: 55616, Loss: 0.0016312985680997372, Accuracy: 0.9380955424785498\n",
      "Iteration: 55680, Loss: 0.0007294383249245584, Accuracy: 0.9436291728343349\n",
      "Iteration: 55744, Loss: 0.0011413396568968892, Accuracy: 0.9367858548066579\n",
      "Iteration: 55808, Loss: 0.0003425432078074664, Accuracy: 0.9490204125031596\n",
      "Iteration: 55872, Loss: 0.012637253850698471, Accuracy: 0.9565943778143264\n",
      "Iteration: 55936, Loss: 0.002497161040082574, Accuracy: 0.948741694126511\n",
      "Iteration: 56000, Loss: 0.0006343610002659261, Accuracy: 0.940047137439251\n",
      "Iteration: 56064, Loss: 0.0010265958262607455, Accuracy: 0.952056598427589\n",
      "Iteration: 56128, Loss: 0.00022457637533079833, Accuracy: 0.9404765589497401\n",
      "Iteration: 56192, Loss: 0.00010977272177115083, Accuracy: 0.9397319765630527\n",
      "Iteration: 56256, Loss: 0.00014509694301523268, Accuracy: 0.9543001489146263\n",
      "Iteration: 56320, Loss: 0.0005832845927216113, Accuracy: 0.9530607884953497\n",
      "Iteration: 56384, Loss: 0.0031445957720279694, Accuracy: 0.9511814712604973\n",
      "Iteration: 56448, Loss: 0.00914731714874506, Accuracy: 0.953568187833298\n",
      "Iteration: 56512, Loss: 0.0001990362216020003, Accuracy: 0.9511386375306756\n",
      "Iteration: 56576, Loss: 0.007482169196009636, Accuracy: 0.9465333882835694\n",
      "Iteration: 56640, Loss: 0.08276785165071487, Accuracy: 0.9477508893833146\n",
      "Iteration: 56704, Loss: 0.021167099475860596, Accuracy: 0.9584624471972347\n",
      "Iteration: 56768, Loss: 0.00014806225954089314, Accuracy: 0.9491645147500094\n",
      "Iteration: 56832, Loss: 0.006511816289275885, Accuracy: 0.9424533767232788\n",
      "Iteration: 56896, Loss: 0.0007927489350549877, Accuracy: 0.9556783027146594\n",
      "Iteration: 56960, Loss: 0.0054279714822769165, Accuracy: 0.9525241533046938\n",
      "Iteration: 57024, Loss: 0.006813038606196642, Accuracy: 0.947333633856033\n",
      "Iteration: 57088, Loss: 4.502429874264635e-05, Accuracy: 0.9512199763630633\n",
      "Iteration: 57152, Loss: 0.00042928327457048, Accuracy: 0.9537059186113765\n",
      "Iteration: 57216, Loss: 0.0005155832623131573, Accuracy: 0.9384015548057505\n",
      "Iteration: 57280, Loss: 0.00460194144397974, Accuracy: 0.9607426006550668\n",
      "Iteration: 57344, Loss: 0.0005081493873149157, Accuracy: 0.9548259543516906\n",
      "Iteration: 57408, Loss: 0.00022601464297622442, Accuracy: 0.9551959602613351\n",
      "Iteration: 57472, Loss: 0.015870358794927597, Accuracy: 0.9436481514421757\n",
      "Iteration: 57536, Loss: 0.012308220379054546, Accuracy: 0.9576909978495678\n",
      "Iteration: 57600, Loss: 0.0013550306903198361, Accuracy: 0.9545543012281996\n",
      "Iteration: 57664, Loss: 0.00020893833425361663, Accuracy: 0.9443994910980109\n",
      "Iteration: 57728, Loss: 0.003252231515944004, Accuracy: 0.9623506765274215\n",
      "Iteration: 57792, Loss: 0.0006980803445912898, Accuracy: 0.9623029293361469\n",
      "Iteration: 57856, Loss: 0.0004083163512405008, Accuracy: 0.961356807492848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 57920, Loss: 0.0001227167813340202, Accuracy: 0.9557878368359525\n",
      "Iteration: 57984, Loss: 2.5374634788022377e-05, Accuracy: 0.9525145824663923\n",
      "Iteration: 58048, Loss: 0.0394507497549057, Accuracy: 0.9536463606054895\n",
      "Iteration: 58112, Loss: 8.124144369503483e-05, Accuracy: 0.9548123324857443\n",
      "Iteration: 58176, Loss: 3.325004581711255e-05, Accuracy: 0.9538363914543879\n",
      "Iteration: 58240, Loss: 0.009331341832876205, Accuracy: 0.9550204932893394\n",
      "Iteration: 58304, Loss: 0.004136497620493174, Accuracy: 0.9615096151756006\n",
      "Iteration: 58368, Loss: 4.436590461409651e-05, Accuracy: 0.9471016555398819\n",
      "Iteration: 58432, Loss: 0.005574692506343126, Accuracy: 0.9616335514147067\n",
      "Iteration: 58496, Loss: 0.004672511946409941, Accuracy: 0.955153309078014\n",
      "Iteration: 58560, Loss: 0.0005708656390197575, Accuracy: 0.9566233486548299\n",
      "Iteration: 58624, Loss: 7.118502981029451e-05, Accuracy: 0.9567514788286644\n",
      "Iteration: 58688, Loss: 0.0004216530069243163, Accuracy: 0.9395863127938355\n",
      "Iteration: 58752, Loss: 0.008447129279375076, Accuracy: 0.953123027109541\n",
      "Iteration: 58816, Loss: 4.7042285586940125e-05, Accuracy: 0.9586330297315726\n",
      "Iteration: 58880, Loss: 3.89838642149698e-05, Accuracy: 0.9575227565946989\n",
      "Iteration: 58944, Loss: 0.0019492781721055508, Accuracy: 0.9634293652197812\n",
      "Iteration: 59008, Loss: 0.01084606721997261, Accuracy: 0.9545126639786758\n",
      "Iteration: 59072, Loss: 0.003399910405278206, Accuracy: 0.9548507876315853\n",
      "Iteration: 59136, Loss: 0.0004275398969184607, Accuracy: 0.9541215024073608\n",
      "Iteration: 59200, Loss: 0.009449045173823833, Accuracy: 0.9511546557259862\n",
      "Iteration: 59264, Loss: 0.000788791396189481, Accuracy: 0.9516997525643092\n",
      "Iteration: 59328, Loss: 0.0006904493202455342, Accuracy: 0.9619146229961189\n",
      "Iteration: 59392, Loss: 0.037241797894239426, Accuracy: 0.9602053059352329\n",
      "Iteration: 59456, Loss: 0.0010879463516175747, Accuracy: 0.9652010893187253\n",
      "Iteration: 59520, Loss: 0.004424809943884611, Accuracy: 0.9513553173019318\n",
      "Iteration: 59584, Loss: 0.13620738685131073, Accuracy: 0.9515478336834349\n",
      "Iteration: 59648, Loss: 0.007237635552883148, Accuracy: 0.9486056517635006\n",
      "Iteration: 59712, Loss: 0.00887470506131649, Accuracy: 0.9677594709719415\n",
      "Iteration: 59776, Loss: 4.1125986172119156e-05, Accuracy: 0.9646830633209902\n",
      "Iteration: 59840, Loss: 0.00019841239554807544, Accuracy: 0.9503488888949505\n",
      "Iteration: 59904, Loss: 0.0006704395636916161, Accuracy: 0.9650450143453781\n",
      "Iteration: 59968, Loss: 0.014770771376788616, Accuracy: 0.966696824390965\n",
      "Iteration: 60032, Loss: 0.00973724015057087, Accuracy: 0.9618460526689887\n",
      "Iteration: 60096, Loss: 4.8700854677008465e-05, Accuracy: 0.9623239956126781\n",
      "Iteration: 60160, Loss: 0.011820710264146328, Accuracy: 0.9592938088899245\n",
      "Iteration: 60224, Loss: 4.274942693882622e-05, Accuracy: 0.9552399459462322\n",
      "Iteration: 60288, Loss: 0.0004148762673139572, Accuracy: 0.956934062684013\n",
      "Iteration: 60352, Loss: 0.002978690667077899, Accuracy: 0.9705642897170037\n",
      "Saved fullModel_dr[5]_replicate2.model\n",
      "Saved W_dr[5]_replicate2.p\n",
      "5 0.9895833333333334 [1.0, 0.96875, 1.0]\n",
      "Saved w_dr[5]_replicate2.p\n",
      "Replicate 2 completed\n",
      "Time elapsed: 891.265625 seconds\n",
      "Iteration: 64, Loss: 0.2866491377353668, Accuracy: 0.4991858075372875\n",
      "Iteration: 128, Loss: 0.2219073325395584, Accuracy: 0.5014163618907332\n",
      "Iteration: 192, Loss: 0.22773496806621552, Accuracy: 0.5023686103522778\n",
      "Iteration: 256, Loss: 0.25833043456077576, Accuracy: 0.5019363048486412\n",
      "Iteration: 320, Loss: 0.21826554834842682, Accuracy: 0.5079208523966372\n",
      "Iteration: 384, Loss: 0.17925786972045898, Accuracy: 0.5332539947703481\n",
      "Iteration: 448, Loss: 0.1814562827348709, Accuracy: 0.5670913755893707\n",
      "Iteration: 512, Loss: 0.19908607006072998, Accuracy: 0.5840254873037338\n",
      "Iteration: 576, Loss: 0.22619973123073578, Accuracy: 0.6003018408082426\n",
      "Iteration: 640, Loss: 0.2038872241973877, Accuracy: 0.6123409024439752\n",
      "Iteration: 704, Loss: 0.17044372856616974, Accuracy: 0.6201496054418385\n",
      "Iteration: 768, Loss: 0.15917496383190155, Accuracy: 0.6296522221527994\n",
      "Iteration: 832, Loss: 0.22171032428741455, Accuracy: 0.6362082944251597\n",
      "Iteration: 896, Loss: 0.23220624029636383, Accuracy: 0.6421454339288175\n",
      "Iteration: 960, Loss: 0.18082301318645477, Accuracy: 0.645498706959188\n",
      "Iteration: 1024, Loss: 0.11973831802606583, Accuracy: 0.6506622713059187\n",
      "Iteration: 1088, Loss: 0.21765731275081635, Accuracy: 0.6546986899338663\n",
      "Iteration: 1152, Loss: 0.216962531208992, Accuracy: 0.6532973432913423\n",
      "Iteration: 1216, Loss: 0.15008211135864258, Accuracy: 0.6578529472462833\n",
      "Iteration: 1280, Loss: 0.17323309183120728, Accuracy: 0.6609899061731994\n",
      "Iteration: 1344, Loss: 0.1465083807706833, Accuracy: 0.664436420891434\n",
      "Iteration: 1408, Loss: 0.08032514899969101, Accuracy: 0.6669323812238872\n",
      "Iteration: 1472, Loss: 0.1731323003768921, Accuracy: 0.663734074216336\n",
      "Iteration: 1536, Loss: 0.1742202490568161, Accuracy: 0.6668378370814025\n",
      "Iteration: 1600, Loss: 0.15877990424633026, Accuracy: 0.6689447041135281\n",
      "Iteration: 1664, Loss: 0.21422535181045532, Accuracy: 0.6718668441753834\n",
      "Iteration: 1728, Loss: 0.1380990892648697, Accuracy: 0.6706892508082092\n",
      "Iteration: 1792, Loss: 0.16092471778392792, Accuracy: 0.6734421758446842\n",
      "Iteration: 1856, Loss: 0.1789962500333786, Accuracy: 0.6730159549042583\n",
      "Iteration: 1920, Loss: 0.06531810015439987, Accuracy: 0.6776944485027343\n",
      "Iteration: 1984, Loss: 0.06471966952085495, Accuracy: 0.677107356954366\n",
      "Iteration: 2048, Loss: 0.17548464238643646, Accuracy: 0.6780011444352567\n",
      "Iteration: 2112, Loss: 0.05978437885642052, Accuracy: 0.678744975477457\n",
      "Iteration: 2176, Loss: 0.19539213180541992, Accuracy: 0.6824465098325163\n",
      "Iteration: 2240, Loss: 0.15676413476467133, Accuracy: 0.681192931951955\n",
      "Iteration: 2304, Loss: 0.16670821607112885, Accuracy: 0.6849328717216849\n",
      "Iteration: 2368, Loss: 0.19249796867370605, Accuracy: 0.684829663252458\n",
      "Iteration: 2432, Loss: 0.16133950650691986, Accuracy: 0.6881972069386393\n",
      "Iteration: 2496, Loss: 0.17591722309589386, Accuracy: 0.6914359622169286\n",
      "Iteration: 2560, Loss: 0.1566973179578781, Accuracy: 0.691640208940953\n",
      "Iteration: 2624, Loss: 0.18082422018051147, Accuracy: 0.6928874389268458\n",
      "Iteration: 2688, Loss: 0.24668776988983154, Accuracy: 0.6912840879522264\n",
      "Iteration: 2752, Loss: 0.051206860691308975, Accuracy: 0.698383754119277\n",
      "Iteration: 2816, Loss: 0.05487501621246338, Accuracy: 0.6965571162290871\n",
      "Iteration: 2880, Loss: 0.15086032450199127, Accuracy: 0.6905322938691825\n",
      "Iteration: 2944, Loss: 0.18053413927555084, Accuracy: 0.7032143599353731\n",
      "Iteration: 3008, Loss: 0.13452720642089844, Accuracy: 0.7003766908310354\n",
      "Iteration: 3072, Loss: 0.15547698736190796, Accuracy: 0.7035334859974682\n",
      "Iteration: 3136, Loss: 0.04021390527486801, Accuracy: 0.7063573973719031\n",
      "Iteration: 3200, Loss: 0.17303693294525146, Accuracy: 0.7055464922450483\n",
      "Iteration: 3264, Loss: 0.14130280911922455, Accuracy: 0.7021571861114353\n",
      "Iteration: 3328, Loss: 0.19050852954387665, Accuracy: 0.7081526161637157\n",
      "Iteration: 3392, Loss: 0.05841085687279701, Accuracy: 0.7051521053072065\n",
      "Iteration: 3456, Loss: 0.16714631021022797, Accuracy: 0.7142116278409958\n",
      "Iteration: 3520, Loss: 0.1983904093503952, Accuracy: 0.7142563997767866\n",
      "Iteration: 3584, Loss: 0.17966841161251068, Accuracy: 0.7184903251472861\n",
      "Iteration: 3648, Loss: 0.14718398451805115, Accuracy: 0.7195373938884586\n",
      "Iteration: 3712, Loss: 0.10003643482923508, Accuracy: 0.7219887673854828\n",
      "Iteration: 3776, Loss: 0.17825810611248016, Accuracy: 0.7222238434478641\n",
      "Iteration: 3840, Loss: 0.042726922780275345, Accuracy: 0.7277779160067439\n",
      "Iteration: 3904, Loss: 0.17879778146743774, Accuracy: 0.723155697574839\n",
      "Iteration: 3968, Loss: 0.0956987515091896, Accuracy: 0.7298654853366315\n",
      "Iteration: 4032, Loss: 0.18558426201343536, Accuracy: 0.7303562327288091\n",
      "Iteration: 4096, Loss: 0.046083852648735046, Accuracy: 0.7262805642094463\n",
      "Iteration: 4160, Loss: 0.03880095109343529, Accuracy: 0.7173108144197613\n",
      "Iteration: 4224, Loss: 0.09112593531608582, Accuracy: 0.7356029124930501\n",
      "Iteration: 4288, Loss: 0.03676031529903412, Accuracy: 0.7372013574931771\n",
      "Iteration: 4352, Loss: 0.08761382848024368, Accuracy: 0.7416125880554318\n",
      "Iteration: 4416, Loss: 0.13574965298175812, Accuracy: 0.7399504068307579\n",
      "Iteration: 4480, Loss: 0.07954427599906921, Accuracy: 0.7362424181774259\n",
      "Iteration: 4544, Loss: 0.1905549317598343, Accuracy: 0.7431337225716561\n",
      "Iteration: 4608, Loss: 0.07595906406641006, Accuracy: 0.7377537931315601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4672, Loss: 0.08315000683069229, Accuracy: 0.741394517943263\n",
      "Iteration: 4736, Loss: 0.07317140698432922, Accuracy: 0.7440597233362496\n",
      "Iteration: 4800, Loss: 0.12206101417541504, Accuracy: 0.7484419416869059\n",
      "Iteration: 4864, Loss: 0.0892619863152504, Accuracy: 0.7510507452534512\n",
      "Iteration: 4928, Loss: 0.030382653698325157, Accuracy: 0.7503473691176623\n",
      "Iteration: 4992, Loss: 0.16264121234416962, Accuracy: 0.7524109565420076\n",
      "Iteration: 5056, Loss: 0.02240913175046444, Accuracy: 0.7548267906531692\n",
      "Iteration: 5120, Loss: 0.06719228625297546, Accuracy: 0.7543429010547698\n",
      "Iteration: 5184, Loss: 0.08153891563415527, Accuracy: 0.7585388768929988\n",
      "Iteration: 5248, Loss: 0.07246813923120499, Accuracy: 0.7574770426144823\n",
      "Iteration: 5312, Loss: 0.15454524755477905, Accuracy: 0.7590797095326707\n",
      "Iteration: 5376, Loss: 0.1328999251127243, Accuracy: 0.7631838209927082\n",
      "Iteration: 5440, Loss: 0.06273620575666428, Accuracy: 0.7579191176919267\n",
      "Iteration: 5504, Loss: 0.14828941226005554, Accuracy: 0.7649854371557012\n",
      "Iteration: 5568, Loss: 0.0406620167195797, Accuracy: 0.7595467333449051\n",
      "Iteration: 5632, Loss: 0.15861359238624573, Accuracy: 0.7633585231378675\n",
      "Iteration: 5696, Loss: 0.11154761910438538, Accuracy: 0.7705695910844952\n",
      "Iteration: 5760, Loss: 0.14402715861797333, Accuracy: 0.7694521150551736\n",
      "Iteration: 5824, Loss: 0.1369786262512207, Accuracy: 0.7658108755713329\n",
      "Iteration: 5888, Loss: 0.06379397958517075, Accuracy: 0.7745481089223176\n",
      "Iteration: 5952, Loss: 0.08272472023963928, Accuracy: 0.7695452191401273\n",
      "Iteration: 6016, Loss: 0.14051873981952667, Accuracy: 0.7709656099323183\n",
      "Iteration: 6080, Loss: 0.019374368712306023, Accuracy: 0.7747497678501531\n",
      "Iteration: 6144, Loss: 0.056323856115341187, Accuracy: 0.7662607976235449\n",
      "Iteration: 6208, Loss: 0.14506684243679047, Accuracy: 0.7697541220113635\n",
      "Iteration: 6272, Loss: 0.028637968003749847, Accuracy: 0.7726974323159084\n",
      "Iteration: 6336, Loss: 0.1309327632188797, Accuracy: 0.780354225425981\n",
      "Iteration: 6400, Loss: 0.04508005455136299, Accuracy: 0.7779230317100883\n",
      "Iteration: 6464, Loss: 0.13142798840999603, Accuracy: 0.7818427578313276\n",
      "Iteration: 6528, Loss: 0.06414440274238586, Accuracy: 0.7858040283899754\n",
      "Iteration: 6592, Loss: 0.09912944585084915, Accuracy: 0.7813979643397033\n",
      "Iteration: 6656, Loss: 0.018368635326623917, Accuracy: 0.7814575277734548\n",
      "Iteration: 6720, Loss: 0.1250767558813095, Accuracy: 0.7899094845633954\n",
      "Iteration: 6784, Loss: 0.35735535621643066, Accuracy: 0.7820660949219018\n",
      "Iteration: 6848, Loss: 0.17807598412036896, Accuracy: 0.7907939441502094\n",
      "Iteration: 6912, Loss: 0.025138480588793755, Accuracy: 0.789148582261987\n",
      "Iteration: 6976, Loss: 0.07824085652828217, Accuracy: 0.7834145979722962\n",
      "Iteration: 7040, Loss: 0.10059210658073425, Accuracy: 0.7860168371116742\n",
      "Iteration: 7104, Loss: 0.02971813827753067, Accuracy: 0.7968557992717251\n",
      "Iteration: 7168, Loss: 0.08631787449121475, Accuracy: 0.7909286842914298\n",
      "Iteration: 7232, Loss: 0.07164809852838516, Accuracy: 0.796628957381472\n",
      "Iteration: 7296, Loss: 0.031595226377248764, Accuracy: 0.8007949737366289\n",
      "Iteration: 7360, Loss: 0.07130269706249237, Accuracy: 0.7907939781434834\n",
      "Iteration: 7424, Loss: 0.08397692441940308, Accuracy: 0.7931264812359586\n",
      "Iteration: 7488, Loss: 0.12146403640508652, Accuracy: 0.7990284773986787\n",
      "Iteration: 7552, Loss: 0.023887060582637787, Accuracy: 0.8017579549923539\n",
      "Iteration: 7616, Loss: 0.07082130014896393, Accuracy: 0.8032858655788004\n",
      "Iteration: 7680, Loss: 0.0763402208685875, Accuracy: 0.7992143643787131\n",
      "Iteration: 7744, Loss: 0.07553672045469284, Accuracy: 0.7965146056376398\n",
      "Iteration: 7808, Loss: 0.02733892761170864, Accuracy: 0.8045065674232319\n",
      "Iteration: 7872, Loss: 0.1229337528347969, Accuracy: 0.804242882411927\n",
      "Iteration: 7936, Loss: 0.14902181923389435, Accuracy: 0.8066258733160794\n",
      "Iteration: 8000, Loss: 0.03221862390637398, Accuracy: 0.8091865419410169\n",
      "Iteration: 8064, Loss: 0.11577463895082474, Accuracy: 0.8102144047152251\n",
      "Iteration: 8128, Loss: 0.09876147657632828, Accuracy: 0.8075597941642627\n",
      "Iteration: 8192, Loss: 0.03128626570105553, Accuracy: 0.8147064240183681\n",
      "Iteration: 8256, Loss: 0.024379177019000053, Accuracy: 0.8057905881432816\n",
      "Iteration: 8320, Loss: 0.02091413550078869, Accuracy: 0.819982014130801\n",
      "Iteration: 8384, Loss: 0.1501864641904831, Accuracy: 0.8115952080115676\n",
      "Iteration: 8448, Loss: 0.033965978771448135, Accuracy: 0.8053930641617626\n",
      "Iteration: 8512, Loss: 0.06986818462610245, Accuracy: 0.8159170601284131\n",
      "Iteration: 8576, Loss: 0.11519647389650345, Accuracy: 0.8239265887532383\n",
      "Iteration: 8640, Loss: 0.04881053790450096, Accuracy: 0.8236418899614364\n",
      "Iteration: 8704, Loss: 0.07002327591180801, Accuracy: 0.8107508532702923\n",
      "Iteration: 8768, Loss: 0.11547092348337173, Accuracy: 0.8263790472410619\n",
      "Iteration: 8832, Loss: 0.06753161549568176, Accuracy: 0.8240659827133641\n",
      "Iteration: 8896, Loss: 0.014775332063436508, Accuracy: 0.8025185600854456\n",
      "Iteration: 8960, Loss: 0.02892143465578556, Accuracy: 0.825568346423097\n",
      "Iteration: 9024, Loss: 0.021489201113581657, Accuracy: 0.8154248003847897\n",
      "Iteration: 9088, Loss: 0.025106355547904968, Accuracy: 0.8213060925481841\n",
      "Iteration: 9152, Loss: 0.012399089522659779, Accuracy: 0.8061862867325544\n",
      "Iteration: 9216, Loss: 0.11231065541505814, Accuracy: 0.8214407102204859\n",
      "Iteration: 9280, Loss: 0.06423730403184891, Accuracy: 0.819381567533128\n",
      "Iteration: 9344, Loss: 0.03401869162917137, Accuracy: 0.8277637776918709\n",
      "Iteration: 9408, Loss: 0.0497480146586895, Accuracy: 0.8307927802670747\n",
      "Iteration: 9472, Loss: 0.06095169112086296, Accuracy: 0.8210078924894333\n",
      "Iteration: 9536, Loss: 0.05836319923400879, Accuracy: 0.823213807772845\n",
      "Iteration: 9600, Loss: 0.04815494641661644, Accuracy: 0.8235115919960663\n",
      "Iteration: 9664, Loss: 0.046968668699264526, Accuracy: 0.8245102608343586\n",
      "Iteration: 9728, Loss: 0.04514008387923241, Accuracy: 0.8272699185181409\n",
      "Iteration: 9792, Loss: 0.11180239170789719, Accuracy: 0.8202993129380047\n",
      "Iteration: 9856, Loss: 0.05758718028664589, Accuracy: 0.8336782633559778\n",
      "Iteration: 9920, Loss: 0.11014009267091751, Accuracy: 0.8351485962048173\n",
      "Iteration: 9984, Loss: 0.05988345667719841, Accuracy: 0.82656843168661\n",
      "Iteration: 10048, Loss: 0.06293724477291107, Accuracy: 0.8250043918378651\n",
      "Iteration: 10112, Loss: 0.09045564383268356, Accuracy: 0.8340247527230531\n",
      "Iteration: 10176, Loss: 0.042445749044418335, Accuracy: 0.8415947427274659\n",
      "Iteration: 10240, Loss: 0.013827470131218433, Accuracy: 0.84107937279623\n",
      "Iteration: 10304, Loss: 0.09374144673347473, Accuracy: 0.8486511749215424\n",
      "Iteration: 10368, Loss: 0.10649999231100082, Accuracy: 0.8466425156220794\n",
      "Iteration: 10432, Loss: 0.007896210066974163, Accuracy: 0.8343809044454247\n",
      "Iteration: 10496, Loss: 0.0152968131005764, Accuracy: 0.8285914863226935\n",
      "Iteration: 10560, Loss: 0.010208994150161743, Accuracy: 0.8404812108492479\n",
      "Iteration: 10624, Loss: 0.10675105452537537, Accuracy: 0.8377593075856566\n",
      "Iteration: 10688, Loss: 0.012994341552257538, Accuracy: 0.840370848425664\n",
      "Iteration: 10752, Loss: 0.10616908222436905, Accuracy: 0.8432883318746462\n",
      "Iteration: 10816, Loss: 0.07375890016555786, Accuracy: 0.8504667050438002\n",
      "Iteration: 10880, Loss: 0.07060544937849045, Accuracy: 0.8388479611603543\n",
      "Iteration: 10944, Loss: 0.050708573311567307, Accuracy: 0.8488954181084409\n",
      "Iteration: 11008, Loss: 0.10205309838056564, Accuracy: 0.8528757201274857\n",
      "Iteration: 11072, Loss: 0.007627303246408701, Accuracy: 0.8596000837860629\n",
      "Iteration: 11136, Loss: 0.00552128441631794, Accuracy: 0.8482024377444759\n",
      "Iteration: 11200, Loss: 0.03132247552275658, Accuracy: 0.8543387302779593\n",
      "Iteration: 11264, Loss: 0.04222312569618225, Accuracy: 0.8395888595841825\n",
      "Iteration: 11328, Loss: 0.04441147670149803, Accuracy: 0.8552055892068893\n",
      "Iteration: 11392, Loss: 0.044832680374383926, Accuracy: 0.8467070658807643\n",
      "Iteration: 11456, Loss: 0.02089860290288925, Accuracy: 0.8517848093761131\n",
      "Iteration: 11520, Loss: 0.10569930076599121, Accuracy: 0.8436384616070427\n",
      "Iteration: 11584, Loss: 0.10942348092794418, Accuracy: 0.8490889050299302\n",
      "Iteration: 11648, Loss: 0.20355074107646942, Accuracy: 0.8482373969745822\n",
      "Iteration: 11712, Loss: 0.03940941020846367, Accuracy: 0.8500203292933293\n",
      "Iteration: 11776, Loss: 0.005834596231579781, Accuracy: 0.8554559561307542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 11840, Loss: 0.00795915350317955, Accuracy: 0.8578633016441017\n",
      "Iteration: 11904, Loss: 0.0868053212761879, Accuracy: 0.8650654328521341\n",
      "Iteration: 11968, Loss: 0.01359447930008173, Accuracy: 0.8590137435821816\n",
      "Iteration: 12032, Loss: 0.022742964327335358, Accuracy: 0.8576920535415411\n",
      "Iteration: 12096, Loss: 0.04141410067677498, Accuracy: 0.8674393058172427\n",
      "Iteration: 12160, Loss: 0.01543288305401802, Accuracy: 0.8501626139041036\n",
      "Iteration: 12224, Loss: 0.04767153039574623, Accuracy: 0.8424273656564765\n",
      "Iteration: 12288, Loss: 0.010124973952770233, Accuracy: 0.856945646868553\n",
      "Iteration: 12352, Loss: 0.04220535233616829, Accuracy: 0.8592271679663099\n",
      "Iteration: 12416, Loss: 0.011371706612408161, Accuracy: 0.865414610831067\n",
      "Iteration: 12480, Loss: 0.026396021246910095, Accuracy: 0.8726458452292718\n",
      "Iteration: 12544, Loss: 0.10676475614309311, Accuracy: 0.8694367662537843\n",
      "Iteration: 12608, Loss: 0.07287082821130753, Accuracy: 0.8618129015667364\n",
      "Iteration: 12672, Loss: 0.03607800602912903, Accuracy: 0.8558160581742413\n",
      "Iteration: 12736, Loss: 0.050221774727106094, Accuracy: 0.8666970814811066\n",
      "Iteration: 12800, Loss: 0.07732150703668594, Accuracy: 0.8725831307237968\n",
      "Iteration: 12864, Loss: 0.00956976693123579, Accuracy: 0.8774763884139247\n",
      "Iteration: 12928, Loss: 0.0415140725672245, Accuracy: 0.8705747134517878\n",
      "Iteration: 12992, Loss: 0.05188581347465515, Accuracy: 0.8426897716126405\n",
      "Iteration: 13056, Loss: 0.011255067773163319, Accuracy: 0.8733188799233176\n",
      "Iteration: 13120, Loss: 0.02145243249833584, Accuracy: 0.8640948854153976\n",
      "Iteration: 13184, Loss: 0.03983956202864647, Accuracy: 0.873070839443244\n",
      "Iteration: 13248, Loss: 0.010386602021753788, Accuracy: 0.8816204972099513\n",
      "Iteration: 13312, Loss: 0.018470047041773796, Accuracy: 0.8786635771975853\n",
      "Iteration: 13376, Loss: 0.029100490733981133, Accuracy: 0.8847284055082127\n",
      "Iteration: 13440, Loss: 0.03636367246508598, Accuracy: 0.8725762116373517\n",
      "Iteration: 13504, Loss: 0.010538092814385891, Accuracy: 0.8767084268038161\n",
      "Iteration: 13568, Loss: 0.010073245503008366, Accuracy: 0.8757802447071299\n",
      "Iteration: 13632, Loss: 0.003493647091090679, Accuracy: 0.8868631554651074\n",
      "Iteration: 13696, Loss: 0.02114916406571865, Accuracy: 0.8813830002909526\n",
      "Iteration: 13760, Loss: 0.03322426602244377, Accuracy: 0.8792941484134644\n",
      "Iteration: 13824, Loss: 0.07584346830844879, Accuracy: 0.8841280620545149\n",
      "Iteration: 13888, Loss: 0.007946592755615711, Accuracy: 0.8762523642508313\n",
      "Iteration: 13952, Loss: 0.025484593585133553, Accuracy: 0.8764919507084414\n",
      "Iteration: 14016, Loss: 0.009243912063539028, Accuracy: 0.884273930627387\n",
      "Iteration: 14080, Loss: 0.029690837487578392, Accuracy: 0.886017128592357\n",
      "Iteration: 14144, Loss: 0.04137334227561951, Accuracy: 0.8815469721448608\n",
      "Iteration: 14208, Loss: 0.03433261811733246, Accuracy: 0.8846859263139777\n",
      "Iteration: 14272, Loss: 0.005660679657012224, Accuracy: 0.8743826668360271\n",
      "Iteration: 14336, Loss: 0.014758561737835407, Accuracy: 0.8865961363189854\n",
      "Iteration: 14400, Loss: 0.04741315916180611, Accuracy: 0.8729253393248655\n",
      "Iteration: 14464, Loss: 0.04973757639527321, Accuracy: 0.8780182412010618\n",
      "Iteration: 14528, Loss: 0.04227324202656746, Accuracy: 0.8930394359631464\n",
      "Iteration: 14592, Loss: 0.03668389841914177, Accuracy: 0.898026498965919\n",
      "Iteration: 14656, Loss: 0.007589381653815508, Accuracy: 0.8898079284117557\n",
      "Iteration: 14720, Loss: 0.054192960262298584, Accuracy: 0.8834315454005264\n",
      "Iteration: 14784, Loss: 0.007712399121373892, Accuracy: 0.8997853476903401\n",
      "Iteration: 14848, Loss: 0.00660279393196106, Accuracy: 0.8878796154167503\n",
      "Iteration: 14912, Loss: 0.02393905259668827, Accuracy: 0.896780893788673\n",
      "Iteration: 14976, Loss: 0.0071000452153384686, Accuracy: 0.8915712637244724\n",
      "Iteration: 15040, Loss: 0.017817120999097824, Accuracy: 0.884965431294404\n",
      "Iteration: 15104, Loss: 0.001817788346670568, Accuracy: 0.892765888303984\n",
      "Iteration: 15168, Loss: 0.006651997100561857, Accuracy: 0.8873991409200244\n",
      "Iteration: 15232, Loss: 0.007680242881178856, Accuracy: 0.907212933874689\n",
      "Iteration: 15296, Loss: 0.022127747535705566, Accuracy: 0.905746593081858\n",
      "Iteration: 15360, Loss: 0.018149608746170998, Accuracy: 0.9012367051327601\n",
      "Iteration: 15424, Loss: 0.0027899129781872034, Accuracy: 0.9072696046787314\n",
      "Iteration: 15488, Loss: 0.05253221094608307, Accuracy: 0.9086815399932675\n",
      "Iteration: 15552, Loss: 0.004929767921566963, Accuracy: 0.9027986391447484\n",
      "Iteration: 15616, Loss: 0.009516500867903233, Accuracy: 0.8961774839553982\n",
      "Iteration: 15680, Loss: 0.007391660008579493, Accuracy: 0.8903953444678336\n",
      "Iteration: 15744, Loss: 0.003861356759443879, Accuracy: 0.903578276396729\n",
      "Iteration: 15808, Loss: 0.010813777334988117, Accuracy: 0.8986736637307331\n",
      "Iteration: 15872, Loss: 0.002361025894060731, Accuracy: 0.9038712608162314\n",
      "Iteration: 15936, Loss: 0.003961550071835518, Accuracy: 0.8957438248326071\n",
      "Iteration: 16000, Loss: 0.005494799930602312, Accuracy: 0.9105871478095651\n",
      "Iteration: 16064, Loss: 0.04153401404619217, Accuracy: 0.9057749232160859\n",
      "Iteration: 16128, Loss: 0.021473385393619537, Accuracy: 0.9095914586214349\n",
      "Iteration: 16192, Loss: 0.028034469112753868, Accuracy: 0.9109699635882862\n",
      "Iteration: 16256, Loss: 0.020233863964676857, Accuracy: 0.891786637250334\n",
      "Iteration: 16320, Loss: 0.011143661104142666, Accuracy: 0.9041134822764434\n",
      "Iteration: 16384, Loss: 0.00282466528005898, Accuracy: 0.913026767258998\n",
      "Iteration: 16448, Loss: 0.004215565510094166, Accuracy: 0.9142389193293639\n",
      "Iteration: 16512, Loss: 0.005591352004557848, Accuracy: 0.9136565538938157\n",
      "Iteration: 16576, Loss: 0.026082724332809448, Accuracy: 0.9128974578343332\n",
      "Iteration: 16640, Loss: 0.01741037704050541, Accuracy: 0.9235411453410052\n",
      "Iteration: 16704, Loss: 0.009968441911041737, Accuracy: 0.9212692769942805\n",
      "Iteration: 16768, Loss: 0.0059760683216154575, Accuracy: 0.9169036161038093\n",
      "Iteration: 16832, Loss: 0.02513684146106243, Accuracy: 0.9198910099221393\n",
      "Iteration: 16896, Loss: 0.002568458905443549, Accuracy: 0.9167555742315017\n",
      "Iteration: 16960, Loss: 0.010053201578557491, Accuracy: 0.9223788041854277\n",
      "Iteration: 17024, Loss: 0.021618187427520752, Accuracy: 0.9178501630667597\n",
      "Iteration: 17088, Loss: 0.010479900985956192, Accuracy: 0.9055133417714387\n",
      "Iteration: 17152, Loss: 0.005292888265103102, Accuracy: 0.9161243386333808\n",
      "Iteration: 17216, Loss: 0.011275512166321278, Accuracy: 0.9076913526514545\n",
      "Iteration: 17280, Loss: 0.0026641462463885546, Accuracy: 0.9084965717047453\n",
      "Iteration: 17344, Loss: 0.00232290243729949, Accuracy: 0.9003030120220501\n",
      "Iteration: 17408, Loss: 0.01698228158056736, Accuracy: 0.9086120637366548\n",
      "Iteration: 17472, Loss: 0.0046171266585588455, Accuracy: 0.9237141975027043\n",
      "Iteration: 17536, Loss: 0.01811620406806469, Accuracy: 0.9235620014369488\n",
      "Iteration: 17600, Loss: 0.005150092765688896, Accuracy: 0.8990237517282367\n",
      "Iteration: 17664, Loss: 0.008349514566361904, Accuracy: 0.9118732789065689\n",
      "Iteration: 17728, Loss: 0.0015405310550704598, Accuracy: 0.9263463973475154\n",
      "Iteration: 17792, Loss: 0.0063297501765191555, Accuracy: 0.925759814097546\n",
      "Iteration: 17856, Loss: 0.017868002876639366, Accuracy: 0.9130140034831129\n",
      "Iteration: 17920, Loss: 0.016193563118577003, Accuracy: 0.9209015658998396\n",
      "Iteration: 17984, Loss: 0.004333481192588806, Accuracy: 0.9164337158726994\n",
      "Iteration: 18048, Loss: 0.0038242703303694725, Accuracy: 0.9102998337475583\n",
      "Iteration: 18112, Loss: 0.012616068124771118, Accuracy: 0.9215336393099278\n",
      "Iteration: 18176, Loss: 0.10159417241811752, Accuracy: 0.9067394091107417\n",
      "Iteration: 18240, Loss: 0.006229599472135305, Accuracy: 0.9186612830380909\n",
      "Iteration: 18304, Loss: 0.003782917046919465, Accuracy: 0.9148057306883857\n",
      "Iteration: 18368, Loss: 0.015131425112485886, Accuracy: 0.9264087751507759\n",
      "Iteration: 18432, Loss: 0.008362013846635818, Accuracy: 0.9194105939823203\n",
      "Iteration: 18496, Loss: 0.006304098758846521, Accuracy: 0.9292396767123137\n",
      "Iteration: 18560, Loss: 0.020210077986121178, Accuracy: 0.9062627703824546\n",
      "Iteration: 18624, Loss: 0.010894094593822956, Accuracy: 0.9293224372086115\n",
      "Iteration: 18688, Loss: 0.010005222633481026, Accuracy: 0.9242768178810365\n",
      "Iteration: 18752, Loss: 0.00915889535099268, Accuracy: 0.9248640885925852\n",
      "Iteration: 18816, Loss: 0.008045227266848087, Accuracy: 0.9372344141302165\n",
      "Iteration: 18880, Loss: 0.010876819491386414, Accuracy: 0.9301670625864062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 18944, Loss: 0.0012682524975389242, Accuracy: 0.9263814032601658\n",
      "Iteration: 19008, Loss: 0.001729993149638176, Accuracy: 0.91592186797061\n",
      "Iteration: 19072, Loss: 0.004694529343396425, Accuracy: 0.9278964434633963\n",
      "Iteration: 19136, Loss: 0.010531743057072163, Accuracy: 0.9338987641676795\n",
      "Iteration: 19200, Loss: 0.007221922278404236, Accuracy: 0.933136478823144\n",
      "Iteration: 19264, Loss: 0.007916377857327461, Accuracy: 0.9398303155612666\n",
      "Iteration: 19328, Loss: 0.003944018390029669, Accuracy: 0.9339552433229983\n",
      "Iteration: 19392, Loss: 0.007208569440990686, Accuracy: 0.9354368552740198\n",
      "Iteration: 19456, Loss: 0.0034309010952711105, Accuracy: 0.938734424271388\n",
      "Iteration: 19520, Loss: 0.010241788811981678, Accuracy: 0.9393926062621176\n",
      "Iteration: 19584, Loss: 0.0020799206104129553, Accuracy: 0.9405671697459184\n",
      "Iteration: 19648, Loss: 0.018519429489970207, Accuracy: 0.9337299284234177\n",
      "Iteration: 19712, Loss: 0.011177348904311657, Accuracy: 0.9300668603682425\n",
      "Iteration: 19776, Loss: 0.0017455735942348838, Accuracy: 0.908354195242282\n",
      "Iteration: 19840, Loss: 0.0011365209938958287, Accuracy: 0.9264151975221466\n",
      "Iteration: 19904, Loss: 0.006132291164249182, Accuracy: 0.9373999160598032\n",
      "Iteration: 19968, Loss: 0.007998104207217693, Accuracy: 0.9438433740870096\n",
      "Iteration: 20032, Loss: 0.00360671803355217, Accuracy: 0.9454264234518632\n",
      "Iteration: 20096, Loss: 0.0021061168517917395, Accuracy: 0.9429369619465433\n",
      "Iteration: 20160, Loss: 0.00784324947744608, Accuracy: 0.9407491624879185\n",
      "Iteration: 20224, Loss: 0.011079195886850357, Accuracy: 0.9392661237798166\n",
      "Iteration: 20288, Loss: 0.0012575382133945823, Accuracy: 0.9392063863924704\n",
      "Iteration: 20352, Loss: 0.0016602050745859742, Accuracy: 0.9431845854269341\n",
      "Iteration: 20416, Loss: 0.006262843031436205, Accuracy: 0.9473076181602664\n",
      "Iteration: 20480, Loss: 0.005873762536793947, Accuracy: 0.9429765754030086\n",
      "Iteration: 20544, Loss: 0.006907071452587843, Accuracy: 0.9405962266610004\n",
      "Iteration: 20608, Loss: 0.0019436172442510724, Accuracy: 0.944682041357737\n",
      "Iteration: 20672, Loss: 0.0032273728866130114, Accuracy: 0.9437036949093454\n",
      "Iteration: 20736, Loss: 0.026758939027786255, Accuracy: 0.9392752060084604\n",
      "Iteration: 20800, Loss: 0.011989529244601727, Accuracy: 0.9474675607634708\n",
      "Iteration: 20864, Loss: 0.006050596013665199, Accuracy: 0.934910026146099\n",
      "Iteration: 20928, Loss: 0.0009682890959084034, Accuracy: 0.9463730201823637\n",
      "Iteration: 20992, Loss: 0.001686075353063643, Accuracy: 0.9489544279931579\n",
      "Iteration: 21056, Loss: 0.004640302155166864, Accuracy: 0.952445078000892\n",
      "Iteration: 21120, Loss: 0.005430468823760748, Accuracy: 0.9475413673208095\n",
      "Iteration: 21184, Loss: 0.008789557963609695, Accuracy: 0.945189334830502\n",
      "Iteration: 21248, Loss: 0.006526149343699217, Accuracy: 0.9318090315791778\n",
      "Iteration: 21312, Loss: 0.008459159173071384, Accuracy: 0.9451485353056341\n",
      "Iteration: 21376, Loss: 0.002321235602721572, Accuracy: 0.9483834992279299\n",
      "Iteration: 21440, Loss: 0.010154730640351772, Accuracy: 0.9467144406225998\n",
      "Iteration: 21504, Loss: 0.11302384734153748, Accuracy: 0.9490935083886143\n",
      "Iteration: 21568, Loss: 0.0020531578920781612, Accuracy: 0.9300417273771018\n",
      "Iteration: 21632, Loss: 0.004034055396914482, Accuracy: 0.9435246307402849\n",
      "Iteration: 21696, Loss: 0.0020391298457980156, Accuracy: 0.9475901705154683\n",
      "Iteration: 21760, Loss: 0.00333272572606802, Accuracy: 0.9474891424179077\n",
      "Iteration: 21824, Loss: 0.004151728469878435, Accuracy: 0.9469000464305282\n",
      "Iteration: 21888, Loss: 0.005799375008791685, Accuracy: 0.9539594197703991\n",
      "Iteration: 21952, Loss: 0.004227868281304836, Accuracy: 0.9474507850536611\n",
      "Iteration: 22016, Loss: 0.000899558886885643, Accuracy: 0.9546489833446685\n",
      "Iteration: 22080, Loss: 0.0006788455066271126, Accuracy: 0.9526970407750923\n",
      "Iteration: 22144, Loss: 0.00108175294008106, Accuracy: 0.9506831679609604\n",
      "Iteration: 22208, Loss: 0.003372176783159375, Accuracy: 0.9563816688314546\n",
      "Iteration: 22272, Loss: 0.003333086147904396, Accuracy: 0.9456228181079496\n",
      "Iteration: 22336, Loss: 0.008792038075625896, Accuracy: 0.9323582609067671\n",
      "Iteration: 22400, Loss: 0.0014289203099906445, Accuracy: 0.9414135776169132\n",
      "Iteration: 22464, Loss: 0.0041493806056678295, Accuracy: 0.9503542172024027\n",
      "Iteration: 22528, Loss: 0.002054909709841013, Accuracy: 0.9518418016814394\n",
      "Iteration: 22592, Loss: 0.0009818794205784798, Accuracy: 0.9552167880028719\n",
      "Iteration: 22656, Loss: 0.0028640914242714643, Accuracy: 0.9427283692348283\n",
      "Iteration: 22720, Loss: 0.0032563807908445597, Accuracy: 0.9428211138001643\n",
      "Iteration: 22784, Loss: 0.0008346918621100485, Accuracy: 0.9558890749758575\n",
      "Iteration: 22848, Loss: 0.0014888698933646083, Accuracy: 0.9489508325059433\n",
      "Iteration: 22912, Loss: 0.004320720676332712, Accuracy: 0.9567884260904975\n",
      "Iteration: 22976, Loss: 0.0020984159782528877, Accuracy: 0.9541666359291412\n",
      "Iteration: 23040, Loss: 0.00386791885830462, Accuracy: 0.9451367086730897\n",
      "Iteration: 23104, Loss: 0.004344700835645199, Accuracy: 0.948312914930284\n",
      "Iteration: 23168, Loss: 0.05065978690981865, Accuracy: 0.9501474828575738\n",
      "Iteration: 23232, Loss: 0.004462369251996279, Accuracy: 0.9592917018453591\n",
      "Iteration: 23296, Loss: 0.0010817706352099776, Accuracy: 0.9530785327078775\n",
      "Iteration: 23360, Loss: 0.0009721299284137785, Accuracy: 0.9508117148070596\n",
      "Iteration: 23424, Loss: 0.0021857500541955233, Accuracy: 0.9547080378688406\n",
      "Iteration: 23488, Loss: 0.001121686422266066, Accuracy: 0.9579774969315622\n",
      "Iteration: 23552, Loss: 0.0030616866424679756, Accuracy: 0.9571915761043783\n",
      "Iteration: 23616, Loss: 0.00199118722230196, Accuracy: 0.956246376328636\n",
      "Iteration: 23680, Loss: 0.000566048373002559, Accuracy: 0.9514720131701324\n",
      "Iteration: 23744, Loss: 0.0021282844245433807, Accuracy: 0.9401302052428946\n",
      "Iteration: 23808, Loss: 0.0024401124101132154, Accuracy: 0.9434641758271027\n",
      "Iteration: 23872, Loss: 0.0006764982244931161, Accuracy: 0.9558323371020379\n",
      "Iteration: 23936, Loss: 0.0020842195954173803, Accuracy: 0.9545218681741972\n",
      "Iteration: 24000, Loss: 0.0014450243907049298, Accuracy: 0.957851347324322\n",
      "Iteration: 24064, Loss: 0.0009411032660864294, Accuracy: 0.9509084819874261\n",
      "Iteration: 24128, Loss: 0.004927559290081263, Accuracy: 0.95787217450561\n",
      "Iteration: 24192, Loss: 0.004283452872186899, Accuracy: 0.9413178160320967\n",
      "Iteration: 24256, Loss: 0.001313429675064981, Accuracy: 0.949375580297783\n",
      "Iteration: 24320, Loss: 0.0003097319568041712, Accuracy: 0.947986831975868\n",
      "Iteration: 24384, Loss: 0.0029564460273832083, Accuracy: 0.9603262773161987\n",
      "Iteration: 24448, Loss: 0.005979956593364477, Accuracy: 0.9499618759436999\n",
      "Iteration: 24512, Loss: 0.001981687033548951, Accuracy: 0.9554469123395393\n",
      "Iteration: 24576, Loss: 0.00661318888887763, Accuracy: 0.957041903064237\n",
      "Iteration: 24640, Loss: 0.0018203089712187648, Accuracy: 0.9617238997889217\n",
      "Iteration: 24704, Loss: 0.0006649396964348853, Accuracy: 0.9580619018961443\n",
      "Iteration: 24768, Loss: 0.005920597817748785, Accuracy: 0.9471351043903269\n",
      "Iteration: 24832, Loss: 0.00189921201672405, Accuracy: 0.9551925964769907\n",
      "Iteration: 24896, Loss: 0.0009129426325671375, Accuracy: 0.9554289936786518\n",
      "Iteration: 24960, Loss: 0.0031319959089159966, Accuracy: 0.9579645910707768\n",
      "Iteration: 25024, Loss: 0.0028912301640957594, Accuracy: 0.9582463197002653\n",
      "Iteration: 25088, Loss: 0.0018064078176394105, Accuracy: 0.9606455625034869\n",
      "Iteration: 25152, Loss: 0.0022310581989586353, Accuracy: 0.9561671291739913\n",
      "Iteration: 25216, Loss: 0.0013026221422478557, Accuracy: 0.9611697862419533\n",
      "Iteration: 25280, Loss: 0.0007058196351863444, Accuracy: 0.9557076773926383\n",
      "Iteration: 25344, Loss: 0.0029682712629437447, Accuracy: 0.9414027899329085\n",
      "Iteration: 25408, Loss: 0.0007246397435665131, Accuracy: 0.9586742045794381\n",
      "Iteration: 25472, Loss: 0.006060037761926651, Accuracy: 0.9258937297418015\n",
      "Iteration: 25536, Loss: 0.0014915392966941, Accuracy: 0.9569824886712013\n",
      "Iteration: 25600, Loss: 0.0035508463624864817, Accuracy: 0.961792136891745\n",
      "Iteration: 25664, Loss: 0.0014386322582140565, Accuracy: 0.9551164185395464\n",
      "Iteration: 25728, Loss: 0.002538146683946252, Accuracy: 0.9644980436714832\n",
      "Iteration: 25792, Loss: 0.0022802408784627914, Accuracy: 0.963568677456351\n",
      "Iteration: 25856, Loss: 0.002461877651512623, Accuracy: 0.9550036591972457\n",
      "Iteration: 25920, Loss: 0.0002200650778831914, Accuracy: 0.9534717692586128\n",
      "Iteration: 25984, Loss: 0.3219783306121826, Accuracy: 0.9464642942330102\n",
      "Iteration: 26048, Loss: 0.0032559167593717575, Accuracy: 0.9452936922461959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 26112, Loss: 0.0010775179835036397, Accuracy: 0.9469537928525824\n",
      "Iteration: 26176, Loss: 0.0014009164879098535, Accuracy: 0.9562803137669107\n",
      "Iteration: 26240, Loss: 0.0002718566684052348, Accuracy: 0.9591792587452801\n",
      "Iteration: 26304, Loss: 0.004295958671718836, Accuracy: 0.957303463932476\n",
      "Iteration: 26368, Loss: 0.0013017290038987994, Accuracy: 0.9666962151386542\n",
      "Iteration: 26432, Loss: 0.001875278539955616, Accuracy: 0.9640904576954199\n",
      "Iteration: 26496, Loss: 0.001657727756537497, Accuracy: 0.9663853153324453\n",
      "Iteration: 26560, Loss: 0.0002421573008177802, Accuracy: 0.9592880640557269\n",
      "Iteration: 26624, Loss: 0.002664720406755805, Accuracy: 0.9664679102716036\n",
      "Iteration: 26688, Loss: 0.001474980846978724, Accuracy: 0.9634458680375246\n",
      "Iteration: 26752, Loss: 0.0012824785662814975, Accuracy: 0.967989709941321\n",
      "Iteration: 26816, Loss: 0.0020658932626247406, Accuracy: 0.9662957747204928\n",
      "Iteration: 26880, Loss: 0.0022461272310465574, Accuracy: 0.965740887550055\n",
      "Iteration: 26944, Loss: 0.002159455558285117, Accuracy: 0.9670285480096936\n",
      "Iteration: 27008, Loss: 0.004854986909776926, Accuracy: 0.9628627086203778\n",
      "Iteration: 27072, Loss: 0.0003451351076364517, Accuracy: 0.9693096419214271\n",
      "Iteration: 27136, Loss: 0.010991405695676804, Accuracy: 0.9564782409433974\n",
      "Iteration: 27200, Loss: 0.004903961438685656, Accuracy: 0.9630557274649618\n",
      "Iteration: 27264, Loss: 0.0012725252890959382, Accuracy: 0.966393671289552\n",
      "Iteration: 27328, Loss: 0.0009413149091415107, Accuracy: 0.9648535929591162\n",
      "Iteration: 27392, Loss: 0.0014513548230752349, Accuracy: 0.9672089325467823\n",
      "Iteration: 27456, Loss: 0.0012577922316268086, Accuracy: 0.9688393570104381\n",
      "Iteration: 27520, Loss: 0.001435771118849516, Accuracy: 0.9683401656220667\n",
      "Iteration: 27584, Loss: 0.0014112228527665138, Accuracy: 0.9698589184990851\n",
      "Iteration: 27648, Loss: 0.0006251706508919597, Accuracy: 0.9679550746659515\n",
      "Iteration: 27712, Loss: 0.0019366232445463538, Accuracy: 0.9709619884233689\n",
      "Saved fullModel_dr[5]_replicate3.model\n",
      "Saved W_dr[5]_replicate3.p\n",
      "5 0.9947916666666666 [0.984375, 1.0, 1.0]\n",
      "Saved w_dr[5]_replicate3.p\n",
      "Replicate 3 completed\n",
      "Time elapsed: 923.75 seconds\n",
      "Iteration: 64, Loss: 0.22766749560832977, Accuracy: 0.49982315534725785\n",
      "Iteration: 128, Loss: 0.25344714522361755, Accuracy: 0.4979378655552864\n",
      "Iteration: 192, Loss: 0.239283487200737, Accuracy: 0.4989118822850287\n",
      "Iteration: 256, Loss: 0.27383992075920105, Accuracy: 0.5008086157031357\n",
      "Iteration: 320, Loss: 0.23909693956375122, Accuracy: 0.49839714262634516\n",
      "Iteration: 384, Loss: 0.23920311033725739, Accuracy: 0.4996010991744697\n",
      "Iteration: 448, Loss: 0.2525551915168762, Accuracy: 0.4997064429335296\n",
      "Iteration: 512, Loss: 0.26417335867881775, Accuracy: 0.4989464511163533\n",
      "Iteration: 576, Loss: 0.2556808292865753, Accuracy: 0.5002768104895949\n",
      "Iteration: 640, Loss: 0.2537895143032074, Accuracy: 0.4996255277656019\n",
      "Iteration: 704, Loss: 0.2508878707885742, Accuracy: 0.49857404455542564\n",
      "Iteration: 768, Loss: 0.2590309679508209, Accuracy: 0.49878766061738133\n",
      "Iteration: 832, Loss: 0.2561098039150238, Accuracy: 0.5000206050463021\n",
      "Iteration: 896, Loss: 0.2493753433227539, Accuracy: 0.49929118575528264\n",
      "Iteration: 960, Loss: 0.2430463433265686, Accuracy: 0.4993913280777633\n",
      "Iteration: 1024, Loss: 0.24967265129089355, Accuracy: 0.4992423225194216\n",
      "Iteration: 1088, Loss: 0.25289979577064514, Accuracy: 0.49878472415730357\n",
      "Iteration: 1152, Loss: 0.2449273318052292, Accuracy: 0.4997801370918751\n",
      "Iteration: 1216, Loss: 0.2477843314409256, Accuracy: 0.49947086023166776\n",
      "Iteration: 1280, Loss: 0.24818231165409088, Accuracy: 0.5006028367206454\n",
      "Iteration: 1344, Loss: 0.24383477866649628, Accuracy: 0.5000563650391996\n",
      "Iteration: 1408, Loss: 0.2505650818347931, Accuracy: 0.49988846853375435\n",
      "Iteration: 1472, Loss: 0.24752001464366913, Accuracy: 0.49975990364328027\n",
      "Iteration: 1536, Loss: 0.22228844463825226, Accuracy: 0.5140155842527747\n",
      "Iteration: 1600, Loss: 0.16214801371097565, Accuracy: 0.5623706830665469\n",
      "Iteration: 1664, Loss: 0.19579334557056427, Accuracy: 0.5927686872892082\n",
      "Iteration: 1728, Loss: 0.19041426479816437, Accuracy: 0.6104425387457013\n",
      "Iteration: 1792, Loss: 0.17084963619709015, Accuracy: 0.6175041329115629\n",
      "Iteration: 1856, Loss: 0.1781023144721985, Accuracy: 0.6282875728793442\n",
      "Iteration: 1920, Loss: 0.17685997486114502, Accuracy: 0.6327987327240407\n",
      "Iteration: 1984, Loss: 0.17449837923049927, Accuracy: 0.6372926267795265\n",
      "Iteration: 2048, Loss: 0.12616698443889618, Accuracy: 0.6429774016141891\n",
      "Iteration: 2112, Loss: 0.17443402111530304, Accuracy: 0.6433301256038249\n",
      "Iteration: 2176, Loss: 0.17290258407592773, Accuracy: 0.6520130038261414\n",
      "Iteration: 2240, Loss: 0.16268225014209747, Accuracy: 0.6560123176313937\n",
      "Iteration: 2304, Loss: 0.16866131126880646, Accuracy: 0.6600100337527692\n",
      "Iteration: 2368, Loss: 0.16949033737182617, Accuracy: 0.663085772190243\n",
      "Iteration: 2432, Loss: 0.16489779949188232, Accuracy: 0.6643029651604593\n",
      "Iteration: 2496, Loss: 0.1635592132806778, Accuracy: 0.6708666598424315\n",
      "Iteration: 2560, Loss: 0.08026155084371567, Accuracy: 0.6711898394860327\n",
      "Iteration: 2624, Loss: 0.06901613622903824, Accuracy: 0.6730345524847507\n",
      "Iteration: 2688, Loss: 0.162950798869133, Accuracy: 0.6784681577701122\n",
      "Iteration: 2752, Loss: 0.16766245663166046, Accuracy: 0.6835497473366559\n",
      "Iteration: 2816, Loss: 0.1655874252319336, Accuracy: 0.6827844537328929\n",
      "Iteration: 2880, Loss: 0.17264501750469208, Accuracy: 0.6877942928113043\n",
      "Iteration: 2944, Loss: 0.06293556094169617, Accuracy: 0.6916627821046859\n",
      "Iteration: 3008, Loss: 0.15855233371257782, Accuracy: 0.6915374030359089\n",
      "Iteration: 3072, Loss: 0.1307760626077652, Accuracy: 0.6970512527041137\n",
      "Iteration: 3136, Loss: 0.06761952489614487, Accuracy: 0.6979435794055462\n",
      "Iteration: 3200, Loss: 0.14018072187900543, Accuracy: 0.7014693829696625\n",
      "Iteration: 3264, Loss: 0.15196721255779266, Accuracy: 0.7036428777500987\n",
      "Iteration: 3328, Loss: 0.17318911850452423, Accuracy: 0.7077064248733222\n",
      "Iteration: 3392, Loss: 0.07267694920301437, Accuracy: 0.7104341704398394\n",
      "Iteration: 3456, Loss: 0.04938436672091484, Accuracy: 0.70833101705648\n",
      "Iteration: 3520, Loss: 0.06363154202699661, Accuracy: 0.7159289484843612\n",
      "Iteration: 3584, Loss: 0.09119009971618652, Accuracy: 0.7167142601683736\n",
      "Iteration: 3648, Loss: 0.06366376578807831, Accuracy: 0.7271098352503031\n",
      "Iteration: 3712, Loss: 0.1632525622844696, Accuracy: 0.7218009212519974\n",
      "Iteration: 3776, Loss: 0.12507392466068268, Accuracy: 0.7280016769655049\n",
      "Iteration: 3840, Loss: 0.14494895935058594, Accuracy: 0.7364876670762897\n",
      "Iteration: 3904, Loss: 0.15606078505516052, Accuracy: 0.738758334191516\n",
      "Iteration: 3968, Loss: 0.146043062210083, Accuracy: 0.7389312330633402\n",
      "Iteration: 4032, Loss: 0.044357623904943466, Accuracy: 0.7422233971301466\n",
      "Iteration: 4096, Loss: 0.06647976487874985, Accuracy: 0.7471575955860317\n",
      "Iteration: 4160, Loss: 0.07215064764022827, Accuracy: 0.7491513197310269\n",
      "Iteration: 4224, Loss: 0.05743294954299927, Accuracy: 0.7511993022635579\n",
      "Iteration: 4288, Loss: 0.07033238559961319, Accuracy: 0.7583084674552083\n",
      "Iteration: 4352, Loss: 0.07971236854791641, Accuracy: 0.7495026346296072\n",
      "Iteration: 4416, Loss: 0.05104900524020195, Accuracy: 0.7565511132124811\n",
      "Iteration: 4480, Loss: 0.06200377270579338, Accuracy: 0.7625778091605753\n",
      "Iteration: 4544, Loss: 0.14025065302848816, Accuracy: 0.7641222225502133\n",
      "Iteration: 4608, Loss: 0.12675981223583221, Accuracy: 0.7558838645927608\n",
      "Iteration: 4672, Loss: 0.04952669143676758, Accuracy: 0.760745455743745\n",
      "Iteration: 4736, Loss: 0.10999071598052979, Accuracy: 0.7654826801735908\n",
      "Iteration: 4800, Loss: 0.06236543133854866, Accuracy: 0.7656205052044243\n",
      "Iteration: 4864, Loss: 0.11789248138666153, Accuracy: 0.7755306817125529\n",
      "Iteration: 4928, Loss: 0.05736206844449043, Accuracy: 0.7785662712994963\n",
      "Iteration: 4992, Loss: 0.1820426732301712, Accuracy: 0.774162988178432\n",
      "Iteration: 5056, Loss: 0.09804294258356094, Accuracy: 0.7790432418696582\n",
      "Iteration: 5120, Loss: 0.05262312293052673, Accuracy: 0.7724816764239222\n",
      "Iteration: 5184, Loss: 0.1215282455086708, Accuracy: 0.783832335844636\n",
      "Iteration: 5248, Loss: 0.11731531471014023, Accuracy: 0.7861605728976429\n",
      "Iteration: 5312, Loss: 0.06123058870434761, Accuracy: 0.7852932575624436\n",
      "Iteration: 5376, Loss: 0.06421740353107452, Accuracy: 0.792875807499513\n",
      "Iteration: 5440, Loss: 0.12389650195837021, Accuracy: 0.7908448688685894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 5504, Loss: 0.11499929428100586, Accuracy: 0.7642476418986917\n",
      "Iteration: 5568, Loss: 0.09210846573114395, Accuracy: 0.7868826605845243\n",
      "Iteration: 5632, Loss: 0.09557036310434341, Accuracy: 0.7890283206943423\n",
      "Iteration: 5696, Loss: 0.12055399268865585, Accuracy: 0.788885903544724\n",
      "Iteration: 5760, Loss: 0.1266273409128189, Accuracy: 0.7896581292152405\n",
      "Iteration: 5824, Loss: 0.09940344840288162, Accuracy: 0.7866066864226013\n",
      "Iteration: 5888, Loss: 0.0991937592625618, Accuracy: 0.7884801817126572\n",
      "Iteration: 5952, Loss: 0.055148813873529434, Accuracy: 0.7957449534442276\n",
      "Iteration: 6016, Loss: 0.05205864831805229, Accuracy: 0.7959026237949729\n",
      "Iteration: 6080, Loss: 0.034205686300992966, Accuracy: 0.7992069239262491\n",
      "Iteration: 6144, Loss: 0.04041913524270058, Accuracy: 0.789625836070627\n",
      "Iteration: 6208, Loss: 0.04397641494870186, Accuracy: 0.7996632049325854\n",
      "Iteration: 6272, Loss: 0.09741288423538208, Accuracy: 0.7961775423027575\n",
      "Iteration: 6336, Loss: 0.116497702896595, Accuracy: 0.7955321774352342\n",
      "Iteration: 6400, Loss: 0.09733110666275024, Accuracy: 0.8029186797793955\n",
      "Iteration: 6464, Loss: 0.039615336805582047, Accuracy: 0.8094277465716004\n",
      "Iteration: 6528, Loss: 0.03847775235772133, Accuracy: 0.7981569776311517\n",
      "Iteration: 6592, Loss: 0.09903479367494583, Accuracy: 0.8042674558237195\n",
      "Iteration: 6656, Loss: 0.05872875452041626, Accuracy: 0.8019164082361385\n",
      "Iteration: 6720, Loss: 0.034563325345516205, Accuracy: 0.8106054578674957\n",
      "Iteration: 6784, Loss: 0.13813118636608124, Accuracy: 0.8067869863007218\n",
      "Iteration: 6848, Loss: 0.11604980379343033, Accuracy: 0.8108928864821792\n",
      "Iteration: 6912, Loss: 0.09584545344114304, Accuracy: 0.8154189266497269\n",
      "Iteration: 6976, Loss: 0.08888629823923111, Accuracy: 0.8079131414415315\n",
      "Iteration: 7040, Loss: 0.05747905746102333, Accuracy: 0.8057499782880768\n",
      "Iteration: 7104, Loss: 0.08398502320051193, Accuracy: 0.8132049726555124\n",
      "Iteration: 7168, Loss: 0.06606511771678925, Accuracy: 0.807328640948981\n",
      "Iteration: 7232, Loss: 0.09007439017295837, Accuracy: 0.8189259653445333\n",
      "Iteration: 7296, Loss: 0.06164928153157234, Accuracy: 0.8074460148345679\n",
      "Iteration: 7360, Loss: 0.06415887922048569, Accuracy: 0.8166766696376726\n",
      "Iteration: 7424, Loss: 0.05317007005214691, Accuracy: 0.8132330181542784\n",
      "Iteration: 7488, Loss: 0.025931626558303833, Accuracy: 0.8190468172542751\n",
      "Iteration: 7552, Loss: 0.043840691447257996, Accuracy: 0.7961771651171148\n",
      "Iteration: 7616, Loss: 0.025023536756634712, Accuracy: 0.8091163362842053\n",
      "Iteration: 7680, Loss: 0.12499960511922836, Accuracy: 0.826073358533904\n",
      "Iteration: 7744, Loss: 0.03478412330150604, Accuracy: 0.8204669690458104\n",
      "Iteration: 7808, Loss: 0.12810049951076508, Accuracy: 0.8208470550598577\n",
      "Iteration: 7872, Loss: 0.08247994631528854, Accuracy: 0.8207757290219888\n",
      "Iteration: 7936, Loss: 0.11373057961463928, Accuracy: 0.8225912665948272\n",
      "Iteration: 8000, Loss: 0.04693200811743736, Accuracy: 0.8230347183998674\n",
      "Iteration: 8064, Loss: 0.06357129663228989, Accuracy: 0.8244413989596069\n",
      "Iteration: 8128, Loss: 0.1102483794093132, Accuracy: 0.8091754596680403\n",
      "Iteration: 8192, Loss: 0.08136182278394699, Accuracy: 0.8229135244619101\n",
      "Iteration: 8256, Loss: 0.028710665181279182, Accuracy: 0.8324091247050092\n",
      "Iteration: 8320, Loss: 0.06629417091608047, Accuracy: 0.8274943835567683\n",
      "Iteration: 8384, Loss: 0.07443639636039734, Accuracy: 0.8300445127533749\n",
      "Iteration: 8448, Loss: 0.05509437620639801, Accuracy: 0.8296419145772234\n",
      "Iteration: 8512, Loss: 0.10982898622751236, Accuracy: 0.8268301935167983\n",
      "Iteration: 8576, Loss: 0.12564705312252045, Accuracy: 0.8203926490386948\n",
      "Iteration: 8640, Loss: 0.03342137113213539, Accuracy: 0.8242386372294277\n",
      "Iteration: 8704, Loss: 0.0646548792719841, Accuracy: 0.8335309870308265\n",
      "Iteration: 8768, Loss: 0.03669465705752373, Accuracy: 0.8193897836608812\n",
      "Iteration: 8832, Loss: 0.11297333985567093, Accuracy: 0.8245398143772036\n",
      "Iteration: 8896, Loss: 0.13013389706611633, Accuracy: 0.8104395681293681\n",
      "Iteration: 8960, Loss: 0.10408750176429749, Accuracy: 0.8304247049381956\n",
      "Iteration: 9024, Loss: 0.10895650833845139, Accuracy: 0.8352578596677631\n",
      "Iteration: 9088, Loss: 0.06580834090709686, Accuracy: 0.8289735793368891\n",
      "Iteration: 9152, Loss: 0.07675977051258087, Accuracy: 0.8363409456796944\n",
      "Iteration: 9216, Loss: 0.06623075157403946, Accuracy: 0.8273351271636784\n",
      "Iteration: 9280, Loss: 0.10467632859945297, Accuracy: 0.824202845338732\n",
      "Iteration: 9344, Loss: 0.02699672430753708, Accuracy: 0.8362263798480853\n",
      "Iteration: 9408, Loss: 0.07595966011285782, Accuracy: 0.8376560093602166\n",
      "Iteration: 9472, Loss: 0.06365201622247696, Accuracy: 0.8377670078771189\n",
      "Iteration: 9536, Loss: 0.08127524703741074, Accuracy: 0.8364238033536822\n",
      "Iteration: 9600, Loss: 0.03347133472561836, Accuracy: 0.8194065946154296\n",
      "Iteration: 9664, Loss: 0.06795555353164673, Accuracy: 0.8362264172174037\n",
      "Iteration: 9728, Loss: 0.049146901816129684, Accuracy: 0.8400159566663206\n",
      "Iteration: 9792, Loss: 0.0497887022793293, Accuracy: 0.825451067998074\n",
      "Iteration: 9856, Loss: 0.07218201458454132, Accuracy: 0.8439310379326344\n",
      "Iteration: 9920, Loss: 0.024122586473822594, Accuracy: 0.8386020003817976\n",
      "Iteration: 9984, Loss: 0.027943307533860207, Accuracy: 0.8458173894323409\n",
      "Iteration: 10048, Loss: 0.05160963162779808, Accuracy: 0.8468729825690389\n",
      "Iteration: 10112, Loss: 0.04177391529083252, Accuracy: 0.8390636354451999\n",
      "Iteration: 10176, Loss: 0.02979893982410431, Accuracy: 0.8407435456756502\n",
      "Iteration: 10240, Loss: 0.10564731806516647, Accuracy: 0.8277562949806452\n",
      "Iteration: 10304, Loss: 0.054852720350027084, Accuracy: 0.8400586702628061\n",
      "Iteration: 10368, Loss: 0.030892258509993553, Accuracy: 0.8323356715263799\n",
      "Iteration: 10432, Loss: 0.09501522034406662, Accuracy: 0.8300589717691764\n",
      "Iteration: 10496, Loss: 0.07144518196582794, Accuracy: 0.8381653053220361\n",
      "Iteration: 10560, Loss: 0.06126755475997925, Accuracy: 0.8483634502626956\n",
      "Iteration: 10624, Loss: 0.04679931327700615, Accuracy: 0.834942840738222\n",
      "Iteration: 10688, Loss: 0.06435732543468475, Accuracy: 0.8564563178224489\n",
      "Iteration: 10752, Loss: 0.04748688265681267, Accuracy: 0.8414456499740481\n",
      "Iteration: 10816, Loss: 0.050370875746011734, Accuracy: 0.8505763106513768\n",
      "Iteration: 10880, Loss: 0.01848793588578701, Accuracy: 0.8501624643104151\n",
      "Iteration: 10944, Loss: 0.021913714706897736, Accuracy: 0.8557101738406345\n",
      "Iteration: 11008, Loss: 0.09143208712339401, Accuracy: 0.8537436308106408\n",
      "Iteration: 11072, Loss: 0.058461934328079224, Accuracy: 0.8563284311676398\n",
      "Iteration: 11136, Loss: 0.061492908746004105, Accuracy: 0.8471442548325285\n",
      "Iteration: 11200, Loss: 0.030301958322525024, Accuracy: 0.8493417790159583\n",
      "Iteration: 11264, Loss: 0.03728893771767616, Accuracy: 0.8602427090518177\n",
      "Iteration: 11328, Loss: 0.07075238972902298, Accuracy: 0.8561145197600126\n",
      "Iteration: 11392, Loss: 0.020609209313988686, Accuracy: 0.8518560881493613\n",
      "Iteration: 11456, Loss: 0.01115356758236885, Accuracy: 0.8522964837029576\n",
      "Iteration: 11520, Loss: 0.026401111856102943, Accuracy: 0.8490803856402636\n",
      "Iteration: 11584, Loss: 0.024516714736819267, Accuracy: 0.8550721814972349\n",
      "Iteration: 11648, Loss: 0.012947955168783665, Accuracy: 0.8448317345464602\n",
      "Iteration: 11712, Loss: 0.03202240169048309, Accuracy: 0.8425938917789608\n",
      "Iteration: 11776, Loss: 0.028388241305947304, Accuracy: 0.8625168040161952\n",
      "Iteration: 11840, Loss: 0.015798572450876236, Accuracy: 0.8656288257334381\n",
      "Iteration: 11904, Loss: 0.05676926672458649, Accuracy: 0.8656117237405851\n",
      "Iteration: 11968, Loss: 0.02492476999759674, Accuracy: 0.8446797633077949\n",
      "Iteration: 12032, Loss: 0.035625018179416656, Accuracy: 0.8636911334469914\n",
      "Iteration: 12096, Loss: 0.069548100233078, Accuracy: 0.8624415168305859\n",
      "Iteration: 12160, Loss: 0.05844491720199585, Accuracy: 0.8527663111453876\n",
      "Iteration: 12224, Loss: 0.02931644767522812, Accuracy: 0.8612827758770436\n",
      "Iteration: 12288, Loss: 0.02621893398463726, Accuracy: 0.8702752591343597\n",
      "Iteration: 12352, Loss: 0.018037572503089905, Accuracy: 0.8693330918322317\n",
      "Iteration: 12416, Loss: 0.04730290547013283, Accuracy: 0.8680620628292672\n",
      "Iteration: 12480, Loss: 0.020938746631145477, Accuracy: 0.8776536518707871\n",
      "Iteration: 12544, Loss: 0.02176923118531704, Accuracy: 0.8733423795783892\n",
      "Iteration: 12608, Loss: 0.02924378402531147, Accuracy: 0.8595066406996921\n",
      "Iteration: 12672, Loss: 0.05021091178059578, Accuracy: 0.8629442398087122\n",
      "Iteration: 12736, Loss: 0.018455320969223976, Accuracy: 0.875218128610868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 12800, Loss: 0.1491919606924057, Accuracy: 0.8657605201005936\n",
      "Iteration: 12864, Loss: 0.17815810441970825, Accuracy: 0.8691706384997815\n",
      "Iteration: 12928, Loss: 0.04702737554907799, Accuracy: 0.865481334971264\n",
      "Iteration: 12992, Loss: 0.03787948563694954, Accuracy: 0.8726984051172622\n",
      "Iteration: 13056, Loss: 0.026993900537490845, Accuracy: 0.8801231292891316\n",
      "Iteration: 13120, Loss: 0.02462688647210598, Accuracy: 0.876459986960981\n",
      "Iteration: 13184, Loss: 0.043612461537122726, Accuracy: 0.8735680762911215\n",
      "Iteration: 13248, Loss: 0.04812275990843773, Accuracy: 0.8677276269881986\n",
      "Iteration: 13312, Loss: 0.024387584999203682, Accuracy: 0.8743381889653392\n",
      "Iteration: 13376, Loss: 0.04118013381958008, Accuracy: 0.8802894923137501\n",
      "Iteration: 13440, Loss: 0.03923439607024193, Accuracy: 0.886809918563813\n",
      "Iteration: 13504, Loss: 0.045681994408369064, Accuracy: 0.8697678735479712\n",
      "Iteration: 13568, Loss: 0.01826331950724125, Accuracy: 0.8835343561368063\n",
      "Iteration: 13632, Loss: 0.024037381634116173, Accuracy: 0.8872068083728664\n",
      "Iteration: 13696, Loss: 0.027904614806175232, Accuracy: 0.8799871185328811\n",
      "Iteration: 13760, Loss: 0.026206811890006065, Accuracy: 0.8902972550131381\n",
      "Iteration: 13824, Loss: 0.03034636378288269, Accuracy: 0.8751739953877404\n",
      "Iteration: 13888, Loss: 0.02250460349023342, Accuracy: 0.8882019692682661\n",
      "Iteration: 13952, Loss: 0.01586344465613365, Accuracy: 0.8913671433110721\n",
      "Iteration: 14016, Loss: 0.023951293900609016, Accuracy: 0.8947579612140544\n",
      "Iteration: 14080, Loss: 0.016416149213910103, Accuracy: 0.8958937671268359\n",
      "Iteration: 14144, Loss: 0.03209724649786949, Accuracy: 0.8861694626975805\n",
      "Iteration: 14208, Loss: 0.016186965629458427, Accuracy: 0.8993121781968512\n",
      "Iteration: 14272, Loss: 0.03151305764913559, Accuracy: 0.8997042176197283\n",
      "Iteration: 14336, Loss: 0.016396183520555496, Accuracy: 0.8752010661992244\n",
      "Iteration: 14400, Loss: 0.021707257255911827, Accuracy: 0.8714997066999786\n",
      "Iteration: 14464, Loss: 0.007830310612916946, Accuracy: 0.885526659199968\n",
      "Iteration: 14528, Loss: 0.01934685930609703, Accuracy: 0.89981027552858\n",
      "Iteration: 14592, Loss: 0.08754604309797287, Accuracy: 0.8886138944653794\n",
      "Iteration: 14656, Loss: 0.01622973009943962, Accuracy: 0.9055028734146617\n",
      "Iteration: 14720, Loss: 0.013059008866548538, Accuracy: 0.8948775301687419\n",
      "Iteration: 14784, Loss: 0.04545143246650696, Accuracy: 0.9047844634624198\n",
      "Iteration: 14848, Loss: 0.004261866677552462, Accuracy: 0.9065134631819092\n",
      "Iteration: 14912, Loss: 0.011667232029139996, Accuracy: 0.8921880492125638\n",
      "Iteration: 14976, Loss: 0.016450373455882072, Accuracy: 0.8880747626535594\n",
      "Iteration: 15040, Loss: 0.011643893085420132, Accuracy: 0.9078193582827225\n",
      "Iteration: 15104, Loss: 0.011055365204811096, Accuracy: 0.896222922950983\n",
      "Iteration: 15168, Loss: 0.005907206330448389, Accuracy: 0.8979915673844516\n",
      "Iteration: 15232, Loss: 0.04642273485660553, Accuracy: 0.9065390711766668\n",
      "Iteration: 15296, Loss: 0.014011886902153492, Accuracy: 0.8972960301325656\n",
      "Iteration: 15360, Loss: 0.02422848902642727, Accuracy: 0.9073442702647299\n",
      "Iteration: 15424, Loss: 0.0026463891845196486, Accuracy: 0.9105167285306379\n",
      "Iteration: 15488, Loss: 0.009811365976929665, Accuracy: 0.8918608728563413\n",
      "Iteration: 15552, Loss: 0.013375376351177692, Accuracy: 0.9125347568187863\n",
      "Iteration: 15616, Loss: 0.006803507450968027, Accuracy: 0.9146168386214413\n",
      "Iteration: 15680, Loss: 0.014380251057446003, Accuracy: 0.8961842299904674\n",
      "Iteration: 15744, Loss: 0.008724589832127094, Accuracy: 0.900610230397433\n",
      "Iteration: 15808, Loss: 0.024660373106598854, Accuracy: 0.8887032330967486\n",
      "Iteration: 15872, Loss: 0.04438493028283119, Accuracy: 0.8878014418878593\n",
      "Iteration: 15936, Loss: 0.015004996210336685, Accuracy: 0.8703763665980659\n",
      "Iteration: 16000, Loss: 0.009062650613486767, Accuracy: 0.9139912195387296\n",
      "Iteration: 16064, Loss: 0.01106853038072586, Accuracy: 0.910277595568914\n",
      "Iteration: 16128, Loss: 0.02464788220822811, Accuracy: 0.9039124733244535\n",
      "Iteration: 16192, Loss: 0.009939747862517834, Accuracy: 0.9011420157621615\n",
      "Iteration: 16256, Loss: 0.01710783876478672, Accuracy: 0.8923503223923035\n",
      "Iteration: 16320, Loss: 0.036596138030290604, Accuracy: 0.9057495493907481\n",
      "Iteration: 16384, Loss: 0.017254436388611794, Accuracy: 0.9110506862052716\n",
      "Iteration: 16448, Loss: 0.009005806408822536, Accuracy: 0.9141433297772892\n",
      "Iteration: 16512, Loss: 0.014718887396156788, Accuracy: 0.914022639481118\n",
      "Iteration: 16576, Loss: 0.015272460877895355, Accuracy: 0.9161212168401107\n",
      "Iteration: 16640, Loss: 0.012667621485888958, Accuracy: 0.9159619968559127\n",
      "Iteration: 16704, Loss: 0.011592485010623932, Accuracy: 0.9164420652086847\n",
      "Iteration: 16768, Loss: 0.006998226046562195, Accuracy: 0.9146624730783515\n",
      "Iteration: 16832, Loss: 0.01386285200715065, Accuracy: 0.9254183469165582\n",
      "Iteration: 16896, Loss: 0.013933290727436543, Accuracy: 0.9158938709297217\n",
      "Iteration: 16960, Loss: 0.026968518272042274, Accuracy: 0.9154716315097176\n",
      "Iteration: 17024, Loss: 0.04111513867974281, Accuracy: 0.9080347833223641\n",
      "Iteration: 17088, Loss: 0.008507687598466873, Accuracy: 0.9149062650394626\n",
      "Iteration: 17152, Loss: 0.006432065274566412, Accuracy: 0.9278109009028412\n",
      "Iteration: 17216, Loss: 0.009372071363031864, Accuracy: 0.9060443590860814\n",
      "Iteration: 17280, Loss: 0.010602002032101154, Accuracy: 0.9234138183528557\n",
      "Iteration: 17344, Loss: 0.0017001720843836665, Accuracy: 0.924450253660325\n",
      "Iteration: 17408, Loss: 0.008349584415555, Accuracy: 0.9239040397806093\n",
      "Iteration: 17472, Loss: 0.009723258204758167, Accuracy: 0.9208022259990685\n",
      "Iteration: 17536, Loss: 0.0074520050548017025, Accuracy: 0.9195977033523377\n",
      "Iteration: 17600, Loss: 0.013617713935673237, Accuracy: 0.929811817855807\n",
      "Iteration: 17664, Loss: 0.010389457456767559, Accuracy: 0.9229394246940501\n",
      "Iteration: 17728, Loss: 0.012557818554341793, Accuracy: 0.9335824780864641\n",
      "Iteration: 17792, Loss: 0.007896906696259975, Accuracy: 0.9217666503391229\n",
      "Iteration: 17856, Loss: 0.004877826198935509, Accuracy: 0.9226881968497764\n",
      "Iteration: 17920, Loss: 0.014577490277588367, Accuracy: 0.9235609037859831\n",
      "Iteration: 17984, Loss: 0.009726773016154766, Accuracy: 0.9274965858494397\n",
      "Iteration: 18048, Loss: 0.016384456306695938, Accuracy: 0.9346900367818307\n",
      "Iteration: 18112, Loss: 0.006933920551091433, Accuracy: 0.9291525113221724\n",
      "Iteration: 18176, Loss: 0.008551699109375477, Accuracy: 0.9278878817567602\n",
      "Iteration: 18240, Loss: 0.007872208952903748, Accuracy: 0.9146352478128392\n",
      "Iteration: 18304, Loss: 0.009852361865341663, Accuracy: 0.9334778712363914\n",
      "Iteration: 18368, Loss: 0.0062712933868169785, Accuracy: 0.9299602112441789\n",
      "Iteration: 18432, Loss: 0.007977931760251522, Accuracy: 0.8979180567839649\n",
      "Iteration: 18496, Loss: 0.00441706320270896, Accuracy: 0.9277092303673271\n",
      "Iteration: 18560, Loss: 0.006998176220804453, Accuracy: 0.9271434386610053\n",
      "Iteration: 18624, Loss: 0.007934396155178547, Accuracy: 0.9314687989244703\n",
      "Iteration: 18688, Loss: 0.01660718210041523, Accuracy: 0.9321367086085957\n",
      "Iteration: 18752, Loss: 0.006308072712272406, Accuracy: 0.9332256028137635\n",
      "Iteration: 18816, Loss: 0.007631794083863497, Accuracy: 0.9215360781236086\n",
      "Iteration: 18880, Loss: 0.2530851662158966, Accuracy: 0.9182234635518398\n",
      "Iteration: 18944, Loss: 0.006414081901311874, Accuracy: 0.9169270340644289\n",
      "Iteration: 19008, Loss: 0.01082583237439394, Accuracy: 0.9266298868751619\n",
      "Iteration: 19072, Loss: 0.006973026320338249, Accuracy: 0.9315068750001956\n",
      "Iteration: 19136, Loss: 0.0009579855832271278, Accuracy: 0.9305961747304536\n",
      "Iteration: 19200, Loss: 0.0060427202843129635, Accuracy: 0.934945657820208\n",
      "Iteration: 19264, Loss: 0.004912663716822863, Accuracy: 0.9388803561159875\n",
      "Iteration: 19328, Loss: 0.007088487967848778, Accuracy: 0.9260871216538362\n",
      "Iteration: 19392, Loss: 0.0028705280274152756, Accuracy: 0.9373841897468083\n",
      "Iteration: 19456, Loss: 0.007724232506006956, Accuracy: 0.93937385987374\n",
      "Iteration: 19520, Loss: 0.013758559711277485, Accuracy: 0.936938909755554\n",
      "Iteration: 19584, Loss: 0.009346253238618374, Accuracy: 0.9361007889092434\n",
      "Iteration: 19648, Loss: 0.005037661176174879, Accuracy: 0.9439872359507717\n",
      "Iteration: 19712, Loss: 0.005282589700073004, Accuracy: 0.9312808211834636\n",
      "Iteration: 19776, Loss: 0.006193915847688913, Accuracy: 0.9402920828142669\n",
      "Iteration: 19840, Loss: 0.010362216271460056, Accuracy: 0.9408858073002193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 19904, Loss: 0.0008974028169177473, Accuracy: 0.9228573713335209\n",
      "Iteration: 19968, Loss: 0.06639963388442993, Accuracy: 0.931404362199828\n",
      "Iteration: 20032, Loss: 0.005469323601573706, Accuracy: 0.92912622334552\n",
      "Iteration: 20096, Loss: 0.002496657194569707, Accuracy: 0.9453925375710241\n",
      "Iteration: 20160, Loss: 0.0033295208122581244, Accuracy: 0.9445505492913071\n",
      "Iteration: 20224, Loss: 0.007389243692159653, Accuracy: 0.94246248275158\n",
      "Iteration: 20288, Loss: 0.005613213870674372, Accuracy: 0.9376364922791254\n",
      "Iteration: 20352, Loss: 0.04702251777052879, Accuracy: 0.934973222843837\n",
      "Iteration: 20416, Loss: 0.0026587138418108225, Accuracy: 0.9393501522717997\n",
      "Iteration: 20480, Loss: 0.0033305168617516756, Accuracy: 0.9443878079473507\n",
      "Iteration: 20544, Loss: 0.007401623297482729, Accuracy: 0.9478977728867903\n",
      "Iteration: 20608, Loss: 0.005450461059808731, Accuracy: 0.9463189362722915\n",
      "Iteration: 20672, Loss: 0.005715330597013235, Accuracy: 0.9469283871876542\n",
      "Iteration: 20736, Loss: 0.00841610413044691, Accuracy: 0.930671881447779\n",
      "Iteration: 20800, Loss: 0.01633313111960888, Accuracy: 0.938965697074309\n",
      "Iteration: 20864, Loss: 0.0022518911864608526, Accuracy: 0.9468050771101844\n",
      "Iteration: 20928, Loss: 0.005609035491943359, Accuracy: 0.9218072870280594\n",
      "Iteration: 20992, Loss: 0.02380402386188507, Accuracy: 0.9311311729834415\n",
      "Iteration: 21056, Loss: 0.0041586910374462605, Accuracy: 0.9451694625458913\n",
      "Iteration: 21120, Loss: 0.005204204004257917, Accuracy: 0.9314070594555233\n",
      "Iteration: 21184, Loss: 0.002772791078314185, Accuracy: 0.9148048786155414\n",
      "Iteration: 21248, Loss: 0.0018745631678029895, Accuracy: 0.9421323933056556\n",
      "Iteration: 21312, Loss: 0.3123963475227356, Accuracy: 0.9267880424449686\n",
      "Iteration: 21376, Loss: 0.0019777072593569756, Accuracy: 0.9301737344940193\n",
      "Iteration: 21440, Loss: 0.001893579144962132, Accuracy: 0.9402223190118093\n",
      "Iteration: 21504, Loss: 0.0028112055733799934, Accuracy: 0.943012845760677\n",
      "Iteration: 21568, Loss: 0.005281283985823393, Accuracy: 0.944315783737693\n",
      "Iteration: 21632, Loss: 0.008120688609778881, Accuracy: 0.955306203730288\n",
      "Iteration: 21696, Loss: 0.01697913184762001, Accuracy: 0.949238710309146\n",
      "Iteration: 21760, Loss: 0.0061072856187820435, Accuracy: 0.9516150798590388\n",
      "Iteration: 21824, Loss: 0.002024963730946183, Accuracy: 0.9547525742527796\n",
      "Iteration: 21888, Loss: 0.0037741120904684067, Accuracy: 0.9494737765780883\n",
      "Iteration: 21952, Loss: 0.004403749015182257, Accuracy: 0.9470741701661609\n",
      "Iteration: 22016, Loss: 0.002020499901846051, Accuracy: 0.948826561376336\n",
      "Iteration: 22080, Loss: 0.0006357500096783042, Accuracy: 0.9443661760014948\n",
      "Iteration: 22144, Loss: 0.0016349524958059192, Accuracy: 0.9440803369798232\n",
      "Iteration: 22208, Loss: 0.0035611495841294527, Accuracy: 0.9427212471200619\n",
      "Iteration: 22272, Loss: 0.0003074567939620465, Accuracy: 0.94704392447602\n",
      "Iteration: 22336, Loss: 0.015822356566786766, Accuracy: 0.9448442673601676\n",
      "Iteration: 22400, Loss: 0.04355375096201897, Accuracy: 0.9407145995792234\n",
      "Iteration: 22464, Loss: 0.0015481499722227454, Accuracy: 0.9391385212802561\n",
      "Iteration: 22528, Loss: 0.006186705082654953, Accuracy: 0.9414550143992528\n",
      "Iteration: 22592, Loss: 0.001092126709409058, Accuracy: 0.9321393502177671\n",
      "Iteration: 22656, Loss: 0.5217920541763306, Accuracy: 0.9319020505354274\n",
      "Iteration: 22720, Loss: 0.002487393794581294, Accuracy: 0.9354039601166733\n",
      "Iteration: 22784, Loss: 0.005050052423030138, Accuracy: 0.9488976496795658\n",
      "Iteration: 22848, Loss: 0.006031761411577463, Accuracy: 0.9417904017027467\n",
      "Iteration: 22912, Loss: 0.0011834531323984265, Accuracy: 0.922461134265177\n",
      "Iteration: 22976, Loss: 0.0017860577208921313, Accuracy: 0.9493789332191227\n",
      "Iteration: 23040, Loss: 0.004042741376906633, Accuracy: 0.9514961208042223\n",
      "Iteration: 23104, Loss: 0.003917753230780363, Accuracy: 0.9485778292873874\n",
      "Iteration: 23168, Loss: 0.0017063259147107601, Accuracy: 0.9539919846429257\n",
      "Iteration: 23232, Loss: 0.0017146909376606345, Accuracy: 0.9493818816554267\n",
      "Iteration: 23296, Loss: 0.005290923174470663, Accuracy: 0.9555527368065668\n",
      "Iteration: 23360, Loss: 0.004643152467906475, Accuracy: 0.942858455615351\n",
      "Iteration: 23424, Loss: 0.0011388288112357259, Accuracy: 0.9521416482748464\n",
      "Iteration: 23488, Loss: 0.0017548114992678165, Accuracy: 0.9547639460943174\n",
      "Iteration: 23552, Loss: 0.0007281589205376804, Accuracy: 0.954665576282423\n",
      "Iteration: 23616, Loss: 0.002468338469043374, Accuracy: 0.9548687390924897\n",
      "Iteration: 23680, Loss: 0.0011479201493784785, Accuracy: 0.947545818562503\n",
      "Iteration: 23744, Loss: 0.013132148422300816, Accuracy: 0.9420473719510483\n",
      "Iteration: 23808, Loss: 0.07657650113105774, Accuracy: 0.9466072115465067\n",
      "Iteration: 23872, Loss: 0.003387939417734742, Accuracy: 0.9568364849110367\n",
      "Iteration: 23936, Loss: 0.0014932533958926797, Accuracy: 0.9391593904874753\n",
      "Iteration: 24000, Loss: 0.17104579508304596, Accuracy: 0.9519408334745094\n",
      "Iteration: 24064, Loss: 0.0017714016139507294, Accuracy: 0.9606083387916442\n",
      "Iteration: 24128, Loss: 0.0032735636923462152, Accuracy: 0.952812227740651\n",
      "Iteration: 24192, Loss: 0.0048056612722575665, Accuracy: 0.9585709573875647\n",
      "Iteration: 24256, Loss: 0.003484472632408142, Accuracy: 0.9623383621656103\n",
      "Iteration: 24320, Loss: 0.005519762169569731, Accuracy: 0.9627119656361174\n",
      "Iteration: 24384, Loss: 0.003185834502801299, Accuracy: 0.9638846143352566\n",
      "Iteration: 24448, Loss: 0.0013407705118879676, Accuracy: 0.9581988542631734\n",
      "Iteration: 24512, Loss: 0.0009649848216213286, Accuracy: 0.9507868299842812\n",
      "Iteration: 24576, Loss: 0.0023453449830412865, Accuracy: 0.9558584955375409\n",
      "Iteration: 24640, Loss: 0.0028795693069696426, Accuracy: 0.9495688933820929\n",
      "Iteration: 24704, Loss: 0.0014150041388347745, Accuracy: 0.9508325299539138\n",
      "Iteration: 24768, Loss: 0.006595855578780174, Accuracy: 0.959939784836024\n",
      "Iteration: 24832, Loss: 0.0008146630716510117, Accuracy: 0.943333655159222\n",
      "Iteration: 24896, Loss: 0.006974685471504927, Accuracy: 0.944250742541044\n",
      "Iteration: 24960, Loss: 0.004004449117928743, Accuracy: 0.9618254688539309\n",
      "Iteration: 25024, Loss: 0.00156405137386173, Accuracy: 0.9646925160341198\n",
      "Iteration: 25088, Loss: 0.0033404154237359762, Accuracy: 0.9530520903645083\n",
      "Iteration: 25152, Loss: 0.0022860572207719088, Accuracy: 0.9572514439641964\n",
      "Iteration: 25216, Loss: 0.0011170216603204608, Accuracy: 0.9530348111875355\n",
      "Iteration: 25280, Loss: 0.0025271393824368715, Accuracy: 0.9606097417417914\n",
      "Iteration: 25344, Loss: 0.006133234594017267, Accuracy: 0.9446466030785814\n",
      "Iteration: 25408, Loss: 0.003994572442024946, Accuracy: 0.9443119073403068\n",
      "Iteration: 25472, Loss: 0.008126948028802872, Accuracy: 0.9471357861475553\n",
      "Iteration: 25536, Loss: 0.0027038550470024347, Accuracy: 0.9603048653079895\n",
      "Iteration: 25600, Loss: 0.004624965135008097, Accuracy: 0.9654642617533682\n",
      "Iteration: 25664, Loss: 0.0026192280929535627, Accuracy: 0.9644822856207611\n",
      "Iteration: 25728, Loss: 0.00477388733997941, Accuracy: 0.9572858926403569\n",
      "Iteration: 25792, Loss: 0.0011244527995586395, Accuracy: 0.9378707898285938\n",
      "Iteration: 25856, Loss: 0.002811403712257743, Accuracy: 0.9535206900036428\n",
      "Iteration: 25920, Loss: 0.0006929696537554264, Accuracy: 0.9574451044900343\n",
      "Iteration: 25984, Loss: 0.002488871105015278, Accuracy: 0.9396450386120705\n",
      "Iteration: 26048, Loss: 0.0030378634110093117, Accuracy: 0.949389162749867\n",
      "Iteration: 26112, Loss: 0.0007792066899128258, Accuracy: 0.9374696745799156\n",
      "Iteration: 26176, Loss: 0.0007198606617748737, Accuracy: 0.9511603179271333\n",
      "Iteration: 26240, Loss: 0.0009460850269533694, Accuracy: 0.9544780780852307\n",
      "Iteration: 26304, Loss: 0.00204236782155931, Accuracy: 0.964255522863823\n",
      "Iteration: 26368, Loss: 0.0024543723557144403, Accuracy: 0.9518504512234358\n",
      "Iteration: 26432, Loss: 0.0027655207086354494, Accuracy: 0.9526697501569288\n",
      "Iteration: 26496, Loss: 0.0037932582199573517, Accuracy: 0.965368254124769\n",
      "Iteration: 26560, Loss: 0.00229523703455925, Accuracy: 0.9583917511045001\n",
      "Iteration: 26624, Loss: 0.0009263959364034235, Accuracy: 0.9578840723988833\n",
      "Iteration: 26688, Loss: 0.002479169750586152, Accuracy: 0.9626641014183406\n",
      "Iteration: 26752, Loss: 0.0004946250119246542, Accuracy: 0.9561851944890805\n",
      "Iteration: 26816, Loss: 0.0020574613008648157, Accuracy: 0.9507497818849515\n",
      "Iteration: 26880, Loss: 0.003147376934066415, Accuracy: 0.9577639735070989\n",
      "Iteration: 26944, Loss: 0.0021305636037141085, Accuracy: 0.9588081972760847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 27008, Loss: 0.0010698552941903472, Accuracy: 0.9538664281717502\n",
      "Iteration: 27072, Loss: 0.0020042331889271736, Accuracy: 0.9507976939930813\n",
      "Iteration: 27136, Loss: 0.0016673525096848607, Accuracy: 0.9402558545261854\n",
      "Iteration: 27200, Loss: 0.003985000774264336, Accuracy: 0.9475982930889586\n",
      "Iteration: 27264, Loss: 0.0017159507842734456, Accuracy: 0.9650729460990988\n",
      "Iteration: 27328, Loss: 0.0024034231901168823, Accuracy: 0.9325831491587451\n",
      "Iteration: 27392, Loss: 0.002228879602625966, Accuracy: 0.9561933224467793\n",
      "Iteration: 27456, Loss: 0.0009373487555421889, Accuracy: 0.9593322896107566\n",
      "Iteration: 27520, Loss: 0.0010803058976307511, Accuracy: 0.9681291442975635\n",
      "Iteration: 27584, Loss: 0.0046087708324193954, Accuracy: 0.9618326298368629\n",
      "Iteration: 27648, Loss: 0.0011227416107431054, Accuracy: 0.9473269205773249\n",
      "Iteration: 27712, Loss: 0.003856045426800847, Accuracy: 0.9585440068767639\n",
      "Iteration: 27776, Loss: 0.0016867265803739429, Accuracy: 0.9655701478768606\n",
      "Iteration: 27840, Loss: 0.0184285007417202, Accuracy: 0.9662568569619907\n",
      "Iteration: 27904, Loss: 0.001946332398802042, Accuracy: 0.9685223452543141\n",
      "Iteration: 27968, Loss: 0.0019801922608166933, Accuracy: 0.966090355112101\n",
      "Iteration: 28032, Loss: 0.000810775498393923, Accuracy: 0.969869768654462\n",
      "Iteration: 28096, Loss: 0.007427500560879707, Accuracy: 0.9643754333956167\n",
      "Iteration: 28160, Loss: 0.0019537738990038633, Accuracy: 0.9652634302328806\n",
      "Iteration: 28224, Loss: 0.0015302430838346481, Accuracy: 0.957199724361999\n",
      "Iteration: 28288, Loss: 0.007689086254686117, Accuracy: 0.9541011147375684\n",
      "Iteration: 28352, Loss: 0.0019313149387016892, Accuracy: 0.9573476996738464\n",
      "Iteration: 28416, Loss: 0.0005106563330627978, Accuracy: 0.9587863367196405\n",
      "Iteration: 28480, Loss: 0.001301656593568623, Accuracy: 0.9691390292282449\n",
      "Iteration: 28544, Loss: 0.00030930989305488765, Accuracy: 0.9593918337777723\n",
      "Iteration: 28608, Loss: 0.0009998944588005543, Accuracy: 0.9685768894851208\n",
      "Iteration: 28672, Loss: 0.0034294649958610535, Accuracy: 0.9637991642812267\n",
      "Iteration: 28736, Loss: 0.0005927259917370975, Accuracy: 0.9544208377919858\n",
      "Iteration: 28800, Loss: 0.0710035040974617, Accuracy: 0.9598475402308395\n",
      "Iteration: 28864, Loss: 0.004678101744502783, Accuracy: 0.9573754008306423\n",
      "Iteration: 28928, Loss: 0.0003644849348347634, Accuracy: 0.9682956187316449\n",
      "Iteration: 28992, Loss: 0.0004073947493452579, Accuracy: 0.9599783025041688\n",
      "Iteration: 29056, Loss: 0.0013568373396992683, Accuracy: 0.9615739997389028\n",
      "Iteration: 29120, Loss: 0.002699417993426323, Accuracy: 0.9673353399412008\n",
      "Iteration: 29184, Loss: 0.0014825438847765326, Accuracy: 0.9696317910565995\n",
      "Iteration: 29248, Loss: 0.00022154893667902797, Accuracy: 0.9549867189780343\n",
      "Iteration: 29312, Loss: 0.005447245668619871, Accuracy: 0.9616286630625837\n",
      "Iteration: 29376, Loss: 0.002638170262798667, Accuracy: 0.9549098604911705\n",
      "Iteration: 29440, Loss: 0.0005744730005972087, Accuracy: 0.9672727761935676\n",
      "Iteration: 29504, Loss: 0.0009750479366630316, Accuracy: 0.9571453353128163\n",
      "Iteration: 29568, Loss: 0.0006191384163685143, Accuracy: 0.9688333952071844\n",
      "Iteration: 29632, Loss: 0.002392621012404561, Accuracy: 0.9506096535333199\n",
      "Iteration: 29696, Loss: 0.002801916329190135, Accuracy: 0.9653120870061684\n",
      "Iteration: 29760, Loss: 0.00570123502984643, Accuracy: 0.9554184552544029\n",
      "Iteration: 29824, Loss: 0.007837250828742981, Accuracy: 0.9645858560979832\n",
      "Iteration: 29888, Loss: 0.0014362604124471545, Accuracy: 0.9716159278759733\n",
      "Saved fullModel_dr[5]_replicate4.model\n",
      "Saved W_dr[5]_replicate4.p\n",
      "5 1.0 [1.0, 1.0, 1.0]\n",
      "Saved w_dr[5]_replicate4.p\n",
      "Replicate 4 completed\n",
      "Time elapsed: 958.515625 seconds\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "delay_ranges = [[1],[2],[3],[4],[5]]\n",
    "#delay_ranges = [[3]]\n",
    "num_replicates = 5\n",
    "models = {}\n",
    "\n",
    "for delayRange in delay_ranges:\n",
    "    print(f\"Training for delay range {delayRange}...\")\n",
    "    all_w = []\n",
    "\n",
    "    for replicate in range(num_replicates):\n",
    "        model=Net(hidden_dim=12,output_dim=6)\n",
    "        optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "        error = nn.MSELoss()\n",
    "        acc=0.0\n",
    "        W=[]\n",
    "        Ts=[]\n",
    "        iteration_list = []\n",
    "        loss_list = []\n",
    "        accuracy_list = []\n",
    "\n",
    "        while acc<0.97:\n",
    "            divs=[]\n",
    "            model.resetHidden()\n",
    "            nX,nY,nS,nW=makeNoisyDataset(X,Y,8,0.2,delayRange=delayRange) #variance for the ND is 0.2\n",
    "            for i in range(nX.shape[0]): #use 64 when training for single delayRange\n",
    "                optimizer.zero_grad()\n",
    "                output = model(torch.Tensor(nX[i].reshape(1,nX[i].shape[0],4))) #shape greater than 8\n",
    "                loss = error(output, torch.Tensor(nY[i]))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                div=output.detach().numpy().reshape(nY[i].shape)-nY[i]\n",
    "                divs.append(1.0-abs(div).mean())\n",
    "                current_iteration = len(iteration_list) + 1\n",
    "                loss_list.append(loss.item())\n",
    "                iteration_list.append(current_iteration)\n",
    "                accuracy_list.append(mean(divs))\n",
    "\n",
    "            acc=mean(divs)\n",
    "            W.append(acc)\n",
    "            total, subA, antiA = test(model, X=nX, Y=nY, S=nS)\n",
    "            Ts.append(subA)\n",
    "            print(f\"Iteration: {current_iteration}, Loss: {loss.item()}, Accuracy: {accuracy_list[-1]}\")\n",
    "\n",
    "        model_name = f\"fullModel_dr{delayRange}_replicate{replicate}.model\"\n",
    "        torch.save(model.state_dict(), model_name)\n",
    "        print(f\"Saved {model_name}\")\n",
    "        models[model_name] = model\n",
    "\n",
    "        W_name = f\"W_dr{delayRange}_replicate{replicate}.p\"\n",
    "        with open(W_name, \"wb\") as f:\n",
    "            pickle.dump(W, f)\n",
    "        print(f\"Saved {W_name}\")\n",
    "\n",
    "        w=[]\n",
    "        for tr in delayRange:\n",
    "            nX,nY,nS,nW=makeNoisyDataset(X,Y,8,0.2,delayRange=[tr])\n",
    "            total, subA, antiA = test(model, X=nX, Y=nY, S=nS)\n",
    "            print(tr,total,subA)\n",
    "            w.append(total)\n",
    "\n",
    "        all_w.append(w)\n",
    "        w_name = f\"w_dr{delayRange}_replicate{replicate}.p\"\n",
    "        with open(w_name, \"wb\") as f:\n",
    "            pickle.dump(w, f)\n",
    "        print(f\"Saved {w_name}\")\n",
    "\n",
    "        print(f\"Replicate {replicate} completed\")\n",
    "        print(f\"Time elapsed: {time.process_time()} seconds\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e883a87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def symbolEntropy(D,base=2):\n",
    "    value,counts = numpy.unique(D, return_counts=True)\n",
    "    return entropy(counts,base=base)\n",
    "\n",
    "def computeTransmissionHfast(I,H,O,maskC,maskNC,iMult=2,oMult=2):\n",
    "    #print(I.shape,H.shape,O.shape)\n",
    "    B=numpy.bitwise_and(H,maskNC)\n",
    "    IB=(B*iMult)+I\n",
    "    AB=H#numpy.bitwise_and(H,maskC+maskNC)\n",
    "    BO=(B*oMult)+O\n",
    "    IAB=(AB*iMult)+I\n",
    "    IBO=(B*(iMult*oMult))+(I*oMult)+O\n",
    "    ABO=(AB*oMult)+O\n",
    "    IABO=(AB*(iMult*oMult))+(I*oMult)+O\n",
    "    hB=symbolEntropy(B, base=2)\n",
    "    hIB=symbolEntropy(IB, base=2)\n",
    "    hAB=symbolEntropy(AB, base=2)\n",
    "    hBO=symbolEntropy(BO, base=2)\n",
    "    hIAB=symbolEntropy(IAB, base=2)\n",
    "    hIBO=symbolEntropy(IBO, base=2)\n",
    "    hABO=symbolEntropy(ABO, base=2)\n",
    "    hIABO=symbolEntropy(IABO, base=2)\n",
    "    #-H(B)+H(IB)+H(AB)+H(BO)-H(IAB)-H(IBO)-H(ABO)+H(IABO)\n",
    "    #print(hB,hIB,hAB,hBO,hIAB,hIBO,hABO,hIABO)\n",
    "    return-hB+hIB+hAB+hBO-hIAB-hIBO-hABO+hIABO\n",
    "\n",
    "def singleShrinkingDecompositionInformation(I,H,O,width,iMult=2,oMult=2):\n",
    "    nodes=list(range(width))\n",
    "    cols=[]\n",
    "    colh=[]\n",
    "    while len(nodes)>0:\n",
    "        infos=[]\n",
    "        for node in nodes:\n",
    "            subset=copy.deepcopy(nodes)\n",
    "            subset.remove(node)\n",
    "            maskA=0\n",
    "            for s in subset:\n",
    "                maskA+=1*(2**s)\n",
    "            maskA=int(maskA)\n",
    "            maskB=numpy.bitwise_and(numpy.bitwise_not(maskA),((2**width)-1))\n",
    "            h=computeTransmissionHfast(I,H,O,maskA,maskB,iMult=iMult,oMult=oMult)\n",
    "            infos.append(h)\n",
    "        nodeToDrop=nodes[infos.index(max(infos))]\n",
    "        nodes.remove(nodeToDrop)\n",
    "        cols.append(copy.deepcopy(nodes))\n",
    "        colh.append(max(infos))\n",
    "    return cols,colh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0178379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOutTaH(model,dataSet):\n",
    "    O,H=model.step(torch.Tensor(dataSet))\n",
    "    H=H.transpose()\n",
    "    O=O.transpose()\n",
    "    B=numpy.zeros(H.shape)\n",
    "    clusterNr=2\n",
    "    for i in range(B.shape[0]):\n",
    "        a=H[i].reshape(-1, 1)\n",
    "        if len(numpy.unique(a))==1:\n",
    "            who=numpy.random.randint(len(a))\n",
    "            a[who]=1-a[who]\n",
    "        kmeans = KMeans(n_clusters=clusterNr).fit(a)\n",
    "        B[i]=kmeans.labels_\n",
    "        #B[i]=1.0*(H[i]>numpy.median(H[i]))\n",
    "\n",
    "\n",
    "    H=numpy.zeros((H.shape))\n",
    "    for i in range(12):\n",
    "        H+=B[i]*(clusterNr**i)\n",
    "    H=H.astype((int))\n",
    "    return O,H\n",
    "\n",
    "def shrinkingDecompositionInformation(model,width,dataSet,target,numbers=[0,1,2],whichTS=5):\n",
    "    output,H=getOutTaH(model,dataSet)\n",
    "    output=output.transpose()[whichTS::8].transpose()\n",
    "    H=H.transpose()[whichTS::8].transpose()\n",
    "    target=target.transpose()[whichTS::8].transpose()\n",
    "    collectorSet=dict()\n",
    "    collectorH=dict()\n",
    "    for number in numbers:\n",
    "        I=target[number].astype(int)\n",
    "        O=(1.0*(output[number*2]>0.5)).astype(int)\n",
    "        #print(\"O\",O,\"T\",target[number])\n",
    "        s,h=singleShrinkingDecompositionInformation(I,H,O,width)\n",
    "        collectorSet[number]=s\n",
    "        collectorH[number]=h\n",
    "    return collectorSet,collectorH\n",
    "\n",
    "for model in models:\n",
    "    #print(models[model])\n",
    "    nX,nY,nS,nW=makeNoisyDataset(X,Y,8,0.1)\n",
    "    S,H=shrinkingDecompositionInformation(models[model],12,nX,nW.transpose())\n",
    "#nX,nY,nS,nW=makeNoisyDataset(X,Y,8,0.1)\n",
    "#S,H=shrinkingDecompositionInformation(model,12,nX,nW.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91c6f999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removalIntoVec(res,width,H):\n",
    "    V=numpy.zeros(width)\n",
    "    #for i,r in enumerate(res):\n",
    "    #    for e in r:\n",
    "    #        V[e]+=H[0]-H[i]\n",
    "    fullSet=list(range(width))\n",
    "    nRes=copy.deepcopy(res)\n",
    "    nRes.insert(0,fullSet)\n",
    "    nodeList=[]\n",
    "    for i in range(width):\n",
    "        removedNode=list(set(nRes[i])-set(nRes[i+1]))[0]\n",
    "        nodeList.append(removedNode)\n",
    "    for i,node in enumerate(nodeList):\n",
    "        V[node]=H[0]-H[i]\n",
    "    #V=sqrt(V)\n",
    "    V=numpy.abs(V)\n",
    "    if V.sum()<=0:\n",
    "        return V\n",
    "    return V #  return V/V.max() (playaround)\n",
    "\n",
    "def removalIntoMatrix(res,width,H):\n",
    "    M=[]\n",
    "    for i in range(len(res)):\n",
    "        M.append(removalIntoVec(res[i],width,H[i]))\n",
    "    return numpy.array(M)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914181f7",
   "metadata": {},
   "source": [
    "# Correlation Coefficient Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8eaf3639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing delay range: 1\n",
      "  Processing model: fullModel_dr[1]_replicate0.model\n",
      "  Model: fullModel_dr[1]_replicate0.model | Comparing images 1 and 2: 0.6489938722861363\n",
      "  Model: fullModel_dr[1]_replicate0.model | Comparing images 1 and 3: 0.5138978774861847\n",
      "  Model: fullModel_dr[1]_replicate0.model | Comparing images 1 and 4: 0.4855653814620975\n",
      "  Model: fullModel_dr[1]_replicate0.model | Comparing images 1 and 5: 0.6729468773414692\n",
      "  Model: fullModel_dr[1]_replicate0.model | Comparing images 2 and 3: 0.6414818757523649\n",
      "  Model: fullModel_dr[1]_replicate0.model | Comparing images 2 and 4: 0.6234197667494218\n",
      "  Model: fullModel_dr[1]_replicate0.model | Comparing images 2 and 5: 0.4183234037676448\n",
      "  Model: fullModel_dr[1]_replicate0.model | Comparing images 3 and 4: 0.9396781347296987\n",
      "  Model: fullModel_dr[1]_replicate0.model | Comparing images 3 and 5: 0.641565596982162\n",
      "  Model: fullModel_dr[1]_replicate0.model | Comparing images 4 and 5: 0.6175343306209324\n",
      "  Processing model: fullModel_dr[1]_replicate1.model\n",
      "  Model: fullModel_dr[1]_replicate1.model | Comparing images 1 and 2: 0.6220410099164178\n",
      "  Model: fullModel_dr[1]_replicate1.model | Comparing images 1 and 3: 0.21467871201999625\n",
      "  Model: fullModel_dr[1]_replicate1.model | Comparing images 1 and 4: -0.06254041908518962\n",
      "  Model: fullModel_dr[1]_replicate1.model | Comparing images 1 and 5: 0.125701459224294\n",
      "  Model: fullModel_dr[1]_replicate1.model | Comparing images 2 and 3: 0.46295352735223044\n",
      "  Model: fullModel_dr[1]_replicate1.model | Comparing images 2 and 4: 0.23039021667681228\n",
      "  Model: fullModel_dr[1]_replicate1.model | Comparing images 2 and 5: 0.39646115024903833\n",
      "  Model: fullModel_dr[1]_replicate1.model | Comparing images 3 and 4: 0.4337008495750535\n",
      "  Model: fullModel_dr[1]_replicate1.model | Comparing images 3 and 5: 0.5955621180278411\n",
      "  Model: fullModel_dr[1]_replicate1.model | Comparing images 4 and 5: 0.35131876923939975\n",
      "  Processing model: fullModel_dr[1]_replicate2.model\n",
      "  Model: fullModel_dr[1]_replicate2.model | Comparing images 1 and 2: 0.31756050320090107\n",
      "  Model: fullModel_dr[1]_replicate2.model | Comparing images 1 and 3: 0.39180622398057435\n",
      "  Model: fullModel_dr[1]_replicate2.model | Comparing images 1 and 4: 0.7055491563025882\n",
      "  Model: fullModel_dr[1]_replicate2.model | Comparing images 1 and 5: 0.674125137659591\n",
      "  Model: fullModel_dr[1]_replicate2.model | Comparing images 2 and 3: 0.6080150337220769\n",
      "  Model: fullModel_dr[1]_replicate2.model | Comparing images 2 and 4: 0.3614114904411794\n",
      "  Model: fullModel_dr[1]_replicate2.model | Comparing images 2 and 5: 0.5593447833458259\n",
      "  Model: fullModel_dr[1]_replicate2.model | Comparing images 3 and 4: 0.6828526911247541\n",
      "  Model: fullModel_dr[1]_replicate2.model | Comparing images 3 and 5: 0.24726992389768016\n",
      "  Model: fullModel_dr[1]_replicate2.model | Comparing images 4 and 5: 0.4485647679893372\n",
      "  Processing model: fullModel_dr[1]_replicate3.model\n",
      "  Model: fullModel_dr[1]_replicate3.model | Comparing images 1 and 2: 0.18809776135160336\n",
      "  Model: fullModel_dr[1]_replicate3.model | Comparing images 1 and 3: 0.13643067895302555\n",
      "  Model: fullModel_dr[1]_replicate3.model | Comparing images 1 and 4: 0.07573606565023117\n",
      "  Model: fullModel_dr[1]_replicate3.model | Comparing images 1 and 5: 0.07114337024734364\n",
      "  Model: fullModel_dr[1]_replicate3.model | Comparing images 2 and 3: 0.019983220129511703\n",
      "  Model: fullModel_dr[1]_replicate3.model | Comparing images 2 and 4: -0.3450607576430775\n",
      "  Model: fullModel_dr[1]_replicate3.model | Comparing images 2 and 5: 0.3026734005704217\n",
      "  Model: fullModel_dr[1]_replicate3.model | Comparing images 3 and 4: 0.2261678994650872\n",
      "  Model: fullModel_dr[1]_replicate3.model | Comparing images 3 and 5: -0.41640732808704767\n",
      "  Model: fullModel_dr[1]_replicate3.model | Comparing images 4 and 5: 0.008122726336504805\n",
      "  Processing model: fullModel_dr[1]_replicate4.model\n",
      "  Model: fullModel_dr[1]_replicate4.model | Comparing images 1 and 2: 0.24293430239768177\n",
      "  Model: fullModel_dr[1]_replicate4.model | Comparing images 1 and 3: 0.09679010320350102\n",
      "  Model: fullModel_dr[1]_replicate4.model | Comparing images 1 and 4: 0.19225535192516252\n",
      "  Model: fullModel_dr[1]_replicate4.model | Comparing images 1 and 5: -0.16787696283773762\n",
      "  Model: fullModel_dr[1]_replicate4.model | Comparing images 2 and 3: -0.029402970129620825\n",
      "  Model: fullModel_dr[1]_replicate4.model | Comparing images 2 and 4: -0.14238887065717734\n",
      "  Model: fullModel_dr[1]_replicate4.model | Comparing images 2 and 5: -0.040717136531320586\n",
      "  Model: fullModel_dr[1]_replicate4.model | Comparing images 3 and 4: 0.2904277503781293\n",
      "  Model: fullModel_dr[1]_replicate4.model | Comparing images 3 and 5: 0.030501115780183947\n",
      "  Model: fullModel_dr[1]_replicate4.model | Comparing images 4 and 5: 0.16893960306481112\n",
      "Mean correlation coefficient for delay range 1: 0.35774624871096145\n",
      "Processing delay range: 2\n",
      "  Processing model: fullModel_dr[2]_replicate0.model\n",
      "  Model: fullModel_dr[2]_replicate0.model | Comparing images 1 and 2: 0.41712724608156815\n",
      "  Model: fullModel_dr[2]_replicate0.model | Comparing images 1 and 3: 0.3533555853388625\n",
      "  Model: fullModel_dr[2]_replicate0.model | Comparing images 1 and 4: -0.005211291297776799\n",
      "  Model: fullModel_dr[2]_replicate0.model | Comparing images 1 and 5: 0.08800629291916008\n",
      "  Model: fullModel_dr[2]_replicate0.model | Comparing images 2 and 3: 0.24429241967393128\n",
      "  Model: fullModel_dr[2]_replicate0.model | Comparing images 2 and 4: 0.004142901510634299\n",
      "  Model: fullModel_dr[2]_replicate0.model | Comparing images 2 and 5: -0.08576614484622702\n",
      "  Model: fullModel_dr[2]_replicate0.model | Comparing images 3 and 4: 0.41181341902971785\n",
      "  Model: fullModel_dr[2]_replicate0.model | Comparing images 3 and 5: 0.40501057638946625\n",
      "  Model: fullModel_dr[2]_replicate0.model | Comparing images 4 and 5: 0.5108679112978054\n",
      "  Processing model: fullModel_dr[2]_replicate1.model\n",
      "  Model: fullModel_dr[2]_replicate1.model | Comparing images 1 and 2: 0.25490538226800163\n",
      "  Model: fullModel_dr[2]_replicate1.model | Comparing images 1 and 3: 0.16900592777276027\n",
      "  Model: fullModel_dr[2]_replicate1.model | Comparing images 1 and 4: 0.45835319768206745\n",
      "  Model: fullModel_dr[2]_replicate1.model | Comparing images 1 and 5: 0.17757006905033065\n",
      "  Model: fullModel_dr[2]_replicate1.model | Comparing images 2 and 3: 0.35757000123382543\n",
      "  Model: fullModel_dr[2]_replicate1.model | Comparing images 2 and 4: 0.19981476955211225\n",
      "  Model: fullModel_dr[2]_replicate1.model | Comparing images 2 and 5: 0.052326542742601116\n",
      "  Model: fullModel_dr[2]_replicate1.model | Comparing images 3 and 4: 0.22977130878851862\n",
      "  Model: fullModel_dr[2]_replicate1.model | Comparing images 3 and 5: 0.42501655694401674\n",
      "  Model: fullModel_dr[2]_replicate1.model | Comparing images 4 and 5: 0.3909020061801173\n",
      "  Processing model: fullModel_dr[2]_replicate2.model\n",
      "  Model: fullModel_dr[2]_replicate2.model | Comparing images 1 and 2: 0.3800638868177622\n",
      "  Model: fullModel_dr[2]_replicate2.model | Comparing images 1 and 3: 0.18046564855734837\n",
      "  Model: fullModel_dr[2]_replicate2.model | Comparing images 1 and 4: 0.3879037647164843\n",
      "  Model: fullModel_dr[2]_replicate2.model | Comparing images 1 and 5: 0.35663456293585993\n",
      "  Model: fullModel_dr[2]_replicate2.model | Comparing images 2 and 3: 0.4411055488010125\n",
      "  Model: fullModel_dr[2]_replicate2.model | Comparing images 2 and 4: 0.4225961128491335\n",
      "  Model: fullModel_dr[2]_replicate2.model | Comparing images 2 and 5: 0.39783621738442204\n",
      "  Model: fullModel_dr[2]_replicate2.model | Comparing images 3 and 4: 0.45026249091169834\n",
      "  Model: fullModel_dr[2]_replicate2.model | Comparing images 3 and 5: 0.5932795810635696\n",
      "  Model: fullModel_dr[2]_replicate2.model | Comparing images 4 and 5: 0.5388913649379355\n",
      "  Processing model: fullModel_dr[2]_replicate3.model\n",
      "  Model: fullModel_dr[2]_replicate3.model | Comparing images 1 and 2: 0.6255258277998469\n",
      "  Model: fullModel_dr[2]_replicate3.model | Comparing images 1 and 3: 0.41567663698270146\n",
      "  Model: fullModel_dr[2]_replicate3.model | Comparing images 1 and 4: 0.09757341432327421\n",
      "  Model: fullModel_dr[2]_replicate3.model | Comparing images 1 and 5: 0.15681319576240685\n",
      "  Model: fullModel_dr[2]_replicate3.model | Comparing images 2 and 3: 0.6038265622159448\n",
      "  Model: fullModel_dr[2]_replicate3.model | Comparing images 2 and 4: 0.4542257292406238\n",
      "  Model: fullModel_dr[2]_replicate3.model | Comparing images 2 and 5: 0.21642089117210134\n",
      "  Model: fullModel_dr[2]_replicate3.model | Comparing images 3 and 4: 0.5396793905535632\n",
      "  Model: fullModel_dr[2]_replicate3.model | Comparing images 3 and 5: 0.2794860156554038\n",
      "  Model: fullModel_dr[2]_replicate3.model | Comparing images 4 and 5: 0.4773093514547032\n",
      "  Processing model: fullModel_dr[2]_replicate4.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model: fullModel_dr[2]_replicate4.model | Comparing images 1 and 2: 0.4334076448373706\n",
      "  Model: fullModel_dr[2]_replicate4.model | Comparing images 1 and 3: -0.19437882050406416\n",
      "  Model: fullModel_dr[2]_replicate4.model | Comparing images 1 and 4: -0.2228332836747815\n",
      "  Model: fullModel_dr[2]_replicate4.model | Comparing images 1 and 5: -0.22230269562927527\n",
      "  Model: fullModel_dr[2]_replicate4.model | Comparing images 2 and 3: -0.019086710957348776\n",
      "  Model: fullModel_dr[2]_replicate4.model | Comparing images 2 and 4: -0.06438812479112739\n",
      "  Model: fullModel_dr[2]_replicate4.model | Comparing images 2 and 5: -0.12482784316906177\n",
      "  Model: fullModel_dr[2]_replicate4.model | Comparing images 3 and 4: 0.18969183536288525\n",
      "  Model: fullModel_dr[2]_replicate4.model | Comparing images 3 and 5: 0.2378202632554096\n",
      "  Model: fullModel_dr[2]_replicate4.model | Comparing images 4 and 5: 0.1371251188146849\n",
      "Mean correlation coefficient for delay range 2: 0.30204536171462615\n",
      "Processing delay range: 3\n",
      "  Processing model: fullModel_dr[3]_replicate0.model\n",
      "  Model: fullModel_dr[3]_replicate0.model | Comparing images 1 and 2: -0.009225637089990657\n",
      "  Model: fullModel_dr[3]_replicate0.model | Comparing images 1 and 3: 0.05740311848643418\n",
      "  Model: fullModel_dr[3]_replicate0.model | Comparing images 1 and 4: 0.13149774058867938\n",
      "  Model: fullModel_dr[3]_replicate0.model | Comparing images 1 and 5: 0.11492515054192354\n",
      "  Model: fullModel_dr[3]_replicate0.model | Comparing images 2 and 3: 0.037698162690126824\n",
      "  Model: fullModel_dr[3]_replicate0.model | Comparing images 2 and 4: 0.13476993950543556\n",
      "  Model: fullModel_dr[3]_replicate0.model | Comparing images 2 and 5: 0.07000173183645354\n",
      "  Model: fullModel_dr[3]_replicate0.model | Comparing images 3 and 4: 0.08405508992724037\n",
      "  Model: fullModel_dr[3]_replicate0.model | Comparing images 3 and 5: 0.08638642561014916\n",
      "  Model: fullModel_dr[3]_replicate0.model | Comparing images 4 and 5: -0.011975453937111826\n",
      "  Processing model: fullModel_dr[3]_replicate1.model\n",
      "  Model: fullModel_dr[3]_replicate1.model | Comparing images 1 and 2: 0.6971613910635837\n",
      "  Model: fullModel_dr[3]_replicate1.model | Comparing images 1 and 3: 0.4413485612208731\n",
      "  Model: fullModel_dr[3]_replicate1.model | Comparing images 1 and 4: 0.42409331745676787\n",
      "  Model: fullModel_dr[3]_replicate1.model | Comparing images 1 and 5: 0.32903377673437484\n",
      "  Model: fullModel_dr[3]_replicate1.model | Comparing images 2 and 3: 0.6075164238925962\n",
      "  Model: fullModel_dr[3]_replicate1.model | Comparing images 2 and 4: 0.5626382447831426\n",
      "  Model: fullModel_dr[3]_replicate1.model | Comparing images 2 and 5: 0.061438538150900265\n",
      "  Model: fullModel_dr[3]_replicate1.model | Comparing images 3 and 4: 0.4360098058869783\n",
      "  Model: fullModel_dr[3]_replicate1.model | Comparing images 3 and 5: 0.11175725494139016\n",
      "  Model: fullModel_dr[3]_replicate1.model | Comparing images 4 and 5: 0.010788308286761887\n",
      "  Processing model: fullModel_dr[3]_replicate2.model\n",
      "  Model: fullModel_dr[3]_replicate2.model | Comparing images 1 and 2: 0.44354943674195385\n",
      "  Model: fullModel_dr[3]_replicate2.model | Comparing images 1 and 3: 0.001989179513691015\n",
      "  Model: fullModel_dr[3]_replicate2.model | Comparing images 1 and 4: -0.35477391209139725\n",
      "  Model: fullModel_dr[3]_replicate2.model | Comparing images 1 and 5: 0.003390620887130071\n",
      "  Model: fullModel_dr[3]_replicate2.model | Comparing images 2 and 3: 0.3015267234564096\n",
      "  Model: fullModel_dr[3]_replicate2.model | Comparing images 2 and 4: -0.2205384187641399\n",
      "  Model: fullModel_dr[3]_replicate2.model | Comparing images 2 and 5: 0.09202554818987782\n",
      "  Model: fullModel_dr[3]_replicate2.model | Comparing images 3 and 4: 0.2927925265918747\n",
      "  Model: fullModel_dr[3]_replicate2.model | Comparing images 3 and 5: 0.0655237341768284\n",
      "  Model: fullModel_dr[3]_replicate2.model | Comparing images 4 and 5: 0.11296725533354049\n",
      "  Processing model: fullModel_dr[3]_replicate3.model\n",
      "  Model: fullModel_dr[3]_replicate3.model | Comparing images 1 and 2: 0.5421947201613615\n",
      "  Model: fullModel_dr[3]_replicate3.model | Comparing images 1 and 3: 0.5584180680602356\n",
      "  Model: fullModel_dr[3]_replicate3.model | Comparing images 1 and 4: 0.03612899159748323\n",
      "  Model: fullModel_dr[3]_replicate3.model | Comparing images 1 and 5: 0.18781563015532865\n",
      "  Model: fullModel_dr[3]_replicate3.model | Comparing images 2 and 3: 0.45927262749517755\n",
      "  Model: fullModel_dr[3]_replicate3.model | Comparing images 2 and 4: 0.16668349165374358\n",
      "  Model: fullModel_dr[3]_replicate3.model | Comparing images 2 and 5: 0.3544258303988842\n",
      "  Model: fullModel_dr[3]_replicate3.model | Comparing images 3 and 4: 0.09983033583273042\n",
      "  Model: fullModel_dr[3]_replicate3.model | Comparing images 3 and 5: 0.4033546430685615\n",
      "  Model: fullModel_dr[3]_replicate3.model | Comparing images 4 and 5: 0.5762726850826517\n",
      "  Processing model: fullModel_dr[3]_replicate4.model\n",
      "  Model: fullModel_dr[3]_replicate4.model | Comparing images 1 and 2: 0.5463025944995289\n",
      "  Model: fullModel_dr[3]_replicate4.model | Comparing images 1 and 3: 0.4056495219828203\n",
      "  Model: fullModel_dr[3]_replicate4.model | Comparing images 1 and 4: 0.4744025394679916\n",
      "  Model: fullModel_dr[3]_replicate4.model | Comparing images 1 and 5: 0.3126276776817546\n",
      "  Model: fullModel_dr[3]_replicate4.model | Comparing images 2 and 3: 0.5359435317864093\n",
      "  Model: fullModel_dr[3]_replicate4.model | Comparing images 2 and 4: 0.4878255458775945\n",
      "  Model: fullModel_dr[3]_replicate4.model | Comparing images 2 and 5: 0.5088108786005902\n",
      "  Model: fullModel_dr[3]_replicate4.model | Comparing images 3 and 4: 0.6231956763915811\n",
      "  Model: fullModel_dr[3]_replicate4.model | Comparing images 3 and 5: 0.7792944095998083\n",
      "  Model: fullModel_dr[3]_replicate4.model | Comparing images 4 and 5: 0.5809523948872051\n",
      "Mean correlation coefficient for delay range 3: 0.29896406445318396\n",
      "Processing delay range: 4\n",
      "  Processing model: fullModel_dr[4]_replicate0.model\n",
      "  Model: fullModel_dr[4]_replicate0.model | Comparing images 1 and 2: -0.0940807303100532\n",
      "  Model: fullModel_dr[4]_replicate0.model | Comparing images 1 and 3: -0.14078293886977822\n",
      "  Model: fullModel_dr[4]_replicate0.model | Comparing images 1 and 4: -0.1993282658499291\n",
      "  Model: fullModel_dr[4]_replicate0.model | Comparing images 1 and 5: -0.15125968371904794\n",
      "  Model: fullModel_dr[4]_replicate0.model | Comparing images 2 and 3: 0.337555266707331\n",
      "  Model: fullModel_dr[4]_replicate0.model | Comparing images 2 and 4: -0.05289020683732928\n",
      "  Model: fullModel_dr[4]_replicate0.model | Comparing images 2 and 5: -0.00238649276055072\n",
      "  Model: fullModel_dr[4]_replicate0.model | Comparing images 3 and 4: -0.029164402098221437\n",
      "  Model: fullModel_dr[4]_replicate0.model | Comparing images 3 and 5: -0.19726538604081345\n",
      "  Model: fullModel_dr[4]_replicate0.model | Comparing images 4 and 5: -0.2638486491682661\n",
      "  Processing model: fullModel_dr[4]_replicate1.model\n",
      "  Model: fullModel_dr[4]_replicate1.model | Comparing images 1 and 2: 0.5091517513913763\n",
      "  Model: fullModel_dr[4]_replicate1.model | Comparing images 1 and 3: 0.6255876361363094\n",
      "  Model: fullModel_dr[4]_replicate1.model | Comparing images 1 and 4: 0.2640130765250266\n",
      "  Model: fullModel_dr[4]_replicate1.model | Comparing images 1 and 5: 0.41782371103152083\n",
      "  Model: fullModel_dr[4]_replicate1.model | Comparing images 2 and 3: 0.4677173342701738\n",
      "  Model: fullModel_dr[4]_replicate1.model | Comparing images 2 and 4: 0.3488696661863131\n",
      "  Model: fullModel_dr[4]_replicate1.model | Comparing images 2 and 5: 0.43895512485465527\n",
      "  Model: fullModel_dr[4]_replicate1.model | Comparing images 3 and 4: 0.2406585255570044\n",
      "  Model: fullModel_dr[4]_replicate1.model | Comparing images 3 and 5: 0.3607820817534668\n",
      "  Model: fullModel_dr[4]_replicate1.model | Comparing images 4 and 5: 0.5679070242021422\n",
      "  Processing model: fullModel_dr[4]_replicate2.model\n",
      "  Model: fullModel_dr[4]_replicate2.model | Comparing images 1 and 2: 0.6478659888655496\n",
      "  Model: fullModel_dr[4]_replicate2.model | Comparing images 1 and 3: 0.5877711246576702\n",
      "  Model: fullModel_dr[4]_replicate2.model | Comparing images 1 and 4: 0.6124684086951097\n",
      "  Model: fullModel_dr[4]_replicate2.model | Comparing images 1 and 5: 0.5474975077558353\n",
      "  Model: fullModel_dr[4]_replicate2.model | Comparing images 2 and 3: 0.8704816471274546\n",
      "  Model: fullModel_dr[4]_replicate2.model | Comparing images 2 and 4: 0.5101041278997832\n",
      "  Model: fullModel_dr[4]_replicate2.model | Comparing images 2 and 5: 0.47966274076012705\n",
      "  Model: fullModel_dr[4]_replicate2.model | Comparing images 3 and 4: 0.46231884573562665\n",
      "  Model: fullModel_dr[4]_replicate2.model | Comparing images 3 and 5: 0.506861237570644\n",
      "  Model: fullModel_dr[4]_replicate2.model | Comparing images 4 and 5: 0.80793898938296\n",
      "  Processing model: fullModel_dr[4]_replicate3.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model: fullModel_dr[4]_replicate3.model | Comparing images 1 and 2: 0.5664219574294745\n",
      "  Model: fullModel_dr[4]_replicate3.model | Comparing images 1 and 3: 0.5946647259944191\n",
      "  Model: fullModel_dr[4]_replicate3.model | Comparing images 1 and 4: 0.4341290261218774\n",
      "  Model: fullModel_dr[4]_replicate3.model | Comparing images 1 and 5: 0.3417908126900322\n",
      "  Model: fullModel_dr[4]_replicate3.model | Comparing images 2 and 3: 0.7510882942579744\n",
      "  Model: fullModel_dr[4]_replicate3.model | Comparing images 2 and 4: 0.47758808476451536\n",
      "  Model: fullModel_dr[4]_replicate3.model | Comparing images 2 and 5: 0.4155131115283076\n",
      "  Model: fullModel_dr[4]_replicate3.model | Comparing images 3 and 4: 0.6590404566614837\n",
      "  Model: fullModel_dr[4]_replicate3.model | Comparing images 3 and 5: 0.45150889000713773\n",
      "  Model: fullModel_dr[4]_replicate3.model | Comparing images 4 and 5: 0.49886258650593995\n",
      "  Processing model: fullModel_dr[4]_replicate4.model\n",
      "  Model: fullModel_dr[4]_replicate4.model | Comparing images 1 and 2: 0.33712781948234727\n",
      "  Model: fullModel_dr[4]_replicate4.model | Comparing images 1 and 3: 0.18497562616097737\n",
      "  Model: fullModel_dr[4]_replicate4.model | Comparing images 1 and 4: 0.1392281998451318\n",
      "  Model: fullModel_dr[4]_replicate4.model | Comparing images 1 and 5: 0.11915344174952133\n",
      "  Model: fullModel_dr[4]_replicate4.model | Comparing images 2 and 3: 0.6819538362005716\n",
      "  Model: fullModel_dr[4]_replicate4.model | Comparing images 2 and 4: 0.4881325475154173\n",
      "  Model: fullModel_dr[4]_replicate4.model | Comparing images 2 and 5: 0.33524491853499716\n",
      "  Model: fullModel_dr[4]_replicate4.model | Comparing images 3 and 4: 0.8172243606315981\n",
      "  Model: fullModel_dr[4]_replicate4.model | Comparing images 3 and 5: 0.6812654175124008\n",
      "  Model: fullModel_dr[4]_replicate4.model | Comparing images 4 and 5: 0.8671097088487894\n",
      "Mean correlation coefficient for delay range 4: 0.4317004479032597\n",
      "Processing delay range: 5\n",
      "  Processing model: fullModel_dr[5]_replicate0.model\n",
      "  Model: fullModel_dr[5]_replicate0.model | Comparing images 1 and 2: 0.07855595246595931\n",
      "  Model: fullModel_dr[5]_replicate0.model | Comparing images 1 and 3: -0.012158694783443212\n",
      "  Model: fullModel_dr[5]_replicate0.model | Comparing images 1 and 4: -0.24506063644667445\n",
      "  Model: fullModel_dr[5]_replicate0.model | Comparing images 1 and 5: -0.2305365998609467\n",
      "  Model: fullModel_dr[5]_replicate0.model | Comparing images 2 and 3: -0.058661902441741916\n",
      "  Model: fullModel_dr[5]_replicate0.model | Comparing images 2 and 4: 0.04014905041647874\n",
      "  Model: fullModel_dr[5]_replicate0.model | Comparing images 2 and 5: -0.08595340779990204\n",
      "  Model: fullModel_dr[5]_replicate0.model | Comparing images 3 and 4: -0.06936163067705005\n",
      "  Model: fullModel_dr[5]_replicate0.model | Comparing images 3 and 5: -0.0438358414399217\n",
      "  Model: fullModel_dr[5]_replicate0.model | Comparing images 4 and 5: 0.08712638371924789\n",
      "  Processing model: fullModel_dr[5]_replicate1.model\n",
      "  Model: fullModel_dr[5]_replicate1.model | Comparing images 1 and 2: 0.15675820188892006\n",
      "  Model: fullModel_dr[5]_replicate1.model | Comparing images 1 and 3: 0.0064634481944862675\n",
      "  Model: fullModel_dr[5]_replicate1.model | Comparing images 1 and 4: 0.18077067884061906\n",
      "  Model: fullModel_dr[5]_replicate1.model | Comparing images 1 and 5: 0.07644484898183324\n",
      "  Model: fullModel_dr[5]_replicate1.model | Comparing images 2 and 3: 0.2634231959810342\n",
      "  Model: fullModel_dr[5]_replicate1.model | Comparing images 2 and 4: 0.04990574017224862\n",
      "  Model: fullModel_dr[5]_replicate1.model | Comparing images 2 and 5: -0.08059544007773708\n",
      "  Model: fullModel_dr[5]_replicate1.model | Comparing images 3 and 4: 0.5365752237504674\n",
      "  Model: fullModel_dr[5]_replicate1.model | Comparing images 3 and 5: 0.5269854703972474\n",
      "  Model: fullModel_dr[5]_replicate1.model | Comparing images 4 and 5: 0.6597713811832049\n",
      "  Processing model: fullModel_dr[5]_replicate2.model\n",
      "  Model: fullModel_dr[5]_replicate2.model | Comparing images 1 and 2: 0.00036283638213400674\n",
      "  Model: fullModel_dr[5]_replicate2.model | Comparing images 1 and 3: 0.2726033846243228\n",
      "  Model: fullModel_dr[5]_replicate2.model | Comparing images 1 and 4: -0.03273896295146268\n",
      "  Model: fullModel_dr[5]_replicate2.model | Comparing images 1 and 5: 0.15447762616201663\n",
      "  Model: fullModel_dr[5]_replicate2.model | Comparing images 2 and 3: -0.21171220164673432\n",
      "  Model: fullModel_dr[5]_replicate2.model | Comparing images 2 and 4: -0.08193248711439012\n",
      "  Model: fullModel_dr[5]_replicate2.model | Comparing images 2 and 5: -0.05681248657181449\n",
      "  Model: fullModel_dr[5]_replicate2.model | Comparing images 3 and 4: 0.1464868446770855\n",
      "  Model: fullModel_dr[5]_replicate2.model | Comparing images 3 and 5: 0.23597257896645826\n",
      "  Model: fullModel_dr[5]_replicate2.model | Comparing images 4 and 5: 0.054711287814732786\n",
      "  Processing model: fullModel_dr[5]_replicate3.model\n",
      "  Model: fullModel_dr[5]_replicate3.model | Comparing images 1 and 2: 0.03202206987035689\n",
      "  Model: fullModel_dr[5]_replicate3.model | Comparing images 1 and 3: -0.004312396587787857\n",
      "  Model: fullModel_dr[5]_replicate3.model | Comparing images 1 and 4: 0.18491508643820387\n",
      "  Model: fullModel_dr[5]_replicate3.model | Comparing images 1 and 5: -0.017011450318950884\n",
      "  Model: fullModel_dr[5]_replicate3.model | Comparing images 2 and 3: -0.03147273865219732\n",
      "  Model: fullModel_dr[5]_replicate3.model | Comparing images 2 and 4: 0.22513246640791978\n",
      "  Model: fullModel_dr[5]_replicate3.model | Comparing images 2 and 5: 0.01705208584425859\n",
      "  Model: fullModel_dr[5]_replicate3.model | Comparing images 3 and 4: -0.23256320070736344\n",
      "  Model: fullModel_dr[5]_replicate3.model | Comparing images 3 and 5: 0.20246099202063383\n",
      "  Model: fullModel_dr[5]_replicate3.model | Comparing images 4 and 5: 0.020382470342884883\n",
      "  Processing model: fullModel_dr[5]_replicate4.model\n",
      "  Model: fullModel_dr[5]_replicate4.model | Comparing images 1 and 2: 0.13474597356387602\n",
      "  Model: fullModel_dr[5]_replicate4.model | Comparing images 1 and 3: -0.19309362375600328\n",
      "  Model: fullModel_dr[5]_replicate4.model | Comparing images 1 and 4: -0.21664485061054567\n",
      "  Model: fullModel_dr[5]_replicate4.model | Comparing images 1 and 5: -0.2466527211856909\n",
      "  Model: fullModel_dr[5]_replicate4.model | Comparing images 2 and 3: -0.018937107101334335\n",
      "  Model: fullModel_dr[5]_replicate4.model | Comparing images 2 and 4: -0.16912764169263592\n",
      "  Model: fullModel_dr[5]_replicate4.model | Comparing images 2 and 5: 0.01345261704291378\n",
      "  Model: fullModel_dr[5]_replicate4.model | Comparing images 3 and 4: -0.49845971131371253\n",
      "  Model: fullModel_dr[5]_replicate4.model | Comparing images 3 and 5: 0.2179951218466566\n",
      "  Model: fullModel_dr[5]_replicate4.model | Comparing images 4 and 5: -0.04670020576785259\n",
      "Mean correlation coefficient for delay range 5: 0.1492007791500419\n",
      "Mean correlation coefficients for all delay ranges: [0.35774624871096145, 0.30204536171462615, 0.29896406445318396, 0.4317004479032597, 0.1492007791500419]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib.pyplot import figure, imshow, title\n",
    "\n",
    "SEED = 42  # Choose any seed value\n",
    "np.random.seed(SEED)\n",
    "\n",
    "nX, nY, nS, nW = makeNoisyDataset(X, Y, 8, 0.1)\n",
    "\n",
    "# Initialize a list to store mean correlation coefficients for all delay ranges\n",
    "mean_corr_coefs_per_dr_IDR = []\n",
    "\n",
    "# Loop through delay ranges\n",
    "for dr in range(1, 6):\n",
    "    print(f\"Processing delay range: {dr}\")\n",
    "\n",
    "    # Initialize a list to store correlation coefficients for the current delay range\n",
    "    all_corr_coefs_dr_IDR = []\n",
    "\n",
    "    # Loop through all the models in `models`\n",
    "    for key, model in models.items():\n",
    "        if f\"dr[{dr}]\" in key:  # Select models within the current delay range\n",
    "            print(f\"  Processing model: {key}\")\n",
    "\n",
    "            # Initialize a list to store the images for the current model\n",
    "            images_IDR = []\n",
    "\n",
    "            # Loop through the time steps 1 to 5\n",
    "            for ts in [1, 2, 3, 4, 5]:\n",
    "                S, H = shrinkingDecompositionInformation(model, 12, nX, nW.transpose(), whichTS=ts)\n",
    "                I = removalIntoMatrix(S, 12, H)\n",
    "                images_IDR.append(I.flatten())\n",
    "\n",
    "            # Loop through pairs of images, calculate their correlation coefficients, and print the results\n",
    "            for i in range(len(images_IDR) - 1):\n",
    "                for j in range(i + 1, len(images_IDR)):\n",
    "                    corr_coef_IDR = np.corrcoef(images_IDR[i], images_IDR[j])[0, 1]\n",
    "                    all_corr_coefs_dr_IDR.append(abs(corr_coef_IDR))\n",
    "                    print(f\"  Model: {key} | Comparing images {i + 1} and {j + 1}: {corr_coef_IDR}\")\n",
    "\n",
    "    # Calculate the mean correlation coefficient for the current delay range\n",
    "    mean_corr_coef_dr_IDR = np.mean(all_corr_coefs_dr_IDR)\n",
    "    mean_corr_coefs_per_dr_IDR.append(mean_corr_coef_dr_IDR)\n",
    "    print(f\"Mean correlation coefficient for delay range {dr}: {mean_corr_coef_dr_IDR}\")\n",
    "\n",
    "print(f\"Mean correlation coefficients for all delay ranges: {mean_corr_coefs_per_dr_IDR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d158be39",
   "metadata": {},
   "source": [
    "# Euclidean Distance Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f63292a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing delay range: 1\n",
      "  Processing model: fullModel_dr[1]_replicate0.model\n",
      "  Model: fullModel_dr[1]_replicate0.model | Comparing images 1 and 2: 1.6153799126315402\n",
      "  Model: fullModel_dr[1]_replicate0.model | Comparing images 1 and 3: 2.0114564849397336\n",
      "  Model: fullModel_dr[1]_replicate0.model | Comparing images 1 and 4: 2.024358068365275\n",
      "  Model: fullModel_dr[1]_replicate0.model | Comparing images 1 and 5: 1.6446822432776405\n",
      "  Model: fullModel_dr[1]_replicate0.model | Comparing images 2 and 3: 1.7330717174817887\n",
      "  Model: fullModel_dr[1]_replicate0.model | Comparing images 2 and 4: 1.7318229176159303\n",
      "  Model: fullModel_dr[1]_replicate0.model | Comparing images 2 and 5: 2.1303498494390767\n",
      "  Model: fullModel_dr[1]_replicate0.model | Comparing images 3 and 4: 0.7347435500424268\n",
      "  Model: fullModel_dr[1]_replicate0.model | Comparing images 3 and 5: 1.797926015648742\n",
      "  Model: fullModel_dr[1]_replicate0.model | Comparing images 4 and 5: 1.8109544310175485\n",
      "  Processing model: fullModel_dr[1]_replicate1.model\n",
      "  Model: fullModel_dr[1]_replicate1.model | Comparing images 1 and 2: 1.6576212066539993\n",
      "  Model: fullModel_dr[1]_replicate1.model | Comparing images 1 and 3: 2.38051827189207\n",
      "  Model: fullModel_dr[1]_replicate1.model | Comparing images 1 and 4: 2.9410576740550898\n",
      "  Model: fullModel_dr[1]_replicate1.model | Comparing images 1 and 5: 2.5122854419822964\n",
      "  Model: fullModel_dr[1]_replicate1.model | Comparing images 2 and 3: 1.9276624782868244\n",
      "  Model: fullModel_dr[1]_replicate1.model | Comparing images 2 and 4: 2.4487690910654236\n",
      "  Model: fullModel_dr[1]_replicate1.model | Comparing images 2 and 5: 2.0491307522597415\n",
      "  Model: fullModel_dr[1]_replicate1.model | Comparing images 3 and 4: 2.0308363230802318\n",
      "  Model: fullModel_dr[1]_replicate1.model | Comparing images 3 and 5: 1.636126264761721\n",
      "  Model: fullModel_dr[1]_replicate1.model | Comparing images 4 and 5: 2.1743578295966928\n",
      "  Processing model: fullModel_dr[1]_replicate2.model\n",
      "  Model: fullModel_dr[1]_replicate2.model | Comparing images 1 and 2: 1.3709931944015628\n",
      "  Model: fullModel_dr[1]_replicate2.model | Comparing images 1 and 3: 1.309391802387935\n",
      "  Model: fullModel_dr[1]_replicate2.model | Comparing images 1 and 4: 1.0638794771854545\n",
      "  Model: fullModel_dr[1]_replicate2.model | Comparing images 1 and 5: 1.1457353184242987\n",
      "  Model: fullModel_dr[1]_replicate2.model | Comparing images 2 and 3: 1.1021736623825105\n",
      "  Model: fullModel_dr[1]_replicate2.model | Comparing images 2 and 4: 1.5065864242639724\n",
      "  Model: fullModel_dr[1]_replicate2.model | Comparing images 2 and 5: 1.2897554085887755\n",
      "  Model: fullModel_dr[1]_replicate2.model | Comparing images 3 and 4: 1.051334353954524\n",
      "  Model: fullModel_dr[1]_replicate2.model | Comparing images 3 and 5: 1.6458126443690548\n",
      "  Model: fullModel_dr[1]_replicate2.model | Comparing images 4 and 5: 1.4957283306108764\n",
      "  Processing model: fullModel_dr[1]_replicate3.model\n",
      "  Model: fullModel_dr[1]_replicate3.model | Comparing images 1 and 2: 1.6422954636622444\n",
      "  Model: fullModel_dr[1]_replicate3.model | Comparing images 1 and 3: 1.3291626247349067\n",
      "  Model: fullModel_dr[1]_replicate3.model | Comparing images 1 and 4: 1.771121021948455\n",
      "  Model: fullModel_dr[1]_replicate3.model | Comparing images 1 and 5: 1.344505593727792\n",
      "  Model: fullModel_dr[1]_replicate3.model | Comparing images 2 and 3: 1.5769342786421048\n",
      "  Model: fullModel_dr[1]_replicate3.model | Comparing images 2 and 4: 2.062683070644758\n",
      "  Model: fullModel_dr[1]_replicate3.model | Comparing images 2 and 5: 1.4638826206414222\n",
      "  Model: fullModel_dr[1]_replicate3.model | Comparing images 3 and 4: 1.4675644303140272\n",
      "  Model: fullModel_dr[1]_replicate3.model | Comparing images 3 and 5: 1.291750037532908\n",
      "  Model: fullModel_dr[1]_replicate3.model | Comparing images 4 and 5: 1.7174725850332677\n",
      "  Processing model: fullModel_dr[1]_replicate4.model\n",
      "  Model: fullModel_dr[1]_replicate4.model | Comparing images 1 and 2: 2.3287337093067086\n",
      "  Model: fullModel_dr[1]_replicate4.model | Comparing images 1 and 3: 2.6287387594833587\n",
      "  Model: fullModel_dr[1]_replicate4.model | Comparing images 1 and 4: 2.6304739000033353\n",
      "  Model: fullModel_dr[1]_replicate4.model | Comparing images 1 and 5: 3.062692433618909\n",
      "  Model: fullModel_dr[1]_replicate4.model | Comparing images 2 and 3: 2.8347360243379405\n",
      "  Model: fullModel_dr[1]_replicate4.model | Comparing images 2 and 4: 3.1426800145271097\n",
      "  Model: fullModel_dr[1]_replicate4.model | Comparing images 2 and 5: 2.9239506810018527\n",
      "  Model: fullModel_dr[1]_replicate4.model | Comparing images 3 and 4: 2.446000755883433\n",
      "  Model: fullModel_dr[1]_replicate4.model | Comparing images 3 and 5: 2.8325320561785428\n",
      "  Model: fullModel_dr[1]_replicate4.model | Comparing images 4 and 5: 2.714131411617714\n",
      "Mean Euclidean distance for delay range 1: 1.9037308522700707\n",
      "Processing delay range: 2\n",
      "  Processing model: fullModel_dr[2]_replicate0.model\n",
      "  Model: fullModel_dr[2]_replicate0.model | Comparing images 1 and 2: 2.449952091042692\n",
      "  Model: fullModel_dr[2]_replicate0.model | Comparing images 1 and 3: 2.603642887852167\n",
      "  Model: fullModel_dr[2]_replicate0.model | Comparing images 1 and 4: 3.031717235027399\n",
      "  Model: fullModel_dr[2]_replicate0.model | Comparing images 1 and 5: 2.960952998530085\n",
      "  Model: fullModel_dr[2]_replicate0.model | Comparing images 2 and 3: 2.897033298804157\n",
      "  Model: fullModel_dr[2]_replicate0.model | Comparing images 2 and 4: 3.117449921836697\n",
      "  Model: fullModel_dr[2]_replicate0.model | Comparing images 2 and 5: 3.335643864863415\n",
      "  Model: fullModel_dr[2]_replicate0.model | Comparing images 3 and 4: 2.4207699820026414\n",
      "  Model: fullModel_dr[2]_replicate0.model | Comparing images 3 and 5: 2.4767015534492165\n",
      "  Model: fullModel_dr[2]_replicate0.model | Comparing images 4 and 5: 2.1141872864823426\n",
      "  Processing model: fullModel_dr[2]_replicate1.model\n",
      "  Model: fullModel_dr[2]_replicate1.model | Comparing images 1 and 2: 2.7913231695227103\n",
      "  Model: fullModel_dr[2]_replicate1.model | Comparing images 1 and 3: 2.832156743938937\n",
      "  Model: fullModel_dr[2]_replicate1.model | Comparing images 1 and 4: 2.365296918549183\n",
      "  Model: fullModel_dr[2]_replicate1.model | Comparing images 1 and 5: 2.8698669542743422\n",
      "  Model: fullModel_dr[2]_replicate1.model | Comparing images 2 and 3: 2.485085031248902\n",
      "  Model: fullModel_dr[2]_replicate1.model | Comparing images 2 and 4: 2.7700146793028018\n",
      "  Model: fullModel_dr[2]_replicate1.model | Comparing images 2 and 5: 3.060527500362504\n",
      "  Model: fullModel_dr[2]_replicate1.model | Comparing images 3 and 4: 2.47392162777484\n",
      "  Model: fullModel_dr[2]_replicate1.model | Comparing images 3 and 5: 2.2083545333400787\n",
      "  Model: fullModel_dr[2]_replicate1.model | Comparing images 4 and 5: 2.262875651618713\n",
      "  Processing model: fullModel_dr[2]_replicate2.model\n",
      "  Model: fullModel_dr[2]_replicate2.model | Comparing images 1 and 2: 2.441389095765565\n",
      "  Model: fullModel_dr[2]_replicate2.model | Comparing images 1 and 3: 2.580903519559792\n",
      "  Model: fullModel_dr[2]_replicate2.model | Comparing images 1 and 4: 2.444225431782482\n",
      "  Model: fullModel_dr[2]_replicate2.model | Comparing images 1 and 5: 2.4121234053454055\n",
      "  Model: fullModel_dr[2]_replicate2.model | Comparing images 2 and 3: 2.1780355096039794\n",
      "  Model: fullModel_dr[2]_replicate2.model | Comparing images 2 and 4: 2.4846975430130045\n",
      "  Model: fullModel_dr[2]_replicate2.model | Comparing images 2 and 5: 2.402505172453617\n",
      "  Model: fullModel_dr[2]_replicate2.model | Comparing images 3 and 4: 2.097929566020144\n",
      "  Model: fullModel_dr[2]_replicate2.model | Comparing images 3 and 5: 1.7355045012483457\n",
      "  Model: fullModel_dr[2]_replicate2.model | Comparing images 4 and 5: 1.9762552559655402\n",
      "  Processing model: fullModel_dr[2]_replicate3.model\n",
      "  Model: fullModel_dr[2]_replicate3.model | Comparing images 1 and 2: 2.0837621586740216\n",
      "  Model: fullModel_dr[2]_replicate3.model | Comparing images 1 and 3: 2.4193902628835007\n",
      "  Model: fullModel_dr[2]_replicate3.model | Comparing images 1 and 4: 3.1581061316895314\n",
      "  Model: fullModel_dr[2]_replicate3.model | Comparing images 1 and 5: 3.029766271570626\n",
      "  Model: fullModel_dr[2]_replicate3.model | Comparing images 2 and 3: 2.034784861479582\n",
      "  Model: fullModel_dr[2]_replicate3.model | Comparing images 2 and 4: 2.4896633508613455\n",
      "  Model: fullModel_dr[2]_replicate3.model | Comparing images 2 and 5: 2.964093510216422\n",
      "  Model: fullModel_dr[2]_replicate3.model | Comparing images 3 and 4: 2.1217259074784844\n",
      "  Model: fullModel_dr[2]_replicate3.model | Comparing images 3 and 5: 2.6232562573581677\n",
      "  Model: fullModel_dr[2]_replicate3.model | Comparing images 4 and 5: 2.3605342069774395\n",
      "  Processing model: fullModel_dr[2]_replicate4.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model: fullModel_dr[2]_replicate4.model | Comparing images 1 and 2: 1.3122279030174158\n",
      "  Model: fullModel_dr[2]_replicate4.model | Comparing images 1 and 3: 1.238692382445519\n",
      "  Model: fullModel_dr[2]_replicate4.model | Comparing images 1 and 4: 1.444520377329322\n",
      "  Model: fullModel_dr[2]_replicate4.model | Comparing images 1 and 5: 1.578537789225649\n",
      "  Model: fullModel_dr[2]_replicate4.model | Comparing images 2 and 3: 1.4543500945062056\n",
      "  Model: fullModel_dr[2]_replicate4.model | Comparing images 2 and 4: 1.5348956110500946\n",
      "  Model: fullModel_dr[2]_replicate4.model | Comparing images 2 and 5: 1.6771587330098319\n",
      "  Model: fullModel_dr[2]_replicate4.model | Comparing images 3 and 4: 0.9493522376535973\n",
      "  Model: fullModel_dr[2]_replicate4.model | Comparing images 3 and 5: 1.0627747382180734\n",
      "  Model: fullModel_dr[2]_replicate4.model | Comparing images 4 and 5: 1.1657936537597802\n",
      "Mean Euclidean distance for delay range 2: 2.299688587399726\n",
      "Processing delay range: 3\n",
      "  Processing model: fullModel_dr[3]_replicate0.model\n",
      "  Model: fullModel_dr[3]_replicate0.model | Comparing images 1 and 2: 2.770698359229991\n",
      "  Model: fullModel_dr[3]_replicate0.model | Comparing images 1 and 3: 3.2355086806209155\n",
      "  Model: fullModel_dr[3]_replicate0.model | Comparing images 1 and 4: 3.1031783943904063\n",
      "  Model: fullModel_dr[3]_replicate0.model | Comparing images 1 and 5: 3.281843709399559\n",
      "  Model: fullModel_dr[3]_replicate0.model | Comparing images 2 and 3: 3.398988268327671\n",
      "  Model: fullModel_dr[3]_replicate0.model | Comparing images 2 and 4: 3.226686060030711\n",
      "  Model: fullModel_dr[3]_replicate0.model | Comparing images 2 and 5: 3.4662798919261526\n",
      "  Model: fullModel_dr[3]_replicate0.model | Comparing images 3 and 4: 3.030137154248628\n",
      "  Model: fullModel_dr[3]_replicate0.model | Comparing images 3 and 5: 3.0798881542399603\n",
      "  Model: fullModel_dr[3]_replicate0.model | Comparing images 4 and 5: 3.2585642591846002\n",
      "  Processing model: fullModel_dr[3]_replicate1.model\n",
      "  Model: fullModel_dr[3]_replicate1.model | Comparing images 1 and 2: 1.8723875531705434\n",
      "  Model: fullModel_dr[3]_replicate1.model | Comparing images 1 and 3: 2.5019363702646555\n",
      "  Model: fullModel_dr[3]_replicate1.model | Comparing images 1 and 4: 2.6247775837620906\n",
      "  Model: fullModel_dr[3]_replicate1.model | Comparing images 1 and 5: 2.7393085968227293\n",
      "  Model: fullModel_dr[3]_replicate1.model | Comparing images 2 and 3: 2.1396387589709707\n",
      "  Model: fullModel_dr[3]_replicate1.model | Comparing images 2 and 4: 2.33822885624089\n",
      "  Model: fullModel_dr[3]_replicate1.model | Comparing images 2 and 5: 3.2509727684317644\n",
      "  Model: fullModel_dr[3]_replicate1.model | Comparing images 3 and 4: 2.644997489107272\n",
      "  Model: fullModel_dr[3]_replicate1.model | Comparing images 3 and 5: 3.158213933707076\n",
      "  Model: fullModel_dr[3]_replicate1.model | Comparing images 4 and 5: 3.157924069236271\n",
      "  Processing model: fullModel_dr[3]_replicate2.model\n",
      "  Model: fullModel_dr[3]_replicate2.model | Comparing images 1 and 2: 2.5138788777974725\n",
      "  Model: fullModel_dr[3]_replicate2.model | Comparing images 1 and 3: 2.979807443401274\n",
      "  Model: fullModel_dr[3]_replicate2.model | Comparing images 1 and 4: 3.5083174379328583\n",
      "  Model: fullModel_dr[3]_replicate2.model | Comparing images 1 and 5: 3.2038836098125443\n",
      "  Model: fullModel_dr[3]_replicate2.model | Comparing images 2 and 3: 2.669661392634836\n",
      "  Model: fullModel_dr[3]_replicate2.model | Comparing images 2 and 4: 3.3819307959385907\n",
      "  Model: fullModel_dr[3]_replicate2.model | Comparing images 2 and 5: 3.035550932762938\n",
      "  Model: fullModel_dr[3]_replicate2.model | Comparing images 3 and 4: 2.525650809689083\n",
      "  Model: fullModel_dr[3]_replicate2.model | Comparing images 3 and 5: 2.9998830856757723\n",
      "  Model: fullModel_dr[3]_replicate2.model | Comparing images 4 and 5: 2.7503684379609563\n",
      "  Processing model: fullModel_dr[3]_replicate3.model\n",
      "  Model: fullModel_dr[3]_replicate3.model | Comparing images 1 and 2: 2.2298279596662245\n",
      "  Model: fullModel_dr[3]_replicate3.model | Comparing images 1 and 3: 2.2109446919377778\n",
      "  Model: fullModel_dr[3]_replicate3.model | Comparing images 1 and 4: 3.215297402517547\n",
      "  Model: fullModel_dr[3]_replicate3.model | Comparing images 1 and 5: 3.1179181230514126\n",
      "  Model: fullModel_dr[3]_replicate3.model | Comparing images 2 and 3: 2.35893988108545\n",
      "  Model: fullModel_dr[3]_replicate3.model | Comparing images 2 and 4: 2.9107073816506923\n",
      "  Model: fullModel_dr[3]_replicate3.model | Comparing images 2 and 5: 2.6854009032846426\n",
      "  Model: fullModel_dr[3]_replicate3.model | Comparing images 3 and 4: 2.977226614528813\n",
      "  Model: fullModel_dr[3]_replicate3.model | Comparing images 3 and 5: 2.5093041127806246\n",
      "  Model: fullModel_dr[3]_replicate3.model | Comparing images 4 and 5: 2.078110459888782\n",
      "  Processing model: fullModel_dr[3]_replicate4.model\n",
      "  Model: fullModel_dr[3]_replicate4.model | Comparing images 1 and 2: 2.207565173763\n",
      "  Model: fullModel_dr[3]_replicate4.model | Comparing images 1 and 3: 2.5439517600923187\n",
      "  Model: fullModel_dr[3]_replicate4.model | Comparing images 1 and 4: 2.692163109990966\n",
      "  Model: fullModel_dr[3]_replicate4.model | Comparing images 1 and 5: 3.0434695178840974\n",
      "  Model: fullModel_dr[3]_replicate4.model | Comparing images 2 and 3: 2.034782077524487\n",
      "  Model: fullModel_dr[3]_replicate4.model | Comparing images 2 and 4: 2.311660362064677\n",
      "  Model: fullModel_dr[3]_replicate4.model | Comparing images 2 and 5: 2.2981667323328514\n",
      "  Model: fullModel_dr[3]_replicate4.model | Comparing images 3 and 4: 1.9864839921503321\n",
      "  Model: fullModel_dr[3]_replicate4.model | Comparing images 3 and 5: 1.5791752585187635\n",
      "  Model: fullModel_dr[3]_replicate4.model | Comparing images 4 and 5: 2.1599235411794053\n",
      "Mean Euclidean distance for delay range 3: 2.7400022158162414\n",
      "Processing delay range: 4\n",
      "  Processing model: fullModel_dr[4]_replicate0.model\n",
      "  Model: fullModel_dr[4]_replicate0.model | Comparing images 1 and 2: 1.2165437637071137\n",
      "  Model: fullModel_dr[4]_replicate0.model | Comparing images 1 and 3: 1.2198791605402448\n",
      "  Model: fullModel_dr[4]_replicate0.model | Comparing images 1 and 4: 1.3127175555003403\n",
      "  Model: fullModel_dr[4]_replicate0.model | Comparing images 1 and 5: 1.234500535887434\n",
      "  Model: fullModel_dr[4]_replicate0.model | Comparing images 2 and 3: 0.5686481778804359\n",
      "  Model: fullModel_dr[4]_replicate0.model | Comparing images 2 and 4: 0.8613862740582434\n",
      "  Model: fullModel_dr[4]_replicate0.model | Comparing images 2 and 5: 0.825449028126431\n",
      "  Model: fullModel_dr[4]_replicate0.model | Comparing images 3 and 4: 0.8270098973329306\n",
      "  Model: fullModel_dr[4]_replicate0.model | Comparing images 3 and 5: 0.8747585809772515\n",
      "  Model: fullModel_dr[4]_replicate0.model | Comparing images 4 and 5: 0.9690407321547023\n",
      "  Processing model: fullModel_dr[4]_replicate1.model\n",
      "  Model: fullModel_dr[4]_replicate1.model | Comparing images 1 and 2: 1.9643612941007091\n",
      "  Model: fullModel_dr[4]_replicate1.model | Comparing images 1 and 3: 1.8555804755221434\n",
      "  Model: fullModel_dr[4]_replicate1.model | Comparing images 1 and 4: 2.5426325836228685\n",
      "  Model: fullModel_dr[4]_replicate1.model | Comparing images 1 and 5: 2.2401585437261975\n",
      "  Model: fullModel_dr[4]_replicate1.model | Comparing images 2 and 3: 2.1052641381337094\n",
      "  Model: fullModel_dr[4]_replicate1.model | Comparing images 2 and 4: 2.2469172518125755\n",
      "  Model: fullModel_dr[4]_replicate1.model | Comparing images 2 and 5: 2.0796871386476345\n",
      "  Model: fullModel_dr[4]_replicate1.model | Comparing images 3 and 4: 2.5891086486607215\n",
      "  Model: fullModel_dr[4]_replicate1.model | Comparing images 3 and 5: 2.3794289662970285\n",
      "  Model: fullModel_dr[4]_replicate1.model | Comparing images 4 and 5: 1.8791559280915158\n",
      "  Processing model: fullModel_dr[4]_replicate2.model\n",
      "  Model: fullModel_dr[4]_replicate2.model | Comparing images 1 and 2: 1.6204591917728874\n",
      "  Model: fullModel_dr[4]_replicate2.model | Comparing images 1 and 3: 1.7799220880806528\n",
      "  Model: fullModel_dr[4]_replicate2.model | Comparing images 1 and 4: 1.8149940908049351\n",
      "  Model: fullModel_dr[4]_replicate2.model | Comparing images 1 and 5: 1.8877670195963494\n",
      "  Model: fullModel_dr[4]_replicate2.model | Comparing images 2 and 3: 0.9846732487606946\n",
      "  Model: fullModel_dr[4]_replicate2.model | Comparing images 2 and 4: 1.8988227274868636\n",
      "  Model: fullModel_dr[4]_replicate2.model | Comparing images 2 and 5: 1.9083100079458717\n",
      "  Model: fullModel_dr[4]_replicate2.model | Comparing images 3 and 4: 1.8692189561310866\n",
      "  Model: fullModel_dr[4]_replicate2.model | Comparing images 3 and 5: 1.7669446261218467\n",
      "  Model: fullModel_dr[4]_replicate2.model | Comparing images 4 and 5: 1.1784800307899217\n",
      "  Processing model: fullModel_dr[4]_replicate3.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model: fullModel_dr[4]_replicate3.model | Comparing images 1 and 2: 2.1623434118555425\n",
      "  Model: fullModel_dr[4]_replicate3.model | Comparing images 1 and 3: 2.1933147124194328\n",
      "  Model: fullModel_dr[4]_replicate3.model | Comparing images 1 and 4: 2.5623837706748254\n",
      "  Model: fullModel_dr[4]_replicate3.model | Comparing images 1 and 5: 2.9013526121632376\n",
      "  Model: fullModel_dr[4]_replicate3.model | Comparing images 2 and 3: 1.6449048435609588\n",
      "  Model: fullModel_dr[4]_replicate3.model | Comparing images 2 and 4: 2.3227953834603188\n",
      "  Model: fullModel_dr[4]_replicate3.model | Comparing images 2 and 5: 2.6078750365461545\n",
      "  Model: fullModel_dr[4]_replicate3.model | Comparing images 3 and 4: 1.7675093046334072\n",
      "  Model: fullModel_dr[4]_replicate3.model | Comparing images 3 and 5: 2.3872076576640016\n",
      "  Model: fullModel_dr[4]_replicate3.model | Comparing images 4 and 5: 2.2427698767177815\n",
      "  Processing model: fullModel_dr[4]_replicate4.model\n",
      "  Model: fullModel_dr[4]_replicate4.model | Comparing images 1 and 2: 2.307245427713527\n",
      "  Model: fullModel_dr[4]_replicate4.model | Comparing images 1 and 3: 2.549432553579049\n",
      "  Model: fullModel_dr[4]_replicate4.model | Comparing images 1 and 4: 2.677969640437514\n",
      "  Model: fullModel_dr[4]_replicate4.model | Comparing images 1 and 5: 2.6706798658148894\n",
      "  Model: fullModel_dr[4]_replicate4.model | Comparing images 2 and 3: 1.6087478195028764\n",
      "  Model: fullModel_dr[4]_replicate4.model | Comparing images 2 and 4: 2.077323737728018\n",
      "  Model: fullModel_dr[4]_replicate4.model | Comparing images 2 and 5: 2.3469386327344988\n",
      "  Model: fullModel_dr[4]_replicate4.model | Comparing images 3 and 4: 1.247313531015417\n",
      "  Model: fullModel_dr[4]_replicate4.model | Comparing images 3 and 5: 1.6264483329265422\n",
      "  Model: fullModel_dr[4]_replicate4.model | Comparing images 4 and 5: 1.0761488813317346\n",
      "Mean Euclidean distance for delay range 4: 1.8296505138950212\n",
      "Processing delay range: 5\n",
      "  Processing model: fullModel_dr[5]_replicate0.model\n",
      "  Model: fullModel_dr[5]_replicate0.model | Comparing images 1 and 2: 1.2181073966114722\n",
      "  Model: fullModel_dr[5]_replicate0.model | Comparing images 1 and 3: 1.3644136785919367\n",
      "  Model: fullModel_dr[5]_replicate0.model | Comparing images 1 and 4: 1.3570163632376773\n",
      "  Model: fullModel_dr[5]_replicate0.model | Comparing images 1 and 5: 1.3135414490396438\n",
      "  Model: fullModel_dr[5]_replicate0.model | Comparing images 2 and 3: 1.1216843065877877\n",
      "  Model: fullModel_dr[5]_replicate0.model | Comparing images 2 and 4: 0.8313254029999061\n",
      "  Model: fullModel_dr[5]_replicate0.model | Comparing images 2 and 5: 0.9232073845269749\n",
      "  Model: fullModel_dr[5]_replicate0.model | Comparing images 3 and 4: 1.0912917818116554\n",
      "  Model: fullModel_dr[5]_replicate0.model | Comparing images 3 and 5: 1.0742678657181823\n",
      "  Model: fullModel_dr[5]_replicate0.model | Comparing images 4 and 5: 0.8125366311206442\n",
      "  Processing model: fullModel_dr[5]_replicate1.model\n",
      "  Model: fullModel_dr[5]_replicate1.model | Comparing images 1 and 2: 2.9551413695524498\n",
      "  Model: fullModel_dr[5]_replicate1.model | Comparing images 1 and 3: 3.2294240121360906\n",
      "  Model: fullModel_dr[5]_replicate1.model | Comparing images 1 and 4: 3.3083714157796735\n",
      "  Model: fullModel_dr[5]_replicate1.model | Comparing images 1 and 5: 3.5115775787249115\n",
      "  Model: fullModel_dr[5]_replicate1.model | Comparing images 2 and 3: 2.63350293109393\n",
      "  Model: fullModel_dr[5]_replicate1.model | Comparing images 2 and 4: 3.193880151372785\n",
      "  Model: fullModel_dr[5]_replicate1.model | Comparing images 2 and 5: 3.4433513880847952\n",
      "  Model: fullModel_dr[5]_replicate1.model | Comparing images 3 and 4: 2.1660869888278618\n",
      "  Model: fullModel_dr[5]_replicate1.model | Comparing images 3 and 5: 2.2292467138608862\n",
      "  Model: fullModel_dr[5]_replicate1.model | Comparing images 4 and 5: 1.8541415783411945\n",
      "  Processing model: fullModel_dr[5]_replicate2.model\n",
      "  Model: fullModel_dr[5]_replicate2.model | Comparing images 1 and 2: 0.8825191403926855\n",
      "  Model: fullModel_dr[5]_replicate2.model | Comparing images 1 and 3: 2.422716718557908\n",
      "  Model: fullModel_dr[5]_replicate2.model | Comparing images 1 and 4: 1.4489230848730452\n",
      "  Model: fullModel_dr[5]_replicate2.model | Comparing images 1 and 5: 1.4249242503301038\n",
      "  Model: fullModel_dr[5]_replicate2.model | Comparing images 2 and 3: 2.5799818621548667\n",
      "  Model: fullModel_dr[5]_replicate2.model | Comparing images 2 and 4: 1.4194084808795493\n",
      "  Model: fullModel_dr[5]_replicate2.model | Comparing images 2 and 5: 1.4625241707273227\n",
      "  Model: fullModel_dr[5]_replicate2.model | Comparing images 3 and 4: 2.2692487299243678\n",
      "  Model: fullModel_dr[5]_replicate2.model | Comparing images 3 and 5: 2.1642891907332187\n",
      "  Model: fullModel_dr[5]_replicate2.model | Comparing images 4 and 5: 1.5313829557450533\n",
      "  Processing model: fullModel_dr[5]_replicate3.model\n",
      "  Model: fullModel_dr[5]_replicate3.model | Comparing images 1 and 2: 2.1255797677279693\n",
      "  Model: fullModel_dr[5]_replicate3.model | Comparing images 1 and 3: 2.293932547686302\n",
      "  Model: fullModel_dr[5]_replicate3.model | Comparing images 1 and 4: 2.123902607401822\n",
      "  Model: fullModel_dr[5]_replicate3.model | Comparing images 1 and 5: 2.1151107645063973\n",
      "  Model: fullModel_dr[5]_replicate3.model | Comparing images 2 and 3: 2.1773938012694942\n",
      "  Model: fullModel_dr[5]_replicate3.model | Comparing images 2 and 4: 2.0927455134691284\n",
      "  Model: fullModel_dr[5]_replicate3.model | Comparing images 2 and 5: 1.8784481542882596\n",
      "  Model: fullModel_dr[5]_replicate3.model | Comparing images 3 and 4: 2.6344740580164023\n",
      "  Model: fullModel_dr[5]_replicate3.model | Comparing images 3 and 5: 1.894766282353532\n",
      "  Model: fullModel_dr[5]_replicate3.model | Comparing images 4 and 5: 2.176029508341065\n",
      "  Processing model: fullModel_dr[5]_replicate4.model\n",
      "  Model: fullModel_dr[5]_replicate4.model | Comparing images 1 and 2: 1.3339254426791711\n",
      "  Model: fullModel_dr[5]_replicate4.model | Comparing images 1 and 3: 1.398476508452501\n",
      "  Model: fullModel_dr[5]_replicate4.model | Comparing images 1 and 4: 1.3442938103122637\n",
      "  Model: fullModel_dr[5]_replicate4.model | Comparing images 1 and 5: 1.3700738696438968\n",
      "  Model: fullModel_dr[5]_replicate4.model | Comparing images 2 and 3: 1.6038752609553306\n",
      "  Model: fullModel_dr[5]_replicate4.model | Comparing images 2 and 4: 1.646772426274569\n",
      "  Model: fullModel_dr[5]_replicate4.model | Comparing images 2 and 5: 1.524735025806262\n",
      "  Model: fullModel_dr[5]_replicate4.model | Comparing images 3 and 4: 1.7248103933924819\n",
      "  Model: fullModel_dr[5]_replicate4.model | Comparing images 3 and 5: 1.2578386103365038\n",
      "  Model: fullModel_dr[5]_replicate4.model | Comparing images 4 and 5: 1.381872352022434\n",
      "Mean Euclidean distance for delay range 5: 1.8667418335454875\n",
      "Mean Euclidean distances for all delay ranges: [1.9037308522700707, 2.299688587399726, 2.7400022158162414, 1.8296505138950212, 1.8667418335454875]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib.pyplot import figure, imshow, title\n",
    "\n",
    "def euclidean_distance(a, b):\n",
    "    return np.sqrt(np.sum((a - b) ** 2))\n",
    "\n",
    "SEED = 42  # Choose any seed value\n",
    "np.random.seed(SEED)\n",
    "\n",
    "nX, nY, nS, nW = makeNoisyDataset(X, Y, 8, 0.1)\n",
    "\n",
    "# Initialize a list to store mean Euclidean distances for all delay ranges\n",
    "mean_euclid_dists_per_dr_IDR = []\n",
    "\n",
    "# Loop through delay ranges\n",
    "for dr in range(1, 6):\n",
    "    print(f\"Processing delay range: {dr}\")\n",
    "\n",
    "    # Initialize a list to store Euclidean distances for the current delay range\n",
    "    all_euclid_dists_dr_IDR = []\n",
    "\n",
    "    # Loop through all the models in `models`\n",
    "    for key, model in models.items():\n",
    "        if f\"dr[{dr}]\" in key:  # Select models within the current delay range\n",
    "            print(f\"  Processing model: {key}\")\n",
    "\n",
    "            # Initialize a list to store the images for the current model\n",
    "            images_IDR = []\n",
    "\n",
    "            # Loop through the time steps 1 to 5\n",
    "            for ts in [1, 2, 3, 4, 5]:\n",
    "                S, H = shrinkingDecompositionInformation(model, 12, nX, nW.transpose(), whichTS=ts)\n",
    "                I = removalIntoMatrix(S, 12, H)\n",
    "                images_IDR.append(I.flatten())\n",
    "\n",
    "            # Loop through pairs of images, calculate their Euclidean distances, and print the results\n",
    "            for i in range(len(images_IDR) - 1):\n",
    "                for j in range(i + 1, len(images_IDR)):\n",
    "                    euclid_dist_IDR = euclidean_distance(images_IDR[i], images_IDR[j])\n",
    "                    all_euclid_dists_dr_IDR.append(euclid_dist_IDR)\n",
    "                    print(f\"  Model: {key} | Comparing images {i + 1} and {j + 1}: {euclid_dist_IDR}\")\n",
    "\n",
    "    # Calculate the mean Euclidean distance for the current delay range\n",
    "    mean_euclid_dist_dr_IDR = np.mean(all_euclid_dists_dr_IDR)\n",
    "    mean_euclid_dists_per_dr_IDR.append(mean_euclid_dist_dr_IDR)\n",
    "    print(f\"Mean Euclidean distance for delay range {dr}: {mean_euclid_dist_dr_IDR}\")\n",
    "\n",
    "print(f\"Mean Euclidean distances for all delay ranges: {mean_euclid_dists_per_dr_IDR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86109192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed2279d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing delay range: 1\n",
      "  Processing model: fullModel_dr[1]_replicate0.model\n",
      "  Model: fullModel_dr[1]_replicate0.model | Comparing images 1 and 2: 1.61537991263154\n",
      "  Model: fullModel_dr[1]_replicate0.model | Comparing images 1 and 3: 2.0114564849397336\n",
      "  Model: fullModel_dr[1]_replicate0.model | Comparing images 1 and 4: 2.0243580683652755\n",
      "  Model: fullModel_dr[1]_replicate0.model | Comparing images 1 and 5: 1.6446822432776405\n",
      "  Model: fullModel_dr[1]_replicate0.model | Comparing images 2 and 3: 1.7330717174817885\n",
      "  Model: fullModel_dr[1]_replicate0.model | Comparing images 2 and 4: 1.7318229176159303\n",
      "  Model: fullModel_dr[1]_replicate0.model | Comparing images 2 and 5: 2.130349849439077\n",
      "  Model: fullModel_dr[1]_replicate0.model | Comparing images 3 and 4: 0.7347435500424269\n",
      "  Model: fullModel_dr[1]_replicate0.model | Comparing images 3 and 5: 1.7979260156487422\n",
      "  Model: fullModel_dr[1]_replicate0.model | Comparing images 4 and 5: 1.8109544310175485\n",
      "  Processing model: fullModel_dr[1]_replicate1.model\n",
      "  Model: fullModel_dr[1]_replicate1.model | Comparing images 1 and 2: 1.657621206653999\n",
      "  Model: fullModel_dr[1]_replicate1.model | Comparing images 1 and 3: 2.38051827189207\n",
      "  Model: fullModel_dr[1]_replicate1.model | Comparing images 1 and 4: 2.9410576740550893\n",
      "  Model: fullModel_dr[1]_replicate1.model | Comparing images 1 and 5: 2.5122854419822964\n",
      "  Model: fullModel_dr[1]_replicate1.model | Comparing images 2 and 3: 1.9276624782868244\n",
      "  Model: fullModel_dr[1]_replicate1.model | Comparing images 2 and 4: 2.4487690910654236\n",
      "  Model: fullModel_dr[1]_replicate1.model | Comparing images 2 and 5: 2.0491307522597415\n",
      "  Model: fullModel_dr[1]_replicate1.model | Comparing images 3 and 4: 2.0308363230802318\n",
      "  Model: fullModel_dr[1]_replicate1.model | Comparing images 3 and 5: 1.636126264761721\n",
      "  Model: fullModel_dr[1]_replicate1.model | Comparing images 4 and 5: 2.1743578295966928\n",
      "  Processing model: fullModel_dr[1]_replicate2.model\n",
      "  Model: fullModel_dr[1]_replicate2.model | Comparing images 1 and 2: 1.3709931944015628\n",
      "  Model: fullModel_dr[1]_replicate2.model | Comparing images 1 and 3: 1.309391802387935\n",
      "  Model: fullModel_dr[1]_replicate2.model | Comparing images 1 and 4: 1.0638794771854545\n",
      "  Model: fullModel_dr[1]_replicate2.model | Comparing images 1 and 5: 1.1457353184242989\n",
      "  Model: fullModel_dr[1]_replicate2.model | Comparing images 2 and 3: 1.1021736623825107\n",
      "  Model: fullModel_dr[1]_replicate2.model | Comparing images 2 and 4: 1.5065864242639724\n",
      "  Model: fullModel_dr[1]_replicate2.model | Comparing images 2 and 5: 1.2897554085887755\n",
      "  Model: fullModel_dr[1]_replicate2.model | Comparing images 3 and 4: 1.051334353954524\n",
      "  Model: fullModel_dr[1]_replicate2.model | Comparing images 3 and 5: 1.6458126443690548\n",
      "  Model: fullModel_dr[1]_replicate2.model | Comparing images 4 and 5: 1.4957283306108766\n",
      "  Processing model: fullModel_dr[1]_replicate3.model\n",
      "  Model: fullModel_dr[1]_replicate3.model | Comparing images 1 and 2: 1.6422954636622447\n",
      "  Model: fullModel_dr[1]_replicate3.model | Comparing images 1 and 3: 1.3291626247349067\n",
      "  Model: fullModel_dr[1]_replicate3.model | Comparing images 1 and 4: 1.771121021948455\n",
      "  Model: fullModel_dr[1]_replicate3.model | Comparing images 1 and 5: 1.344505593727792\n",
      "  Model: fullModel_dr[1]_replicate3.model | Comparing images 2 and 3: 1.5769342786421048\n",
      "  Model: fullModel_dr[1]_replicate3.model | Comparing images 2 and 4: 2.062683070644758\n",
      "  Model: fullModel_dr[1]_replicate3.model | Comparing images 2 and 5: 1.4638826206414222\n",
      "  Model: fullModel_dr[1]_replicate3.model | Comparing images 3 and 4: 1.467564430314027\n",
      "  Model: fullModel_dr[1]_replicate3.model | Comparing images 3 and 5: 1.2917500375329078\n",
      "  Model: fullModel_dr[1]_replicate3.model | Comparing images 4 and 5: 1.7174725850332677\n",
      "  Processing model: fullModel_dr[1]_replicate4.model\n",
      "  Model: fullModel_dr[1]_replicate4.model | Comparing images 1 and 2: 2.3287337093067086\n",
      "  Model: fullModel_dr[1]_replicate4.model | Comparing images 1 and 3: 2.6287387594833587\n",
      "  Model: fullModel_dr[1]_replicate4.model | Comparing images 1 and 4: 2.630473900003335\n",
      "  Model: fullModel_dr[1]_replicate4.model | Comparing images 1 and 5: 3.062692433618909\n",
      "  Model: fullModel_dr[1]_replicate4.model | Comparing images 2 and 3: 2.8347360243379405\n",
      "  Model: fullModel_dr[1]_replicate4.model | Comparing images 2 and 4: 3.14268001452711\n",
      "  Model: fullModel_dr[1]_replicate4.model | Comparing images 2 and 5: 2.9239506810018527\n",
      "  Model: fullModel_dr[1]_replicate4.model | Comparing images 3 and 4: 2.446000755883433\n",
      "  Model: fullModel_dr[1]_replicate4.model | Comparing images 3 and 5: 2.8325320561785423\n",
      "  Model: fullModel_dr[1]_replicate4.model | Comparing images 4 and 5: 2.714131411617714\n",
      "Mean Euclidean distance for delay range 1 (using linalg.norm): 1.9037308522700707\n",
      "Processing delay range: 2\n",
      "  Processing model: fullModel_dr[2]_replicate0.model\n",
      "  Model: fullModel_dr[2]_replicate0.model | Comparing images 1 and 2: 2.449952091042692\n",
      "  Model: fullModel_dr[2]_replicate0.model | Comparing images 1 and 3: 2.603642887852167\n",
      "  Model: fullModel_dr[2]_replicate0.model | Comparing images 1 and 4: 3.0317172350273984\n",
      "  Model: fullModel_dr[2]_replicate0.model | Comparing images 1 and 5: 2.960952998530085\n",
      "  Model: fullModel_dr[2]_replicate0.model | Comparing images 2 and 3: 2.897033298804157\n",
      "  Model: fullModel_dr[2]_replicate0.model | Comparing images 2 and 4: 3.117449921836697\n",
      "  Model: fullModel_dr[2]_replicate0.model | Comparing images 2 and 5: 3.3356438648634144\n",
      "  Model: fullModel_dr[2]_replicate0.model | Comparing images 3 and 4: 2.4207699820026414\n",
      "  Model: fullModel_dr[2]_replicate0.model | Comparing images 3 and 5: 2.476701553449217\n",
      "  Model: fullModel_dr[2]_replicate0.model | Comparing images 4 and 5: 2.1141872864823426\n",
      "  Processing model: fullModel_dr[2]_replicate1.model\n",
      "  Model: fullModel_dr[2]_replicate1.model | Comparing images 1 and 2: 2.7913231695227103\n",
      "  Model: fullModel_dr[2]_replicate1.model | Comparing images 1 and 3: 2.832156743938937\n",
      "  Model: fullModel_dr[2]_replicate1.model | Comparing images 1 and 4: 2.3652969185491832\n",
      "  Model: fullModel_dr[2]_replicate1.model | Comparing images 1 and 5: 2.8698669542743422\n",
      "  Model: fullModel_dr[2]_replicate1.model | Comparing images 2 and 3: 2.485085031248902\n",
      "  Model: fullModel_dr[2]_replicate1.model | Comparing images 2 and 4: 2.7700146793028018\n",
      "  Model: fullModel_dr[2]_replicate1.model | Comparing images 2 and 5: 3.060527500362504\n",
      "  Model: fullModel_dr[2]_replicate1.model | Comparing images 3 and 4: 2.47392162777484\n",
      "  Model: fullModel_dr[2]_replicate1.model | Comparing images 3 and 5: 2.2083545333400783\n",
      "  Model: fullModel_dr[2]_replicate1.model | Comparing images 4 and 5: 2.262875651618713\n",
      "  Processing model: fullModel_dr[2]_replicate2.model\n",
      "  Model: fullModel_dr[2]_replicate2.model | Comparing images 1 and 2: 2.441389095765565\n",
      "  Model: fullModel_dr[2]_replicate2.model | Comparing images 1 and 3: 2.580903519559792\n",
      "  Model: fullModel_dr[2]_replicate2.model | Comparing images 1 and 4: 2.4442254317824825\n",
      "  Model: fullModel_dr[2]_replicate2.model | Comparing images 1 and 5: 2.4121234053454055\n",
      "  Model: fullModel_dr[2]_replicate2.model | Comparing images 2 and 3: 2.1780355096039794\n",
      "  Model: fullModel_dr[2]_replicate2.model | Comparing images 2 and 4: 2.4846975430130045\n",
      "  Model: fullModel_dr[2]_replicate2.model | Comparing images 2 and 5: 2.402505172453617\n",
      "  Model: fullModel_dr[2]_replicate2.model | Comparing images 3 and 4: 2.097929566020144\n",
      "  Model: fullModel_dr[2]_replicate2.model | Comparing images 3 and 5: 1.7355045012483457\n",
      "  Model: fullModel_dr[2]_replicate2.model | Comparing images 4 and 5: 1.9762552559655402\n",
      "  Processing model: fullModel_dr[2]_replicate3.model\n",
      "  Model: fullModel_dr[2]_replicate3.model | Comparing images 1 and 2: 2.0837621586740216\n",
      "  Model: fullModel_dr[2]_replicate3.model | Comparing images 1 and 3: 2.4193902628835007\n",
      "  Model: fullModel_dr[2]_replicate3.model | Comparing images 1 and 4: 3.158106131689532\n",
      "  Model: fullModel_dr[2]_replicate3.model | Comparing images 1 and 5: 3.0297662715706255\n",
      "  Model: fullModel_dr[2]_replicate3.model | Comparing images 2 and 3: 2.034784861479582\n",
      "  Model: fullModel_dr[2]_replicate3.model | Comparing images 2 and 4: 2.489663350861346\n",
      "  Model: fullModel_dr[2]_replicate3.model | Comparing images 2 and 5: 2.9640935102164225\n",
      "  Model: fullModel_dr[2]_replicate3.model | Comparing images 3 and 4: 2.1217259074784844\n",
      "  Model: fullModel_dr[2]_replicate3.model | Comparing images 3 and 5: 2.6232562573581677\n",
      "  Model: fullModel_dr[2]_replicate3.model | Comparing images 4 and 5: 2.3605342069774395\n",
      "  Processing model: fullModel_dr[2]_replicate4.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model: fullModel_dr[2]_replicate4.model | Comparing images 1 and 2: 1.312227903017416\n",
      "  Model: fullModel_dr[2]_replicate4.model | Comparing images 1 and 3: 1.238692382445519\n",
      "  Model: fullModel_dr[2]_replicate4.model | Comparing images 1 and 4: 1.4445203773293223\n",
      "  Model: fullModel_dr[2]_replicate4.model | Comparing images 1 and 5: 1.578537789225649\n",
      "  Model: fullModel_dr[2]_replicate4.model | Comparing images 2 and 3: 1.4543500945062056\n",
      "  Model: fullModel_dr[2]_replicate4.model | Comparing images 2 and 4: 1.5348956110500946\n",
      "  Model: fullModel_dr[2]_replicate4.model | Comparing images 2 and 5: 1.6771587330098316\n",
      "  Model: fullModel_dr[2]_replicate4.model | Comparing images 3 and 4: 0.9493522376535972\n",
      "  Model: fullModel_dr[2]_replicate4.model | Comparing images 3 and 5: 1.0627747382180734\n",
      "  Model: fullModel_dr[2]_replicate4.model | Comparing images 4 and 5: 1.1657936537597802\n",
      "Mean Euclidean distance for delay range 2 (using linalg.norm): 2.299688587399726\n",
      "Processing delay range: 3\n",
      "  Processing model: fullModel_dr[3]_replicate0.model\n",
      "  Model: fullModel_dr[3]_replicate0.model | Comparing images 1 and 2: 2.770698359229991\n",
      "  Model: fullModel_dr[3]_replicate0.model | Comparing images 1 and 3: 3.2355086806209155\n",
      "  Model: fullModel_dr[3]_replicate0.model | Comparing images 1 and 4: 3.103178394390406\n",
      "  Model: fullModel_dr[3]_replicate0.model | Comparing images 1 and 5: 3.281843709399559\n",
      "  Model: fullModel_dr[3]_replicate0.model | Comparing images 2 and 3: 3.398988268327671\n",
      "  Model: fullModel_dr[3]_replicate0.model | Comparing images 2 and 4: 3.2266860600307106\n",
      "  Model: fullModel_dr[3]_replicate0.model | Comparing images 2 and 5: 3.4662798919261526\n",
      "  Model: fullModel_dr[3]_replicate0.model | Comparing images 3 and 4: 3.0301371542486275\n",
      "  Model: fullModel_dr[3]_replicate0.model | Comparing images 3 and 5: 3.0798881542399608\n",
      "  Model: fullModel_dr[3]_replicate0.model | Comparing images 4 and 5: 3.2585642591846007\n",
      "  Processing model: fullModel_dr[3]_replicate1.model\n",
      "  Model: fullModel_dr[3]_replicate1.model | Comparing images 1 and 2: 1.8723875531705434\n",
      "  Model: fullModel_dr[3]_replicate1.model | Comparing images 1 and 3: 2.5019363702646555\n",
      "  Model: fullModel_dr[3]_replicate1.model | Comparing images 1 and 4: 2.6247775837620906\n",
      "  Model: fullModel_dr[3]_replicate1.model | Comparing images 1 and 5: 2.7393085968227293\n",
      "  Model: fullModel_dr[3]_replicate1.model | Comparing images 2 and 3: 2.1396387589709702\n",
      "  Model: fullModel_dr[3]_replicate1.model | Comparing images 2 and 4: 2.33822885624089\n",
      "  Model: fullModel_dr[3]_replicate1.model | Comparing images 2 and 5: 3.250972768431764\n",
      "  Model: fullModel_dr[3]_replicate1.model | Comparing images 3 and 4: 2.644997489107272\n",
      "  Model: fullModel_dr[3]_replicate1.model | Comparing images 3 and 5: 3.158213933707076\n",
      "  Model: fullModel_dr[3]_replicate1.model | Comparing images 4 and 5: 3.157924069236271\n",
      "  Processing model: fullModel_dr[3]_replicate2.model\n",
      "  Model: fullModel_dr[3]_replicate2.model | Comparing images 1 and 2: 2.5138788777974725\n",
      "  Model: fullModel_dr[3]_replicate2.model | Comparing images 1 and 3: 2.979807443401274\n",
      "  Model: fullModel_dr[3]_replicate2.model | Comparing images 1 and 4: 3.5083174379328583\n",
      "  Model: fullModel_dr[3]_replicate2.model | Comparing images 1 and 5: 3.2038836098125443\n",
      "  Model: fullModel_dr[3]_replicate2.model | Comparing images 2 and 3: 2.6696613926348354\n",
      "  Model: fullModel_dr[3]_replicate2.model | Comparing images 2 and 4: 3.3819307959385907\n",
      "  Model: fullModel_dr[3]_replicate2.model | Comparing images 2 and 5: 3.035550932762938\n",
      "  Model: fullModel_dr[3]_replicate2.model | Comparing images 3 and 4: 2.525650809689083\n",
      "  Model: fullModel_dr[3]_replicate2.model | Comparing images 3 and 5: 2.9998830856757728\n",
      "  Model: fullModel_dr[3]_replicate2.model | Comparing images 4 and 5: 2.7503684379609563\n",
      "  Processing model: fullModel_dr[3]_replicate3.model\n",
      "  Model: fullModel_dr[3]_replicate3.model | Comparing images 1 and 2: 2.2298279596662245\n",
      "  Model: fullModel_dr[3]_replicate3.model | Comparing images 1 and 3: 2.2109446919377778\n",
      "  Model: fullModel_dr[3]_replicate3.model | Comparing images 1 and 4: 3.215297402517547\n",
      "  Model: fullModel_dr[3]_replicate3.model | Comparing images 1 and 5: 3.1179181230514126\n",
      "  Model: fullModel_dr[3]_replicate3.model | Comparing images 2 and 3: 2.3589398810854503\n",
      "  Model: fullModel_dr[3]_replicate3.model | Comparing images 2 and 4: 2.910707381650692\n",
      "  Model: fullModel_dr[3]_replicate3.model | Comparing images 2 and 5: 2.6854009032846426\n",
      "  Model: fullModel_dr[3]_replicate3.model | Comparing images 3 and 4: 2.977226614528813\n",
      "  Model: fullModel_dr[3]_replicate3.model | Comparing images 3 and 5: 2.509304112780624\n",
      "  Model: fullModel_dr[3]_replicate3.model | Comparing images 4 and 5: 2.0781104598887814\n",
      "  Processing model: fullModel_dr[3]_replicate4.model\n",
      "  Model: fullModel_dr[3]_replicate4.model | Comparing images 1 and 2: 2.207565173763\n",
      "  Model: fullModel_dr[3]_replicate4.model | Comparing images 1 and 3: 2.5439517600923183\n",
      "  Model: fullModel_dr[3]_replicate4.model | Comparing images 1 and 4: 2.6921631099909664\n",
      "  Model: fullModel_dr[3]_replicate4.model | Comparing images 1 and 5: 3.0434695178840974\n",
      "  Model: fullModel_dr[3]_replicate4.model | Comparing images 2 and 3: 2.034782077524487\n",
      "  Model: fullModel_dr[3]_replicate4.model | Comparing images 2 and 4: 2.311660362064677\n",
      "  Model: fullModel_dr[3]_replicate4.model | Comparing images 2 and 5: 2.2981667323328514\n",
      "  Model: fullModel_dr[3]_replicate4.model | Comparing images 3 and 4: 1.9864839921503321\n",
      "  Model: fullModel_dr[3]_replicate4.model | Comparing images 3 and 5: 1.5791752585187637\n",
      "  Model: fullModel_dr[3]_replicate4.model | Comparing images 4 and 5: 2.1599235411794053\n",
      "Mean Euclidean distance for delay range 3 (using linalg.norm): 2.7400022158162414\n",
      "Processing delay range: 4\n",
      "  Processing model: fullModel_dr[4]_replicate0.model\n",
      "  Model: fullModel_dr[4]_replicate0.model | Comparing images 1 and 2: 1.2165437637071137\n",
      "  Model: fullModel_dr[4]_replicate0.model | Comparing images 1 and 3: 1.2198791605402448\n",
      "  Model: fullModel_dr[4]_replicate0.model | Comparing images 1 and 4: 1.3127175555003403\n",
      "  Model: fullModel_dr[4]_replicate0.model | Comparing images 1 and 5: 1.234500535887434\n",
      "  Model: fullModel_dr[4]_replicate0.model | Comparing images 2 and 3: 0.5686481778804359\n",
      "  Model: fullModel_dr[4]_replicate0.model | Comparing images 2 and 4: 0.8613862740582434\n",
      "  Model: fullModel_dr[4]_replicate0.model | Comparing images 2 and 5: 0.825449028126431\n",
      "  Model: fullModel_dr[4]_replicate0.model | Comparing images 3 and 4: 0.8270098973329306\n",
      "  Model: fullModel_dr[4]_replicate0.model | Comparing images 3 and 5: 0.8747585809772515\n",
      "  Model: fullModel_dr[4]_replicate0.model | Comparing images 4 and 5: 0.9690407321547024\n",
      "  Processing model: fullModel_dr[4]_replicate1.model\n",
      "  Model: fullModel_dr[4]_replicate1.model | Comparing images 1 and 2: 1.9643612941007091\n",
      "  Model: fullModel_dr[4]_replicate1.model | Comparing images 1 and 3: 1.8555804755221434\n",
      "  Model: fullModel_dr[4]_replicate1.model | Comparing images 1 and 4: 2.5426325836228685\n",
      "  Model: fullModel_dr[4]_replicate1.model | Comparing images 1 and 5: 2.240158543726198\n",
      "  Model: fullModel_dr[4]_replicate1.model | Comparing images 2 and 3: 2.105264138133709\n",
      "  Model: fullModel_dr[4]_replicate1.model | Comparing images 2 and 4: 2.2469172518125755\n",
      "  Model: fullModel_dr[4]_replicate1.model | Comparing images 2 and 5: 2.0796871386476345\n",
      "  Model: fullModel_dr[4]_replicate1.model | Comparing images 3 and 4: 2.5891086486607215\n",
      "  Model: fullModel_dr[4]_replicate1.model | Comparing images 3 and 5: 2.3794289662970285\n",
      "  Model: fullModel_dr[4]_replicate1.model | Comparing images 4 and 5: 1.8791559280915158\n",
      "  Processing model: fullModel_dr[4]_replicate2.model\n",
      "  Model: fullModel_dr[4]_replicate2.model | Comparing images 1 and 2: 1.6204591917728877\n",
      "  Model: fullModel_dr[4]_replicate2.model | Comparing images 1 and 3: 1.7799220880806526\n",
      "  Model: fullModel_dr[4]_replicate2.model | Comparing images 1 and 4: 1.8149940908049353\n",
      "  Model: fullModel_dr[4]_replicate2.model | Comparing images 1 and 5: 1.8877670195963494\n",
      "  Model: fullModel_dr[4]_replicate2.model | Comparing images 2 and 3: 0.9846732487606946\n",
      "  Model: fullModel_dr[4]_replicate2.model | Comparing images 2 and 4: 1.8988227274868636\n",
      "  Model: fullModel_dr[4]_replicate2.model | Comparing images 2 and 5: 1.9083100079458717\n",
      "  Model: fullModel_dr[4]_replicate2.model | Comparing images 3 and 4: 1.8692189561310866\n",
      "  Model: fullModel_dr[4]_replicate2.model | Comparing images 3 and 5: 1.7669446261218467\n",
      "  Model: fullModel_dr[4]_replicate2.model | Comparing images 4 and 5: 1.1784800307899215\n",
      "  Processing model: fullModel_dr[4]_replicate3.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model: fullModel_dr[4]_replicate3.model | Comparing images 1 and 2: 2.1623434118555425\n",
      "  Model: fullModel_dr[4]_replicate3.model | Comparing images 1 and 3: 2.1933147124194328\n",
      "  Model: fullModel_dr[4]_replicate3.model | Comparing images 1 and 4: 2.562383770674826\n",
      "  Model: fullModel_dr[4]_replicate3.model | Comparing images 1 and 5: 2.9013526121632376\n",
      "  Model: fullModel_dr[4]_replicate3.model | Comparing images 2 and 3: 1.6449048435609583\n",
      "  Model: fullModel_dr[4]_replicate3.model | Comparing images 2 and 4: 2.3227953834603188\n",
      "  Model: fullModel_dr[4]_replicate3.model | Comparing images 2 and 5: 2.607875036546154\n",
      "  Model: fullModel_dr[4]_replicate3.model | Comparing images 3 and 4: 1.7675093046334072\n",
      "  Model: fullModel_dr[4]_replicate3.model | Comparing images 3 and 5: 2.3872076576640016\n",
      "  Model: fullModel_dr[4]_replicate3.model | Comparing images 4 and 5: 2.2427698767177815\n",
      "  Processing model: fullModel_dr[4]_replicate4.model\n",
      "  Model: fullModel_dr[4]_replicate4.model | Comparing images 1 and 2: 2.307245427713527\n",
      "  Model: fullModel_dr[4]_replicate4.model | Comparing images 1 and 3: 2.549432553579049\n",
      "  Model: fullModel_dr[4]_replicate4.model | Comparing images 1 and 4: 2.677969640437514\n",
      "  Model: fullModel_dr[4]_replicate4.model | Comparing images 1 and 5: 2.67067986581489\n",
      "  Model: fullModel_dr[4]_replicate4.model | Comparing images 2 and 3: 1.6087478195028766\n",
      "  Model: fullModel_dr[4]_replicate4.model | Comparing images 2 and 4: 2.0773237377280185\n",
      "  Model: fullModel_dr[4]_replicate4.model | Comparing images 2 and 5: 2.3469386327344983\n",
      "  Model: fullModel_dr[4]_replicate4.model | Comparing images 3 and 4: 1.247313531015417\n",
      "  Model: fullModel_dr[4]_replicate4.model | Comparing images 3 and 5: 1.6264483329265425\n",
      "  Model: fullModel_dr[4]_replicate4.model | Comparing images 4 and 5: 1.0761488813317346\n",
      "Mean Euclidean distance for delay range 4 (using linalg.norm): 1.8296505138950214\n",
      "Processing delay range: 5\n",
      "  Processing model: fullModel_dr[5]_replicate0.model\n",
      "  Model: fullModel_dr[5]_replicate0.model | Comparing images 1 and 2: 1.218107396611472\n",
      "  Model: fullModel_dr[5]_replicate0.model | Comparing images 1 and 3: 1.3644136785919367\n",
      "  Model: fullModel_dr[5]_replicate0.model | Comparing images 1 and 4: 1.3570163632376773\n",
      "  Model: fullModel_dr[5]_replicate0.model | Comparing images 1 and 5: 1.3135414490396438\n",
      "  Model: fullModel_dr[5]_replicate0.model | Comparing images 2 and 3: 1.1216843065877877\n",
      "  Model: fullModel_dr[5]_replicate0.model | Comparing images 2 and 4: 0.8313254029999061\n",
      "  Model: fullModel_dr[5]_replicate0.model | Comparing images 2 and 5: 0.9232073845269749\n",
      "  Model: fullModel_dr[5]_replicate0.model | Comparing images 3 and 4: 1.0912917818116554\n",
      "  Model: fullModel_dr[5]_replicate0.model | Comparing images 3 and 5: 1.0742678657181826\n",
      "  Model: fullModel_dr[5]_replicate0.model | Comparing images 4 and 5: 0.8125366311206442\n",
      "  Processing model: fullModel_dr[5]_replicate1.model\n",
      "  Model: fullModel_dr[5]_replicate1.model | Comparing images 1 and 2: 2.9551413695524498\n",
      "  Model: fullModel_dr[5]_replicate1.model | Comparing images 1 and 3: 3.2294240121360906\n",
      "  Model: fullModel_dr[5]_replicate1.model | Comparing images 1 and 4: 3.3083714157796735\n",
      "  Model: fullModel_dr[5]_replicate1.model | Comparing images 1 and 5: 3.5115775787249115\n",
      "  Model: fullModel_dr[5]_replicate1.model | Comparing images 2 and 3: 2.63350293109393\n",
      "  Model: fullModel_dr[5]_replicate1.model | Comparing images 2 and 4: 3.193880151372785\n",
      "  Model: fullModel_dr[5]_replicate1.model | Comparing images 2 and 5: 3.4433513880847957\n",
      "  Model: fullModel_dr[5]_replicate1.model | Comparing images 3 and 4: 2.1660869888278618\n",
      "  Model: fullModel_dr[5]_replicate1.model | Comparing images 3 and 5: 2.229246713860886\n",
      "  Model: fullModel_dr[5]_replicate1.model | Comparing images 4 and 5: 1.8541415783411943\n",
      "  Processing model: fullModel_dr[5]_replicate2.model\n",
      "  Model: fullModel_dr[5]_replicate2.model | Comparing images 1 and 2: 0.8825191403926856\n",
      "  Model: fullModel_dr[5]_replicate2.model | Comparing images 1 and 3: 2.4227167185579077\n",
      "  Model: fullModel_dr[5]_replicate2.model | Comparing images 1 and 4: 1.4489230848730452\n",
      "  Model: fullModel_dr[5]_replicate2.model | Comparing images 1 and 5: 1.4249242503301038\n",
      "  Model: fullModel_dr[5]_replicate2.model | Comparing images 2 and 3: 2.579981862154867\n",
      "  Model: fullModel_dr[5]_replicate2.model | Comparing images 2 and 4: 1.4194084808795493\n",
      "  Model: fullModel_dr[5]_replicate2.model | Comparing images 2 and 5: 1.4625241707273227\n",
      "  Model: fullModel_dr[5]_replicate2.model | Comparing images 3 and 4: 2.2692487299243678\n",
      "  Model: fullModel_dr[5]_replicate2.model | Comparing images 3 and 5: 2.1642891907332182\n",
      "  Model: fullModel_dr[5]_replicate2.model | Comparing images 4 and 5: 1.5313829557450531\n",
      "  Processing model: fullModel_dr[5]_replicate3.model\n",
      "  Model: fullModel_dr[5]_replicate3.model | Comparing images 1 and 2: 2.1255797677279693\n",
      "  Model: fullModel_dr[5]_replicate3.model | Comparing images 1 and 3: 2.293932547686302\n",
      "  Model: fullModel_dr[5]_replicate3.model | Comparing images 1 and 4: 2.1239026074018224\n",
      "  Model: fullModel_dr[5]_replicate3.model | Comparing images 1 and 5: 2.115110764506398\n",
      "  Model: fullModel_dr[5]_replicate3.model | Comparing images 2 and 3: 2.1773938012694942\n",
      "  Model: fullModel_dr[5]_replicate3.model | Comparing images 2 and 4: 2.092745513469129\n",
      "  Model: fullModel_dr[5]_replicate3.model | Comparing images 2 and 5: 1.8784481542882594\n",
      "  Model: fullModel_dr[5]_replicate3.model | Comparing images 3 and 4: 2.634474058016402\n",
      "  Model: fullModel_dr[5]_replicate3.model | Comparing images 3 and 5: 1.894766282353532\n",
      "  Model: fullModel_dr[5]_replicate3.model | Comparing images 4 and 5: 2.176029508341065\n",
      "  Processing model: fullModel_dr[5]_replicate4.model\n",
      "  Model: fullModel_dr[5]_replicate4.model | Comparing images 1 and 2: 1.3339254426791711\n",
      "  Model: fullModel_dr[5]_replicate4.model | Comparing images 1 and 3: 1.398476508452501\n",
      "  Model: fullModel_dr[5]_replicate4.model | Comparing images 1 and 4: 1.3442938103122637\n",
      "  Model: fullModel_dr[5]_replicate4.model | Comparing images 1 and 5: 1.3700738696438968\n",
      "  Model: fullModel_dr[5]_replicate4.model | Comparing images 2 and 3: 1.6038752609553306\n",
      "  Model: fullModel_dr[5]_replicate4.model | Comparing images 2 and 4: 1.646772426274569\n",
      "  Model: fullModel_dr[5]_replicate4.model | Comparing images 2 and 5: 1.5247350258062617\n",
      "  Model: fullModel_dr[5]_replicate4.model | Comparing images 3 and 4: 1.7248103933924819\n",
      "  Model: fullModel_dr[5]_replicate4.model | Comparing images 3 and 5: 1.2578386103365038\n",
      "  Model: fullModel_dr[5]_replicate4.model | Comparing images 4 and 5: 1.381872352022434\n",
      "Mean Euclidean distance for delay range 5 (using linalg.norm): 1.8667418335454875\n",
      "Mean Euclidean distances for all delay ranges (using linalg.norm): [1.9037308522700707, 2.299688587399726, 2.7400022158162414, 1.8296505138950214, 1.8667418335454875]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib.pyplot import figure, imshow, title\n",
    "\n",
    "SEED = 42  # Choose any seed value\n",
    "np.random.seed(SEED)\n",
    "\n",
    "nX, nY, nS, nW = makeNoisyDataset(X, Y, 8, 0.1)\n",
    "\n",
    "# Initialize a list to store mean Euclidean distances for all delay ranges (using linalg.norm method)\n",
    "mean_linalg_dists_per_dr = []\n",
    "\n",
    "# Loop through delay ranges\n",
    "for dr in range(1, 6):\n",
    "    print(f\"Processing delay range: {dr}\")\n",
    "\n",
    "    # Initialize a list to store Euclidean distances for the current delay range (using linalg.norm method)\n",
    "    all_linalg_dists_dr = []\n",
    "\n",
    "    # Loop through all the models in `models`\n",
    "    for key, model in models.items():\n",
    "        if f\"dr[{dr}]\" in key:  # Select models within the current delay range\n",
    "            print(f\"  Processing model: {key}\")\n",
    "\n",
    "            # Initialize a list to store the images for the current model\n",
    "            images_IDR = []\n",
    "\n",
    "            # Loop through the time steps 1 to 5\n",
    "            for ts in [1, 2, 3, 4, 5]:\n",
    "                S, H = shrinkingDecompositionInformation(model, 12, nX, nW.transpose(), whichTS=ts)\n",
    "                I = removalIntoMatrix(S, 12, H)\n",
    "                images_IDR.append(I.flatten())\n",
    "\n",
    "            # Loop through pairs of images, calculate their Euclidean distances using linalg.norm, and print the results\n",
    "            for i in range(len(images_IDR) - 1):\n",
    "                for j in range(i + 1, len(images_IDR)):\n",
    "                    linalg_dist_IDR = np.linalg.norm(images_IDR[i] - images_IDR[j])\n",
    "                    all_linalg_dists_dr.append(linalg_dist_IDR)\n",
    "                    print(f\"  Model: {key} | Comparing images {i + 1} and {j + 1}: {linalg_dist_IDR}\")\n",
    "\n",
    "    # Calculate the mean Euclidean distance for the current delay range (using linalg.norm method)\n",
    "    mean_linalg_dist_dr = np.mean(all_linalg_dists_dr)\n",
    "    mean_linalg_dists_per_dr.append(mean_linalg_dist_dr)\n",
    "    print(f\"Mean Euclidean distance for delay range {dr} (using linalg.norm): {mean_linalg_dist_dr}\")\n",
    "\n",
    "print(f\"Mean Euclidean distances for all delay ranges (using linalg.norm): {mean_linalg_dists_per_dr}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0115977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing delay range: 1\n",
      "  Processing model: fullModel_dr[1]_replicate0.model\n",
      "  Model: fullModel_dr[1]_replicate0.model | Comparing images 1 and 2: 1.61537991263154\n",
      "  Model: fullModel_dr[1]_replicate0.model | Comparing images 1 and 3: 2.0114564849397336\n",
      "  Model: fullModel_dr[1]_replicate0.model | Comparing images 1 and 4: 2.0243580683652755\n",
      "  Model: fullModel_dr[1]_replicate0.model | Comparing images 1 and 5: 1.6446822432776405\n",
      "  Model: fullModel_dr[1]_replicate0.model | Comparing images 2 and 3: 1.7330717174817885\n",
      "  Model: fullModel_dr[1]_replicate0.model | Comparing images 2 and 4: 1.7318229176159303\n",
      "  Model: fullModel_dr[1]_replicate0.model | Comparing images 2 and 5: 2.130349849439077\n",
      "  Model: fullModel_dr[1]_replicate0.model | Comparing images 3 and 4: 0.7347435500424269\n",
      "  Model: fullModel_dr[1]_replicate0.model | Comparing images 3 and 5: 1.7979260156487422\n",
      "  Model: fullModel_dr[1]_replicate0.model | Comparing images 4 and 5: 1.8109544310175485\n",
      "  Processing model: fullModel_dr[1]_replicate1.model\n",
      "  Model: fullModel_dr[1]_replicate1.model | Comparing images 1 and 2: 1.657621206653999\n",
      "  Model: fullModel_dr[1]_replicate1.model | Comparing images 1 and 3: 2.38051827189207\n",
      "  Model: fullModel_dr[1]_replicate1.model | Comparing images 1 and 4: 2.9410576740550893\n",
      "  Model: fullModel_dr[1]_replicate1.model | Comparing images 1 and 5: 2.5122854419822964\n",
      "  Model: fullModel_dr[1]_replicate1.model | Comparing images 2 and 3: 1.9276624782868244\n",
      "  Model: fullModel_dr[1]_replicate1.model | Comparing images 2 and 4: 2.4487690910654236\n",
      "  Model: fullModel_dr[1]_replicate1.model | Comparing images 2 and 5: 2.0491307522597415\n",
      "  Model: fullModel_dr[1]_replicate1.model | Comparing images 3 and 4: 2.0308363230802318\n",
      "  Model: fullModel_dr[1]_replicate1.model | Comparing images 3 and 5: 1.636126264761721\n",
      "  Model: fullModel_dr[1]_replicate1.model | Comparing images 4 and 5: 2.1743578295966928\n",
      "  Processing model: fullModel_dr[1]_replicate2.model\n",
      "  Model: fullModel_dr[1]_replicate2.model | Comparing images 1 and 2: 1.3709931944015628\n",
      "  Model: fullModel_dr[1]_replicate2.model | Comparing images 1 and 3: 1.309391802387935\n",
      "  Model: fullModel_dr[1]_replicate2.model | Comparing images 1 and 4: 1.0638794771854545\n",
      "  Model: fullModel_dr[1]_replicate2.model | Comparing images 1 and 5: 1.1457353184242989\n",
      "  Model: fullModel_dr[1]_replicate2.model | Comparing images 2 and 3: 1.1021736623825107\n",
      "  Model: fullModel_dr[1]_replicate2.model | Comparing images 2 and 4: 1.5065864242639724\n",
      "  Model: fullModel_dr[1]_replicate2.model | Comparing images 2 and 5: 1.2897554085887755\n",
      "  Model: fullModel_dr[1]_replicate2.model | Comparing images 3 and 4: 1.051334353954524\n",
      "  Model: fullModel_dr[1]_replicate2.model | Comparing images 3 and 5: 1.6458126443690548\n",
      "  Model: fullModel_dr[1]_replicate2.model | Comparing images 4 and 5: 1.4957283306108766\n",
      "  Processing model: fullModel_dr[1]_replicate3.model\n",
      "  Model: fullModel_dr[1]_replicate3.model | Comparing images 1 and 2: 1.6422954636622447\n",
      "  Model: fullModel_dr[1]_replicate3.model | Comparing images 1 and 3: 1.3291626247349067\n",
      "  Model: fullModel_dr[1]_replicate3.model | Comparing images 1 and 4: 1.771121021948455\n",
      "  Model: fullModel_dr[1]_replicate3.model | Comparing images 1 and 5: 1.344505593727792\n",
      "  Model: fullModel_dr[1]_replicate3.model | Comparing images 2 and 3: 1.5769342786421048\n",
      "  Model: fullModel_dr[1]_replicate3.model | Comparing images 2 and 4: 2.062683070644758\n",
      "  Model: fullModel_dr[1]_replicate3.model | Comparing images 2 and 5: 1.4638826206414222\n",
      "  Model: fullModel_dr[1]_replicate3.model | Comparing images 3 and 4: 1.467564430314027\n",
      "  Model: fullModel_dr[1]_replicate3.model | Comparing images 3 and 5: 1.2917500375329078\n",
      "  Model: fullModel_dr[1]_replicate3.model | Comparing images 4 and 5: 1.7174725850332677\n",
      "  Processing model: fullModel_dr[1]_replicate4.model\n",
      "  Model: fullModel_dr[1]_replicate4.model | Comparing images 1 and 2: 2.3287337093067086\n",
      "  Model: fullModel_dr[1]_replicate4.model | Comparing images 1 and 3: 2.6287387594833587\n",
      "  Model: fullModel_dr[1]_replicate4.model | Comparing images 1 and 4: 2.630473900003335\n",
      "  Model: fullModel_dr[1]_replicate4.model | Comparing images 1 and 5: 3.062692433618909\n",
      "  Model: fullModel_dr[1]_replicate4.model | Comparing images 2 and 3: 2.8347360243379405\n",
      "  Model: fullModel_dr[1]_replicate4.model | Comparing images 2 and 4: 3.14268001452711\n",
      "  Model: fullModel_dr[1]_replicate4.model | Comparing images 2 and 5: 2.9239506810018527\n",
      "  Model: fullModel_dr[1]_replicate4.model | Comparing images 3 and 4: 2.446000755883433\n",
      "  Model: fullModel_dr[1]_replicate4.model | Comparing images 3 and 5: 2.8325320561785423\n",
      "  Model: fullModel_dr[1]_replicate4.model | Comparing images 4 and 5: 2.714131411617714\n",
      "Mean Euclidean distance for delay range 1 (using custom method): 1.9037308522700707\n",
      "Processing delay range: 2\n",
      "  Processing model: fullModel_dr[2]_replicate0.model\n",
      "  Model: fullModel_dr[2]_replicate0.model | Comparing images 1 and 2: 2.449952091042692\n",
      "  Model: fullModel_dr[2]_replicate0.model | Comparing images 1 and 3: 2.603642887852167\n",
      "  Model: fullModel_dr[2]_replicate0.model | Comparing images 1 and 4: 3.0317172350273984\n",
      "  Model: fullModel_dr[2]_replicate0.model | Comparing images 1 and 5: 2.960952998530085\n",
      "  Model: fullModel_dr[2]_replicate0.model | Comparing images 2 and 3: 2.897033298804157\n",
      "  Model: fullModel_dr[2]_replicate0.model | Comparing images 2 and 4: 3.117449921836697\n",
      "  Model: fullModel_dr[2]_replicate0.model | Comparing images 2 and 5: 3.3356438648634144\n",
      "  Model: fullModel_dr[2]_replicate0.model | Comparing images 3 and 4: 2.4207699820026414\n",
      "  Model: fullModel_dr[2]_replicate0.model | Comparing images 3 and 5: 2.476701553449217\n",
      "  Model: fullModel_dr[2]_replicate0.model | Comparing images 4 and 5: 2.1141872864823426\n",
      "  Processing model: fullModel_dr[2]_replicate1.model\n",
      "  Model: fullModel_dr[2]_replicate1.model | Comparing images 1 and 2: 2.7913231695227103\n",
      "  Model: fullModel_dr[2]_replicate1.model | Comparing images 1 and 3: 2.832156743938937\n",
      "  Model: fullModel_dr[2]_replicate1.model | Comparing images 1 and 4: 2.3652969185491832\n",
      "  Model: fullModel_dr[2]_replicate1.model | Comparing images 1 and 5: 2.8698669542743422\n",
      "  Model: fullModel_dr[2]_replicate1.model | Comparing images 2 and 3: 2.485085031248902\n",
      "  Model: fullModel_dr[2]_replicate1.model | Comparing images 2 and 4: 2.7700146793028018\n",
      "  Model: fullModel_dr[2]_replicate1.model | Comparing images 2 and 5: 3.060527500362504\n",
      "  Model: fullModel_dr[2]_replicate1.model | Comparing images 3 and 4: 2.47392162777484\n",
      "  Model: fullModel_dr[2]_replicate1.model | Comparing images 3 and 5: 2.2083545333400783\n",
      "  Model: fullModel_dr[2]_replicate1.model | Comparing images 4 and 5: 2.262875651618713\n",
      "  Processing model: fullModel_dr[2]_replicate2.model\n",
      "  Model: fullModel_dr[2]_replicate2.model | Comparing images 1 and 2: 2.441389095765565\n",
      "  Model: fullModel_dr[2]_replicate2.model | Comparing images 1 and 3: 2.580903519559792\n",
      "  Model: fullModel_dr[2]_replicate2.model | Comparing images 1 and 4: 2.4442254317824825\n",
      "  Model: fullModel_dr[2]_replicate2.model | Comparing images 1 and 5: 2.4121234053454055\n",
      "  Model: fullModel_dr[2]_replicate2.model | Comparing images 2 and 3: 2.1780355096039794\n",
      "  Model: fullModel_dr[2]_replicate2.model | Comparing images 2 and 4: 2.4846975430130045\n",
      "  Model: fullModel_dr[2]_replicate2.model | Comparing images 2 and 5: 2.402505172453617\n",
      "  Model: fullModel_dr[2]_replicate2.model | Comparing images 3 and 4: 2.097929566020144\n",
      "  Model: fullModel_dr[2]_replicate2.model | Comparing images 3 and 5: 1.7355045012483457\n",
      "  Model: fullModel_dr[2]_replicate2.model | Comparing images 4 and 5: 1.9762552559655402\n",
      "  Processing model: fullModel_dr[2]_replicate3.model\n",
      "  Model: fullModel_dr[2]_replicate3.model | Comparing images 1 and 2: 2.0837621586740216\n",
      "  Model: fullModel_dr[2]_replicate3.model | Comparing images 1 and 3: 2.4193902628835007\n",
      "  Model: fullModel_dr[2]_replicate3.model | Comparing images 1 and 4: 3.158106131689532\n",
      "  Model: fullModel_dr[2]_replicate3.model | Comparing images 1 and 5: 3.0297662715706255\n",
      "  Model: fullModel_dr[2]_replicate3.model | Comparing images 2 and 3: 2.034784861479582\n",
      "  Model: fullModel_dr[2]_replicate3.model | Comparing images 2 and 4: 2.489663350861346\n",
      "  Model: fullModel_dr[2]_replicate3.model | Comparing images 2 and 5: 2.9640935102164225\n",
      "  Model: fullModel_dr[2]_replicate3.model | Comparing images 3 and 4: 2.1217259074784844\n",
      "  Model: fullModel_dr[2]_replicate3.model | Comparing images 3 and 5: 2.6232562573581677\n",
      "  Model: fullModel_dr[2]_replicate3.model | Comparing images 4 and 5: 2.3605342069774395\n",
      "  Processing model: fullModel_dr[2]_replicate4.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model: fullModel_dr[2]_replicate4.model | Comparing images 1 and 2: 1.312227903017416\n",
      "  Model: fullModel_dr[2]_replicate4.model | Comparing images 1 and 3: 1.238692382445519\n",
      "  Model: fullModel_dr[2]_replicate4.model | Comparing images 1 and 4: 1.4445203773293223\n",
      "  Model: fullModel_dr[2]_replicate4.model | Comparing images 1 and 5: 1.578537789225649\n",
      "  Model: fullModel_dr[2]_replicate4.model | Comparing images 2 and 3: 1.4543500945062056\n",
      "  Model: fullModel_dr[2]_replicate4.model | Comparing images 2 and 4: 1.5348956110500946\n",
      "  Model: fullModel_dr[2]_replicate4.model | Comparing images 2 and 5: 1.6771587330098316\n",
      "  Model: fullModel_dr[2]_replicate4.model | Comparing images 3 and 4: 0.9493522376535972\n",
      "  Model: fullModel_dr[2]_replicate4.model | Comparing images 3 and 5: 1.0627747382180734\n",
      "  Model: fullModel_dr[2]_replicate4.model | Comparing images 4 and 5: 1.1657936537597802\n",
      "Mean Euclidean distance for delay range 2 (using custom method): 2.299688587399726\n",
      "Processing delay range: 3\n",
      "  Processing model: fullModel_dr[3]_replicate0.model\n",
      "  Model: fullModel_dr[3]_replicate0.model | Comparing images 1 and 2: 2.770698359229991\n",
      "  Model: fullModel_dr[3]_replicate0.model | Comparing images 1 and 3: 3.2355086806209155\n",
      "  Model: fullModel_dr[3]_replicate0.model | Comparing images 1 and 4: 3.103178394390406\n",
      "  Model: fullModel_dr[3]_replicate0.model | Comparing images 1 and 5: 3.281843709399559\n",
      "  Model: fullModel_dr[3]_replicate0.model | Comparing images 2 and 3: 3.398988268327671\n",
      "  Model: fullModel_dr[3]_replicate0.model | Comparing images 2 and 4: 3.2266860600307106\n",
      "  Model: fullModel_dr[3]_replicate0.model | Comparing images 2 and 5: 3.4662798919261526\n",
      "  Model: fullModel_dr[3]_replicate0.model | Comparing images 3 and 4: 3.0301371542486275\n",
      "  Model: fullModel_dr[3]_replicate0.model | Comparing images 3 and 5: 3.0798881542399608\n",
      "  Model: fullModel_dr[3]_replicate0.model | Comparing images 4 and 5: 3.2585642591846007\n",
      "  Processing model: fullModel_dr[3]_replicate1.model\n",
      "  Model: fullModel_dr[3]_replicate1.model | Comparing images 1 and 2: 1.8723875531705434\n",
      "  Model: fullModel_dr[3]_replicate1.model | Comparing images 1 and 3: 2.5019363702646555\n",
      "  Model: fullModel_dr[3]_replicate1.model | Comparing images 1 and 4: 2.6247775837620906\n",
      "  Model: fullModel_dr[3]_replicate1.model | Comparing images 1 and 5: 2.7393085968227293\n",
      "  Model: fullModel_dr[3]_replicate1.model | Comparing images 2 and 3: 2.1396387589709702\n",
      "  Model: fullModel_dr[3]_replicate1.model | Comparing images 2 and 4: 2.33822885624089\n",
      "  Model: fullModel_dr[3]_replicate1.model | Comparing images 2 and 5: 3.250972768431764\n",
      "  Model: fullModel_dr[3]_replicate1.model | Comparing images 3 and 4: 2.644997489107272\n",
      "  Model: fullModel_dr[3]_replicate1.model | Comparing images 3 and 5: 3.158213933707076\n",
      "  Model: fullModel_dr[3]_replicate1.model | Comparing images 4 and 5: 3.157924069236271\n",
      "  Processing model: fullModel_dr[3]_replicate2.model\n",
      "  Model: fullModel_dr[3]_replicate2.model | Comparing images 1 and 2: 2.5138788777974725\n",
      "  Model: fullModel_dr[3]_replicate2.model | Comparing images 1 and 3: 2.979807443401274\n",
      "  Model: fullModel_dr[3]_replicate2.model | Comparing images 1 and 4: 3.5083174379328583\n",
      "  Model: fullModel_dr[3]_replicate2.model | Comparing images 1 and 5: 3.2038836098125443\n",
      "  Model: fullModel_dr[3]_replicate2.model | Comparing images 2 and 3: 2.6696613926348354\n",
      "  Model: fullModel_dr[3]_replicate2.model | Comparing images 2 and 4: 3.3819307959385907\n",
      "  Model: fullModel_dr[3]_replicate2.model | Comparing images 2 and 5: 3.035550932762938\n",
      "  Model: fullModel_dr[3]_replicate2.model | Comparing images 3 and 4: 2.525650809689083\n",
      "  Model: fullModel_dr[3]_replicate2.model | Comparing images 3 and 5: 2.9998830856757728\n",
      "  Model: fullModel_dr[3]_replicate2.model | Comparing images 4 and 5: 2.7503684379609563\n",
      "  Processing model: fullModel_dr[3]_replicate3.model\n",
      "  Model: fullModel_dr[3]_replicate3.model | Comparing images 1 and 2: 2.2298279596662245\n",
      "  Model: fullModel_dr[3]_replicate3.model | Comparing images 1 and 3: 2.2109446919377778\n",
      "  Model: fullModel_dr[3]_replicate3.model | Comparing images 1 and 4: 3.215297402517547\n",
      "  Model: fullModel_dr[3]_replicate3.model | Comparing images 1 and 5: 3.1179181230514126\n",
      "  Model: fullModel_dr[3]_replicate3.model | Comparing images 2 and 3: 2.3589398810854503\n",
      "  Model: fullModel_dr[3]_replicate3.model | Comparing images 2 and 4: 2.910707381650692\n",
      "  Model: fullModel_dr[3]_replicate3.model | Comparing images 2 and 5: 2.6854009032846426\n",
      "  Model: fullModel_dr[3]_replicate3.model | Comparing images 3 and 4: 2.977226614528813\n",
      "  Model: fullModel_dr[3]_replicate3.model | Comparing images 3 and 5: 2.509304112780624\n",
      "  Model: fullModel_dr[3]_replicate3.model | Comparing images 4 and 5: 2.0781104598887814\n",
      "  Processing model: fullModel_dr[3]_replicate4.model\n",
      "  Model: fullModel_dr[3]_replicate4.model | Comparing images 1 and 2: 2.207565173763\n",
      "  Model: fullModel_dr[3]_replicate4.model | Comparing images 1 and 3: 2.5439517600923183\n",
      "  Model: fullModel_dr[3]_replicate4.model | Comparing images 1 and 4: 2.6921631099909664\n",
      "  Model: fullModel_dr[3]_replicate4.model | Comparing images 1 and 5: 3.0434695178840974\n",
      "  Model: fullModel_dr[3]_replicate4.model | Comparing images 2 and 3: 2.034782077524487\n",
      "  Model: fullModel_dr[3]_replicate4.model | Comparing images 2 and 4: 2.311660362064677\n",
      "  Model: fullModel_dr[3]_replicate4.model | Comparing images 2 and 5: 2.2981667323328514\n",
      "  Model: fullModel_dr[3]_replicate4.model | Comparing images 3 and 4: 1.9864839921503321\n",
      "  Model: fullModel_dr[3]_replicate4.model | Comparing images 3 and 5: 1.5791752585187637\n",
      "  Model: fullModel_dr[3]_replicate4.model | Comparing images 4 and 5: 2.1599235411794053\n",
      "Mean Euclidean distance for delay range 3 (using custom method): 2.7400022158162414\n",
      "Processing delay range: 4\n",
      "  Processing model: fullModel_dr[4]_replicate0.model\n",
      "  Model: fullModel_dr[4]_replicate0.model | Comparing images 1 and 2: 1.2165437637071137\n",
      "  Model: fullModel_dr[4]_replicate0.model | Comparing images 1 and 3: 1.2198791605402448\n",
      "  Model: fullModel_dr[4]_replicate0.model | Comparing images 1 and 4: 1.3127175555003403\n",
      "  Model: fullModel_dr[4]_replicate0.model | Comparing images 1 and 5: 1.234500535887434\n",
      "  Model: fullModel_dr[4]_replicate0.model | Comparing images 2 and 3: 0.5686481778804359\n",
      "  Model: fullModel_dr[4]_replicate0.model | Comparing images 2 and 4: 0.8613862740582434\n",
      "  Model: fullModel_dr[4]_replicate0.model | Comparing images 2 and 5: 0.825449028126431\n",
      "  Model: fullModel_dr[4]_replicate0.model | Comparing images 3 and 4: 0.8270098973329306\n",
      "  Model: fullModel_dr[4]_replicate0.model | Comparing images 3 and 5: 0.8747585809772515\n",
      "  Model: fullModel_dr[4]_replicate0.model | Comparing images 4 and 5: 0.9690407321547024\n",
      "  Processing model: fullModel_dr[4]_replicate1.model\n",
      "  Model: fullModel_dr[4]_replicate1.model | Comparing images 1 and 2: 1.9643612941007091\n",
      "  Model: fullModel_dr[4]_replicate1.model | Comparing images 1 and 3: 1.8555804755221434\n",
      "  Model: fullModel_dr[4]_replicate1.model | Comparing images 1 and 4: 2.5426325836228685\n",
      "  Model: fullModel_dr[4]_replicate1.model | Comparing images 1 and 5: 2.240158543726198\n",
      "  Model: fullModel_dr[4]_replicate1.model | Comparing images 2 and 3: 2.105264138133709\n",
      "  Model: fullModel_dr[4]_replicate1.model | Comparing images 2 and 4: 2.2469172518125755\n",
      "  Model: fullModel_dr[4]_replicate1.model | Comparing images 2 and 5: 2.0796871386476345\n",
      "  Model: fullModel_dr[4]_replicate1.model | Comparing images 3 and 4: 2.5891086486607215\n",
      "  Model: fullModel_dr[4]_replicate1.model | Comparing images 3 and 5: 2.3794289662970285\n",
      "  Model: fullModel_dr[4]_replicate1.model | Comparing images 4 and 5: 1.8791559280915158\n",
      "  Processing model: fullModel_dr[4]_replicate2.model\n",
      "  Model: fullModel_dr[4]_replicate2.model | Comparing images 1 and 2: 1.6204591917728877\n",
      "  Model: fullModel_dr[4]_replicate2.model | Comparing images 1 and 3: 1.7799220880806526\n",
      "  Model: fullModel_dr[4]_replicate2.model | Comparing images 1 and 4: 1.8149940908049353\n",
      "  Model: fullModel_dr[4]_replicate2.model | Comparing images 1 and 5: 1.8877670195963494\n",
      "  Model: fullModel_dr[4]_replicate2.model | Comparing images 2 and 3: 0.9846732487606946\n",
      "  Model: fullModel_dr[4]_replicate2.model | Comparing images 2 and 4: 1.8988227274868636\n",
      "  Model: fullModel_dr[4]_replicate2.model | Comparing images 2 and 5: 1.9083100079458717\n",
      "  Model: fullModel_dr[4]_replicate2.model | Comparing images 3 and 4: 1.8692189561310866\n",
      "  Model: fullModel_dr[4]_replicate2.model | Comparing images 3 and 5: 1.7669446261218467\n",
      "  Model: fullModel_dr[4]_replicate2.model | Comparing images 4 and 5: 1.1784800307899215\n",
      "  Processing model: fullModel_dr[4]_replicate3.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model: fullModel_dr[4]_replicate3.model | Comparing images 1 and 2: 2.1623434118555425\n",
      "  Model: fullModel_dr[4]_replicate3.model | Comparing images 1 and 3: 2.1933147124194328\n",
      "  Model: fullModel_dr[4]_replicate3.model | Comparing images 1 and 4: 2.562383770674826\n",
      "  Model: fullModel_dr[4]_replicate3.model | Comparing images 1 and 5: 2.9013526121632376\n",
      "  Model: fullModel_dr[4]_replicate3.model | Comparing images 2 and 3: 1.6449048435609583\n",
      "  Model: fullModel_dr[4]_replicate3.model | Comparing images 2 and 4: 2.3227953834603188\n",
      "  Model: fullModel_dr[4]_replicate3.model | Comparing images 2 and 5: 2.607875036546154\n",
      "  Model: fullModel_dr[4]_replicate3.model | Comparing images 3 and 4: 1.7675093046334072\n",
      "  Model: fullModel_dr[4]_replicate3.model | Comparing images 3 and 5: 2.3872076576640016\n",
      "  Model: fullModel_dr[4]_replicate3.model | Comparing images 4 and 5: 2.2427698767177815\n",
      "  Processing model: fullModel_dr[4]_replicate4.model\n",
      "  Model: fullModel_dr[4]_replicate4.model | Comparing images 1 and 2: 2.307245427713527\n",
      "  Model: fullModel_dr[4]_replicate4.model | Comparing images 1 and 3: 2.549432553579049\n",
      "  Model: fullModel_dr[4]_replicate4.model | Comparing images 1 and 4: 2.677969640437514\n",
      "  Model: fullModel_dr[4]_replicate4.model | Comparing images 1 and 5: 2.67067986581489\n",
      "  Model: fullModel_dr[4]_replicate4.model | Comparing images 2 and 3: 1.6087478195028766\n",
      "  Model: fullModel_dr[4]_replicate4.model | Comparing images 2 and 4: 2.0773237377280185\n",
      "  Model: fullModel_dr[4]_replicate4.model | Comparing images 2 and 5: 2.3469386327344983\n",
      "  Model: fullModel_dr[4]_replicate4.model | Comparing images 3 and 4: 1.247313531015417\n",
      "  Model: fullModel_dr[4]_replicate4.model | Comparing images 3 and 5: 1.6264483329265425\n",
      "  Model: fullModel_dr[4]_replicate4.model | Comparing images 4 and 5: 1.0761488813317346\n",
      "Mean Euclidean distance for delay range 4 (using custom method): 1.8296505138950214\n",
      "Processing delay range: 5\n",
      "  Processing model: fullModel_dr[5]_replicate0.model\n",
      "  Model: fullModel_dr[5]_replicate0.model | Comparing images 1 and 2: 1.218107396611472\n",
      "  Model: fullModel_dr[5]_replicate0.model | Comparing images 1 and 3: 1.3644136785919367\n",
      "  Model: fullModel_dr[5]_replicate0.model | Comparing images 1 and 4: 1.3570163632376773\n",
      "  Model: fullModel_dr[5]_replicate0.model | Comparing images 1 and 5: 1.3135414490396438\n",
      "  Model: fullModel_dr[5]_replicate0.model | Comparing images 2 and 3: 1.1216843065877877\n",
      "  Model: fullModel_dr[5]_replicate0.model | Comparing images 2 and 4: 0.8313254029999061\n",
      "  Model: fullModel_dr[5]_replicate0.model | Comparing images 2 and 5: 0.9232073845269749\n",
      "  Model: fullModel_dr[5]_replicate0.model | Comparing images 3 and 4: 1.0912917818116554\n",
      "  Model: fullModel_dr[5]_replicate0.model | Comparing images 3 and 5: 1.0742678657181826\n",
      "  Model: fullModel_dr[5]_replicate0.model | Comparing images 4 and 5: 0.8125366311206442\n",
      "  Processing model: fullModel_dr[5]_replicate1.model\n",
      "  Model: fullModel_dr[5]_replicate1.model | Comparing images 1 and 2: 2.9551413695524498\n",
      "  Model: fullModel_dr[5]_replicate1.model | Comparing images 1 and 3: 3.2294240121360906\n",
      "  Model: fullModel_dr[5]_replicate1.model | Comparing images 1 and 4: 3.3083714157796735\n",
      "  Model: fullModel_dr[5]_replicate1.model | Comparing images 1 and 5: 3.5115775787249115\n",
      "  Model: fullModel_dr[5]_replicate1.model | Comparing images 2 and 3: 2.63350293109393\n",
      "  Model: fullModel_dr[5]_replicate1.model | Comparing images 2 and 4: 3.193880151372785\n",
      "  Model: fullModel_dr[5]_replicate1.model | Comparing images 2 and 5: 3.4433513880847957\n",
      "  Model: fullModel_dr[5]_replicate1.model | Comparing images 3 and 4: 2.1660869888278618\n",
      "  Model: fullModel_dr[5]_replicate1.model | Comparing images 3 and 5: 2.229246713860886\n",
      "  Model: fullModel_dr[5]_replicate1.model | Comparing images 4 and 5: 1.8541415783411943\n",
      "  Processing model: fullModel_dr[5]_replicate2.model\n",
      "  Model: fullModel_dr[5]_replicate2.model | Comparing images 1 and 2: 0.8825191403926856\n",
      "  Model: fullModel_dr[5]_replicate2.model | Comparing images 1 and 3: 2.4227167185579077\n",
      "  Model: fullModel_dr[5]_replicate2.model | Comparing images 1 and 4: 1.4489230848730452\n",
      "  Model: fullModel_dr[5]_replicate2.model | Comparing images 1 and 5: 1.4249242503301038\n",
      "  Model: fullModel_dr[5]_replicate2.model | Comparing images 2 and 3: 2.579981862154867\n",
      "  Model: fullModel_dr[5]_replicate2.model | Comparing images 2 and 4: 1.4194084808795493\n",
      "  Model: fullModel_dr[5]_replicate2.model | Comparing images 2 and 5: 1.4625241707273227\n",
      "  Model: fullModel_dr[5]_replicate2.model | Comparing images 3 and 4: 2.2692487299243678\n",
      "  Model: fullModel_dr[5]_replicate2.model | Comparing images 3 and 5: 2.1642891907332182\n",
      "  Model: fullModel_dr[5]_replicate2.model | Comparing images 4 and 5: 1.5313829557450531\n",
      "  Processing model: fullModel_dr[5]_replicate3.model\n",
      "  Model: fullModel_dr[5]_replicate3.model | Comparing images 1 and 2: 2.1255797677279693\n",
      "  Model: fullModel_dr[5]_replicate3.model | Comparing images 1 and 3: 2.293932547686302\n",
      "  Model: fullModel_dr[5]_replicate3.model | Comparing images 1 and 4: 2.1239026074018224\n",
      "  Model: fullModel_dr[5]_replicate3.model | Comparing images 1 and 5: 2.115110764506398\n",
      "  Model: fullModel_dr[5]_replicate3.model | Comparing images 2 and 3: 2.1773938012694942\n",
      "  Model: fullModel_dr[5]_replicate3.model | Comparing images 2 and 4: 2.092745513469129\n",
      "  Model: fullModel_dr[5]_replicate3.model | Comparing images 2 and 5: 1.8784481542882594\n",
      "  Model: fullModel_dr[5]_replicate3.model | Comparing images 3 and 4: 2.634474058016402\n",
      "  Model: fullModel_dr[5]_replicate3.model | Comparing images 3 and 5: 1.894766282353532\n",
      "  Model: fullModel_dr[5]_replicate3.model | Comparing images 4 and 5: 2.176029508341065\n",
      "  Processing model: fullModel_dr[5]_replicate4.model\n",
      "  Model: fullModel_dr[5]_replicate4.model | Comparing images 1 and 2: 1.3339254426791711\n",
      "  Model: fullModel_dr[5]_replicate4.model | Comparing images 1 and 3: 1.398476508452501\n",
      "  Model: fullModel_dr[5]_replicate4.model | Comparing images 1 and 4: 1.3442938103122637\n",
      "  Model: fullModel_dr[5]_replicate4.model | Comparing images 1 and 5: 1.3700738696438968\n",
      "  Model: fullModel_dr[5]_replicate4.model | Comparing images 2 and 3: 1.6038752609553306\n",
      "  Model: fullModel_dr[5]_replicate4.model | Comparing images 2 and 4: 1.646772426274569\n",
      "  Model: fullModel_dr[5]_replicate4.model | Comparing images 2 and 5: 1.5247350258062617\n",
      "  Model: fullModel_dr[5]_replicate4.model | Comparing images 3 and 4: 1.7248103933924819\n",
      "  Model: fullModel_dr[5]_replicate4.model | Comparing images 3 and 5: 1.2578386103365038\n",
      "  Model: fullModel_dr[5]_replicate4.model | Comparing images 4 and 5: 1.381872352022434\n",
      "Mean Euclidean distance for delay range 5 (using custom method): 1.8667418335454875\n",
      "Mean Euclidean distances for all delay ranges (using custom method): [1.9037308522700707, 2.299688587399726, 2.7400022158162414, 1.8296505138950214, 1.8667418335454875]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib.pyplot import figure, imshow, title\n",
    "\n",
    "SEED = 42  # Choose any seed value\n",
    "np.random.seed(SEED)\n",
    "\n",
    "nX, nY, nS, nW = makeNoisyDataset(X, Y, 8, 0.1)\n",
    "\n",
    "# Initialize a list to store mean Euclidean distances for all delay ranges (using custom method)\n",
    "mean_custom_dists_per_dr = []\n",
    "\n",
    "# Loop through delay ranges\n",
    "for dr in range(1, 6):\n",
    "    print(f\"Processing delay range: {dr}\")\n",
    "\n",
    "    # Initialize a list to store Euclidean distances for the current delay range (using custom method)\n",
    "    all_custom_dists_dr = []\n",
    "\n",
    "    # Loop through all the models in `models`\n",
    "    for key, model in models.items():\n",
    "        if f\"dr[{dr}]\" in key:  # Select models within the current delay range\n",
    "            print(f\"  Processing model: {key}\")\n",
    "\n",
    "            # Initialize a list to store the images for the current model\n",
    "            images_IDR = []\n",
    "\n",
    "            # Loop through the time steps 1 to 5\n",
    "            for ts in [1, 2, 3, 4, 5]:\n",
    "                S, H = shrinkingDecompositionInformation(model, 12, nX, nW.transpose(), whichTS=ts)\n",
    "                I = removalIntoMatrix(S, 12, H)\n",
    "                images_IDR.append(I.flatten())\n",
    "\n",
    "            # Loop through pairs of images, calculate their Euclidean distances using custom method, and print the results\n",
    "            for i in range(len(images_IDR) - 1):\n",
    "                for j in range(i + 1, len(images_IDR)):\n",
    "                    diff = images_IDR[i] - images_IDR[j]\n",
    "                    dot_product = np.dot(diff, diff.T)\n",
    "                    custom_dist_IDR = np.sqrt(dot_product)\n",
    "                    all_custom_dists_dr.append(custom_dist_IDR)\n",
    "                    print(f\"  Model: {key} | Comparing images {i + 1} and {j + 1}: {custom_dist_IDR}\")\n",
    "\n",
    "    # Calculate the mean Euclidean distance for the current delay range (using custom method)\n",
    "    mean_custom_dist_dr = np.mean(all_custom_dists_dr)\n",
    "    mean_custom_dists_per_dr.append(mean_custom_dist_dr)\n",
    "    print(f\"Mean Euclidean distance for delay range {dr} (using custom method): {mean_custom_dist_dr}\")\n",
    "\n",
    "print(f\"Mean Euclidean distances for all delay ranges (using custom method): {mean_custom_dists_per_dr}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fff3472",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
